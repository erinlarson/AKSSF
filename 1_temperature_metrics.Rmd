---
title: "1_temperature_metrics"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(ggfortify)
library(lubridate)
library(readxl)
```

# Read in final dataset

Read in new daily dataset that has daily min and max from UW data - received from Jackie and QAed in SWSHP repo. Note that this won't exactly match the sites and dates in the DFA analysis. There we some sites and years Jackie didn't have data for, some dates got removed so summer data may not be complete, and there were also some missing min and max for USGS sites.

* remove nps newhalen for 2015, obvious air temperatures when compared to other years.

```{r}
tr_dat <- readRDS("data_preparation/final_data/daily_dat_forTR_2022-02-08.rds") %>% 
  mutate(Year = year(sampleDate))

md <- readRDS("data_preparation/final_data/md_2022-02-08.rds")

md %>% 
  distinct(HUC8, Name) %>% 
  arrange(HUC8)

tr_dat <- tr_dat %>% 
  filter(!(SiteID == "NPS_Newhalen_River" & year(sampleDate) == 2015))

```


# Calculate temperature metrics

This takes a long time to run. Saved as an rds to the output folder. Currently, the metrics files is based off of daily means only because missing max and min for UW. Emailed Tim to see if he has the raw data handy and could provide daily max, min, and mean (11/15/21).

```{r calculate metrics, eval = FALSE}

source("temp_metrics_fcn_akssf_2021.R")

sites_complete_summers <- tr_dat %>%
  filter(month(sampleDate) %in% 6:8) %>% 
  group_by(SiteID, Year) %>% 
  mutate(percent_complete = sum(month(sampleDate) %in% 6:8)/92) %>%
  filter(percent_complete >= 0.8)

nrow(tr_dat %>% distinct(SiteID, Year)) - nrow(sites_complete_summers %>% distinct(SiteID, Year))

tr_dat %>%
  filter(month(sampleDate) %in% 6:8) %>% 
  group_by(SiteID, Year) %>% 
  mutate(percent_complete = sum(month(sampleDate) %in% 6:8)/92) %>%
  filter(percent_complete < 0.8) %>% 
  distinct(SiteID, Year) %>% #441 site years
  ungroup() %>% 
  group_by(SiteID) %>% 
  summarize(yrs_missing = paste(Year, collapse = ", "))

#note warming is because the function evaluates the RHS of a case_when even though not true
metrics <- sites_complete_summers %>% 
  tempmetrics(.)


```


Add in the regions and thermal sensitivity from the model data frame.
Add in the filter that removes most of the Deshka sites so they don't overwhelm the summaries.

```{r add regions and ts}
# metrics <- read_rds("output/metrics_2021-11-15.rds")

mod_dat <- readRDS("data_preparation/final_data/model_data2022-02-24.rds") #saved from combining response and covariates in 2c.

left_join(metrics, mod_dat %>% select(SiteID, Year, TempSens, Region)) %>% 
  filter(is.na(TempSens)) %>% 
  count(Year) #mostly before 2011 or 2020, also quite a few from removing deshka sites in 2017-2019


metrics2 <- left_join(metrics, 
                      mod_dat %>% select(SiteID, Year, TempSens, Region)) %>% 
  left_join(md %>% select(SiteID = Site, subset1, deshka))


```
Save metrics data frame with the regions and subset1 on there.

```{r save metrics}

saveRDS(metrics2, paste("output/metrics_", Sys.Date(), ".rds", sep = ""))


```




# Review outliers for bad data

Convert the metrics long form so can add a group name.

```{r add metric group name}
mets_lg <- metrics2 %>% 
  pivot_longer(cols = MA7d_DAT:TempSens, names_to = "metric", values_to = "value") %>% 
  mutate(group = case_when(grepl("SIGMA|MxDIFF|SD|CV|RANGE", metric) ~ "Variability",
                           grepl("dur", metric) ~ "Duration",
                           grepl("SUM", metric) ~ "Frequency",
                           grepl("jd", metric) ~ "Timing",
                           metric == "TempSens" ~ "Sensitivity",
                           TRUE ~ "Magnitude")) 

```

Pairplots of different metrics by group. Good way to see outliers and correlations.

```{r}
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- abs(cor(x, y, use = "complete.obs"))
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
    text(0.5, 0.5, txt, cex = cex.cor * r)
}

panel.hist <- function(x, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(usr[1:2], 0, 1.5) )
    h <- hist(x, plot = FALSE)
    breaks <- h$breaks; nB <- length(breaks)
    y <- h$counts; y <- y/max(y)
    rect(breaks[-nB], 0, breaks[-1], y, col = "cyan", ...)
}

mets_lg %>% 
  filter(group %in% c("Magnitude", "Timing"))  %>%
  select(-group) %>% 
  pivot_wider(names_from = metric, values_from = value) %>%
  select(MA7d_DAT:Jun) %>% 
  pairs(upper.panel = panel.cor, diag.panel = panel.hist)

mets_lg %>% 
  filter(group == "Variability")  %>%
  pivot_wider(names_from = metric, values_from = value) %>%
  select(MxDIFF:RANGE_MN) %>% 
  pairs(upper.panel = panel.cor)

mets_lg %>% 
  filter(group %in% c("Frequency", "Duration"))  %>%
  select(-group) %>% 
  pivot_wider(names_from = metric, values_from = value) %>%
  select(SUM_13_DMT:dur20ct) %>% 
  pairs(upper.panel = panel.cor, diag.panel = panel.hist)
  
```

Check some of the sites with large maximum daily range and large variance.

* 2018 for Little Martin River seems suspicious, possibly buried for most of the summer.
* 2015 for silver salmon creek, suspiciously warm (24) max temp in early june about 5 days earlier than any of the other bb sites. But, there are many sites with 2015 data that were warm in early June, had a cold period, and got warm again. This site drains a lot of wetlands and lakes so hard to say. 


```{r variance of dmt outliers}
mets_lg %>% 
  filter(metric == "SIGMA_DMT") %>% 
  arrange(desc(value))

#2013 is outlier for variance of daily max, but looks to be a year that started really cold and got warm.
# this matches pattern in UW dataset, 2013 big snow year, but one of warmest years for stream temp in their dataset.
sites_complete_summers %>% 
  filter(SiteID  == "USFS_Solf Lake Fish Pass") %>% 
  ggplot() +
  geom_line(aes(x = sampleDate, y= maxDT), color = "red") +
  geom_line(aes(x = sampleDate, y= minDT), color = "blue") +
  geom_line(aes(x = sampleDate, y= meanDT)) +
  facet_wrap(~Year, scales = "free_x")

#2018 was outlier. Hard to say, could have been buried coming into 2018 and also 2012. 2012 was a big snow year as was 2013,
# but not 2018. 
sites_complete_summers %>% 
  filter(SiteID  == "USFS_Little Martin River") %>% 
  ggplot() +
  geom_line(aes(x = sampleDate, y= maxDT), color = "red") +
  geom_line(aes(x = sampleDate, y= minDT), color = "blue") +
  geom_line(aes(x = sampleDate, y= meanDT)) +
  facet_wrap(~Year, scales = "free_x")

mod_dat %>% 
  filter(Site  == "USFS_Little Martin River") %>%
  select(wtd_lcld_jd, Year) %>% 
  arrange(desc(wtd_lcld_jd))

#2013 was outlier, but I think this is valid, big snow year means cold in June.
# many of the UW sites got really warm later that summer. 
sites_complete_summers %>% 
  filter(SiteID  == "UW_Nerka Hidden Lake Creek") %>% 
  ggplot() +
  geom_line(aes(x = sampleDate, y= maxDT), color = "red") +
  geom_line(aes(x = sampleDate, y= minDT), color = "blue") +
  geom_line(aes(x = sampleDate, y= meanDT)) +
  facet_wrap(~Year, scales = "free_x")

```

```{r max range outliers}

mets_lg %>% 
  filter(metric == "RANGE_MAX") %>% 
  arrange(desc(value))

#2013 was an outlier, but that was a hot year in bb.
sites_complete_summers %>% 
  filter(SiteID  == "accs_mutsk09") %>% 
  ggplot() +
  geom_line(aes(x = sampleDate, y= maxDT), color = "red") +
  geom_line(aes(x = sampleDate, y= minDT), color = "blue") +
  geom_line(aes(x = sampleDate, y= meanDT)) +
  facet_wrap(~Year, scales = "free_x")

#outlier from 2015, but the large spike was June 10, could have been when things were starting to warm up.
sites_complete_summers %>% 
  filter(SiteID  == "UW_Aleknagik Silver Salmon Creek") %>% 
  ggplot() +
  geom_line(aes(x = sampleDate, y= maxDT), color = "red") +
  geom_line(aes(x = sampleDate, y= minDT), color = "blue") +
  geom_line(aes(x = sampleDate, y= meanDT)) +
  facet_wrap(~Year, scales = "free_x") 

#check date of max temp for other sites in 2015.
metrics2 %>% 
  filter(Site  == "UW_Aleknagik Silver Salmon Creek", Year == 2015) %>% 
  select(MxDMT_jd) #161

# about 5 days earlier than the rest of the sites.
metrics2 %>% 
  filter(Year == 2015, Region == "Bristol_Bay") %>% 
  select(MxDMT_jd) %>%
  arrange(MxDMT_jd) %>% 
  ggplot() +
  geom_histogram(aes(x = MxDMT_jd))

#check max temps
metrics2 %>% 
  filter(Year == 2015, Region == "Bristol_Bay") %>% 
  select(MxDMT) %>% 
  ggplot() +
  geom_histogram(aes(x = MxDMT))

#warmest temp outside of bad newhalen data.
metrics2 %>% 
  filter(Year == 2015, Region == "Bristol_Bay") %>% 
  select(Site, MxDMT) %>% 
  arrange(desc(MxDMT))
```

Obvious outlier on duration 20, but also check multiple outliers for 18. All of them seem valid, except for the Newhalen.

* remove newhalen river 2015.


```{r}
mets_lg %>% 
  filter(metric == "dur20") %>% 
  arrange(desc(value))

mets_lg %>% 
  filter(metric == "dur18") %>% 
  arrange(desc(value))

sites_complete_summers %>% 
  filter(SiteID  == "NPS_Newhalen_River") %>% 
  ggplot() +
  geom_line(aes(x = sampleDate, y= maxDT), color = "red") +
  geom_line(aes(x = sampleDate, y= minDT), color = "blue") +
  geom_line(aes(x = sampleDate, y= meanDT)) +
  facet_wrap(~Year, scales = "free_x") +
  labs(title="NPS_Newhalen_River")
# ggsave("output/nps_bad_data.jpeg")

#small deshka stream in 2019
sites_complete_summers %>% 
  filter(SiteID  == "OWL1") %>% 
  ggplot() +
  geom_line(aes(x = sampleDate, y= maxDT), color = "red") +
  geom_line(aes(x = sampleDate, y= minDT), color = "blue") +
  geom_line(aes(x = sampleDate, y= meanDT)) +
  facet_wrap(~Year, scales = "free_x")

#our hot trib in little su in 2016, which was a pretty warm summer
sites_complete_summers %>% 
  filter(SiteID  == "lslak7") %>% 
  ggplot() +
  geom_line(aes(x = sampleDate, y= maxDT), color = "red") +
  geom_line(aes(x = sampleDate, y= minDT), color = "blue") +
  geom_line(aes(x = sampleDate, y= meanDT)) +
  facet_wrap(~Year, scales = "free_x")

#wow the gulkana got really hot in 2019
sites_complete_summers %>% 
  filter(SiteID  == "usgs_15200280") %>% 
  ggplot() +
  geom_line(aes(x = sampleDate, y= maxDT), color = "red") +
  geom_line(aes(x = sampleDate, y= minDT), color = "blue") +
  geom_line(aes(x = sampleDate, y= meanDT)) +
  facet_wrap(~Year, scales = "free_x")

#2015 is outlier, looks pretty normal for this site.
#note this is a lake outlet, some strange minimums in June, but maybe that is normal for lakes during breakup?
sites_complete_summers %>% 
  filter(SiteID  == "fws_Long Lake Creek") %>% 
  ggplot() +
  geom_line(aes(x = sampleDate, y= maxDT), color = "red") +
  geom_line(aes(x = sampleDate, y= minDT), color = "blue") +
  geom_line(aes(x = sampleDate, y= meanDT)) +
  facet_wrap(~Year, scales = "free_x")

mets_lg %>% 
  filter(metric == "dur20mx") %>% 
  arrange(desc(value))

mets_lg %>% 
  filter(metric == "dur20gt6") %>% 
  arrange(desc(value))
```

Make a rolling pdf of plots for all sites that show the max, min, mean faceted by year. Use complete so no straight lines across missing values. This seems like a pretty simple QA step that can flag bad years, burials, air temps, etc. Not sure how I missed the 2015 year for Newhalen.


```{r pdf of dailies}

sites <- left_join(sites_complete_summers, md %>% select(Site, Waterbody_name), by = c("SiteID" = "Site")) %>% 
  ungroup() %>% 
  distinct(SiteID, Waterbody_name)

pdf("output/daily mean max min-all sites.pdf", width = 10)
for(i in 1:nrow(sites)) {
  dat <- left_join(sites %>% slice(i), sites_complete_summers)
  dat2 <- dat %>%
    mutate(date = as.Date(sampleDate)) %>% 
    complete(date = seq.Date(min(date), max(date), by="day")) %>% 
    mutate(Year = year(date)) %>% 
    group_by(Year) %>% 
    mutate(yrct = sum(!is.na(meanDT))) %>% 
    filter(!yrct == 0)
  p1 <- dat2 %>% 
    filter(month(date) %in% 6:8) %>% 
    ggplot() +
    geom_line(aes(x = date, y= maxDT), color = "red") +
    geom_line(aes(x = date, y= minDT), color = "blue") +
    geom_line(aes(x = date, y= meanDT)) +
    facet_wrap(~Year, scales = "free_x") +
    labs(title = sites %>% slice(i) %>% pull(SiteID),
         subtitle = sites %>% slice(i) %>% pull(Waterbody_name))
  print(p1)
}
dev.off()


```

Observations: 

* kdk_eftrv01 2016 looks buried.
* USFS_Ibeck Creek-Low has really large daily variation in 2016/2017, but not 18/19. This doesn't match with snow or precip.
* USFS_Little Martin River looks buried for half of 2012 and 2018.
* USFS_Power Creek looks buried for parts of 2016, 2018, and 2019.
* UW_Nerka Sam Creek possible air temp in July 2013.
* UW_Aleknagik Big Whitefish looks buried in 2012, but also other years with low daily range.



```{r}
mod_dat %>% 
  filter(Site == "USFS_Ibeck Creek-Low") %>% 
  select(Year, summer_precip, wtd_lcld_jd)
```

# Reduced list of metrics

```{r}
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- abs(cor(x, y, use = "complete.obs"))
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
    text(0.5, 0.5, txt, cex = cex.cor * r)
}

panel.hist <- function(x, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(usr[1:2], 0, 1.5) )
    h <- hist(x, plot = FALSE)
    breaks <- h$breaks; nB <- length(breaks)
    y <- h$counts; y <- y/max(y)
    rect(breaks[-nB], 0, breaks[-1], y, col = "cyan", ...)
}

mets_lg %>% 
  filter(group %in% c("Magnitude", "Timing")|metric == "TempSens")  %>%
  select(-group) %>% 
  pivot_wider(names_from = metric, values_from = value) %>%
  select(MA7d_DAT:TempSens) %>% 
  pairs(upper.panel = panel.cor, diag.panel = panel.hist)

mets_lg %>% 
  filter(group == "Variability")  %>%
  pivot_wider(names_from = metric, values_from = value) %>%
  select(MxDIFF:RANGE_MN) %>% 
  pairs(upper.panel = panel.cor)

mets_lg %>% 
  filter(group %in% c("Frequency", "Duration"))  %>%
  select(-group) %>% 
  pivot_wider(names_from = metric, values_from = value) %>%
  select(SUM_13_DMT:dur20ct) %>% 
  pairs(upper.panel = panel.cor, diag.panel = panel.hist)
  
```

For Mat-Su thermal regimes, settled on 10 metrics:

* MWMT = MA7d_DMT
* Range = RANGE_MAX 
* Variance = SIGMA_DMT
* CV - not valid for C, could use CV_DAT_K or SD, which are exactly correlated, but these have high correlation to variance
* Freq_13 = SUM_13_DMT
* Freq_18 = SUM_18_DMT
* Dur_13 - dur13mx
* Dur_18 = dur18mx
* Tim_Max = MxDMT_jd
* Tim_MWMT = MA7d_DMT_jd

Others to consider that aren't r > 0.8 with metrics above:

* NDNT - minimum of daily mins
* TempSens
* MnDAT - mean of daily averages over summer, e.g. mean summer temperature



```{r}
mets_12 <- c("MA7d_DMT", "RANGE_MAX", "SIGMA_DMT", "SUM_13_DMT", "SUM_18_DMT", "dur13mx", "dur18mx",
             "MxDMT_jd", "MA7d_DMT_jd", "NDNT", "TempSens", "MnDAT", "RANGE_MN", "MxDMT")

mets_lg %>% 
  # distinct(metric)
  filter(metric %in% mets_12)  %>%
  select(-group) %>% 
  pivot_wider(names_from = metric, values_from = value) %>%
  select(MA7d_DMT:TempSens) %>% 
  pairs(upper.panel = panel.cor, diag.panel = panel.hist)

mets_lg %>% 
  distinct(Site, Year) %>% 
  count(Site) %>% 
  arrange(desc(n))

mets_lg %>% 
  filter(metric %in% mets_11, Site == "CIK_6") %>% 
  select(-group) %>% 
  pivot_wider(names_from = metric, values_from = value) %>% 
  arrange(TempSens) %>% 
  select(MA7d_DMT:TempSens) %>% 
  pairs(upper.panel = panel.cor, diag.panel = panel.hist)

mets_lg %>% 
  filter(metric %in% mets_11)  %>%
  select(-group) %>% 
  pivot_wider(names_from = metric, values_from = value) %>%
  select(TempSens, Region, RANGE_MAX) %>% 
  filter(!is.na(TempSens)) %>% 
  ggplot(aes(x = TempSens, y = RANGE_MAX)) +
  geom_point() +
  facet_wrap(~Region)
  

```


```{r}
mets10_scwd <- mets_lg %>% 
  filter(metric %in% mets_10) %>% 
  group_by(metric) %>% 
  mutate(value_sc = scale(value)) %>% 
  select(Site, Year, metric, value_sc) %>% 
  pivot_wider(names_from = metric, values_from = value_sc)

summary(mets10_scwd)

mets10_dist <- dist(mets10_scwd %>% select(-Site, -Year))

hclust(mets10_dist, method = "ward.D2") %>% plot()


```



pca

```{r}

data.frame(mets = names(metrics))


metrics_in <- metrics %>% 
  filter(year > 2009) %>% 
  select(-SiteID, -year, -SUM_20, -DUR_mx20, -SUM_18, -DUR_mx18, -Jul, -Aug, -Sep, -Jun) 

metrics_env <- left_join(metrics %>% filter(year > 2009) %>% select(SiteID, year), 
                         md %>% distinct(SiteID, SourceName, Waterbody_name, Waterbody_type, Name, HUC8, Region)) %>%
  mutate(yearf = as.factor(year))


pc1 <- prcomp(metrics_in, scale. = TRUE) 

biplot(pc1)

autoplot(pc1, data = metrics_env, colour = 'Region', labels = TRUE, loadings.label = TRUE,
         frame = TRUE, frame.type = "t", frame.colour = 'Region')

autoplot(pc1, data = metrics_env, colour = 'yearf', labels = TRUE, loadings.label = TRUE,
         frame = TRUE, frame.type = "t", frame.colour = 'yearf')

pc1.scores <- scores(pc1)
```

