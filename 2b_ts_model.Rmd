---
title: "Stream Thermal Sensitivity Model"
output:
  html_document: 
    df_print: paged
    fig_width: 10
    fig_height: 6
    fig_caption: yes
    code_folding: hide
    toc: true
    toc_depth: 4
    toc_float:
      collapsed: false
      smooth_scroll: false
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(readxl)
library(lubridate)
library(GGally)
library(corrplot)
library(car)
library(nlme)
library(MuMIn)
library(gpboost)
library(randomForest)
library(rfUtilities)
library(MASS)
library(geosphere)
library(sf)
library(glmmLasso)
library(ggpubr)
library(rnoaa)
library(e1071)
library(rpart)
library(partykit)
library(rpart.plot)
library(REEMtree)
library(MixRF)
library(tidyverse)

```



Model thermal sensitivities: mixed model or RF with random effects. First tested for random effect then removed covariates using liklihood ratio tests. Compared results to variable importance from dredging all model subsets of the global model.

```{r read in data}

mod_dat <- readRDS("data_preparation/final_data/model_data2022-01-19.rds") #saved from combining response and covariates in 2a.

md <- read_rds("data_preparation/final_data/md.rds")
mod_dat <- left_join(mod_dat, md %>% dplyr::select(SiteID, deshka, HUC8, Name, Latitude, Longitude, SourceName, Waterbody_name), by = c("Site" = "SiteID")) 

#additional data transformations added in below.
mod_dat %>%
  distinct(str_slope) %>%
  arrange(str_slope)

min_slope = 0.0000100000
c_slope = as.integer(log10(min_slope))
d_slope = 10^c_slope

mod_dat <- mod_dat %>% 
  mutate(log_area = log10(wtd_area_sqKM),
         log_slope = log10(str_slope + d_slope) - c_slope,
         asrt_glac = asin(sqrt(wtd_glacier_per/100)),
         asrt_lake = asin(sqrt(wtd_lake_per/100)),
         asrt_wet = asin(sqrt(wtd_wet_per/100)),
         glac_10 = case_when(wtd_glacier_per > 0 ~ 1,
                             TRUE ~ 0),
         log_cat_elev = log10(cat_elev_MEAN),
         log_cat_slope = log10(cat_slope_MEAN))

# #80% of the sample size for training the model
# smp_size <- floor(0.8 * nrow(mod_dat))
# 
# ## set the seed to make your partition reproducible
# set.seed(123)
# train_ind <- sample(seq_len(nrow(mod_dat)), size = smp_size)
# 
# train <- mod_dat[train_ind, ]
# test <- mod_dat[-train_ind, ]

```


# Mixed effects model

Simple mixed effects model for this dataset. 

* split data into training and test sets (80/20).
* assess need for random effect for region/site and site using AIC -- lme with REML.
* generate global model with 




Random effects on global model.

1. should consider possible interactions - add 5 from Tim's results: north x snow, north x slope, north x precip, precip x slope, slope x snow.
2. Better for prediction would be hu12 or hu10. But can still include site within region but predict with level 1 (level 0 is population, level 1 is region, level 2 is site).
3a. use liklihood ratio test or step aic to get a simpler model and evaluate using 10 fold xval and test set.
3b. alternatively try glmmlasso to use regularization to minimize model coefficients for unimportant predictors. (and other recommendations in Treddenick 2021). I could not get this to run!
3c. or start with global model, use dredge and cross-validate all models with AIC < 6 (Tim's cutoff), which is ~300,
4. for xval, could set up a temporal using years and a separate spatial using huc8 or other major grouping since plan will be to predict for normal year + 2019 and also across all catchments.

```{r random effects}
lme1Ar <- lme(TempSens ~ log_slope + log_cat_elev + log_cat_slope + wtd_north_per +
                wtd_slope_MEAN + log_area + dist_coast_km + 
                asrt_wet + asrt_glac + asrt_lake + snow_ind +summer_precip + glac_10 +
                wtd_north_per*snow_ind + wtd_north_per*wtd_slope_MEAN + wtd_north_per*summer_precip +
                summer_precip*wtd_slope_MEAN + wtd_slope_MEAN*snow_ind, 
              data = mod_dat, random = ~1 | Region/Site, method = "REML")

lme1Br <- lme(TempSens ~ log_slope + log_cat_elev + log_cat_slope + wtd_north_per +
                wtd_slope_MEAN + log_area + dist_coast_km + 
                asrt_wet + asrt_glac + asrt_lake + snow_ind +summer_precip + glac_10 +
                wtd_north_per*snow_ind + wtd_north_per*wtd_slope_MEAN + wtd_north_per*summer_precip +
                summer_precip*wtd_slope_MEAN + wtd_slope_MEAN*snow_ind, 
              data = mod_dat, random = ~1 | Site, method = "REML")

lme1Cr <- lme(TempSens ~ log_slope + log_cat_elev + log_cat_slope + wtd_north_per +
                wtd_slope_MEAN + log_area + dist_coast_km + 
                asrt_wet + asrt_glac + asrt_lake + snow_ind +summer_precip + glac_10 +
                wtd_north_per*snow_ind + wtd_north_per*wtd_slope_MEAN + wtd_north_per*summer_precip +
                summer_precip*wtd_slope_MEAN + wtd_slope_MEAN*snow_ind, 
              data = mod_dat, random = ~1 | Region, method = "REML")

lme1Dr <- lme(TempSens ~ log_slope + log_cat_elev + log_cat_slope + wtd_north_per +
                wtd_slope_MEAN + log_area + dist_coast_km + 
                asrt_wet + asrt_glac + asrt_lake + snow_ind +summer_precip + glac_10 +
                wtd_north_per*snow_ind + wtd_north_per*wtd_slope_MEAN + wtd_north_per*summer_precip +
                summer_precip*wtd_slope_MEAN + wtd_slope_MEAN*snow_ind, 
              data = mod_dat, random = ~1 | HUC8, method = "REML")

lme1Er <- lme(TempSens ~ log_slope + log_cat_elev + log_cat_slope + wtd_north_per +
                wtd_slope_MEAN + log_area + dist_coast_km + 
                asrt_wet + asrt_glac + asrt_lake + snow_ind +summer_precip + glac_10 +
                wtd_north_per*snow_ind + wtd_north_per*wtd_slope_MEAN + wtd_north_per*summer_precip +
                summer_precip*wtd_slope_MEAN + wtd_slope_MEAN*snow_ind, 
              data = mod_dat, random = ~1 | HUC8/Site, method = "REML")

lme1Fr <- gls(TempSens ~ log_slope + log_cat_elev + log_cat_slope + wtd_north_per +
                wtd_slope_MEAN + log_area + dist_coast_km + 
                asrt_wet + asrt_glac + asrt_lake + snow_ind +summer_precip + glac_10 +
                wtd_north_per*snow_ind + wtd_north_per*wtd_slope_MEAN + wtd_north_per*summer_precip +
                summer_precip*wtd_slope_MEAN + wtd_slope_MEAN*snow_ind, 
              data = mod_dat, method = "REML")

AIC(lme1Ar, lme1Br, lme1Cr, lme1Dr, lme1Er, lme1Fr) %>% arrange(AIC)
```




```{r HUC8 intercepts}

mod_dat %>% count(HUC8)

left_join(as_tibble(lme1Er$coefficients$random$HUC8, rownames = "HUC8"), mod_dat %>% distinct(HUC8, Name)) %>% 
  arrange(`(Intercept)`)
```



Move forward with fixed effects, use AIC or liklihood ratio test to remove parameters. Switch to ML.

```{r include = FALSE}
lme1m <- lme(TempSens ~ log_slope + log_cat_elev + log_cat_slope + wtd_north_per +
                wtd_slope_MEAN + log_area + dist_coast_km + 
                asrt_wet + asrt_glac + asrt_lake + snow_ind +summer_precip + glac_10 +
                wtd_north_per*snow_ind + wtd_north_per*wtd_slope_MEAN + wtd_north_per*summer_precip +
                summer_precip*wtd_slope_MEAN + wtd_slope_MEAN*snow_ind, 
             data = mod_dat, random = ~1 | HUC8/Site, method = "ML")


lme1m_nosite <- lme(TempSens ~ log_slope + log_cat_elev + log_cat_slope + wtd_north_per +
                wtd_slope_MEAN + log_area + dist_coast_km + 
                asrt_wet + asrt_glac + asrt_lake + snow_ind +summer_precip + glac_10 +
                wtd_north_per*snow_ind + wtd_north_per*wtd_slope_MEAN + wtd_north_per*summer_precip +
                summer_precip*wtd_slope_MEAN + wtd_slope_MEAN*snow_ind, 
             data = mod_dat, random = ~1 | HUC8, method = "ML")

plot(lme1m)
hist(resid(lme1m))
summary(lme1m)

data.frame(preds = predict(lme1m, level = 1), test %>% select(TempSens, Site)) %>% 
  mutate(error.sq = (preds - TempSens)^2,
         error.abs = abs(preds - TempSens)) %>% 
  summarize(rmse = sqrt(mean(error.sq)),
            mae = mean(error.abs))

#model with site grouping doesn't improve predictions at regional level.
data.frame(preds = predict(lme1m_nosite, level = 1), test %>% select(TempSens, Site)) %>% 
  mutate(error.sq = (preds - TempSens)^2,
         error.abs = abs(preds - TempSens)) %>% 
  summarize(rmse = sqrt(mean(error.sq)),
            mae = mean(error.abs))


#much better marginal r2 with site grouping.
r.squaredGLMM(lme1m_nosite)
r.squaredGLMM(lme1m)


```

## model selection


Alternative is to dredge the global model for all subsets and examine most important predictors by summing the model weight for the models in which each covariate is included.


```{r dredge global model}
lme1m <- lme(TempSens ~ log_slope + log_cat_elev + log_cat_slope + wtd_north_per +
                wtd_slope_MEAN + log_area + dist_coast_km + 
                asrt_wet + asrt_glac + asrt_lake + snow_ind +summer_precip + glac_10 +
                wtd_north_per*snow_ind + wtd_north_per*wtd_slope_MEAN + wtd_north_per*summer_precip +
                summer_precip*wtd_slope_MEAN + wtd_slope_MEAN*snow_ind, 
             data = mod_dat, random = ~1 | HUC8/Site, method = "ML")


lme1_dr <- dredge(lme1m, rank = "AIC")
saveRDS(lme1_dr, "output/lme1m_dredge_results.rds")
```

Look at dredge results and use subset for model-selection. Test using cross validation. 
Temporal cross-validation is 5 groups that are relatively balanced:

* 2001-2011
* 2012-2014
* 2015-2016
* 2017-2018
* 2019


```{r generate temporal xval groups}

mod_dat %>% count(Year) #not much data in early years

#generate balanced groups using quantile
yr_breaks <- quantile(mod_dat$Year, probs = seq(0, 1, 0.2)) %>% unique()
yr_breaks[1] <- 2000 #replace leftmost bound with 2000 so 2001 is included

#add temporal xval groups
mod_dat <- mod_dat %>% 
  mutate(yeargr = cut(Year, yr_breaks))

mod_dat %>% 
  count(yeargr)
mod_dat %>% 
  count(Region)

mod_dat %>% 
  distinct(Region, Site) %>% 
  count(Region)

mod_dat %>% 
  distinct(yeargr, Site) %>% 
  count(yeargr)

```

I think that finding the distance at which sites are correlated is a good guidance for picking spatial xval groups, but I don't really understand this so need to dig further if it is important to guide the spatial groups.

```{r spatial variogram}

dists <- distm(mod_dat %>% select(Longitude, Latitude), fun = distCosine)
summary(dists)

dists <- dist(mod_dat %>% select(Longitude, Latitude))


breaks <- seq(0, 20, l = 11)

lme1reml <- lme(TempSens ~ log_slope + log_cat_elev + log_cat_slope + wtd_north_per +
                wtd_slope_MEAN + log_area + dist_coast_km + 
                asrt_wet + asrt_glac + asrt_lake + snow_ind +summer_precip +
                wtd_north_per*snow_ind + wtd_north_per*wtd_slope_MEAN + wtd_north_per*summer_precip +
                summer_precip*wtd_slope_MEAN + wtd_slope_MEAN*snow_ind, 
             data = mod_dat, random = ~1 | Region/Site, method = "REML")


resid(lme1reml)
var <- nlme::Variogram(resid(lme1reml), dists)
var <- Variogram(lme1reml, dists, "normalized", maxDist = 20)
plot(var, smooth = TRUE)
```



I tried using region for a first go, but then I can't predict using that using the null model, so try other grouping based on combingin HUC8 that is a little larger (8 groups).

Possibly change this to huc10 because for the final model we'll be able to use the huc8 levels for prediction so we want all in each training dataset so we can predict with level 1 groups. If I randomly combine different HU10 then the sites are still spatially clustered but don't include all sites within a HU8.

```{r generate spatial xval groups}

mod_dat %>% 
  distinct(Site, HUC8, Name) %>% 
  count(HUC8, Name)

#this results in 9 groups, but one with just 5, combine with closest HUC6 to west.
mod_dat %>% 
  mutate(HUC6 = substr(HUC8, 1, 6)) %>% 
  distinct(Site, HUC6) %>% 
  count(HUC6)

mod_dat <- mod_dat %>% 
  mutate(HU6 = substr(HUC8, 1, 6),
         sp_xval = case_when(HU6 %in% c(190206, 190302) ~ "190206_302",
                             TRUE ~ as.character(HU6))) %>% 
  group_by(sp_xval) %>%
  mutate(huc8_names = toString(unique(Name))) %>% 
  ungroup()

mod_dat %>% 
  distinct(Site, sp_xval) %>% 
  count(sp_xval)

```


```{r hu10 xval groups}
hu10 <- st_read(dsn = "S:/Leslie/GIS/NHD Harmonized/WBD_19_GDB.gdb", layer = "WBDHU10")
st_crs(hu10)
hu10_wgs84 <- st_transform(hu10, crs = "WGS84")

md_sf <- st_as_sf(md, coords = c("Longitude", "Latitude"), crs = "WGS84")

st_is_valid(hu10_wgs84) %>% sum() #2410 that is correct

```

This still isn't working because if I shoot for a similar size of spatial xval groups as there are huc8, there is still a 1:1 relationship between huc8 and group, which means we aren't predicting with the random intercept, which really improves the model. Try randomly assigning huc10 to groups that are small.

```{r add huc10 code}

ptm <- proc.time()
md_sf2 <- st_join(md_sf, hu10_wgs84 %>% select(HU10_Name = Name, HUC10))
join_time <- proc.time() - ptm
join_time

#limit to just 408 sites with data
huc10_groups <- left_join(mod_dat %>% distinct(Site), md_sf2, by = c("Site" = "SiteID"))

#create random groups of huc10 across the study area by ordering by huc10 and assigning ids of 1-21 (each group will have 6 huc10)
#this gives us 21 groupings of huc10 with 7 - 48 sites in each group (6 huc10 in each group)
huc10_groups <- left_join(huc10_groups, huc10_groups %>% 
                            arrange(HUC10) %>% 
                            count(HUC10) %>% 
                            mutate(gr_id = rep(seq(1:21), 6)))

huc10_groups %>% 
  count(gr_id)

ggplot() +
  geom_sf(data = left_join(md_sf2, huc10_groups), aes(color = as.factor(gr_id)))

mod_dat <- left_join(mod_dat, huc10_groups %>% select(Site, HUC10, gr_id)) 
  
```


```{r variable importance}

lme1_dr <- readRDS("output/lme1m_dredge_results.rds")

#variable importance
lme1_dr %>% 
  as_tibble() %>% 
  mutate(across(asrt_glac:'wtd_north_per:wtd_slope_MEAN', ~ case_when(!is.na(.) ~ weight))) %>% 
  select(asrt_glac:'wtd_north_per:wtd_slope_MEAN') %>% 
  colSums(., na.rm = TRUE) %>% 
  enframe() %>% 
  arrange(desc(value)) %>% 
  ggplot(aes(y = fct_reorder(name, value), x = value)) +
  geom_point()

```

Create model set based on variable importance:

* global model
* drop 6 covariates and interactions in group with lowest variable important - 12 left
* drop next group of 4 - 8 left
* drop final group of 4 only keeping top 4 predictors


```{r formulas for model set}

lme_all <- formula(TempSens ~ log_slope + log_cat_elev + log_cat_slope + wtd_north_per +
                wtd_slope_MEAN + log_area + dist_coast_km + asrt_wet + 
                  asrt_glac + asrt_lake + snow_ind +summer_precip + 
                  glac_10 + wtd_north_per*snow_ind + wtd_north_per*wtd_slope_MEAN + wtd_north_per*summer_precip +
                summer_precip*wtd_slope_MEAN + wtd_slope_MEAN*snow_ind)

lme_12vars <- formula(TempSens ~ log_cat_elev + log_cat_slope + wtd_north_per +
                wtd_slope_MEAN + log_area +  
                asrt_wet + asrt_glac + asrt_lake + snow_ind + summer_precip + 
                wtd_north_per*wtd_slope_MEAN + 
                summer_precip*wtd_slope_MEAN)

lme_8vars <- formula(TempSens ~ log_cat_elev + wtd_north_per +
                wtd_slope_MEAN + asrt_glac + asrt_lake + snow_ind +summer_precip + 
                summer_precip*wtd_slope_MEAN)

lme_4vars <- formula(TempSens ~ log_cat_elev + 
                wtd_slope_MEAN + summer_precip + 
                summer_precip*wtd_slope_MEAN)
  
```

Temporal xvalidation. For each test set, make predictions using the models built from the training data and the set of years in the test set. Once the OOB predictions are saved, use them to calculate a data frame with model performance metrics for each model: RMSE, MAE, and obs v pred. 

```{r temporal cross-validation}

tempxval_preds <- data.frame()

for(i in 1:5) {
  temp_xval <- mod_dat %>% distinct(yeargr) %>% slice(i) 
  train <- mod_dat %>% 
    anti_join(temp_xval)
  test <- mod_dat %>% 
    right_join(temp_xval)
  
  #global model
  lmegl <- lme(lme_all, data = train, random = ~1 | HUC8/Site, method = "REML")    
  lme2 <- lme(lme_12vars, data = train, random = ~1 | HUC8/Site, method = "REML")    
  lme3 <- lme(lme_8vars, data = train, random = ~1 | HUC8/Site, method = "REML")    
  lme4 <- lme(lme_4vars, data = train, random = ~1 | HUC8/Site, method = "REML")    
  lme5 <- lme(TempSens~1, data = train, random = ~1 | HUC8/Site, method = "REML")
  rf1 <- randomForest(TempSens ~ log_slope + log_cat_elev + log_cat_slope + wtd_north_per +
                        wtd_slope_MEAN + log_area + dist_coast_km + asrt_wet + 
                        asrt_glac + asrt_lake + snow_ind + summer_precip + Region + glac_10, 
                      data = train %>% group_by(Site) %>% sample_n(1),
                      ntree=1000, importance=TRUE,proximity=TRUE,mtry=5)
  
  tempxval_preds <- bind_rows(tempxval_preds,
                            bind_cols(test %>% select(Site, Year, TempSens), 
                                      global = predict(lmegl, newdata = test, level = 1),
                                      lme_12vars = predict(lme2, newdata = test, level = 1),
                                      lme_8vars = predict(lme3, newdata = test, level = 1),
                                      lme_4vars = predict(lme4, newdata = test, level = 1),
                                      lme_null = predict(lme5, newdata = test, level = 1),
                                      rf = predict(rf1, newdata = test)) %>% 
                              pivot_longer(names_to = "model", values_to = "preds", cols = global:rf) %>% 
                              mutate(xval_type = "temporal",
                                     xval_group = temp_xval %>% pull(yeargr) %>% as.character())
  )
}


# tempxval_preds <- xval_preds %>% filter(xval_type == "temporal")

tempxval_results <- tempxval_preds %>% 
  mutate(sqerror = (preds - TempSens)^2,
         abserror = abs(preds - TempSens)) %>%
  group_by(model, xval_type, xval_group) %>% 
  summarize(rmse = sqrt(mean(sqerror, na.rm = TRUE)),
            mae = mean(abserror, na.rm = TRUE),
            obs_pred = cor(preds, TempSens, use = "pairwise.complete.obs"),
            obs_pred_rank = cor(preds, TempSens, method = "spearman", use = "pairwise.complete.obs")) 

tempxval_results %>% 
  ggplot(aes(x = xval_group, y = rmse, color = model)) +
  geom_point()

```

Everything I tried above to get spatial xval groups that would allow me to predict at level 1 isn't working. I would have to predict site by site and some would be level 0 and some would be level 1. 

These are new spatial cross-validation groups where I sequentially placed HUC10 in 21 groups (6 HUC10 each) in order to try and randomize the spatial clusters of sites across the study area in each test set (rather than all together). Predictions are still at population level because many of these groups overlap with HUC8.

```{r spatial cross-validation}

spxval_preds <- data.frame()

for(i in 1:21) {
  train <- mod_dat %>% filter(!gr_id == i)
  test <- mod_dat %>% filter(gr_id == i)

  #global model
  lmegl <- lme(lme_all, data = train, random = ~1 | HUC8/Site, method = "REML")    
  lme2 <- lme(lme_12vars, data = train, random = ~1 | HUC8/Site, method = "REML")    
  lme3 <- lme(lme_8vars, data = train, random = ~1 | HUC8/Site, method = "REML")    
  lme4 <- lme(lme_4vars, data = train, random = ~1 | HUC8/Site, method = "REML")    
  lme5 <- lme(TempSens~1, data = train, random = ~1 | HUC8/Site, method = "REML")
  #for rf, make sure just one year from each site
  rf1 <- randomForest(TempSens ~ log_slope + log_cat_elev + log_cat_slope + wtd_north_per +
                        wtd_slope_MEAN + log_area + dist_coast_km + asrt_wet + 
                        asrt_glac + asrt_lake + snow_ind + summer_precip + Region + glac_10, 
                      data = train %>% group_by(Site) %>% sample_n(1),
                      ntree=1000, importance=TRUE,proximity=TRUE,mtry=5)
  
spxval_preds <- bind_rows(spxval_preds,
                            bind_cols(test %>% select(Site, Year, TempSens), 
                                      global = predict(lmegl, newdata = test, level = 0),
                                      lme_12vars = predict(lme2, newdata = test, level = 0),
                                      lme_8vars = predict(lme3, newdata = test, level = 0),
                                      lme_4vars = predict(lme4, newdata = test, level = 0),
                                      lme_null = predict(lme5, newdata = test, level = 0),
                                      rf = predict(rf1, newdata = test)) %>% 
                              pivot_longer(names_to = "model", values_to = "preds", cols = global:rf) %>% 
                              mutate(xval_type = "spatial",
                                     xval_group = i)
  )
}

# spxval_preds <- xval_preds %>% filter(xval_type == "spatial")

spxval_results <- spxval_preds %>% 
  mutate(sqerror = (preds - TempSens)^2,
         abserror = abs(preds - TempSens)) %>%
  group_by(model, xval_type, xval_group) %>% 
  summarize(rmse = sqrt(mean(sqerror, na.rm = TRUE)),
            mae = mean(abserror, na.rm = TRUE),
            obs_pred = cor(preds, TempSens, use = "pairwise.complete.obs"),
            obs_pred_rank = cor(preds, TempSens, method = "spearman", use = "pairwise.complete.obs")) 

spxval_results %>% 
  ggplot(aes(x = xval_group, y = rmse, color = model)) +
  geom_point()
  
```



```{r spatial LOO cross-validation}

sploo_preds <- data.frame()

# DF of sites: remove any that comprise a single huc8 so can predict using level 1 (only 3 removed).
sites <- mod_dat %>% distinct(Site, HUC8)
sites <- sites %>% 
  group_by(HUC8) %>% 
  mutate(count = n()) %>% 
  filter(count > 1) %>% 
  ungroup()
  
for(i in 1:nrow(sites)) {
  sp_xval <- sites %>% slice(i) 
  train <- mod_dat %>%
    anti_join(sp_xval)
  test <- mod_dat %>%
    right_join(sp_xval)
  
  #global model
  lmegl <- lme(lme_all, data = train, random = ~1 | HUC8/Site, method = "REML")    
  lme2 <- lme(lme_12vars, data = train, random = ~1 | HUC8/Site, method = "REML")    
  lme3 <- lme(lme_8vars, data = train, random = ~1 | HUC8/Site, method = "REML")    
  lme4 <- lme(lme_4vars, data = train, random = ~1 | HUC8/Site, method = "REML")    
  lme5 <- lme(TempSens~1, data = train, random = ~1 | HUC8/Site, method = "REML")
  #for rf, make sure just one year from each site
  rf1 <- randomForest(TempSens ~ log_slope + log_cat_elev + log_cat_slope + wtd_north_per +
                        wtd_slope_MEAN + log_area + dist_coast_km + asrt_wet + 
                        asrt_glac + asrt_lake + snow_ind + summer_precip + Region + glac_10, 
                      data = train %>% group_by(Site) %>% sample_n(1),
                      ntree=1000, importance=TRUE,proximity=TRUE,mtry=5)
  
  sploo_preds <- 
    bind_rows(sploo_preds, 
              bind_cols(test %>% select(Site, Year, TempSens), 
                        global = predict(lmegl, newdata = test, level = 1),
                        lme_12vars = predict(lme2, newdata = test, level = 1),
                        lme_8vars = predict(lme3, newdata = test, level = 1),
                        lme_4vars = predict(lme4, newdata = test, level = 1),
                        lme_null = predict(lme5, newdata = test, level = 1),
                        rf = predict(rf1, newdata = test)) %>% 
                pivot_longer(names_to = "model", values_to = "preds", cols = global:rf) %>% 
                mutate(xval_type = "LOO",
                       xval_group = sp_xval %>% pull(Site))
    )
}


sploo_results <- sploo_preds %>% 
  mutate(sqerror = (preds - TempSens)^2,
         abserror = abs(preds - TempSens)) %>%
  group_by(model, xval_type) %>% 
  summarize(rmse = sqrt(mean(sqerror, na.rm = TRUE)),
            mae = mean(abserror, na.rm = TRUE),
            obs_pred = cor(preds, TempSens, use = "pairwise.complete.obs"),
            obs_pred_rank = cor(preds, TempSens, method = "spearman", use = "pairwise.complete.obs"),
            n()) 

```



```{r rmse plot for different xval types}
# , sploo_results
bind_rows(tempxval_results, spxval_results %>% mutate(xval_group = as.character(xval_group)), sploo_results) %>% 
  mutate(modelf = factor(model, levels = c("global", "lme_12vars", "lme_8vars", "lme_4vars", "lme_null", "rf"),
                         labels = c("global", "12 vars.", "8 vars.", "4 vars.", "null", "RF"))) %>% 
  ggplot(aes(x = modelf, y = rmse, color = xval_type)) +
  stat_summary(fun = "mean", geom = "point") +
  stat_summary(fun.data = "mean_se", geom = "errorbar", width = 0.2) +
  labs(y = "RMSE on Validation Data", x = "Model", color = "Cross-validation Type") +
  theme_bw() +
  theme(legend.position = "bottom")

bind_rows(tempxval_results, spxval_results %>% mutate(xval_group = as.character(xval_group)), sploo_results) %>% 
  saveRDS("output/xval_results.rds")

```



```{r loo observed v predicted}
left_join(sploo_preds, mod_dat %>% distinct(Site, Region))  %>% 
  mutate(modelf = factor(model, levels = c("global", "lme_11vars", "lme_8vars", "lme_3vars", "lme_null", "rf"),
                         labels = c("global", "11 vars.", "8 vars.", "3 vars.", "null", "RF"))) %>% 
  ggplot(aes(x = TempSens, y = preds)) +
  geom_point() +
  geom_abline(aes(intercept = 0, slope = 1)) +
  facet_grid(cols = vars(Region), rows = vars(modelf)) +
  coord_cartesian(xlim = c(-0.2, 1), ylim = c(-0.2,1)) +
  stat_cor(label.x.npc = 0, label.y = c(seq(0.6, 1, 0.1)))

```

Save predictions for all of the cross-validations.

```{r}
left_join(sploo_preds, mod_dat %>% distinct(Site, Region))  %>% 
  bind_rows(tempxval_preds, spxval_preds %>% mutate(xval_group = as.character(xval_group))) %>% 
  saveRDS("output/xval_preds.rds")

# xval_preds <- readRDS("output/xval_preds.rds")

summary(xval_preds)
xval_preds %>% filter(is.na(preds))


```

Predictions using full models and all data.

```{r internal predictions and results}
lmegl <- lme(lme_all, data = mod_dat, random = ~1 | HUC8/Site, method = "REML")    
lme2 <- lme(lme_11vars, data = mod_dat, random = ~1 | HUC8/Site, method = "REML")    
lme3 <- lme(lme_8vars, data = mod_dat, random = ~1 | HUC8/Site, method = "REML")    
lme4 <- lme(lme_3vars, data = mod_dat, random = ~1 | HUC8/Site, method = "REML")    
lme5 <- lme(TempSens~1, data = mod_dat, random = ~1 | HUC8/Site, method = "REML")
#for rf, make sure just one year from each site
rf1 <- randomForest(TempSens ~ log_slope + log_cat_elev + log_cat_slope + wtd_north_per +
                      wtd_slope_MEAN + log_area + dist_coast_km + asrt_wet + 
                      asrt_glac + asrt_lake + snow_ind + summer_precip, 
                    data = mod_dat %>% group_by(Site) %>% sample_n(1),
                    ntree=1000, importance=TRUE,proximity=TRUE,mtry=5)

preds <- bind_cols(mod_dat %>% select(Site, Year, TempSens), 
                      global = predict(lmegl, level = 1),
                      lme_11vars = predict(lme2, level = 1),
                      lme_8vars = predict(lme3, level = 1),
                      lme_3vars = predict(lme4, level = 1),
                      lme_null = predict(lme5, level = 1),
                      rf = predict(rf1, newdata = mod_dat)) %>% 
              pivot_longer(names_to = "model", values_to = "preds", cols = global:rf) 

internal_results <- preds %>% 
  mutate(sqerror = (preds - TempSens)^2,
         abserror = abs(preds - TempSens)) %>%
  group_by(model) %>% 
  summarize(rmse = sqrt(mean(sqerror, na.rm = TRUE)),
            mae = mean(abserror, na.rm = TRUE),
            obs_pred = cor(preds, TempSens, use = "pairwise.complete.obs"),
            obs_pred_rank = cor(preds, TempSens, method = "spearman", use = "pairwise.complete.obs")) 


left_join(preds, mod_dat %>% distinct(Site, Region))  %>% 
  mutate(modelf = factor(model, levels = c("global", "lme_11vars", "lme_8vars", "lme_3vars", "lme_null", "rf"),
                         labels = c("global", "11 vars.", "8 vars.", "3 vars.", "null", "RF"))) %>% 
  ggplot(aes(x = TempSens, y = preds)) +
  geom_point() +
  geom_abline(aes(intercept = 0, slope = 1)) +
  facet_grid(cols = vars(Region), rows = vars(modelf)) +
  coord_cartesian(xlim = c(-0.2, 1), ylim = c(-0.2,1)) +
  stat_cor(label.x.npc = 0, label.y = c(seq(0.6, 1, 0.1)))

summary(lme3)

summary(preds)
```




# Regional models

The models with all data are really only predicting Cook Inlet with much accuracy. Try building separate models for Kodiak or PWS or Copper River and see if they are much better. The dredging is where we ended up with different models. Try dredging for each region and see if the variable importance plots look different.

```{r dredge Copper River}
cr_dat <- mod_dat %>% filter(Region == "Copper_River")
cr_dat %>% count(Site) %>% arrange(n) # 28 sites with 1-10 years of data - 162 total site years

lme1m_cr <- lme(TempSens ~ log_slope + log_cat_elev + log_cat_slope + wtd_north_per +
                wtd_slope_MEAN + log_area + dist_coast_km + 
                asrt_wet + asrt_glac + asrt_lake + snow_ind +summer_precip +
                wtd_north_per*snow_ind + wtd_north_per*wtd_slope_MEAN + wtd_north_per*summer_precip +
                summer_precip*wtd_slope_MEAN + wtd_slope_MEAN*snow_ind, 
             data = cr_dat, random = ~1 | HUC8/Site, method = "ML")


lme1_cr_dr <- dredge(lme1m_cr, rank = "AIC")
# saveRDS(lme1_dr, "output/lme1m_dredge_results.rds")
```


What about a single random forest for Copper River?

```{r}
#all sites and years
rf_cr1 <- randomForest(TempSens ~ log_slope + log_cat_elev + log_cat_slope + wtd_north_per +
                      wtd_slope_MEAN + log_area + dist_coast_km + asrt_wet + 
                      asrt_glac + asrt_lake + snow_ind + summer_precip, 
                    data = cr_dat,
                    ntree=1000, importance=TRUE,proximity=TRUE,mtry=5)

#all sites and years
rf_cr2 <- randomForest(TempSens ~ log_slope + log_cat_elev + log_cat_slope + wtd_north_per +
                      wtd_slope_MEAN + log_area + dist_coast_km + asrt_wet + 
                      asrt_glac + asrt_lake + snow_ind + summer_precip, 
                    data = cr_dat %>% group_by(Site) %>% sample_n(1),
                    ntree=1000, importance=TRUE,proximity=TRUE,mtry=5)

rf_cr1
rf_cr2

varImpPlot(rf_cr1)
bind_cols(cr_dat %>% select(TempSens), preds = predict(rf_cr1)) %>% 
  ggplot(aes(x = TempSens, y = preds)) +
  geom_point()

bind_cols(cr_dat %>% select(TempSens), preds = predict(rf_cr1)) %>% 
  lm(preds ~ TempSens, data = .) %>% 
  summary()
```

Try LOO xval for just copper river data and random forest and see how it performs.

```{r LOO copper}

sploo_preds_cr <- data.frame()

# DF of sites: remove any that comprise a single huc8 so can predict using level 1 (only 3 removed).
sites <- cr_dat %>% distinct(Site, HUC8)

for(i in 1:nrow(sites)) {
  sp_xval <- sites %>% slice(i) 
  train <- mod_dat %>%
    anti_join(sp_xval)
  test <- mod_dat %>%
    right_join(sp_xval)
  
  rf1 <- randomForest(TempSens ~ log_slope + log_cat_elev + log_cat_slope + wtd_north_per +
                        wtd_slope_MEAN + log_area + dist_coast_km + asrt_wet + 
                        asrt_glac + asrt_lake + snow_ind + summer_precip, 
                      data = train,
                      ntree=1000, importance=TRUE,proximity=TRUE,mtry=5)
  
  sploo_preds_cr <- 
    bind_rows(sploo_preds_cr, 
              bind_cols(test %>% select(Site, Year, TempSens), 
                        rf = predict(rf1, newdata = test)) %>% 
                mutate(xval_type = "LOO",
                       xval_group = sp_xval %>% pull(Site))
    )
}


sploo_results_cr <- sploo_preds_cr %>% 
  rename(preds = rf) %>% 
  mutate(sqerror = (preds - TempSens)^2,
         abserror = abs(preds - TempSens)) %>%
  summarize(rmse = sqrt(mean(sqerror, na.rm = TRUE)),
            mae = mean(abserror, na.rm = TRUE),
            obs_pred = cor(preds, TempSens, use = "pairwise.complete.obs"),
            obs_pred_rank = cor(preds, TempSens, method = "spearman", use = "pairwise.complete.obs"),
            n()) 

sploo_preds_cr %>% 
  ggplot(aes(x = TempSens, y = rf)) +
  geom_point() +
  geom_abline(aes(intercept = 0, slope = 1)) +
  coord_cartesian(xlim = c(-0.2, 1), ylim = c(-0.2,1)) +
  stat_cor(label.x.npc = 0, label.y = c(seq(0.6, 1, 0.1)))

sploo_preds_cr %>% 
  lm(rf ~ TempSens, data = .) %>% summary()
```









# LASSO regularization 

Try LASSO for predictive model.

```{r glmmlasso demo}
data("soccer")

## generalized additive mixed model
## grid for the smoothing parameter

## center all metric variables so that also the starting values with glmmPQL are in the correct scaling

soccer[,c(4,5,9:16)]<-scale(soccer[,c(4,5,9:16)],center=T,scale=T)

soccer<-data.frame(soccer)

lambda <- seq(500,0,by=-5)

family = poisson(link = log)
 

################## Second Simple Method ###########################
## Using 5-fold CV to determine the optimal tuning parameter lambda
 
### set seed
set.seed(123)

N<-dim(soccer)[1]

ind<-sample(N,N)

lambda <- seq(500,0,by=-5)

kk<-5

nk <- floor(N/kk)

Devianz_ma<-matrix(Inf,ncol=kk,nrow=length(lambda))

## first fit good starting model

PQL<-glmmPQL(points~1,random = ~1|team,family=family,data=soccer)

Delta.start<-c(as.numeric(PQL$coef$fixed),rep(0,6),as.numeric(t(PQL$coef$random$team)))

Q.start<-as.numeric(VarCorr(PQL)[1,1])

for(j in 1:length(lambda))
{
  print(paste("Iteration ", j,sep=""))
  
  for (i in 1:kk)
  {
    if (i < kk)
    {
      indi <- ind[(i-1)*nk+(1:nk)]
    }else{
      indi <- ind[((i-1)*nk+1):N]
    }
    
    soccer.train<-soccer[-indi,]
    soccer.test<-soccer[indi,]
    
    glm2 <- try(glmmLasso(points~transfer.spendings  
                          + ave.unfair.score  + ball.possession
                          + tackles + ave.attend + sold.out, rnd = list(team=~1),  
                          family = family, data = soccer.train, lambda=lambda[j],switch.NR=F,final.re=TRUE,
                          control=list(start=Delta.start,q_start=Q.start))
                ,silent=TRUE) 
    
    if(class(glm2)!="try-error")
    {  
      y.hat<-predict(glm2,soccer.test)    
      
      Devianz_ma[j,i]<-sum(family$dev.resids(soccer.test$points,y.hat,wt=rep(1,length(y.hat))))
    }
  }
  print(sum(Devianz_ma[j,]))
}

Devianz_vec<-apply(Devianz_ma,1,sum)

 opt2<-which.min(Devianz_vec)

 glm2_final <- glmmLasso(points~transfer.spendings  
                         + ave.unfair.score + ball.possession
                         + tackles + ave.attend + sold.out, rnd = list(team=~1),  
                         family = family, data = soccer, lambda=lambda[opt2],switch.NR=F,final.re=TRUE,
                         control=list(start=Delta.start,q_start=Q.start))

 summary(glm2_final)
```

Try code above with our dataset, but with different cross-validation groups (10 sets of 2 years each and 5 regions).

```{r glmmlasso xval}


## center all metric variables so that also the starting values with glmmPQL are in the correct scaling

mod_dat

mod_dat_sc <- bind_cols(mod_dat %>% select(Region, TempSens) %>% mutate(Region = factor(Region)), 
                        data.frame(scale(mod_dat %>% select(log_slope, log_cat_elev, log_cat_slope, 
                                                            wtd_north_per,wtd_slope_MEAN, log_area, 
                                                            dist_coast_km, asrt_wet, asrt_glac, 
                                                            asrt_lake, snow_ind, summer_precip), scale = TRUE, center = TRUE)))


lambda <- seq(500,0,by=-5)

family = gaussian()
 

################## Second Simple Method ###########################
## Using 5-fold CV to determine the optimal tuning parameter lambda
 
### set seed
set.seed(123)

N<-dim(mod_dat_sc)[1]

ind<-sample(N,N)

lambda <- seq(500,0,by=-5)

kk<-5 #first attempt with just 5 random xval

nk <- floor(N/kk)

Devianz_ma<-matrix(Inf,ncol=kk,nrow=length(lambda))

## first fit good starting model

PQL<-glmmPQL(TempSens~1,random = ~1|Region,family=family,data=mod_dat_sc)

#note rep 0s by number of fixed effects
Delta.start<-c(as.numeric(PQL$coef$fixed),rep(0,17),as.numeric(t(PQL$coef$random$Region)))

Q.start<-as.numeric(VarCorr(PQL)[1,1])

for(j in 1:length(lambda)) {
  print(paste("Iteration ", j,sep=""))
  
  for (i in 1:kk)
  {
    if (i < kk)
    {
      indi <- ind[(i-1)*nk+(1:nk)]
    }else{
      indi <- ind[((i-1)*nk+1):N]
    }
    
    ts.train<-mod_dat_sc[-indi,]
    ts.test<-mod_dat_sc[indi,]
    
    glm2 <- try(glmmLasso(TempSens ~ log_slope + log_cat_elev + log_cat_slope + wtd_north_per +
                            wtd_slope_MEAN + log_area + dist_coast_km + 
                            asrt_wet + asrt_glac + asrt_lake + snow_ind +summer_precip +
                            wtd_north_per:snow_ind + wtd_north_per:wtd_slope_MEAN + wtd_north_per:summer_precip +
                            summer_precip:wtd_slope_MEAN + wtd_slope_MEAN:snow_ind, 
                          rnd = list(Region=~1),  
                          family = family, data = ts.train, lambda=lambda[j], switch.NR=F, final.re=TRUE,
                          control=list(start=Delta.start,q_start=Q.start))
                ,silent=TRUE) 
    
    print(class(glm2))
    
    if(class(glm2)!="try-error")
    {  
      y.hat<-predict(glm2,ts.test)    
      
      Devianz_ma[j,i]<-sum(family$dev.resids(ts.test$points,y.hat,wt=rep(1,length(y.hat))))
    }
  }
  print(sum(Devianz_ma[j,]))
}

Devianz_vec<-apply(Devianz_ma,1,sum)

opt2<-which.min(Devianz_vec)

glm2_final <- glmmLasso(points~transfer.spendings  
                         + ave.unfair.score + ball.possession
                         + tackles + ave.attend + sold.out, rnd = list(team=~1),  
                         family = family, data = soccer, lambda=lambda[opt2],switch.NR=F,final.re=TRUE,
                         control=list(start=Delta.start,q_start=Q.start))

 summary(glm2_final)
```




# Machine learning methods

## Random forest

First option is to build a random forest using subsets of the data. In this case, I randomly selected one year from each site to create 10 different forests and combined them to generate one model of 10,000 trees for prediction (per JAWRA 2020 paper).

```{r random forest by site}

sites <- mod_dat %>% distinct(Site) %>% pull(Site)
random.df <- data.frame()


for (i in sites) {
  yrs <- mod_dat %>% filter(Site %in% i) %>% distinct(Year) %>% pull(Year) 
  yrs10 <- rep(yrs,10)[1:10] #creates vector of 10 years
  ran.yrs <- sample(yrs10,10,replace=FALSE) #reorders vector randomly
  newrow <- data.frame(Site = i, Year = ran.yrs, Forest = 1:10)
  random.df <- bind_rows(random.df, newrow)
}

#initialize first random forest and then combine forests 2:10 to it.
rf_10 <- randomForest(TempSens ~ log_slope + log_cat_elev + log_cat_slope + wtd_north_per +
                      wtd_slope_MEAN + log_area + dist_coast_km + 
                      asrt_wet + asrt_glac + asrt_lake + snow_ind + Region, 
                    data = left_join(random.df %>% filter(Forest ==  1), mod_dat),
                    ntree=1000, importance=TRUE,proximity=TRUE,mtry=5)
rf_stats <- data.frame(mse = rf_10$mse, rsq = rf_10$rsq)


for (i in 2:10){
  rfnew <- randomForest(TempSens ~ log_slope + log_cat_elev + log_cat_slope + wtd_north_per +
                      wtd_slope_MEAN + log_area + dist_coast_km + 
                      asrt_wet + asrt_glac + asrt_lake + snow_ind + Region, 
                      data = left_join(random.df %>% filter(Forest ==  i), mod_dat),
                    ntree=1000, importance=TRUE,proximity=TRUE,mtry=5)
  rf_10 <- randomForest::combine(rf_10, rfnew)
  rf_stats <- bind_rows(rf_stats, data.frame(mse = rfnew$mse, rsq = rfnew$rsq))
}

varImpPlot(rf_10)

#xval MSE
rf_stats %>% 
  summarize(mean(mse),
            mean(rsq))


bind_cols(mod_dat %>% select(Site, Year, TempSens, Region), 
          rf = predict(rf_10, newdata = mod_dat)) %>% 
  ggplot(aes(x = TempSens, y = rf, color = Region)) +
  geom_point() +
  geom_abline(aes(intercept = 0, slope = 1)) +
  coord_cartesian(xlim = c(-0.2, 1), ylim = c(-0.2,1)) +
  stat_cor(label.x.npc = 0, label.y = c(seq(0.6, 1, 0.1)))
```



Other alternatives that allow for extrapolation:
lightgbm: https://papers.nips.cc/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf

## Regression trees with random effects

I can't get this to work.

```{r}

retree <- MixRF(Y = mod_dat$TempSens, X = as.data.frame(mod_dat %>% select(log_slope, log_cat_elev, 
                                                                   log_cat_slope, wtd_north_per,
                                                                   wtd_slope_MEAN, log_area,
                                                                   dist_coast_km , asrt_wet, 
                                                                   asrt_glac, asrt_lake, 
                                                                   snow_ind, summer_precip)),
                                                data = mod_dat, random = "~1|Site")


```



## Classification tree

Using rpart to create a regression tree with all of the data.

```{r}
ct_all <- rpart(TempSens ~ log_slope + log_cat_elev + log_cat_slope + wtd_north_per +
                      wtd_slope_MEAN + log_area + dist_coast_km + asrt_wet + 
                      asrt_glac + asrt_lake + snow_ind + summer_precip, 
                    data = mod_dat, method = "anova")
```

Print the cross validation results to select a complexity parameter for tree-pruning. From plotcp:
"A good choice of cp for pruning is often the leftmost value for which the mean lies below the horizontal line." Select cp for 12 splits.

```{r}
plotcp(ct_all) 
printcp(ct_all) 
cp_parm <- 0.011197

```

Prune the tree and print the results.

```{r}
ct_pr <- prune(ct_all, cp = cp_parm)

# print(ct_pr)

par(xpd = TRUE)
plot(ct_pr, compress = TRUE)
text(ct_pr, use.n = TRUE)


```

Summary table indicates variable importance and also lists surrogate splits. Interesting that snow index and precipitation are the least important variables.

```{r}
summary(ct_pr)
```

## CT by region

```{r}
ct_models <- dlply(mod_dat, "Region", function(df) 
  rpart(TempSens ~ log_slope + log_cat_elev + log_cat_slope + wtd_north_per +
                      wtd_slope_MEAN + log_area + dist_coast_km + asrt_wet + 
                      asrt_glac + asrt_lake + snow_ind + summer_precip, 
                    data = df, method = "anova")
  )

map(ct_models, function(x) prp(x))

```


## CT with unbiased variable selection

Try the partykit package and ctree for unbiased variable selection. The rpart tree had lowest variable importance for the two temporal-spatial variables -- precip and snow, which is suspicious since the regression methods indicated they were both important.

```{r}
citree <- ctree(TempSens ~ log_slope + log_cat_elev + log_cat_slope + wtd_north_per +
                      wtd_slope_MEAN + log_area + dist_coast_km + asrt_wet + 
                      asrt_glac + asrt_lake + snow_ind + summer_precip, 
                    data = mod_dat, control = ctree_control(minbucket = 20))

citree
plot(citree)
mean((mod_dat$TempSens - predict(citree))^2)

varimp(citree)*100

mod_dat %>% 
  mutate(preds = predict(citree)) %>% 
  ggplot(aes(x = TempSens, y = preds, color = Region)) +
  geom_point() +
  geom_abline(aes(intercept = 0, slope = 1)) +
  stat_cor() +
  facet_wrap(~Region)
```



# Climate data for 2001-2019

Anchorage forecast office at airport: GHCND:USC00500275
King salmon airport: GHCND:USW00025503 (missing 2006-2012)
Iliamna: GHCND:USW00025506 (even worse only 2001-2005)
Kodiak airport: GHCND:USW00025501
Cordova airport: GHCND:USW00026410

```{r}
mynoaakey = "LmempjqpgcLSxDQWiLvuaOAGmscrQCrb"


clim_dat <- meteo_pull_monitors(monitors = c('USC00500275', 'USW00025503', 'USW00025506'), date_min = "2001-01-01",
                      date_max = "2019-12-31", var = c("PRCP", "TAVG", "TMAX", "TMIN"))
```


