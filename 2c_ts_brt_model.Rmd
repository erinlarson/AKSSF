---
title: "2c_ts_brt_model"
output: html_document
date: '2022-02-25'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(dismo)
library(gbm)
library(ggpubr)
library(tidyverse)
library(sf)
library(gridExtra)
library(lubridate)
library(nlme)

select <- dplyr::select
```

Update this with TS created by Tim on 3/17/22. Model data frame created in script 2a with some exploration of response and covariates.

* check rmse on individual sites. Luca had tagged some sites with very local hydrologic inputs that would be difficult to model using landscape covariates. Revisit his list with any sites that do poorly in this model.
* Two outliers for minimum catchment slope, one matches a high stream slope, but other does not. Try model with and without these strange outliers to see if they have high leverage on model results.


```{r read in model data frame}
dat <- readRDS("data_preparation/final_data/model_data2022-05-09.rds")

```



# Boosted regression tree

## Initial two models

Dismo example

```{r}
library(dismo) 
data(Anguilla_train)
angaus.tc5.lr01 <- gbm.step(data=Anguilla_train, gbm.x = 3:13, gbm.y = 2,
family = "bernoulli", tree.complexity = 5, learning.rate = 0.01, 
bag.fraction = 0.5)

# Find interactions in the gbm model:
find.int <- gbm.interactions( angaus.tc5.lr01)
find.int$interactions
find.int$rank.list
```

Transformed covariates: log_slope, log_cat_elev, log_cat_slope, wtd_north_per, wtd_slope_MEAN, log_area, dist_coast_km, asrt_glac, asrt_lake, asrt_wet, snow_ind, summer_precip, Region


```{r brt data frame}
brt_in <- dat %>% 
  mutate(Region = as.factor(Region)) %>% 
  as.data.frame() %>% 
  dplyr::select(TempSens_Air, str_slope, cat_elev_MEAN, cat_slope_MEAN, 
                             wtd_north_per, wtd_slope_MEAN, wtd_area_sqKM, dist_coast_km,
                             wtd_glacier_per, wtd_lake_per, wtd_wet_per, snow_tc, summer_precip, Region)

brt_in_dl <- dat %>% 
  mutate(Region = as.factor(Region)) %>% 
  as.data.frame() %>% 
  dplyr::select(TempSens_Air.DayLen, str_slope, cat_elev_MEAN, cat_slope_MEAN, 
                             wtd_north_per, wtd_slope_MEAN, wtd_area_sqKM, dist_coast_km,
                             wtd_glacier_per, wtd_lake_per, wtd_wet_per, snow_tc, summer_precip, Region)

```

Interactions are all really weak, < 0.5 so they don't indicate any interaction in the perspectives plot. 

Output from step run:
fitting final gbm model with a fixed number of 7300 trees for TempSens_Air

mean total deviance = 0.065 
mean residual deviance = 0.007 
 
estimated cv deviance = 0.019 ; se = 0.001 
 
training data correlation = 0.943 
cv correlation =  0.839 ; se = 0.01 
 
elapsed time -  0.03 minutes 



```{r brt with ts from air only model}

brt_step <- gbm.step(gbm.y = 1, gbm.x = 2:14, 
                     data = brt_in,
                     tree.complexity = 5, learning.rate = 0.005, bag.fraction = 0.5,
                     n.folds = 10, family = "gaussian", max.trees = 30000,
                     keep.fold.models = TRUE, keep.fold.vector = TRUE, keep.fold.fit = TRUE)

saveRDS(brt_step, paste("output/brt_dfa1tr_air", Sys.Date(), ".rds", sep = ""))
```


fitting final gbm model with a fixed number of 5400 trees for TempSens_Air.DayLen

mean total deviance = 0.028 
mean residual deviance = 0.006 
 
estimated cv deviance = 0.014 ; se = 0.001 
 
training data correlation = 0.897 
cv correlation =  0.721 ; se = 0.016 
 
elapsed time -  0.02 minutes 

```{r brt with ts from air plus daylength model}

brt_step_dl <- gbm.step(gbm.y = 1, gbm.x = 2:14, 
                     data = brt_in_dl,
                     tree.complexity = 5, learning.rate = 0.005, bag.fraction = 0.5,
                     n.folds = 10, family = "gaussian", max.trees = 30000,
                     keep.fold.models = TRUE, keep.fold.vector = TRUE, keep.fold.fit = TRUE)

saveRDS(brt_step_dl, paste("output/brt_dfa1tr_AirDL", Sys.Date(), ".rds", sep = ""))
```


```{r}

summary(brt_step)
summary(brt_step_dl)

gbm.plot(brt_step, smooth = TRUE, n.plots = 13) #plots of first order relationships
gbm.plot(brt_step_dl, smooth = TRUE, n.plots = 13) #plots of first order relationships

# brt_simplify <- gbm.simplify(brt_step) #this takes a long time to run.

brt_int <- gbm.interactions(brt_step) #identifies interactions
brt_int$rank.list

brt_int_dl <- gbm.interactions(brt_step_dl) #identifies interactions
brt_int_dl$rank.list


gbm.perspec(brt_step, x = 12, y =5) #plots interactions, but I can't get this to show anything

#error
interact.gbm(brt_step, data = brt_in, n.trees = 200)
```

## Simplified air + DL model

fitting final gbm model with a fixed number of 6150 trees for TempSens_Air.DayLen

mean total deviance = 0.028 
mean residual deviance = 0.006 
 
estimated cv deviance = 0.014 ; se = 0.001 
 
training data correlation = 0.894 
cv correlation =  0.705 ; se = 0.019 
 
elapsed time -  0.94 minutes


```{r brt simplify}
brt_step_simp <- gbm.simplify(brt_step)
brt_stepdl_simp <- gbm.simplify(brt_step_dl)

brt_step_dl2 <- gbm.step(gbm.y = 1, gbm.x = brt_stepdl_simp$pred.list[[7]], 
                     data = brt_in_dl,
                     tree.complexity = 5, learning.rate = 0.005, bag.fraction = 0.5,
                     n.folds = 10, family = "gaussian", max.trees = 30000,
                     keep.fold.models = TRUE, keep.fold.vector = TRUE, keep.fold.fit = TRUE)

saveRDS(brt_step_dl2, paste("output/brt_dfa1tr_AirDL_simp", Sys.Date(), ".rds", sep = ""))
```


```{r}
gbm.plot(brt_step_dl2, smooth = TRUE, n.plots = 13) #plots of first order relationships

brt_int <- gbm.interactions(brt_step_dl2) #identifies interactions
brt_int$rank.list
```



```{r brt interaction}
int_vars <- c("summer_precip", "wtd_slope_MEAN")

pd_precip_slope <- pdp::partial(brt_step_dl2, pred.var = int_vars, 
              n.trees = 5200, train = brt_in_dl, plot = TRUE, chull = TRUE, rug = TRUE)
pd_precip_slope


int_vars <- c("snow_tc", "wtd_slope_MEAN")
pd_snow_slope <- pdp::partial(brt_step_dl2, pred.var = int_vars, 
              n.trees = 5200, train = brt_in_dl, plot = TRUE, chull = TRUE, rug = TRUE)
pd_snow_slope
```

## Model Performance

Deviance explained.

```{r elith model data and deviance explained}

eel_dat <- read_csv("S:/Classes/Machine Learning Seminar/Boosted Regression Trees - supplementary material/jane_1390_sm_appendixs3/data/model.data.csv") %>% 
  mutate(Method = as.factor(Method)) %>% 
  as.data.frame()

eel_brt <- gbm_step(Angaus ~ ., data = eel_dat[,-1], distribution = "bernoulli",
               n.trees = 1000, shrinkage = 0.01, interaction.depth = 5)

eel_brt <- gbm.step(gbm.y = 1, gbm.x = 2:13, 
                     data = eel_dat[,-1],
                     tree.complexity = 5, learning.rate = 0.01, bag.fraction = 0.5,
                     n.folds = 10, family = "bernoulli", max.trees = 2000)


summary(eel_brt)

cv.dev <- eel_brt$cv.statistics$deviance.mean # same as estimated cv deviance in output
null.dev <- eel_brt$self.statistics$mean.null #same as mean total deviance in output
train.dev <- eel_brt$self.statistics$mean.resid #same as mean residual deviance in output

dev.exp <- (null.dev - cv.dev)/null.dev
dev.exp.train <- (null.dev - train.dev)/null.dev

```

Deviance explained.

```{r brt deviance air only}
cv.dev <- brt_step$cv.statistics$deviance.mean # same as estimated cv deviance in output
null.dev <- brt_step$self.statistics$mean.null #same as mean total deviance in output
train.dev <- brt_step$self.statistics$mean.resid #same as mean residual deviance in output

dev.exp <- (null.dev - cv.dev)/null.dev
dev.exp.train <- (null.dev - train.dev)/null.dev

dev.exp
dev.exp.train
```


```{r brt deviance air and dl}
cv.dev <- brt_step_dl$cv.statistics$deviance.mean # same as estimated cv deviance in output
null.dev <- brt_step_dl$self.statistics$mean.null #same as mean total deviance in output
train.dev <- brt_step_dl$self.statistics$mean.resid #same as mean residual deviance in output

dev.exp <- (null.dev - cv.dev)/null.dev
dev.exp.train <- (null.dev - train.dev)/null.dev

dev.exp
dev.exp.train
```
```{r brt deviance air and dl simlified model}
cv.dev <- brt_step_dl2$cv.statistics$deviance.mean # same as estimated cv deviance in output
null.dev <- brt_step_dl2$self.statistics$mean.null #same as mean total deviance in output
train.dev <- brt_step_dl2$self.statistics$mean.resid #same as mean residual deviance in output

dev.exp <- (null.dev - cv.dev)/null.dev
dev.exp.train <- (null.dev - train.dev)/null.dev

dev.exp
dev.exp.train
```

Variable importance.

```{r variable importance plot}

p1 <- brt_step_dl2$contributions %>% 
  mutate(var_names = case_when(var == "wtd_slope_MEAN" ~ "Watershed slope",
                               var == "cat_elev_MEAN" ~ "Catchment elevation",
                               var == "wtd_lake_per" ~ "Lake cover",
                               var == "wtd_area_sqKM" ~ "Watershed size",
                               var == "summer_precip" ~ "Summer precipitation",
                               var == "dist_coast_km" ~ "Distance to coast",
                               var == "snow_tc" ~ "Snow index",
                               var == "asrt_wet" ~ "Wetland cover",
                               var == "log_cat_slope" ~ "Catchment slope",
                               var == "log_slope" ~ "Stream gradient",
                               var == "wtd_north_per" ~ "North aspect",
                               var == "asrt_glac" ~ "Glacier cover",
                               TRUE ~ var)) %>%
  ggplot(aes(x = rel.inf, y = fct_reorder(var_names, rel.inf))) +
  geom_col() +
  geom_vline(aes(xintercept = 10)) +
  theme_bw() +
  theme(text = element_text(size = 18), axis.title.y = element_blank()) +
  labs(x = "Relative Variable Importance")



p1

```

OP plot for internal cross-validation predictions by region.

```{r brt internal xval}
brt_out <- brt_in_dl %>% 
  mutate(preds = predict(brt_step_dl2),
         cv.preds = brt_step_dl2$fold.fit)
summary(brt_out)


brt_out %>% 
  # mutate(Region = gsub("_", " ", Region)) %>% 
  ggplot(aes(x = cv.preds, y = TempSens_Air.DayLen)) +
  geom_point() +
  geom_smooth(method = "lm") +
  geom_abline(aes(slope = 1, intercept = 0)) +
  facet_wrap(~Region) +
  coord_cartesian(xlim = c(-0.7, 1.5), ylim = c(-0.7, 1.5)) +
  stat_regline_equation(label.x = -0.6, label.y = 1.2,
                        aes(label = ..eq.label..)) +
  stat_regline_equation(label.x = -0.65, label.y = 0.9,
                        aes(label = ..adj.rr.label..)) +
  theme_bw() +
  labs(y = "Observed Thermal Sensitivity",x = "Predicted Thermal Sensitivity") +
  theme(text = element_text(size = 18))

# ggsave("output/presentation_figs/brt OP plot.jpeg", width = 10, height = 8) 

brt_out %>% 
  mutate(sqerror = (TempSens_Air.DayLen - cv.preds)^2) %>% 
  summarize(sqrt(mean(sqerror)))

```

OP plot for internal xval predictions, all data together.

```{r internal cv predictions single plot}

brt_out %>% 
  ggplot(aes(x = cv.preds, y = TempSens_Air.DayLen)) +
  geom_point() +
  geom_smooth(method = "lm") +
  geom_abline(aes(slope = 1, intercept = 0)) +
  coord_cartesian(xlim = c(-0.7, 1.5), ylim = c(-0.7, 1.5)) +
  stat_regline_equation(label.x = -0.6, label.y = 1.2,
                        aes(label = ..eq.label..)) +
  stat_regline_equation(label.x = -0.65, label.y = 0.9,
                        aes(label = ..adj.rr.label..)) +
  theme_bw() +
  labs(y = "Observed Thermal Sensitivity",x = "Predicted Thermal Sensitivity") +
  theme(text = element_text(size = 18))

# ggsave("output/presentation_figs/brt OP single plot.jpeg", width = 10, height = 8)
```


## Site cross validation - NOT RUN

Site cross-validation for gbm.

```{r brt site cross val, eval = FALSE}
site_xval <- mod_dat2 %>% 
  distinct(SiteID) %>% 
  mutate(group = sample(1:15, 318, replace = TRUE)) 

brt_xval_preds <- data.frame()

ptm <- proc.time()

#save the preds on testing data
for(i in 1:15) {
  test <- left_join(site_xval %>% filter(group == i), mod_dat2)
  train <- left_join(site_xval %>% filter(!group == i), mod_dat2)
  brt_train <- train %>% dplyr::select(TempSens, log_slope, log_cat_elev, log_cat_slope, 
                             wtd_north_per, wtd_slope_MEAN, log_area, dist_coast_km,
                             asrt_glac, asrt_lake, asrt_wet, snow_ind, summer_precip, Region) %>% 
  mutate(Region = as.factor(Region)) %>% 
  as.data.frame()

  brt_train[] <- lapply(brt_train, c)
  
  brt_step <- gbm.step(gbm.y = 1, gbm.x = 2:14, 
                     data = brt_train,
                     tree.complexity = 5, learning.rate = 0.005, bag.fraction = 0.5,
                     n.folds = 10, family = "gaussian", max.trees = 30000)

  newpreds <- test %>% 
    select(SiteID, Year) %>% 
    mutate(preds = predict(brt_step, test))
  
  brt_xval_preds <- bind_rows(newpreds, brt_xval_preds)
}

# Stop the clock
proc.time() - ptm

 # user  system elapsed 
 # 998.64    3.62 1001.77 
1001/60 #17 minutes

brt_xval_preds %>% count(SiteID, Year) %>% distinct(n)


```


```{r}
left_join(mod_dat2 %>% select(SiteID, Year, Region, TempSens), brt_xval_preds) %>% 
  mutate(Region = gsub("_", " ", Region)) %>% 
  ggplot(aes(x = preds, y = TempSens)) +
  geom_point() +
  geom_smooth(method = "lm") +
  geom_abline(aes(slope = 1, intercept = 0)) +
  facet_wrap(~Region) +
  coord_cartesian(xlim = c(-0.7, 1.5), ylim = c(-0.7, 1.5)) +
  stat_regline_equation(label.x = -0.6, label.y = 1.2,
                        aes(label = ..eq.label..)) +
  stat_regline_equation(label.x = -0.65, label.y = 0.9,
                        aes(label = ..adj.rr.label..)) +
  theme_bw() +
  labs(y = "Observed Thermal Sensitivity",x = "Predicted Thermal Sensitivity")


left_join(mod_dat2 %>% select(SiteID, Year, Region, TempSens), brt_xval_preds) %>% 
  ggplot(aes(x = preds, y = TempSens)) +
  geom_point() +
  geom_smooth(method = "lm") +
  geom_abline(aes(slope = 1, intercept = 0)) +
  coord_cartesian(xlim = c(-0.7, 1.5), ylim = c(-0.7, 1.5)) +
  stat_regline_equation(label.x = -0.6, label.y = 1.2,
                        aes(label = ..eq.label..)) +
  stat_regline_equation(label.x = -0.65, label.y = 0.9,
                        aes(label = ..adj.rr.label..)) +
  theme_bw() +
  labs(y = "Observed Thermal Sensitivity",x = "Predicted Thermal Sensitivity")

```

```{r}
left_join(site_xval, mod_dat2 %>% distinct(SiteID, Region)) %>% 
  count(group, Region) %>% 
  arrange(desc(Region))

left_join(site_xval, mod_dat2 %>% distinct(SiteID, Region)) %>% 
  count(Region) 

```


# Predictions

Bring in hu12 outlet covariates and snowpack and summer precip for all years. Need to rename all covariates in these files so they match the names in the model, so prediction will work.

```{r create hu12 covariate df}
hu12.cov <- read_csv("data_preparation/sensitivity_drivers/AKSSF_AWC_HUC12s_Covariates.csv")
hu12.spls <- read_csv("data_preparation/sensitivity_drivers/AKSSF_awcHuc12s_SpLs.csv") 
hu12.pts <- read_csv("data_preparation/sensitivity_drivers/AKSSF_AWCHuc12s_strwtd_cv.csv")

# dput(names(brt_in)) #getting correct variable names from model

hu12.cov <- hu12.cov %>% 
  select(cat_ID_con, cat_elev_MEAN = AwcHuc12_cat_elev_MEAN,
         cat_slope_MEAN = AwcHuc12_cat_slope_MEAN,
         wtd_north_per = AwcHuc12_wtd_north_per,
         wtd_slope_MEAN = AwcHuc12_wtd_slope_MEAN,
         wtd_glacier_per = AwcHuc12_wtd_glacier_per,
         wtd_lake_per = AwcHuc12_wtd_lake_per,
         wtd_wet_per = AwcHuc12_wtd_wet_per,
         AwcHuc12_wtd_lcld_mn_2001:AwcHuc12_wtd_lcld_mn_2019) %>% 
  pivot_longer(cols = AwcHuc12_wtd_lcld_mn_2001:AwcHuc12_wtd_lcld_mn_2019, names_to = "name", values_to = "wtd_lcld_jd") %>% 
  mutate(Year = substr(name, 22, 26) %>% as.numeric())

# Four sites with watersheds that don't overlap MODIS, we're dropping them because they
# are coastal. 
summary(hu12.cov)
hu12.cov %>% filter(is.na(wtd_lcld_jd)) %>% select(cat_ID_con, Year)

hu12.cov <- hu12.cov %>% 
  filter(!is.na(wtd_lcld_jd))

# Convert na to 0 for lake and glacier percent.
hu12.cov[is.na(hu12.cov)] <- 0

hu12.spls <- hu12.spls %>% 
  select(cat_ID_con, HUC12, sp_ls, dist_coast_km = dist_catch_coast_km)

hu12.pts <- hu12.pts %>% 
  select(cat_ID_con, Region = region, wtd_area_sqKM = wtd_AreaSqKm, str_slope)


hu12.df <- left_join(hu12.spls, hu12.pts) %>% left_join(hu12.cov)

#one site with missing data - this is a coastal outlet that we dropped above because 
# it is missing MODIS.
hu12.df %>% filter(is.na(cat_elev_MEAN))

hu12.df <- hu12.df %>% 
  filter(!is.na(cat_elev_MEAN))

```

Add in summer precipitation that was downloaded for all outlet catchment points in the air temperature script.

```{r add in daymet precipitation for outlets}

hu12_dm <- read_csv("data_preparation/HUC12_cat_pts_daymet_2001-19.csv") %>% 
  as_tibble()

#get rid of attributes, which are affecting merge below
attr(hu12_dm, "spec")
attr(hu12_dm, "spec") <- NULL
str(hu12_dm)

hu12_prp <- hu12_dm %>%
  filter(measurement %in% c("prcp..mm.day.")) %>% 
  mutate(sampleDate = as.Date(paste(year, yday), format = "%Y %j")) %>% 
  filter(month(sampleDate) %in% 6:8) %>% 
  rename(cat_ID_con = site, Year = year) %>% 
  group_by(cat_ID_con, Year) %>% 
  summarize(summer_precip = sum(value)) %>% 
  ungroup()


hu12.df <- left_join(hu12.df, hu12_prp) %>% 
  mutate(HUC12 = as.character(HUC12))


summary(hu12.df)
```

Add in snow index.

```{r snow index}
hu12.df %>% 
  ggplot(aes(y = wtd_lcld_jd, x = wtd_slope_MEAN)) +
  geom_point() +
  geom_smooth()

ess_hu12 <- lme(wtd_lcld_jd ~ wtd_slope_MEAN, dat = hu12.df, random = ~1|Year)
ess_hu12$coefficients$fixed 

ess_hu12_ints <- ess_hu12$coefficients$random$Year %>% as_tibble(rownames = "Year") %>% 
  rename(intercept = `(Intercept)`) %>% 
  mutate(Year = as.numeric(Year))

hu12.df <- hu12.df %>% 
  left_join(ess_hu12_ints) %>% 
  mutate(snow_tc = intercept + (wtd_lcld_jd - 1.814789 * wtd_slope_MEAN))
```

Comparing snowpack across hucs from 2012 to 2015 versus high versus low snow across all years.
We have a lot more variation in changes in snow from 2012 to 2015 than in the BB dataset. When we inspect high versus low snow years and slope, there isn't the same relationship. The largest differences 


```{r}

hu12.df %>% 
  group_by(HUC12) %>%
  filter(Year %in% c(2012, 2015)) %>%
  select(HUC12, wtd_lcld_jd, Year, wtd_slope_MEAN) %>% 
  pivot_wider(names_from = Year, values_from = wtd_lcld_jd) %>% 
  mutate(snow_diff = -(`2012` - `2015`)) %>% 
  ggplot(aes(y = snow_diff, x = wtd_slope_MEAN)) + 
  geom_point()

hu12.df %>% 
  group_by(HUC12, wtd_slope_MEAN, dist_coast_km) %>%
  summarize(min_snow = min(wtd_lcld_jd),
            max_snow = max(wtd_lcld_jd),
            snow_diff = -(max_snow - min_snow)) %>% 
  ggplot(aes(x = wtd_slope_MEAN, y = snow_diff, color = dist_coast_km)) +
  geom_point()


# all of these are on islands in PWS, but on the very front towards the open North Pacific
# maybe they stayed really cold in spring 2012 so had snow for a very long time and/or
# 2015 was a bit abnormal for them too so snow stayed longer.
hu12.df %>% 
  group_by(HUC12) %>%
  filter(Year %in% c(2012, 2015)) %>%
  select(HUC12, wtd_lcld_jd, Year, wtd_slope_MEAN) %>% 
  pivot_wider(names_from = Year, values_from = wtd_lcld_jd) %>% 
  mutate(snow_diff = `2012` - `2015`) %>% 
  filter(snow_diff > 90)
  
```


Create predictions using both models for all years and use to create scenarios.

```{r TS predictions}
hu12.df <- hu12.df %>% 
  mutate(preds_air = predict(brt_step, newdata = hu12.df),
         preds_airDL = predict(brt_step_dl, newdata = hu12.df)) 

summary(hu12.df) 

hu12.df %>% 
  ggplot(aes(x = preds_air, y = preds_airDL)) +
  geom_point() +
  facet_wrap(~Year)

#differences in predictions by model type.
hu12.df %>% 
  pivot_longer(cols = starts_with("preds"), names_to = "preds", values_to = "values") %>% 
  ggplot(aes(x = values, color = preds)) +
  geom_freqpoly()

```

Data frames of predicted TS differences comparing 2012/2015 and the highest and lowest snowpack years from 2001-2019.

```{r}
hu12.df %>% 
  filter(Year %in% c(2012, 2015)) %>%
  ggplot(aes(x = preds_airDL, color = as.factor(Year))) +
  geom_freqpoly()

bind_rows(hu12.df %>% 
            group_by(HUC12) %>% 
            slice_min(wtd_lcld_jd, with_ties = FALSE) %>% 
            mutate(snow_year = "min"),
          hu12.df %>% 
            group_by(HUC12) %>% 
            slice_max(wtd_lcld_jd, with_ties = FALSE) %>% 
            mutate(snow_year = "max")) %>% 
  ggplot(aes(x = preds_airDL, color = snow_year)) +
  geom_freqpoly() 

bind_rows(hu12.df %>% 
            group_by(HUC12) %>% 
            slice_min(summer_precip, with_ties = FALSE) %>% 
            mutate(prp_year = "min"),
          hu12.df %>% 
            group_by(HUC12) %>% 
            slice_max(summer_precip, with_ties = FALSE) %>% 
            mutate(prp_year = "max")) %>% 
  ggplot(aes(x = preds_airDL, color = prp_year)) +
  geom_freqpoly() 
  
  
  
```




```{r maps of TS}
hu12 <- st_read("T:\\Aquatic\\AKSSF\\AKSSF_Hydrography.gdb", layer = "AKSSF_awcHuc12s")


hu12_snow <- left_join(hu12, 
                       bind_rows(hu12.df %>% 
                                   group_by(HUC12) %>% 
                                   slice_min(wtd_lcld_jd) %>% 
                                   mutate(snow_year = "min"),
                                 hu12.df %>% 
                                   group_by(HUC12) %>% 
                                   slice_max(wtd_lcld_jd) %>% 
                                   mutate(snow_year = "max")) %>% 
                         select(HUC12, snow_year, Year, preds_airDL, Region)) %>% 
  filter(!is.na(preds_airDL)) 

ggplot() +
  geom_sf(data = hu12_snow, aes(fill = preds_airDL), color = NA) +
  facet_wrap(~snow_year)

hu12_precip <- left_join(hu12, 
                       bind_rows(hu12.df %>% 
                                   group_by(HUC12) %>% 
                                   slice_min(summer_precip) %>% 
                                   mutate(precip_year = "min"),
                                 hu12.df %>% 
                                   group_by(HUC12) %>% 
                                   slice_max(summer_precip) %>% 
                                   mutate(precip_year = "max")) %>% 
                         select(HUC12, precip_year, Year, preds_airDL, Region)) %>% 
  filter(!is.na(preds_airDL)) 

ggplot() +
  geom_sf(data = hu12_precip, aes(fill = preds_airDL), color = NA) +
  facet_wrap(~precip_year)

snow_prp_diffs <- left_join(
  bind_rows(
    hu12.df %>% 
      group_by(HUC12) %>% 
      slice_min(wtd_lcld_jd) %>% 
      mutate(snow_year = "min"),
    hu12.df %>% 
      group_by(HUC12) %>% 
      slice_max(wtd_lcld_jd) %>% 
      mutate(snow_year = "max")) %>%
    select(preds_airDL, snow_year, HUC12) %>% 
    pivot_wider(names_from = snow_year, values_from = preds_airDL) %>% 
    mutate(snow_diff = min - max) %>% 
    select(HUC12, snow_diff),
  bind_rows(
    hu12.df %>% 
      group_by(HUC12) %>% 
      slice_min(summer_precip) %>% 
      mutate(precip_year = "min"),
    hu12.df %>% 
      group_by(HUC12) %>% 
      slice_max(summer_precip) %>% 
      mutate(precip_year = "max")) %>%
    select(preds_airDL, precip_year, HUC12) %>% 
    pivot_wider(names_from = precip_year, values_from = preds_airDL) %>% 
    mutate(precip_diff = min - max) %>% 
    select(HUC12, precip_diff)) %>% 
  pivot_longer(cols = ends_with("diff"), names_to = "diff", values_to = "value") %>% 
  mutate(diff = case_when(diff == "precip_diff" ~ "Precipitation",
                          diff == "snow_diff" ~ "Snowpack"))
  
hu12_scens <- left_join(hu12, snow_prp_diffs) %>% 
    filter(!is.na(value)) 

hu12_scens$value %>% summary()

zCuts <- seq(-.15, 0.15, length.out = 10) %>% round(2)

ggplot() +
  geom_sf(data = hu12_scens, aes(fill = cut(value, zCuts)), color = NA) +
  facet_wrap(~diff, ncol = 1) +
  scale_fill_brewer(palette = "RdBu", drop = FALSE) +
  theme(legend.position = "right") +
  labs(fill = expression(paste(Delta, tau)),
       title = expression(paste("Decrease in ", tau, " when precipitation or snowpack increases")))
  
```

Create a data frame with scenarios for low and high snowpack for each salmon stream. Add in species and life stage information as new columns and save a csv for Dustin in output folder so he can add to the web mapper.

```{r snow scenarios}
hu12.snow <- bind_rows(hu12.df %>% 
            group_by(HUC12) %>% 
            slice_min(wtd_lcld_jd, with_ties = FALSE) %>% 
            mutate(snow_year = "min"),
          hu12.df %>% 
            group_by(HUC12) %>% 
            slice_max(wtd_lcld_jd, with_ties = FALSE) %>% 
            mutate(snow_year = "max")) %>% 
  ungroup()



hu12.snow %>% 
  select(HUC12, preds, snow_year) %>% 
  pivot_wider(names_from = snow_year, values_from = preds) %>% 
  mutate(diff = min - max) %>% 
  arrange(diff) %>% 
  count(diff > 0)


hu12 <- left_join(hu12, hu12.snow %>% 
  select(HUC12, preds, snow_year) %>% 
  pivot_wider(names_from = snow_year, values_from = preds) %>% 
  mutate(diff = max - min,
         error = case_when(diff > 0 ~ 1,
                           TRUE ~ 0)) %>% 
  select(HUC12, diff, error)) %>% 
  filter(!is.na(diff))

ggplot() +
  geom_sf(data = hu12, aes(fill = diff, color = as.factor(error))) 



#figure showing count of high or low snow by year for all huc12 outlets.
hu12.snow %>% 
  group_by(snow_year, Region) %>% 
  count(Year) %>% 
  ggplot(aes(x = Year, y = n, color = snow_year)) +
  geom_point() + 
  scale_x_continuous(breaks = seq(2001, 2019, by= 2)) +
  facet_wrap(~ Region, ncol = 1, scales = "free_y")

#add in species and life stage columns
hu12.snow.splsWd <- hu12.snow %>% 
  mutate(Chinook = case_when(grepl("K_", sp_ls) ~ 1,
                             TRUE ~ 0),
         Sockeye = case_when(grepl("S_", sp_ls) ~ 1,
                             TRUE ~ 0),
         Chum = case_when(grepl("CH_", sp_ls) ~ 1,
                          TRUE ~ 0),
         Pink = case_when(grepl("P_", sp_ls) ~ 1,
                          TRUE ~ 0),
         Coho = case_when(grepl("CO_", sp_ls) ~ 1,
                          TRUE ~ 0),
         Spawning = case_when(grepl("_s", sp_ls) ~ 1,
                          TRUE ~ 0),
         Rearing = case_when(grepl("_r", sp_ls) ~ 1,
                          TRUE ~ 0)) 

hu12.snow.splsWd %>% 
  write_csv(paste0("output/snow_scenarios_byhu12_spls_", Sys.Date(), ".csv"))

hu12.snow.splsWd %>% 
  select()
  pivot_longer(cols = Chinook:Coho, names_to = "species") %>%
  filter(value == 1) %>% 
  group_by(species) %>% 
  summarize(mean_ts = mean(preds),
            sd_ts = sd(preds))

hu12.df %>% 
  count(sp_ls) %>% 
  mutate(species = case_hgrepl("CO_", sp_ls)) %>% 
  summarize(sum(coho))
  
```





Double checked that values for all covariates are roughly in same ranges as in mod_dat -- they look fine, could probably make a figure showing histograms for both sets of covariates for team, but I don't think this is a problem, it seems no other variables have any effects of magnitude besides watershed slope.

```{r}

names(hu12_dat)

brt_step2$var.names

hu12_preds <- hu12_dat %>% 
  mutate(glac_10 = case_when(AwcHuc12_wtd_glacier_per > 0 ~ 1,
                             TRUE ~ 0),
         wtd_area_sqKM = Shape_Area/1000000,
         wtd_glacier_per = case_when(is.na(AwcHuc12_wtd_glacier_per) ~ 0,
                                     TRUE ~ AwcHuc12_wtd_glacier_per),
         wtd_lake_per = case_when(is.na(AwcHuc12_wtd_lake_per) ~ 0,
                                  TRUE ~ AwcHuc12_wtd_lake_per),
         Region = case_when(grepl("Cook", cat_ID_con) ~ "Cook Inlet",
                            grepl("Bristol", cat_ID_con) ~ "Bristol Bay",
                            grepl("Prince", cat_ID_con) ~ "Prince William Sound",
                            grepl("Kodiak", cat_ID_con) ~ "Kodiak",
                            grepl("Copper", cat_ID_con) ~ "Copper River",
                            TRUE ~ NA_character_)) %>%  
  dplyr::select(cat_elev_MEAN = AwcHuc12_cat_elev_MEAN,
         cat_slope_MEAN = AwcHuc12_cat_slope_MEAN,
         wtd_north_per = AwcHuc12_wtd_north_per,
         wtd_slope_MEAN = AwcHuc12_wtd_slope_MEAN,
         wtd_area_sqKM,
         glac_10,
         wtd_glacier_per,
         wtd_lake_per,
         wtd_wet_per = AwcHuc12_wtd_wet_per,
         cat_ID_con,
         Region) %>% 
  left_join(hu12_snow %>% 
              dplyr::select(snow_ind = snow_ind, cat_ID_con, year) %>% 
              filter(year %in% c(2012, 2015)))

summary(hu12_preds)
summary(mod_dat2)

preds_hisnow = bind_cols(hu12_preds %>% 
                           filter(year == 2012) %>% 
                           dplyr::select(Region, cat_ID_con, year), 
                         preds = predict(brt_step2, newdata = hu12_preds %>% filter(year == 2012)))
preds_losnow = bind_cols(hu12_preds %>% 
                           filter(year == 2015) %>% 
                           dplyr::select(Region, cat_ID_con, year), 
                         preds = predict(brt_step2, newdata = hu12_preds %>% filter(year == 2015)))


left_join(preds_hisnow %>% dplyr::select(hi = preds, cat_ID_con), preds_losnow %>% dplyr::select(lo = preds, cat_ID_con)) %>% 
  mutate(diff = hi - lo) %>% summarize(mean(diff))




```


Read in spatial data. The cat_ID_con in the covariate data frame links to that field in the outlet point file, which also has the HUC12 code so can link to the huc12 polygons for mapping.

```{r}
hu12_pts <- st_read(dsn = "T:\\Aquatic\\AKSSF\\AKSSF_Hydrography.gdb", layer = "AKSSF_awcHuc12_outlet_cats_points")
hu12_polys <- st_read(dsn = "T:\\Aquatic\\AKSSF\\AKSSF_Hydrography.gdb", layer = "AKSSF_AWC_HUC12s")
regions <- st_read(dsn = "W:\\GIS\\AKSSF Southcentral\\AKSSF Southcentral.gdb", layer = "AKSSF_regions")

hu12_polys <- hu12_polys %>% 
  left_join(hu12_pts %>% st_drop_geometry() %>% dplyr::select(HUC12, cat_ID_con)) %>% 
  left_join(preds_hisnow %>% dplyr::select(Region, cat_ID_con, preds))

#the polygons have two datasets where there is nhd plus, just keep the nhdplus polygons
hu12_polys <- hu12_polys %>% 
  mutate(keep = case_when(Region %in% c("Cook Inlet", "Copper River") & MERGE_SRC == "NHD_H_HUC12" ~ 0,
                          TRUE ~ 1)) %>% 
  filter(!keep == 0)

hu12_polys %>% st_drop_geometry() %>% count(Region, MERGE_SRC)

ggplot() +
  geom_sf(data = hu12_polys %>% filter(!is.na(preds)), aes(fill = preds), color = NA) +
  geom_sf(data = regions %>% filter(Study_Region %in% c("Cook Inlet", "Copper River", "Prince William Sound")),
          fill = NA) +
  scale_fill_viridis_c() +
  labs(fill = "Predicted Thermal Sensitivity") +
  theme_bw() +
  theme(legend.position = "bottom", text = element_text(size = 18))

ggsave("output/presentation_figs/ts map.jpeg", width = 8, height = 6)

```


```{r}
hu12_polys %>% st_drop_geometry() %>% distinct(HUType)
  filter(!is.na(HUType))
  
hu12_polys %>% st_drop_geometry() %>% count(HUC12) %>% filter(n==2) %>%  arrange(HUC12)

hu12_polys %>% st_drop_geometry() %>%  distinct(HUC12) #1035
hu12_pts %>% st_drop_geometry() %>% distinct(cat_ID_con) #1018
left_join(hu12_polys %>% st_drop_geometry() %>%  distinct(HUC12), 
          hu12_pts %>% st_drop_geometry() %>% dplyr::select(HUC12, cat_ID_con)) %>% 
  filter(is.na(cat_ID_con))
hu12_polys %>% filter(is.na(preds)) %>% st_drop_geometry()

preds_hisnow %>% 
  group_by(Region) %>% 
  # summarize(mean(preds),
  #           sd(preds)) %>%
  mutate(med = median(preds)) %>% distinct(Region, med)

preds_hisnow %>% 
  group_by(Region) %>% 
  # summarize(mean(preds),
  #           sd(preds)) %>%
  mutate(med = median(preds),
         med_pos = case_when(Region %in% c("Prince William Sound", "Cook Inlet") ~ med - 0.1,
                             TRUE ~ med + 0.1)) %>% 
  ggplot(aes(x = preds, color = Region)) +
  geom_freqpoly() +
  geom_vline(aes(xintercept = med, color = Region), linetype = 2, size = 1, show.legend = FALSE) +
  geom_text(aes(x = med_pos, y = 50, label = round(med, 2)), show.legend = FALSE) +
  theme_bw() +
  theme(legend.position = "bottom", text = element_text(size = 18)) +
  labs(y = "Count", x = "Predicted Thermal Sensitivity") 

ggsave("output/presentation_figs/ts preds freq plot.jpeg", width = 8, height = 6)
```

Look at distribution of AWC stream lengths across HU12s.

```{r}
awc_hu12 <- read_csv("data_preparation/sensitivity_drivers/awcEventArcs_Intersect_H12s_Diss.csv")

awc_hu12 %>% 
  group_by(HUC12) %>% 
  summarize(tot_len = sum(Shape_Length)) %>%
  filter(tot_len > 2000) %>% 
  ggplot(aes(x = tot_len)) +
  geom_histogram(bins = 100) +
  scale_x_log10()

awc_hu12 %>% 
  mutate(huc12f = as.factor(HUC12)) %>% 
  group_by(huc12f) %>%
  summarize(tot_len = sum(Shape_Length)) %>% 
  ggplot(aes(x = tot_len, y = fct_reorder(huc12f, tot_len))) +
  geom_point() +
  theme(axis.text.y = element_blank())

awc_hu12 %>% 
  group_by(HUC12) %>% 
  summarize(tot_len = sum(Shape_Length)) %>%
  filter(tot_len < 1000)


awc_hu12 %>% 
  group_by(HUC12) %>% 
  summarize(tot_len = sum(Shape_Length)) %>%
  summarize(quantile(tot_len, probs = 0.07))
```

