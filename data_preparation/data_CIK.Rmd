---
title: "data_CIK"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = normalizePath(".."))

library(broom)
library(readxl)
library(stringr)
library(lubridate)
library(googlesheets4)
library(rnoaa)
library(hms)
library(tidyverse)

```


# Data archived on KNB - sites through 2017.

Read in data files saved on S drive. These are all the data that Sue archived on KNB. These include some Bristol Bay data that will have to be removed. The site IDs for just Cook Inlet sites all have "CIK" in the name.

```{r}
cik.files <- list.files("S:/Stream Temperature Data/Cook Inletkeeper", pattern = ".csv", full.names = TRUE)

cik.files <- cik.files[!grepl("SiteLevelMetadata_Mauger", cik.files)]

```

Metadata

```{r}
cik_md <- read_csv("S:\\Stream Temperature Data\\Cook Inletkeeper\\SiteLevelMetadata_Mauger.csv") 

cik_knb_md <- cik_md %>% 
  filter(grepl("CIK", SiteID)) %>% 
  select(AKOATS_ID, SiteID, SourceName, Contact_person, Latitude, Longitude, Waterbody_name)

cik_knb_md

```

Combined data files and get information from metadata file.

```{r}
cik.data <- cik.files %>% 
  map_df(function(x) read_csv(x) %>% 
  mutate(file_name = gsub(".csv","",basename(x))))

cik.data <- left_join(cik.data, cik_knb_md %>% select(AKOATS_ID, SiteID, Waterbody_name)) %>% 
  filter(grepl("CIK", SiteID))

cik.data #removed ~500K rows of data that were from Bristol bay, still > 4M rows of data for cook inlet.
```

# New data

Sue sent over two zip files saved in separate folders. One is a submission to NCEAS that she thinks didn't get uploaded -- folder name is "new submissions Dec 2018". It looks like some data from 2017 to 2018. The second zip folder has data from 2018-2020 and is called "UAA". There is a metadata file in each one with site IDs that should link to AKOATs.

I'll remove the Bristol Bay sites and read them in separately in the SWSHP repo. All the Bristol Bay data are being used for one project with Erik and then also being brought into this repo for the larger AKSSF project.

```{r}
cik_folder <- ("S:/Stream Temperature Data/Cook Inletkeeper")

cik_files1 <- list.files(paste(cik_folder, "/February_2021/new submissions Dec 2018", sep = ""), full.names = TRUE)
cik_files1 <- cik_files1[!grepl("new submissions Dec 2018.xlsx", cik_files1)]

cik_files2 <- list.files(paste(cik_folder, "/February_2021/UAA", sep = ""), full.names = TRUE)
cik_files2 <- cik_files2[!grepl("new submissions Jan 2021.xlsx", cik_files2)]

```

Read in each set of data and combine them.

```{r}

cik_dat1 <- map_df(cik_files1, function(x) read_excel(x) %>% mutate(file_name = gsub(".xlsx", "", basename(x))))

summary(cik_dat1)

#two time fields are independent
cik_dat1 %>% 
  count(is.na(Time), is.na(`Time, GMT-08:00`))

#for site naming pattern, trim last 8 characters (_xx_xxxx) to get SiteID
cik_dat1 %>% distinct(file_name)

cik_dat1 <- cik_dat1 %>% 
  mutate(sampleDate = as.Date(Date),
         sampleTime = case_when(is.na(`Time, GMT-08:00`) ~ as_hms(Time),
                                TRUE ~ as_hms(`Time, GMT-08:00`)),
         Temperature = `Temp, °C`,
         SiteID = substr(file_name, 1, nchar(file_name) - 8))  %>% 
  select(SiteID, sampleDate, sampleTime, Temperature)
  
```

```{r}
cik_dat2 <- map_df(cik_files2, function(x) read_excel(x) %>% mutate(file_name = gsub(".xlsx", "", basename(x))))

summary(cik_dat2)

#for site naming pattern, trim last 8 characters (_xx_xxxx) to get SiteID
cik_dat2 %>% distinct(file_name)

cik_dat2 <- cik_dat2 %>% 
  mutate(sampleDate = as.Date(Date),
         sampleTime = as_hms(`Time, GMT-08:00`),
         Temperature = `Temp, °C`,
         SiteID = substr(file_name, 1, nchar(file_name) - 8))  %>% 
  select(SiteID, sampleDate, sampleTime, Temperature)
  
cik_dat <- bind_rows(cik_dat1, cik_dat2) %>% 
  filter(grepl("CIK", SiteID))

cik_dat %>% distinct(SiteID)
```

Make sure that SiteIDs in the data link to AKOATs and get the waterbody name so that we have it for plotting.

```{r}
akoats <- read_excel("S:/EPA AKTEMP/AKOATS_DATA_2020_working.xlsx", sheet = "AKOATS_COMPLETE") 

#filter on continuous sites
akoats <- akoats %>% 
  filter(Sample_interval == "continuous")

```

All are there.

```{r}
cik_dat <- cik_dat %>% 
  left_join(akoats %>% select(Agency_ID, seq_id, Waterbody_name), by = c("SiteID" = "Agency_ID")) %>% 
  rename(AKOATS_ID = seq_id)

```

Combine with 2017 data, but add UseData field first.

```{r}
cik_dat <- cik_dat %>% 
  mutate(UseData = 1)

intersect(names(cik.data), names(cik_dat))
cik_dat <- bind_rows(cik.data, cik_dat)

cik_dat %>% 
  distinct(SiteID, AKOATS_ID, Waterbody_name, year = year(sampleDate)) %>% 
  group_by(SiteID, AKOATS_ID, Waterbody_name) %>% 
  summarize(n = n(),
            minYr = min(year),
            maxYr = max(year))
```

# Review data

Check for duplicates in this dataset. Add in DT first.

```{r}
cik_dat <- cik_dat %>% 
  mutate(DT = as.POSIXct(paste(sampleDate, sampleTime)))
```

Mean and sd of differences between duplicate values by site. They are all really low so I think it's best to average them.

```{r}
dups <- cik_dat %>% 
  count(SiteID, DT) %>% 
  filter(n > 1)

dup_diffs <- left_join(dups, cik_dat) %>% 
  ungroup() %>% 
  group_by(SiteID, DT) %>% 
  mutate(id = row_number()) %>% 
  select(SiteID, id, DT, Temperature) %>% 
  pivot_wider(names_from = id, values_from = Temperature) %>% 
  mutate(diff = abs(`1` - `2`))

dup_diffs %>% 
  group_by(SiteID) %>% 
  summarize(mn_diff = mean(diff, na.rm = TRUE),
            sd_diff = sd(diff, na.rm = TRUE)) %>% 
  arrange(desc(mn_diff))

```
Cleaning out duplicate values in this dataset by taking average.

```{r}
cik_dat <- cik_dat %>% 
  group_by(AKOATS_ID, SiteID, Waterbody_name, sampleDate, sampleTime, DT, UseData) %>% 
  summarize(Temperature = mean(Temperature))
```

We should also check to see if any of the data from the KNB submission and new set of files overlaps with sites that we used in the stream temperature models. Import the final data frame for those models and check if any sites overlap.

```{r}


```


Add year for plotting.

```{r}
cik_dat <- cik_dat %>% 
  mutate(year = year(sampleDate)) 
```




Plot of raw data, but Sue typically provides only QAed data. Some useData==0 from KNB.

```{r}
cik_dat %>% ungroup() %>% count(UseData)

cikSites <- cik_dat %>% distinct(SiteID)

pdf("output/CIK raw data by site.pdf")

for(i in 1:nrow(cikSites)) {
  dat <- left_join(cikSites %>% slice(i), cik_dat)
  p1 <- dat %>% 
    filter(UseData == 1) %>%
    ggplot(aes(x = dt, y = Temperature)) +
    geom_line() +
    # facet_wrap(~year) +
    labs(title = dat %>% distinct(SiteID))
  print(p1)  
}

dev.off()

```


Save data for downstream reports. 

```{r}
saveRDS(cik_dat, "data_preparation/formatted_data/cik_dat.rds")
```


