---
title: "data_QA_USFS_Chugach"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warnings = FALSE, messages = FALSE)
knitr::opts_knit$set(root.dir = normalizePath("..")) #this sets the root.dir up one level back to the project so that paths are relative to the project directory.

library(readxl)
library(stringr)
library(lubridate)
library(googlesheets4)
library(rnoaa)
library(hms)
library(tidyverse)
```

Data QA is done using dynamic plots and reviewing data by site. For AKSSF,
we are only reviewing June - September data and flagging obvious air
temperatures. Burials are a lot harder to confirm without a duplicate logger.


# QA data for air temperatures
## Pull in Airtemp for comparison from NOAA GHCN stations

Go to [GHCN Daily](https://www.ncdc.noaa.gov/cdo-web/search?datasetid=GHCND)
website and locate stations - try to identify stations with mean/min/max
air temps for period of interest.

Note - have had trouble with lcd function recently

```{r NOAA data, message=FALSE, warning=FALSE}

#Token obtained from NOAA to access API
noaaTok <- "LmempjqpgcLSxDQWiLvuaOAGmscrQCrb"

# lcd(station = "26410", year = 2013)
# 
# ncdc_locs(locationcategoryid = "CITY")

#Station Codes for area of interest
cd.climStat <- c( "USC00502179","USW00026410", "USW00096405")


cd.climDat <- tibble( name = c( "CORDOVA WWTP", "CORDOVA AIRPORT",
"CORDOVA 14"),
                 id = cd.climStat)

# Pull Climate data from Cordova Airport
climDat <- meteo_pull_monitors(cd.climStat)  
str(climDat)
  

cd.climDat <- cd.climDat %>% 
  left_join( climDat[,c( "id", "date", "tmax", "tmin")], by = 'id') %>% 
  filter( date >= "2008-06-01",
          date <= "2020-12-30",
          name == "CORDOVA AIRPORT") %>% 
  # Temperature and Precipitation values are in tenths of degree/mm
  mutate_if( is.numeric, ~ . * 0.1) %>% 
  mutate(year = as.factor(year(date)),
         day = yday(date),
         dt = as.POSIXct(paste(date), format = "%Y-%m-%d"))
  

cd.climDat

```
# Begin QA
# STOPPED HERE - ADDED IN NEW DATA 1/25/21
MOVE TO QA
MAKE REVIEW GROUPS - TIDAL/NOT

Quick plots of data to make sure they read in ok. Start by summarizing daily means because quicker to plot. Looks like some bad winter temps well below zero that could be clipped later. No obvious air temps in summer as everything is < = 20 or so.

```{r plot of dialy means, message=FALSE, warning=FALSE}

fschdat %>% 
  group_by(SiteID, sampleDate) %>% 
  summarize(meant = mean(Temperature)) %>% 
  ggplot(aes(x = sampleDate, y = meant)) +
  geom_line() +
  facet_wrap(~SiteID)

```

Wrong! The sub-daily temps show more errors, definitely some air temps that need to be removed. This will be a good dataset for testing scripts, although it will probably need cleaning sooner rather than later for AKSSF.

```{r plot of raw data}

fschdat %>% 
  ggplot(aes(x = dt, y = Temperature)) +
  geom_line() +
  facet_wrap(~SiteID)


```

Rolling pdf of raw data to send to Luca and check on status of data QA.

```{r plot of raw data by site-year}
fs_sites <- fschdat %>% distinct(Agency_ID, year) %>% arrange(Agency_ID, year)

pdf("data_preparation/USFS Raw Data by Site and Year.pdf", width = 11, height = 8.5)

for(i in 1:nrow(fs_sites)) {
  dat <- left_join(fs_sites %>% slice(i), fschdat)
  subtitle <- dat %>% distinct(useSite) %>% pull(useSite)
  p1 <- dat %>% 
    ggplot(aes(x = dt, y = Temperature)) +
    geom_line() +
    labs(title = fs_sites %>% slice(i) %>% unite(site_year) %>%
           pull(site_year),
         subtitle = paste0("Use Site: ", subtitle)) +
    theme(legend.position = "bottom")
  print(p1)
}

dev.off()

```


Save file for summary report.

```{r}
fschdat

names(fschdat)

fschdat %>% 
  rename(SiteID = Agency_ID) %>% 
  select(SiteID, useSite, sampleDate, sampleTime, dt, year, Temperature) %>% 
  saveRDS("output/fschdat.rds")
```

# Save QAed dataset for AKTEMP

Save a copy of the final data with the QA flags for AKTEMP as a .csv.

# Remove sites

Filter to remove any sites that are not being used for the AKSSF analysis. These could be sites with very incomplete time series or sites that have hydrologic inputs that affect stream temperatures -- e.g. tidally-influenced sites. Note that a list of these sites may be developed at the top of this script so that we don't spend time reviewing data for these sites. That is fine, just note that the sites not used for the AKSSF analysis were NOT reviewed.

# Save daily data

Save a copy of the daily statistics in the final data folder for the AKSSF analysis. There are two helper functions that add the mode of the time difference for each day and calculate the daily min, mean, and max and removed days with less than 90% of measurements.

* temp_msmt_freq
* daily_screen

```{r}
source("day_and_month_functions.R")

```

