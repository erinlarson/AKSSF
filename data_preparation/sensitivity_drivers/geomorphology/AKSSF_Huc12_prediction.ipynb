{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Huc 12 Predictors\n",
    "## Test 19020302 HUC 8 incl chugach nforest\n",
    "All Huc 12s- Intersect w/catchments and find catchment (find downstream most catchment) with most upstream contribution and build watersheds for all ds catchments\n",
    "\n",
    "Keep -\n",
    "mnwtd_slope\n",
    "% lake\n",
    "summer precip - Runs in R but need downstream point (centroid of ds catchment)\n",
    "predict for huc8\n",
    "\n",
    "Visualize by HUC12 - Join data back to Huc12"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section\n",
    "Import modules\n",
    "Set/Create Workspaces\n",
    " * Create Huc12 Catchment dataset to store catchments that will have watersheds generated\n",
    " * Crate Catchment point dataset to store catchment centroids\n",
    "Collect Data\n",
    " * Set up data dictionary with VPU as key and store path to source data\n",
    "    * Slope - Can link to already created slope rasters from original covariates worflow\n",
    "    * NHDPlus Waterbodies - Can link to waterbody feature clase from original covariate workflow\n",
    "Merge Data\n",
    " * Merge data together and or copy to local/in_memory and check that all projections match\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports complete\n",
      "sys paths ['C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\AKSSF\\\\data_preparation\\\\sensitivity_drivers\\\\geomorphology', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\Resources\\\\ArcPy', 'C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\AKSSF', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\python37.zip', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\DLLs', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3', '', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\Resources\\\\ArcToolbox\\\\Scripts', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\Resources\\\\ArcToolBox\\\\Scripts', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\Resources\\\\ArcToolBox\\\\Scripts\\\\archydro', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\Resources\\\\ArcToolBox\\\\Scripts\\\\GRAIP', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\future-0.18.2-py3.7.egg', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\pytz-2020.1-py3.7.egg', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\pywin32_ctypes-0.2.0-py3.7.egg', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\pywin32security', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\sympy-1.5.1-py3.7.egg', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\dwmerrigan\\\\.ipython']\n",
      "2022-01-31 00:30:41.121445\n"
     ]
    }
   ],
   "source": [
    "import os, arcpy, sys\n",
    "arcpy.env.overwriteOutput = True\n",
    "sr = arcpy.SpatialReference(3338)  #'NAD_1983_Alaska_Albers'\n",
    "arcpy.env.outputCoordinateSystem = sr\n",
    "\n",
    "print('imports complete')\n",
    "print(f'sys paths {sys.path}')\n",
    "print (datetime.datetime.now())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Function to add key, value pairs to dictionary\n",
    "def append_value(dict_obj, key, value):\n",
    "    # Check if key exist in dict or not\n",
    "    if key in dict_obj:\n",
    "        # Key exist in dict.\n",
    "        # Check if type of value of key is list or not\n",
    "        if not isinstance(dict_obj[key], list):\n",
    "            # If type is not list then make it list\n",
    "            dict_obj[key] = [dict_obj[key]]\n",
    "        # Append the value in list\n",
    "        dict_obj[key].append(value)\n",
    "    else:\n",
    "        # As key is not in dict,\n",
    "        # so, add key-value pair\n",
    "        dict_obj[key] = value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Collect NHDPlus Datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020202_HU8_GDB.gdb', 'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020301_HU8_GDB.gdb', 'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020302_HU8_GDB.gdb', 'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020401_HU8_GDB.gdb', 'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020402_HU8_GDB.gdb', 'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020501_HU8_GDB.gdb', 'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020502_HU8_GDB.gdb', 'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020503_HU8_GDB.gdb', 'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020504_HU8_GDB.gdb', 'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020505_HU8_GDB.gdb', 'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020601_HU8_GDB.gdb', 'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020602_HU8_GDB.gdb', 'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020800_HU8_GDB.gdb']\n",
      "19020202\n",
      "19020301\n",
      "19020302\n",
      "19020401\n",
      "19020402\n",
      "19020501\n",
      "19020502\n",
      "19020503\n",
      "19020504\n",
      "19020505\n",
      "19020601\n",
      "19020602\n",
      "19020800\n",
      "['D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020101_HU8_GDB.gdb', 'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020102_HU8_GDB.gdb', 'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020103_HU8_GDB.gdb', 'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020104_HU8_GDB.gdb']\n",
      "19020101\n",
      "19020102\n",
      "19020103\n",
      "19020104\n"
     ]
    }
   ],
   "source": [
    "#Create Dictionary to relate datasets to vpu\n",
    "vpuDict = {}\n",
    "# Walk through folders and subfolders to collect vpus\n",
    "\n",
    "#Path to folder with NHDPlus data separated by vpu\n",
    "nhdPlusfol = r'D:\\Basedata\\NHDPlus'\n",
    "rois = ['Cook_Inlet','Copper_River']\n",
    "vpuList = []\n",
    "regDict = {}\n",
    "\n",
    "#NHD folders - Update to new data downloaded Nov 8, 2021\n",
    "for roi in rois:\n",
    "    arcpy.env.workspace = os.path.join(nhdPlusfol,roi)\n",
    "    gdbs = arcpy.ListWorkspaces('NHDPLUS*','FileGDB')\n",
    "    print(gdbs)\n",
    "    Cats = []\n",
    "    VAA = []\n",
    "    waterbodies = []\n",
    "    flowlines = []\n",
    "\n",
    "    for gdb in gdbs:\n",
    "        arcpy.env.workspace = gdb\n",
    "        huc = gdb[-20:-12]\n",
    "        print(huc)\n",
    "        vpuList.append(huc)\n",
    "        append_value(vpuDict,huc,gdb)\n",
    "        datasets = arcpy.ListDatasets(feature_type='feature')\n",
    "        for ds in datasets:\n",
    "            for fc in arcpy.ListFeatureClasses(feature_dataset=ds):\n",
    "                if fc == \"NHDFlowline\":\n",
    "                    flowpath = os.path.join(arcpy.env.workspace, ds, fc)\n",
    "                    flowname = 'flowline_' + str(huc)\n",
    "                    append_value(vpuDict,huc,flowpath)\n",
    "                #     print(f'Copying {flowname}...')\n",
    "                #     flowcopypath = os.path.join(scratch, flowname)\n",
    "                #     arcpy.management.CopyFeatures(flowpath, flowcopypath)\n",
    "                #     flowlines.append(flowcopypath)\n",
    "                elif fc == \"NHDWaterbody\":\n",
    "                    waterbodyname = 'waterbody_' + str(huc)\n",
    "                    #waterbodycopypath = os.path.join(scratch, waterbodyname)\n",
    "                    waterpath = os.path.join(arcpy.env.workspace, ds, fc)\n",
    "                    #print(f'Copying {waterbodyname}...')\n",
    "                    append_value(vpuDict,huc,waterpath)\n",
    "                    # arcpy.management.CopyFeatures(waterpath, waterbodycopypath)\n",
    "                    # waterbodies.append(waterbodycopypath)\n",
    "                elif fc == \"NHDPlusCatchment\":\n",
    "                    catchpath = os.path.join(arcpy.env.workspace, ds, fc)\n",
    "                    append_value(vpuDict, huc, catchpath)\n",
    "                elif fc == \"WBDHU12\":\n",
    "                    hucpath = os.path.join(arcpy.env.workspace, ds, fc)\n",
    "                    append_value(vpuDict, huc, hucpath)\n",
    "\n",
    "        vaapath = os.path.join(arcpy.env.workspace, \"NHDPlusFlowlineVAA\")\n",
    "        #print(f'Vaa table at {vaapath} exists = {arcpy.Exists(vaapath)}')\n",
    "        append_value(vpuDict,huc,vaapath)\n",
    "        append_value(vpuDict,huc,roi)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "{'19020202': ['D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020202_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020202_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020202_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020202_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020202_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020202_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Cook_Inlet'],\n '19020301': ['D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020301_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020301_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020301_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020301_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020301_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020301_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Cook_Inlet'],\n '19020302': ['D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020302_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020302_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020302_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020302_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020302_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020302_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Cook_Inlet'],\n '19020401': ['D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020401_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020401_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020401_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020401_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020401_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020401_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Cook_Inlet'],\n '19020402': ['D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020402_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020402_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020402_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020402_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020402_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020402_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Cook_Inlet'],\n '19020501': ['D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020501_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020501_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020501_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020501_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020501_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020501_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Cook_Inlet'],\n '19020502': ['D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020502_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020502_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020502_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020502_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020502_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020502_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Cook_Inlet'],\n '19020503': ['D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020503_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020503_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020503_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020503_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020503_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020503_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Cook_Inlet'],\n '19020504': ['D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020504_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020504_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020504_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020504_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020504_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020504_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Cook_Inlet'],\n '19020505': ['D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020505_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020505_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020505_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020505_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020505_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020505_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Cook_Inlet'],\n '19020601': ['D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020601_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020601_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020601_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020601_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020601_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020601_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Cook_Inlet'],\n '19020602': ['D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020602_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020602_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020602_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020602_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020602_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020602_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Cook_Inlet'],\n '19020800': ['D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020800_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020800_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020800_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020800_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020800_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020800_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Cook_Inlet'],\n '19020101': ['D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020101_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020101_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020101_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020101_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020101_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020101_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Copper_River'],\n '19020102': ['D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020102_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020102_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020102_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020102_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020102_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020102_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Copper_River'],\n '19020103': ['D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020103_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020103_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020103_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020103_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020103_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020103_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Copper_River'],\n '19020104': ['D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020104_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020104_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020104_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020104_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020104_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020104_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Copper_River']}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vpuDict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scratch folder will be created D:\\\\huc12_Outputs\n",
      "Scratch GDB at D:\\\\huc12_Outputs\\\\huc12_scratch.gdb \n",
      "Using AWC events from D:\\Basedata\\AWC\\AWC_2021_SpeciesEvents.gdb\\awcEventArcs\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Scratch folder D:\\\\huc12_Outputs already exists\n",
      "----------\n",
      "Scratch folder D:\\\\huc12_Outputs\\\\huc12_scratch.gdb already exists\n",
      "----------\n",
      "Scratch folder for 19020202 already created at D:\\\\huc12_Outputs\\19020202_h12\n",
      "----------\n",
      "Scratch folder for 19020301 already created at D:\\\\huc12_Outputs\\19020301_h12\n",
      "----------\n",
      "Scratch folder for 19020302 already created at D:\\\\huc12_Outputs\\19020302_h12\n",
      "----------\n",
      "Scratch folder for 19020401 already created at D:\\\\huc12_Outputs\\19020401_h12\n",
      "----------\n",
      "Scratch folder for 19020402 already created at D:\\\\huc12_Outputs\\19020402_h12\n",
      "----------\n",
      "Scratch folder for 19020501 already created at D:\\\\huc12_Outputs\\19020501_h12\n",
      "----------\n",
      "Scratch folder for 19020502 already created at D:\\\\huc12_Outputs\\19020502_h12\n",
      "----------\n",
      "Scratch folder for 19020503 already created at D:\\\\huc12_Outputs\\19020503_h12\n",
      "----------\n",
      "Scratch folder for 19020504 already created at D:\\\\huc12_Outputs\\19020504_h12\n",
      "----------\n",
      "Scratch folder for 19020505 already created at D:\\\\huc12_Outputs\\19020505_h12\n",
      "----------\n",
      "Scratch folder for 19020601 already created at D:\\\\huc12_Outputs\\19020601_h12\n",
      "----------\n",
      "Scratch folder for 19020602 already created at D:\\\\huc12_Outputs\\19020602_h12\n",
      "----------\n",
      "Scratch folder for 19020800 already created at D:\\\\huc12_Outputs\\19020800_h12\n",
      "----------\n",
      "Scratch folder for 19020101 already created at D:\\\\huc12_Outputs\\19020101_h12\n",
      "----------\n",
      "Scratch folder for 19020102 already created at D:\\\\huc12_Outputs\\19020102_h12\n",
      "----------\n",
      "Scratch folder for 19020103 already created at D:\\\\huc12_Outputs\\19020103_h12\n",
      "----------\n",
      "Scratch folder for 19020104 already created at D:\\\\huc12_Outputs\\19020104_h12\n",
      "----------\n",
      "All scratch workspaces set\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'19020202': 'D:\\\\\\\\huc12_Outputs\\\\19020202_h12',\n '19020301': 'D:\\\\\\\\huc12_Outputs\\\\19020301_h12',\n '19020302': 'D:\\\\\\\\huc12_Outputs\\\\19020302_h12',\n '19020401': 'D:\\\\\\\\huc12_Outputs\\\\19020401_h12',\n '19020402': 'D:\\\\\\\\huc12_Outputs\\\\19020402_h12',\n '19020501': 'D:\\\\\\\\huc12_Outputs\\\\19020501_h12',\n '19020502': 'D:\\\\\\\\huc12_Outputs\\\\19020502_h12',\n '19020503': 'D:\\\\\\\\huc12_Outputs\\\\19020503_h12',\n '19020504': 'D:\\\\\\\\huc12_Outputs\\\\19020504_h12',\n '19020505': 'D:\\\\\\\\huc12_Outputs\\\\19020505_h12',\n '19020601': 'D:\\\\\\\\huc12_Outputs\\\\19020601_h12',\n '19020602': 'D:\\\\\\\\huc12_Outputs\\\\19020602_h12',\n '19020800': 'D:\\\\\\\\huc12_Outputs\\\\19020800_h12',\n '19020101': 'D:\\\\\\\\huc12_Outputs\\\\19020101_h12',\n '19020102': 'D:\\\\\\\\huc12_Outputs\\\\19020102_h12',\n '19020103': 'D:\\\\\\\\huc12_Outputs\\\\19020103_h12',\n '19020104': 'D:\\\\\\\\huc12_Outputs\\\\19020104_h12'}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set data dir equal to directory containing the AKSSF regional sub-folders.\n",
    "akssf_data_dir = r'D:\\\\GIS\\\\AKSSF'\n",
    "nhd_data_dir = r'D:\\\\Basedata\\\\NHDPlus'\n",
    "\n",
    "# Create dictionaries\n",
    "nhdDict = {}\n",
    "tauDict = {}\n",
    "inputDict = {\"'\":\"\",'\"':\"\"}\n",
    "scrDict = {}\n",
    "\n",
    "def replace_all(userinput, dic):\n",
    "    for i, j in dic.items():\n",
    "        userinput = userinput.replace(i, j)\n",
    "    return userinput\n",
    "\n",
    "\n",
    "# Create scratch workspace\n",
    "while True:\n",
    "    try:\n",
    "        userinput = replace_all((input('Input drive or directory to create scratch workspaces ex. \\'W:\\\\\\GIS\\'\\n') or 'D:\\\\GIS'),inputDict)\n",
    "        if not arcpy.Exists(userinput):\n",
    "            print('Path specified does not exist!\\nPlease re-enter a valid path')\n",
    "            continue\n",
    "        else:\n",
    "            scratchdrive = userinput\n",
    "            break\n",
    "    except arcpy.ExecuteError:\n",
    "            print(arcpy.GetMessages())\n",
    "\n",
    "huc12cv_scratchgdb = os.path.join(scratchdrive,r\"\\\\huc12_Outputs\\\\huc12_scratch.gdb\")\n",
    "huc12cv_scratchfol = os.path.dirname(huc12cv_scratchgdb)\n",
    "print(f'Scratch folder will be created {huc12cv_scratchfol}\\nScratch GDB at {huc12cv_scratchgdb} ')\n",
    "\n",
    "# Specify path to AWC events fc\n",
    "while True:\n",
    "    try:\n",
    "        userinput2 = replace_all((input('Input path to awc events feature class or shapefile. \\'\"J:\\\\GIS_data\\\\biota\\\\Aquatic\\\\Fauna\\\\AWC\\\\2021_Species_LifeStage.gdb\\\\AWC_2021_SpeciesEvents.gdb\\\\awcEventArcs\"\\'\\n') or\n",
    "                                  'D:\\\\Basedata\\\\AWC\\\\AWC_2021_SpeciesEvents.gdb\\\\awcEventArcs'), inputDict)\n",
    "        if not arcpy.Exists(userinput2):\n",
    "            print('Path specified does not exist!\\nPlease re-enter a valid path')\n",
    "            continue\n",
    "        else:\n",
    "            awc_events = userinput2\n",
    "            break\n",
    "    except arcpy.ExecuteError:\n",
    "            print(arcpy.GetMessages())\n",
    "\n",
    "print(f'Using AWC events from {awc_events}\\n {\"-\"*100}')\n",
    "\n",
    "# Create Scratch Workspaces and add to dictionary\n",
    "if not arcpy.Exists(huc12cv_scratchfol):\n",
    "    os.mkdir(huc12cv_scratchfol)\n",
    "    print(f'Creating scratch folder {huc12cv_scratchfol}')\n",
    "else:\n",
    "    print(f'Scratch folder {huc12cv_scratchfol} already exists')\n",
    "print('----------')\n",
    "\n",
    "if not arcpy.Exists(huc12cv_scratchgdb):\n",
    "    arcpy.CreateFileGDB_management(huc12cv_scratchfol,\"huc12_scratch.gdb\")\n",
    "    print(f'Creating scratch gdb {huc12cv_scratchgdb}')\n",
    "else:\n",
    "    print(f'Scratch folder {huc12cv_scratchgdb} already exists')\n",
    "print('----------')\n",
    "\n",
    "# Create VPU output folders\n",
    "for vpu in vpuList:\n",
    "    vpu_name = os.path.basename(vpu)\n",
    "    hucscratchpath = os.path.join(huc12cv_scratchfol, vpu_name + '_h12')\n",
    "    append_value(scrDict,vpu_name,hucscratchpath)\n",
    "    if not arcpy.Exists(hucscratchpath):\n",
    "        os.mkdir(hucscratchpath)\n",
    "        print (f'{vpu_name} does not have a scratch folder')\n",
    "        print (f'Creating contributing area scratch folder at  {hucscratchpath}')\n",
    "    else:\n",
    "        print(f'Scratch folder for {vpu_name} already created at {hucscratchpath}')\n",
    "\n",
    "    print('----------')\n",
    "print(f'All scratch workspaces set')\n",
    "scrDict\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 2\n",
    "### By Vector Processing Unit\n",
    "Identify downstream-most catchment for each Huc 12\n",
    " * Select by location and select catchment with most us contributing area\n",
    "    * NHDPlus\n",
    "        * Use update cursor to join TotalDrainageAreaSqKm from vaa table to catchment\n",
    "        * Find max value from selection and save as outlet catchment for that HUC12\n",
    "    * TauDEM\n",
    "        * DSContArea - Drainage area at the downstream end of the link. Generally this is one grid cell upstream of the downstream end because the drainage area at the downstream end grid cell includes the area of the stream being joined.\n",
    " * Generate Centroid point and append to centroid dataset\n",
    "    * Retain cat_id and Huc12-id\n",
    " * Append to HUC12 catchment dataset\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Basedata\\NHDPlus\\Cook_Inlet\\NHDPLUS_H_19020302_HU8_GDB.gdb. 0\n",
      "D:\\Basedata\\NHDPlus\\Cook_Inlet\\NHDPLUS_H_19020302_HU8_GDB.gdb\\NHDPlus\\NHDPlusCatchment. 1\n",
      "D:\\Basedata\\NHDPlus\\Cook_Inlet\\NHDPLUS_H_19020302_HU8_GDB.gdb\\WBD\\WBDHU12. 2\n",
      "D:\\Basedata\\NHDPlus\\Cook_Inlet\\NHDPLUS_H_19020302_HU8_GDB.gdb\\Hydrography\\NHDFlowline. 3\n",
      "D:\\Basedata\\NHDPlus\\Cook_Inlet\\NHDPLUS_H_19020302_HU8_GDB.gdb\\Hydrography\\NHDWaterbody. 4\n",
      "D:\\Basedata\\NHDPlus\\Cook_Inlet\\NHDPLUS_H_19020302_HU8_GDB.gdb\\NHDPlusFlowlineVAA. 5\n",
      "Cook_Inlet. 6\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "for v in vpuDict['19020302']:\n",
    "    print(f'{v}. {c}')\n",
    "    c+=1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020202 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020301 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "Huc 19020302 will be processed\n",
      "Catchments located D:\\Basedata\\NHDPlus\\Cook_Inlet\\NHDPLUS_H_19020302_HU8_GDB.gdb\\NHDPlus\\NHDPlusCatchment\n",
      "Vaas located D:\\Basedata\\NHDPlus\\Cook_Inlet\\NHDPLUS_H_19020302_HU8_GDB.gdb\\NHDPlusFlowlineVAA\n",
      "NHD waterbodies located D:\\Basedata\\NHDPlus\\Cook_Inlet\\NHDPLUS_H_19020302_HU8_GDB.gdb\\Hydrography\\NHDWaterbody\n",
      "Huc12s located D:\\Basedata\\NHDPlus\\Cook_Inlet\\NHDPLUS_H_19020302_HU8_GDB.gdb\\WBD\\WBDHU12\n",
      "****************************************************************************************************\n",
      "99 of 112 HUC12s in 19020302 intersect awc events input\n",
      "Finding outlet for HUC 190203021004 out of 80 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020303 out of 134 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020502 out of 93 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020503 out of 204 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203022002 out of 158 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020904 out of 115 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021601 out of 37 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021701 out of 71 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021104 out of 81 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021908 out of 43 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021405 out of 174 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203022004 out of 8 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021007 out of 151 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203022001 out of 23 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203022005 out of 26 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021602 out of 46 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021201 out of 129 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021406 out of 223 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020603 out of 50 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020702 out of 276 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020305 out of 451 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021103 out of 136 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020404 out of 80 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020501 out of 97 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021802 out of 47 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021801 out of 71 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020802 out of 24 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021505 out of 96 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021006 out of 47 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021806 out of 121 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021805 out of 71 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020806 out of 144 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021003 out of 309 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020903 out of 219 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020703 out of 111 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021808 out of 24 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021803 out of 48 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020804 out of 86 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021904 out of 100 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020205 out of 177 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020202 out of 259 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020701 out of 103 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020902 out of 196 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020101 out of 105 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020604 out of 20 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020406 out of 122 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021804 out of 27 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021604 out of 23 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021905 out of 25 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021205 out of 292 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020801 out of 27 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021606 out of 44 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020201 out of 84 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021605 out of 56 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021607 out of 24 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020803 out of 61 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020302 out of 42 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021504 out of 135 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021303 out of 185 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021005 out of 68 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020407 out of 292 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020408 out of 259 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021203 out of 206 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021403 out of 96 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021704 out of 26 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021102 out of 133 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021409 out of 195 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021407 out of 36 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020304 out of 113 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021501 out of 81 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021002 out of 45 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021902 out of 24 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021401 out of 206 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203022003 out of 36 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020601 out of 56 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020607 out of 31 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020504 out of 68 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020301 out of 77 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020102 out of 206 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021503 out of 112 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021408 out of 29 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020203 out of 167 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021903 out of 50 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020705 out of 430 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020606 out of 43 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021807 out of 21 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020605 out of 41 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020405 out of 70 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020704 out of 86 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020204 out of 90 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021204 out of 267 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020403 out of 85 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021901 out of 79 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021404 out of 62 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021603 out of 10 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203021809 out of 63 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020608 out of 33 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020609 out of 50 catchments.\n",
      "************************************************************\n",
      "Finding outlet for HUC 190203020602 out of 60 catchments.\n",
      "************************************************************\n",
      "Creating copy of 99 outlet catchments for Huc 19020302 at D:\\\\huc12_Outputs\\\\huc12_scratch.gdb\\HUC_19020302_out_cats\n",
      "****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020401 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020402 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020501 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020502 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020503 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020504 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020505 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020601 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020602 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020800 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020101 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020102 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020103 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020104 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of HUC12s to be processed\n",
    "import operator\n",
    "proclist = ['19020302']\n",
    "outletDict = {}\n",
    "outletList = []\n",
    "outletcats = []\n",
    "outletcatpts = []\n",
    "\n",
    "for vpu in vpuList:\n",
    "    if vpu in proclist:\n",
    "        try:\n",
    "            print(f'Huc {vpu} will be processed')\n",
    "            # Inputs\n",
    "            cats = vpuDict[vpu][1]\n",
    "            vaas = vpuDict[vpu][5]\n",
    "            hucs = vpuDict[vpu][2]\n",
    "            lakes = vpuDict[vpu][4]\n",
    "            #Output names and paths\n",
    "            outletcatsname = 'HUC_' + str(vpu) +'_out_cats'\n",
    "            outcatspath = os.path.join(huc12cv_scratchgdb,outletcatsname)\n",
    "            outletcatptsname = 'HUC_' + str(vpu) +'_out_catspts'\n",
    "            outcatptspath = os.path.join(huc12cv_scratchgdb,outletcatptsname)\n",
    "            # Select by expression for outlet cats\n",
    "\n",
    "            print (f'Catchments located {cats}')\n",
    "            print (f'Vaas located {vaas}')\n",
    "            print (f'NHD waterbodies located {lakes}')\n",
    "            print (f'Huc12s located {hucs}')\n",
    "            # Use list comprehension to build a dictionary from a da SearchCursor\n",
    "            fields = ['NHDPlusID','TotDASqKm']\n",
    "            # Build Value dictionary to relate NHDPlus id to contributing area\n",
    "            valueDict = {r[0]:(r[1:]) for r in arcpy.da.SearchCursor(vaas, fields)}\n",
    "            hucselect = arcpy.SelectLayerByLocation_management(hucs,'INTERSECT',awc_events,'','NEW_SELECTION')\n",
    "            print(('*'*100))\n",
    "            print(f'{arcpy.GetCount_management(hucselect)} of {arcpy.GetCount_management(hucs)} HUC12s in {vpu} intersect awc events input')\n",
    "            with arcpy.da.SearchCursor(hucselect,['HUC12','SHAPE@']) as cur:\n",
    "                for row in cur:\n",
    "                    #print(f'Processing HUC {row[0]}')\n",
    "                    inhuc = row[1]\n",
    "                    cat_layer = arcpy.MakeFeatureLayer_management(cats,'cat_layer')\n",
    "                    # Select by location using awc and huc 12\n",
    "                    arcpy.SelectLayerByLocation_management(cat_layer,'HAVE_THEIR_CENTER_IN',inhuc,'','NEW_SELECTION')\n",
    "                    print(f'Finding outlet for HUC {row[0]} out of {arcpy.GetCount_management(cat_layer)} catchments.\\n{(\"*\" * 60)}')\n",
    "                    catList = [r[0] for r in arcpy.da.SearchCursor(cat_layer, 'NHDPlusID')]\n",
    "                    intersect = list(set(catList).intersection(valueDict))\n",
    "                    catDict = {i:(valueDict[i]) for i in intersect}\n",
    "                    # Find Catchment with max drainage area\n",
    "                    outcatch = max(catDict.items(), key = operator.itemgetter(1))[0]\n",
    "                    append_value(outletDict, row[0], int(outcatch))\n",
    "                    outletList.append(int(outcatch))\n",
    "            outlet_cats = arcpy.MakeFeatureLayer_management(cats,'outlet_cats')\n",
    "            out_expression ='\"NHDPlusID\" IN ' + str(tuple(outletList))\n",
    "            #print(out_expression)\n",
    "            outlet_cats_select = arcpy.SelectLayerByAttribute_management(outlet_cats,'NEW_SELECTION', out_expression)\n",
    "            print(f'Creating copy of {arcpy.GetCount_management(outlet_cats)} outlet catchments for Huc {vpu} at {outcatspath}')\n",
    "            print(('*'*100))\n",
    "            arcpy.FeatureClassToFeatureClass_conversion(outlet_cats_select,huc12cv_scratchgdb,outletcatsname)\n",
    "            cat_points = arcpy.FeatureToPoint_management(outcatspath, outcatptspath, 'INSIDE')\n",
    "            outletcats.append(outcatspath)\n",
    "            outletcatpts.append(outcatptspath)\n",
    "\n",
    "        except Exception:\n",
    "            e = sys.exc_info()[1]\n",
    "            print(e.args[0])\n",
    "            arcpy.AddError(e.args[0])\n",
    "\n",
    "    else:\n",
    "        print(('-'*100))\n",
    "        print(f'Huc {vpu} will not be processed')\n",
    "        print(('-'*100),'\\n')\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 3\n",
    "### Generate watersheds\n",
    "Iterate over HUC12 catchment dataset and create watersheds\n",
    " * Append output wtd to wtd dataset - Link back to catchment using catID (create catIDcon for unique identifier field)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Huc 19020302 will be processed\n",
      "Creating index for D:\\\\huc12_Outputs\\\\huc12_scratch.gdb\\huc_19020302_cats\n",
      "1. Starting watershed for: 75004400005344\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "2. Starting watershed for: 75004400011755\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "3. Starting watershed for: 75004400010352\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "4. Starting watershed for: 75004400007996\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "5. Starting watershed for: 75004400004850\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "6. Starting watershed for: 75004400005312\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "7. Starting watershed for: 75004400004652\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "8. Starting watershed for: 75004400006033\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "9. Starting watershed for: 75004400009412\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "10. Starting watershed for: 75004400008887\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "11. Starting watershed for: 75004400010754\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "12. Starting watershed for: 75004400006170\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "13. Starting watershed for: 75004400008216\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "14. Starting watershed for: 75004400007830\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "15. Starting watershed for: 75004400009109\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "16. Starting watershed for: 75004400007550\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "17. Starting watershed for: 75004400003815\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "18. Starting watershed for: 75004400000334\n",
      "Elapsed time: (0:00:07)\n",
      "************************************************************\n",
      "19. Starting watershed for: 75004400010699\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "20. Starting watershed for: 75004400001136\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "21. Starting watershed for: 75004400007224\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "22. Starting watershed for: 75004400002041\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "23. Starting watershed for: 75004400011320\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "24. Starting watershed for: 75004400006433\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "25. Starting watershed for: 75004400005985\n",
      "Elapsed time: (0:00:13)\n",
      "************************************************************\n",
      "26. Starting watershed for: 75004400005909\n",
      "Elapsed time: (0:00:11)\n",
      "************************************************************\n",
      "27. Starting watershed for: 75004400008859\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "28. Starting watershed for: 75004400001616\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "29. Starting watershed for: 75004400000862\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "30. Starting watershed for: 75004400010386\n",
      "Elapsed time: (0:00:14)\n",
      "************************************************************\n",
      "31. Starting watershed for: 75004400008899\n",
      "Elapsed time: (0:00:14)\n",
      "************************************************************\n",
      "32. Starting watershed for: 75004400010422\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "33. Starting watershed for: 75004400003876\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "34. Starting watershed for: 75004400009792\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "35. Starting watershed for: 75004400005660\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "36. Starting watershed for: 75004400010402\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "37. Starting watershed for: 75004400001521\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "38. Starting watershed for: 75004400000153\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "39. Starting watershed for: 75004400007465\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "40. Starting watershed for: 75004400010175\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "41. Starting watershed for: 75004400010221\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "42. Starting watershed for: 75004400011086\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "43. Starting watershed for: 75004400011230\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "44. Starting watershed for: 75004400006692\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "45. Starting watershed for: 75004400010610\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "46. Starting watershed for: 75004400001464\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "47. Starting watershed for: 75004400010320\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "48. Starting watershed for: 75004400002957\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "49. Starting watershed for: 75004400000141\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "50. Starting watershed for: 75004400010328\n",
      "Elapsed time: (0:00:05)\n",
      "************************************************************\n",
      "51. Starting watershed for: 75004400003189\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "52. Starting watershed for: 75004400007512\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "53. Starting watershed for: 75004400010270\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "54. Starting watershed for: 75004400002954\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "55. Starting watershed for: 75004400004450\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "56. Starting watershed for: 75004400002953\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "57. Starting watershed for: 75004400002718\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "58. Starting watershed for: 75004400003165\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "59. Starting watershed for: 75004400000370\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "60. Starting watershed for: 75004400008242\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "61. Starting watershed for: 75004400008192\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "62. Starting watershed for: 75004400002279\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "63. Starting watershed for: 75004400008856\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "64. Starting watershed for: 75004400009331\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "65. Starting watershed for: 75004400007493\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "66. Starting watershed for: 75004400010351\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "67. Starting watershed for: 75004400001652\n",
      "Elapsed time: (0:00:09)\n",
      "************************************************************\n",
      "68. Starting watershed for: 75004400010639\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "69. Starting watershed for: 75004400011676\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "70. Starting watershed for: 75004400004680\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "71. Starting watershed for: 75004400008539\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "72. Starting watershed for: 75004400001443\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "73. Starting watershed for: 75004400002950\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "74. Starting watershed for: 75004400004743\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "75. Starting watershed for: 75004400009198\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "76. Starting watershed for: 75004400007686\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "77. Starting watershed for: 75004400000627\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "78. Starting watershed for: 75004400004213\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "79. Starting watershed for: 75004400002258\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "80. Starting watershed for: 75004400003230\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "81. Starting watershed for: 75004400001670\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "82. Starting watershed for: 75004400007351\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "83. Starting watershed for: 75004400001656\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "84. Starting watershed for: 75004400004166\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "85. Starting watershed for: 75004400010627\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "86. Starting watershed for: 75004400001569\n",
      "Elapsed time: (0:00:12)\n",
      "************************************************************\n",
      "87. Starting watershed for: 75004400004707\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "88. Starting watershed for: 75004400011322\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "89. Starting watershed for: 75004400001134\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "90. Starting watershed for: 75004400004344\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "91. Starting watershed for: 75004400009562\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "92. Starting watershed for: 75004400003768\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "93. Starting watershed for: 75004400000171\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "94. Starting watershed for: 75004400009308\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "95. Starting watershed for: 75004400010337\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "96. Starting watershed for: 75004400008879\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "97. Starting watershed for: 75004400004457\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "98. Starting watershed for: 75004400005924\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "99. Starting watershed for: 75004400004455\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "'da.UpdateCursor' object has no attribute 'UpdateRows'\n",
      "Process completed at 2022-01-31 00:36 (Elapsed time: 0:04:23)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Begin generating watersheds\n",
    "# List of HUC12s to be processed\n",
    "import arcpy, time, datetime, os\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "# steps 4-9 for loop to create watersheds\n",
    "arcpy.env.workspace = huc12cv_scratchgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.qualifiedFieldNames = False\n",
    "sr = arcpy.SpatialReference(3338)  #'NAD_1983_Alaska_Albers'\n",
    "arcpy.env.outputCoordinateSystem = sr\n",
    "\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "\n",
    "proclist = ['19020302']\n",
    "wtdDict = {}\n",
    "\n",
    "\n",
    "for vpu in vpuList:\n",
    "    if vpu in proclist:\n",
    "        try:\n",
    "            wtdList=[]\n",
    "            print(f'Huc {vpu} will be processed')\n",
    "            # Inputs\n",
    "            cats = vpuDict[vpu][1]\n",
    "            vaas = vpuDict[vpu][5]\n",
    "            hucs = vpuDict[vpu][2]\n",
    "            lakes = vpuDict[vpu][4]\n",
    "            streams = vpuDict[vpu][3]\n",
    "            catscopy = arcpy.CopyFeatures_management(cats,os.path.join(huc12cv_scratchgdb,'huc_'+str(vpu)+'_cats'))\n",
    "            # Get list of index names for cats merge and add index if not already created\n",
    "            index_names = [i.name for i in arcpy.ListIndexes(catscopy)]\n",
    "\n",
    "            if 'NHDPlusID_index' not in index_names:\n",
    "                print (f'Creating index for {catscopy}')\n",
    "                arcpy.AddIndex_management(catscopy,'NHDPlusID','NHDPlusID_index')\n",
    "            else:\n",
    "                print(f'{catscopy} Indexed')\n",
    "\n",
    "            #watersheds feature dataset for storing fcs\n",
    "            fdatname = 'Huc_' + str(vpu) + '_Watersheds'\n",
    "            fdat = os.path.join(huc12cv_scratchgdb, fdatname)\n",
    "            if not arcpy.Exists(fdat):\n",
    "                arcpy.management.CreateFeatureDataset(huc12cv_scratchgdb, fdatname, sr)\n",
    "            else:\n",
    "                print(f'{fdat} exists for {vpu}')\n",
    "\n",
    "            vaa_df1 = pd.DataFrame(arcpy.da.TableToNumPyArray(vaas, (\"NHDPlusID\", \"FromNode\", \"ToNode\", \"StartFlag\")))\n",
    "            stream_df = pd.DataFrame(arcpy.da.TableToNumPyArray(streams, (\"NHDPlusID\", \"FType\")))\n",
    "            dfs = [vaa_df1, stream_df]\n",
    "            vaa_df = reduce(lambda left,right: pd.merge(left,right,on='NHDPlusID',how=\"outer\"), dfs)\n",
    "            # remove pipelines\n",
    "            vaa_df = vaa_df[(vaa_df['FType'] != 428 )]\n",
    "            vaa_df\n",
    "\n",
    "            c=1\n",
    "\n",
    "            for id in outletList:\n",
    "                # Start iter timing function\n",
    "                iteration_start = time.time()\n",
    "\n",
    "                print(f\"{c}. Starting watershed for: \" + str(id))\n",
    "                rec = [id]\n",
    "                up_ids = []\n",
    "                up_ids.append(rec)\n",
    "                rec_len = len(rec)\n",
    "                hws_sum = 0\n",
    "\n",
    "                while rec_len != hws_sum:\n",
    "                    fromnode = vaa_df.loc[vaa_df[\"NHDPlusID\"].isin(rec), \"FromNode\"]\n",
    "                    rec = vaa_df.loc[vaa_df[\"ToNode\"].isin(fromnode), \"NHDPlusID\"]\n",
    "                    rec_len = len(rec)\n",
    "                    rec_hws = vaa_df.loc[vaa_df[\"ToNode\"].isin(fromnode), \"StartFlag\"]\n",
    "                    hws_sum = sum(rec_hws)\n",
    "                    up_ids.append(rec)\n",
    "                #up_ids is a list with more than numbers, use extend to only keep numeric nhdplusids\n",
    "                newup_ids = []\n",
    "                for x in up_ids:\n",
    "                    newup_ids.extend(x)\n",
    "\n",
    "                tempLayer = \"catsLyr\"\n",
    "                expression = '\"NHDPlusID\" IN ({0})'.format(', '.join(map(str, newup_ids)) or 'NULL')\n",
    "                arcpy.MakeFeatureLayer_management(cats, tempLayer, where_clause=expression)\n",
    "                outdis = \"memory/wtd_\" + str(round(id))\n",
    "                outwtd = os.path.join(fdat,'wtd_'+ str(id))\n",
    "\n",
    "                dis = arcpy.Dissolve_management(tempLayer, outdis)\n",
    "                watershed = arcpy.EliminatePolygonPart_management(dis, outwtd,\"PERCENT\", \"0 SquareKilometers\", 90, \"CONTAINED_ONLY\")\n",
    "                wtdList.append(outwtd)\n",
    "                append_value(wtdDict,vpu,outwtd)\n",
    "                c=c+1\n",
    "\n",
    "                # Stop iteration timer\n",
    "                iteration_stop = time.time()\n",
    "                iter_time = int (iteration_stop - iteration_start)\n",
    "                print(f'Elapsed time: ({datetime.timedelta(seconds=iter_time)})')\n",
    "                print(f'{\"*\"*60}')\n",
    "\n",
    "            wtd_merge = arcpy.Merge_management(wtdList, os.path.join(huc12cv_scratchgdb,'AKSSF_HUC_'+str(vpu)+'_wtds_merge'),'','ADD_SOURCE_INFO')\n",
    "            arcpy.AddField_management(wtd_merge,'cat_ID_con','TEXT')\n",
    "            arcpy.AddField_management(wtd_merge,'cat_ID','DOUBLE')\n",
    "            arcpy.AddField_management(wtd_merge,'cat_ID_txt','TEXT')\n",
    "            arcpy.AddField_management(wtd_merge,'NHDPlusID','DOUBLE')\n",
    "            with arcpy.da.UpdateCursor(wtd_merge,['MERGE_SRC','NHDPlusID','cat_ID_con','cat_ID','cat_ID_txt']) as cur:\n",
    "                for row in cur:\n",
    "                    # Pull nhdplus id from merge source and calculate fields\n",
    "                    nhdplusid= int(row[0].split('\\\\')[-1:][0].split('_')[1])\n",
    "                    row[1] = nhdplusid\n",
    "                    row[2] = vpuDict[vpu][6] + '_' + str(nhdplusid)\n",
    "                    row[3] = nhdplusid\n",
    "                    row[4] = str(nhdplusid)\n",
    "                    cur.updateRow(row)\n",
    "                del(row)\n",
    "            del(cur)\n",
    "\n",
    "        except:\n",
    "            e = sys.exc_info()[1]\n",
    "            print(e.args[0])\n",
    "            arcpy.AddError(e.args[0])\n",
    "\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "\n",
    "# Report success\n",
    "print(f'Process completed at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "      f'(Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print('----------')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "vpu = '19020302'\n",
    "wtd_merge = arcpy.Merge_management(wtdList, os.path.join(huc12cv_scratchgdb,'AKSSF_HUC_'+str(vpu)+'_wtds_merge'),'','ADD_SOURCE_INFO')\n",
    "arcpy.AddField_management(wtd_merge,'cat_ID_con','TEXT')\n",
    "arcpy.AddField_management(wtd_merge,'cat_ID','DOUBLE')\n",
    "arcpy.AddField_management(wtd_merge,'cat_ID_txt','TEXT')\n",
    "arcpy.AddField_management(wtd_merge,'NHDPlusID','DOUBLE')\n",
    "with arcpy.da.UpdateCursor(wtd_merge,['MERGE_SRC','NHDPlusID','cat_ID_con','cat_ID','cat_ID_txt']) as cur:\n",
    "    for row in cur:\n",
    "        # Pull nhdplus id from merge source and calculate fields\n",
    "        nhdplusid= int(row[0].split('\\\\')[-1:][0].split('_')[1])\n",
    "        row[1] = nhdplusid\n",
    "        row[2] = vpuDict[vpu][6] + '_' + str(nhdplusid)\n",
    "        row[3] = nhdplusid\n",
    "        row[4] = str(nhdplusid)\n",
    "        cur.updateRow(row)\n",
    "    del(row)\n",
    "del(cur)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 4\n",
    "###Calculate covariates\n",
    "Iterate over watersheds and calculate the following:\n",
    "* Mean wtd slope\n",
    "* % Lake Cover\n",
    "* Mean LCLD\n",
    "* % Glacier Cover"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cook_Inlet_19020302\n",
      "Begin Slope zonal statistics min/mean/max std dev for watersheds and catchments in Cook_Inlet region\n",
      "Calculating Cook_Inlet watershed slope zonal stats...\n",
      "Begin tabulate intersection between D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\AKSSF_NHDPlus_LakePond_alb and watersheds in Cook_Inlet region\n",
      "----------\n",
      "['OBJECTID', 'cat_ID_txt', 'FType', 'wtd_lake_area_sqm', 'wtd_lake_per', 'region', 'cat_ID', 'cat_ID_con']\n",
      "Begin tabulate intersection between D:\\\\GIS\\\\AKSSF\\\\Cook_Inlet\\\\Cook_Inlet.gdb\\\\glaciers and watersheds in Cook_Inlet region\n",
      "----------\n",
      "['OBJECTID', 'cat_ID_txt', 'O1Region', 'wtd_glacier_area_sqm', 'wtd_glacier_per', 'region', 'cat_ID', 'cat_ID_con']\n",
      "Year: 2001 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2001_lcld_32.tif\n",
      "Calculating 2001_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2001_lcld_32.tif\n",
      "Zonal Stats for 2001_lcld_32.tif Elapsed time: (0:00:13)\n",
      "Year: 2002 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2002_lcld_32.tif\n",
      "Calculating 2002_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2002_lcld_32.tif\n",
      "Zonal Stats for 2002_lcld_32.tif Elapsed time: (0:00:12)\n",
      "Year: 2003 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2003_lcld_32.tif\n",
      "Calculating 2003_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2003_lcld_32.tif\n",
      "Zonal Stats for 2003_lcld_32.tif Elapsed time: (0:00:12)\n",
      "Year: 2004 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2004_lcld_32.tif\n",
      "Calculating 2004_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2004_lcld_32.tif\n",
      "Zonal Stats for 2004_lcld_32.tif Elapsed time: (0:00:12)\n",
      "Year: 2005 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2005_lcld_32.tif\n",
      "Calculating 2005_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2005_lcld_32.tif\n",
      "Zonal Stats for 2005_lcld_32.tif Elapsed time: (0:00:12)\n",
      "Year: 2006 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2006_lcld_32.tif\n",
      "Calculating 2006_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2006_lcld_32.tif\n",
      "Zonal Stats for 2006_lcld_32.tif Elapsed time: (0:00:12)\n",
      "Year: 2007 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2007_lcld_32.tif\n",
      "Calculating 2007_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2007_lcld_32.tif\n",
      "Zonal Stats for 2007_lcld_32.tif Elapsed time: (0:00:12)\n",
      "Year: 2008 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2008_lcld_32.tif\n",
      "Calculating 2008_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2008_lcld_32.tif\n",
      "Zonal Stats for 2008_lcld_32.tif Elapsed time: (0:00:12)\n",
      "Year: 2009 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2009_lcld_32.tif\n",
      "Calculating 2009_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2009_lcld_32.tif\n",
      "Zonal Stats for 2009_lcld_32.tif Elapsed time: (0:00:12)\n",
      "Year: 2010 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2010_lcld_32.tif\n",
      "Calculating 2010_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2010_lcld_32.tif\n",
      "Zonal Stats for 2010_lcld_32.tif Elapsed time: (0:00:12)\n",
      "Year: 2011 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2011_lcld_32.tif\n",
      "Calculating 2011_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2011_lcld_32.tif\n",
      "Zonal Stats for 2011_lcld_32.tif Elapsed time: (0:00:13)\n",
      "Year: 2012 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2012_lcld_32.tif\n",
      "Calculating 2012_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2012_lcld_32.tif\n",
      "Zonal Stats for 2012_lcld_32.tif Elapsed time: (0:00:12)\n",
      "Year: 2013 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2013_lcld_32.tif\n",
      "Calculating 2013_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2013_lcld_32.tif\n",
      "Zonal Stats for 2013_lcld_32.tif Elapsed time: (0:00:12)\n",
      "Year: 2014 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2014_lcld_32.tif\n",
      "Calculating 2014_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2014_lcld_32.tif\n",
      "Zonal Stats for 2014_lcld_32.tif Elapsed time: (0:00:12)\n",
      "Year: 2015 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2015_lcld_32.tif\n",
      "Calculating 2015_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2015_lcld_32.tif\n",
      "Zonal Stats for 2015_lcld_32.tif Elapsed time: (0:00:12)\n",
      "Year: 2016 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2016_lcld_32.tif\n",
      "Calculating 2016_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2016_lcld_32.tif\n",
      "Zonal Stats for 2016_lcld_32.tif Elapsed time: (0:00:12)\n",
      "Year: 2017 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2017_lcld_32.tif\n",
      "Calculating 2017_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2017_lcld_32.tif\n",
      "Zonal Stats for 2017_lcld_32.tif Elapsed time: (0:00:12)\n",
      "Year: 2018 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2018_lcld_32.tif\n",
      "Calculating 2018_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2018_lcld_32.tif\n",
      "Zonal Stats for 2018_lcld_32.tif Elapsed time: (0:00:12)\n",
      "Year: 2019 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2019_lcld_32.tif\n",
      "Calculating 2019_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2019_lcld_32.tif\n",
      "Zonal Stats for 2019_lcld_32.tif Elapsed time: (0:00:12)\n",
      "Process completed at 2022-01-31 01:59 (Elapsed time: 0:04:56)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "from arcpy.sa import *\n",
    "\n",
    "# Path to lcld rasters\n",
    "lcld_folder = r'D:\\\\Basedata\\\\LCLD_rasters_archive'\n",
    "\n",
    "# Create Dictionary to link input raster/fc data from original covariate workflow\n",
    "dataDict={'Cook_Inlet':[r\"D:\\\\GIS\\\\AKSSF\\\\Cook_Inlet\\\\slope.tif\",r\"D:\\\\GIS\\\\AKSSF\\\\Cook_Inlet\\\\Cook_Inlet.gdb\\\\glaciers\"],\n",
    "          'Copper_River':[r\"D:\\\\GIS\\\\AKSSF\\\\Copper_River\\\\slope.tif\",r\"D:\\\\GIS\\\\AKSSF\\\\Copper_River\\\\Copper_River.gdb\\\\glaciers\"],\n",
    "          'Prince_William_Sound':[r\"D:\\\\GIS\\\\AKSSF\\\\Prince_William_Sound\\\\slope.tif\",r\"D:\\\\GIS\\\\AKSSF\\\\Prince_William_Sound\\\\Prince_William_Sound.gdb\\\\glaciers\"]\n",
    "          }\n",
    "\n",
    "# Set output gdb\n",
    "outgdb = huc12cv_scratchgdb\n",
    "\n",
    "# Separate data by\n",
    "nhdplus_dat = ['Cook_Inlet','Copper_River']\n",
    "tauDem_dat = ['Bristol_Bay', 'Kodiak', 'Prince_William_Sound']\n",
    "\n",
    "# Lists to store output tables\n",
    "wtd_lp_tabint_tables = []\n",
    "wtd_glac_tabint_tables = []\n",
    "wtd_slope_ztables = []\n",
    "lcld_Ztables = []\n",
    "\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "\n",
    "# Iterate over merged watersheds and calculate covariates\n",
    "arcpy.env.workspace = huc12cv_scratchgdb\n",
    "for fc in arcpy.ListFeatureClasses('*wtds_merge'):\n",
    "    vpu = fc[10:18]\n",
    "    roi = vpuDict[vpu][6]\n",
    "    tableid = roi + '_' + str(vpu)\n",
    "    print(tableid)\n",
    "    # Set Slope raster from data dictionary\n",
    "    slope_rast = dataDict[vpuDict[vpu][6]][0]\n",
    "    # Set glacier fc from data dictionary\n",
    "    glac_fc = dataDict[vpuDict[vpu][6]][1]\n",
    "    wtd_cur_fields = ['cat_ID_txt', 'cat_ID',\"cat_ID_con\"]\n",
    "    if roi in nhdplus_dat:\n",
    "        lakes_fc = r\"D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\AKSSF_NHDPlus_LakePond_alb\"\n",
    "    # Set data and variables unique to regions with TauDEM Data\n",
    "    elif roi in tauDem_dat:\n",
    "        lakes_fc = r\"D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\AKSSF_NHD_LakesPonds_alb\"\n",
    "\n",
    "    wtds = []\n",
    "\n",
    "    # Slope variables\n",
    "    wtd_merge_slope_table_name = tableid + \"_Watershed_Merge_SlopeZstats\"\n",
    "    wtd_merge_slope_table_path = os.path.join(outgdb, wtd_merge_slope_table_name)\n",
    "    # Lakes Ponds variables\n",
    "    wtd_merge_lp_table_name = tableid + \"_Watershed_Merge_LakesPonds\"\n",
    "    wtd_merge_lp_table_path = os.path.join(outgdb, wtd_merge_lp_table_name)\n",
    "    # Glaciers\n",
    "    wtd_merge_glac_table_name = tableid + \"_Watershed_Merge_Glaciers\"\n",
    "    wtd_merge_glac_table_path = os.path.join(outgdb, wtd_merge_glac_table_name)\n",
    "\n",
    "    # Watershed slope Zonal Statistics\n",
    "    print(f'Begin Slope zonal statistics min/mean/max std dev for watersheds and catchments in {roi}'\n",
    "          f' region')\n",
    "\n",
    "    # Slope Zonal statistics  for watersheds\n",
    "    print(f'Calculating {roi} watershed slope zonal stats...')\n",
    "    arcpy.env.snapRaster = slope_rast\n",
    "    arcpy.env.cellSize = slope_rast\n",
    "    wtd_slope_metrics_table = ZonalStatisticsAsTable(in_zone_data = wtd_merge,\n",
    "                                                    zone_field = wtd_cur_fields[0],\n",
    "                                                    in_value_raster = slope_rast,\n",
    "                                                    out_table = wtd_merge_slope_table_path,\n",
    "                                                    statistics_type='ALL'\n",
    "                                                    )\n",
    "\n",
    "    # Add region identifier field for watershed tables                                                )\n",
    "    arcpy.AddField_management(wtd_slope_metrics_table,'region',field_type='TEXT')\n",
    "    # Add cat_ID_Con field\n",
    "    arcpy.AddField_management(wtd_slope_metrics_table,'cat_ID_con',field_type='TEXT')\n",
    "\n",
    "    # Update region field\n",
    "    with arcpy.da.UpdateCursor(wtd_slope_metrics_table,['region','cat_ID_txt','cat_ID_con']) as cur:\n",
    "        for row in cur:\n",
    "            row[0] = roi\n",
    "            strval = str(row[1])\n",
    "            row[2] = roi+\"_\"+strval.replace(\".0\",\"\")\n",
    "            # Update\n",
    "            cur.updateRow(row)\n",
    "        del(row)\n",
    "    del(cur)\n",
    "    # Append watershed slope table to list\n",
    "    wtd_slope_ztables.append(wtd_slope_metrics_table)\n",
    "\n",
    "    # Percent Lakes Ponds using Tabulate Intersection for watersheds\n",
    "    print(f'Begin tabulate intersection between {lakes_fc} and watersheds in {roi} region')\n",
    "    print('----------')\n",
    "    wtd_lp_tabint = arcpy.TabulateIntersection_analysis(wtd_merge,\n",
    "                                                        zone_fields=wtd_cur_fields[0],\n",
    "                                                        in_class_features=lakes_fc,\n",
    "                                                        out_table=wtd_merge_lp_table_path,\n",
    "                                                        class_fields='Ftype',\n",
    "                                                        out_units=\"SQUARE_METERS\"\n",
    "                                                        )\n",
    "    # Add region and cat id fields\n",
    "    arcpy.AlterField_management(wtd_lp_tabint,'PERCENTAGE','wtd_lake_per','wtd_lake_per')\n",
    "    arcpy.AlterField_management(wtd_lp_tabint,'AREA','wtd_lake_area_sqm','wtd_lake_area_sqm')\n",
    "    arcpy.AddField_management(wtd_lp_tabint, 'region', field_type='TEXT')\n",
    "    arcpy.AddField_management(wtd_lp_tabint, wtd_cur_fields[1], field_type='TEXT')\n",
    "    arcpy.AddField_management(wtd_lp_tabint, wtd_cur_fields[2], field_type='TEXT')\n",
    "    wtdlpfields = [f.name for f in arcpy.ListFields(wtd_lp_tabint)]\n",
    "    print (wtdlpfields)\n",
    "    with arcpy.da.UpdateCursor(wtd_lp_tabint, wtdlpfields) as cur:\n",
    "        for row in cur:\n",
    "            strval = str(row[1])\n",
    "            row[5] = roi\n",
    "            row[6] = strval.replace('.0','')\n",
    "            row[7] = roi +'_'+ strval.replace(\".0\",\"\")\n",
    "            # Update\n",
    "            cur.updateRow(row)\n",
    "        del(row)\n",
    "    del(cur)\n",
    "\n",
    "    # Append watershed lakes ponds table to list\n",
    "    wtd_lp_tabint_tables.append(wtd_lp_tabint)\n",
    "\n",
    "    # Percent glaciers using Tabulate Intersection for watersheds\n",
    "    print(f'Begin tabulate intersection between {glac_fc} and watersheds in {roi} region')\n",
    "    print('----------')\n",
    "    wtd_glac_tabint = arcpy.TabulateIntersection_analysis(wtd_merge,\n",
    "                                                        zone_fields=wtd_cur_fields[0],\n",
    "                                                        in_class_features=glac_fc,\n",
    "                                                        out_table=wtd_merge_glac_table_path,\n",
    "                                                        class_fields='O1Region',\n",
    "                                                        out_units=\"SQUARE_METERS\"\n",
    "                                                        )\n",
    "    # Add region and cat id fields\n",
    "    arcpy.AlterField_management(wtd_glac_tabint,'PERCENTAGE','wtd_glacier_per','wtd_glacier_per')\n",
    "    arcpy.AlterField_management(wtd_glac_tabint,'AREA','wtd_glacier_area_sqm','wtd_glacier_area_sqm')\n",
    "    arcpy.AddField_management(wtd_glac_tabint, 'region', field_type='TEXT')\n",
    "    arcpy.AddField_management(wtd_glac_tabint, wtd_cur_fields[1], field_type='TEXT')\n",
    "    arcpy.AddField_management(wtd_glac_tabint, wtd_cur_fields[2], field_type='TEXT')\n",
    "    wtdglacfields = [f.name for f in arcpy.ListFields(wtd_glac_tabint)]\n",
    "    print (wtdglacfields)\n",
    "    with arcpy.da.UpdateCursor(wtd_glac_tabint, wtdglacfields) as cur:\n",
    "        for row in cur:\n",
    "            strval = str(row[1])\n",
    "            row[5] = roi\n",
    "            row[6] = strval.replace('.0','')\n",
    "            row[7] = roi +'_'+ strval.replace(\".0\",\"\")\n",
    "            # Update\n",
    "            cur.updateRow(row)\n",
    "        del(row)\n",
    "    del(cur)\n",
    "    # Append watershed percent north table to list\n",
    "    wtd_glac_tabint_tables.append(wtd_glac_tabint)\n",
    "\n",
    "    # Begin LCLD calculations\n",
    "    walk = arcpy.da.Walk(lcld_folder, datatype='RasterDataset')\n",
    "    for dirpath, dirnames, filenames in walk:\n",
    "        for filename in filenames:\n",
    "            raspath = os.path.join(dirpath, filename)\n",
    "            year = filename[0:4]\n",
    "            lcld_outname = 'lcld_'+str(year)+'_zStats'\n",
    "            lcld_outpath = os.path.join(outgdb, lcld_outname)\n",
    "            print(f'Year: {year} - raster path {raspath}')\n",
    "            colname = 'wtd_lcld_mn_' + str(year)\n",
    "            # lcld zonal statistics as table for all akssf watersheds\n",
    "            print(f'Calculating {filename} zonal stats for all AKSSF watersheds...')\n",
    "            #arcpy.env.snapRaster = raspath\n",
    "            #arcpy.env.cellSize = raspath\n",
    "            try:\n",
    "                # Begin Zonal Stats\n",
    "                zstat_start = time.time()\n",
    "                print(f'Begin zonal stats for {filename}')\n",
    "                lcld_table = ZonalStatisticsAsTable(in_zone_data = fc,\n",
    "                                                                zone_field = 'cat_ID_con',\n",
    "                                                                in_value_raster = raspath,\n",
    "                                                                out_table = lcld_outpath,\n",
    "                                                                statistics_type='MEAN'\n",
    "                                                                )\n",
    "                # Append zTable to table list\n",
    "                lcld_Ztables.append(lcld_outpath)\n",
    "                arcpy.AlterField_management(lcld_table,'MEAN', colname,colname)\n",
    "                proc_list = [row[0] for row in arcpy.da.SearchCursor(lcld_table,'cat_ID_con')]\n",
    "                zstat_stop = time.time()\n",
    "                zstat_time = int (zstat_stop - zstat_start)\n",
    "                print(f'Zonal Stats for {filename} Elapsed time: ({datetime.timedelta(seconds=zstat_time)})')\n",
    "\n",
    "\n",
    "            except:\n",
    "                e = sys.exc_info()[1]\n",
    "                print(e.args[0])\n",
    "                arcpy.AddError(e.args[0])\n",
    "\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "\n",
    "# Report success\n",
    "print(f'Process completed at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "      f'(Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print('----------')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Examine tables and merge/export"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lcld_2001_zStats\n",
      "lcld_2002_zStats\n",
      "lcld_2003_zStats\n",
      "lcld_2004_zStats\n",
      "lcld_2005_zStats\n",
      "lcld_2006_zStats\n",
      "lcld_2007_zStats\n",
      "lcld_2008_zStats\n",
      "lcld_2009_zStats\n",
      "lcld_2010_zStats\n",
      "lcld_2011_zStats\n",
      "lcld_2012_zStats\n",
      "lcld_2013_zStats\n",
      "lcld_2014_zStats\n",
      "lcld_2015_zStats\n",
      "lcld_2016_zStats\n",
      "lcld_2017_zStats\n",
      "lcld_2018_zStats\n",
      "lcld_2019_zStats\n"
     ]
    },
    {
     "data": {
      "text/plain": "                           wtd_lcld_mn_2001  wtd_lcld_mn_2002  \\\ncat_ID_con                                                      \nCook_Inlet_75004400005344        520.509051        508.405433   \nCook_Inlet_75004400011755        564.444009        553.189850   \nCook_Inlet_75004400010352        509.551592        501.181799   \nCook_Inlet_75004400007996        504.175142        495.784529   \nCook_Inlet_75004400004850        484.997404        487.153397   \n...                                     ...               ...   \nCook_Inlet_75004400010337        475.481973        482.757579   \nCook_Inlet_75004400008879        473.000779        479.593725   \nCook_Inlet_75004400004457        482.066856        485.844861   \nCook_Inlet_75004400005924        478.103658        485.468504   \nCook_Inlet_75004400004455        490.843163        488.031708   \n\n                           wtd_lcld_mn_2003  wtd_lcld_mn_2004  \\\ncat_ID_con                                                      \nCook_Inlet_75004400005344        505.377240        500.963714   \nCook_Inlet_75004400011755        546.676839        545.389134   \nCook_Inlet_75004400010352        491.832787        493.722468   \nCook_Inlet_75004400007996        489.857588        491.170970   \nCook_Inlet_75004400004850        451.456256        482.279436   \n...                                     ...               ...   \nCook_Inlet_75004400010337        423.842961        477.607190   \nCook_Inlet_75004400008879        430.429066        472.965813   \nCook_Inlet_75004400004457        443.333986        484.460604   \nCook_Inlet_75004400005924        435.507130        482.883556   \nCook_Inlet_75004400004455        455.239659        486.764625   \n\n                           wtd_lcld_mn_2005  wtd_lcld_mn_2006  \\\ncat_ID_con                                                      \nCook_Inlet_75004400005344        500.532097        515.671108   \nCook_Inlet_75004400011755        543.951730        556.857700   \nCook_Inlet_75004400010352        494.759142        507.035132   \nCook_Inlet_75004400007996        489.220219        502.619685   \nCook_Inlet_75004400004850        469.999586        485.523631   \n...                                     ...               ...   \nCook_Inlet_75004400010337        464.195834        473.934574   \nCook_Inlet_75004400008879        469.316728        477.245322   \nCook_Inlet_75004400004457        467.505422        485.081167   \nCook_Inlet_75004400005924        461.210466        478.689286   \nCook_Inlet_75004400004455        471.112494        487.524519   \n\n                           wtd_lcld_mn_2007  wtd_lcld_mn_2008  \\\ncat_ID_con                                                      \nCook_Inlet_75004400005344        509.995206        522.716878   \nCook_Inlet_75004400011755        552.409089        559.785748   \nCook_Inlet_75004400010352        498.694661        517.818537   \nCook_Inlet_75004400007996        495.572548        508.803808   \nCook_Inlet_75004400004850        481.105462        495.159942   \n...                                     ...               ...   \nCook_Inlet_75004400010337        469.370365        473.545688   \nCook_Inlet_75004400008879        459.450837        476.794236   \nCook_Inlet_75004400004457        483.132374        491.201997   \nCook_Inlet_75004400005924        477.094741        484.974631   \nCook_Inlet_75004400004455        481.886031        493.923468   \n\n                           wtd_lcld_mn_2009  wtd_lcld_mn_2010  \\\ncat_ID_con                                                      \nCook_Inlet_75004400005344        505.710495        519.811718   \nCook_Inlet_75004400011755        551.837955        554.837759   \nCook_Inlet_75004400010352        491.611237        508.359131   \nCook_Inlet_75004400007996        490.665353        500.640127   \nCook_Inlet_75004400004850        478.876774        483.054496   \n...                                     ...               ...   \nCook_Inlet_75004400010337        476.126278        474.148137   \nCook_Inlet_75004400008879        477.664237        470.348740   \nCook_Inlet_75004400004457        477.718749        481.870984   \nCook_Inlet_75004400005924        475.984779        478.832972   \nCook_Inlet_75004400004455        480.029365        487.341816   \n\n                           wtd_lcld_mn_2011  wtd_lcld_mn_2012  \\\ncat_ID_con                                                      \nCook_Inlet_75004400005344        507.799762        520.476156   \nCook_Inlet_75004400011755        550.503730        561.177930   \nCook_Inlet_75004400010352        500.773588        513.361570   \nCook_Inlet_75004400007996        495.863432        507.356903   \nCook_Inlet_75004400004850        483.135788        496.730896   \n...                                     ...               ...   \nCook_Inlet_75004400010337        478.633391        479.490321   \nCook_Inlet_75004400008879        472.191278        481.256098   \nCook_Inlet_75004400004457        483.173043        496.106864   \nCook_Inlet_75004400005924        480.536786        490.866367   \nCook_Inlet_75004400004455        485.337057        496.918620   \n\n                           wtd_lcld_mn_2013  wtd_lcld_mn_2014  \\\ncat_ID_con                                                      \nCook_Inlet_75004400005344        520.574698        494.189799   \nCook_Inlet_75004400011755        553.761947        539.041351   \nCook_Inlet_75004400010352        511.525629        481.955786   \nCook_Inlet_75004400007996        509.346870        478.528016   \nCook_Inlet_75004400004850        502.512729        444.622105   \n...                                     ...               ...   \nCook_Inlet_75004400010337        494.054570        466.436651   \nCook_Inlet_75004400008879        490.865165        469.645157   \nCook_Inlet_75004400004457        501.102991        438.825152   \nCook_Inlet_75004400005924        497.288233        444.013029   \nCook_Inlet_75004400004455        499.986261        448.828650   \n\n                           wtd_lcld_mn_2015  wtd_lcld_mn_2016  \\\ncat_ID_con                                                      \nCook_Inlet_75004400005344        497.637066        509.934038   \nCook_Inlet_75004400011755        542.309656        543.853671   \nCook_Inlet_75004400010352        481.891787        496.708530   \nCook_Inlet_75004400007996        484.090911        491.223736   \nCook_Inlet_75004400004850        451.619080        452.742992   \n...                                     ...               ...   \nCook_Inlet_75004400010337        432.107032        441.154316   \nCook_Inlet_75004400008879        423.882979        438.889834   \nCook_Inlet_75004400004457        444.976096        451.657545   \nCook_Inlet_75004400005924        438.265750        445.608104   \nCook_Inlet_75004400004455        456.618872        462.515358   \n\n                           wtd_lcld_mn_2017  wtd_lcld_mn_2018  \\\ncat_ID_con                                                      \nCook_Inlet_75004400005344        510.466283        506.270304   \nCook_Inlet_75004400011755        548.696056        545.134762   \nCook_Inlet_75004400010352        496.161511        503.096208   \nCook_Inlet_75004400007996        490.668783        490.608826   \nCook_Inlet_75004400004850        479.077717        477.712043   \n...                                     ...               ...   \nCook_Inlet_75004400010337        471.937621        475.286969   \nCook_Inlet_75004400008879        466.550128        468.182090   \nCook_Inlet_75004400004457        476.677755        476.303059   \nCook_Inlet_75004400005924        474.754330        471.987825   \nCook_Inlet_75004400004455        476.844836        477.910791   \n\n                           wtd_lcld_mn_2019  \ncat_ID_con                                   \nCook_Inlet_75004400005344        503.402322  \nCook_Inlet_75004400011755        540.182484  \nCook_Inlet_75004400010352        497.693959  \nCook_Inlet_75004400007996        493.742622  \nCook_Inlet_75004400004850        475.224581  \n...                                     ...  \nCook_Inlet_75004400010337        455.941913  \nCook_Inlet_75004400008879        461.628005  \nCook_Inlet_75004400004457        470.164198  \nCook_Inlet_75004400005924        463.714536  \nCook_Inlet_75004400004455        474.398831  \n\n[99 rows x 19 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>wtd_lcld_mn_2001</th>\n      <th>wtd_lcld_mn_2002</th>\n      <th>wtd_lcld_mn_2003</th>\n      <th>wtd_lcld_mn_2004</th>\n      <th>wtd_lcld_mn_2005</th>\n      <th>wtd_lcld_mn_2006</th>\n      <th>wtd_lcld_mn_2007</th>\n      <th>wtd_lcld_mn_2008</th>\n      <th>wtd_lcld_mn_2009</th>\n      <th>wtd_lcld_mn_2010</th>\n      <th>wtd_lcld_mn_2011</th>\n      <th>wtd_lcld_mn_2012</th>\n      <th>wtd_lcld_mn_2013</th>\n      <th>wtd_lcld_mn_2014</th>\n      <th>wtd_lcld_mn_2015</th>\n      <th>wtd_lcld_mn_2016</th>\n      <th>wtd_lcld_mn_2017</th>\n      <th>wtd_lcld_mn_2018</th>\n      <th>wtd_lcld_mn_2019</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Cook_Inlet_75004400005344</th>\n      <td>520.509051</td>\n      <td>508.405433</td>\n      <td>505.377240</td>\n      <td>500.963714</td>\n      <td>500.532097</td>\n      <td>515.671108</td>\n      <td>509.995206</td>\n      <td>522.716878</td>\n      <td>505.710495</td>\n      <td>519.811718</td>\n      <td>507.799762</td>\n      <td>520.476156</td>\n      <td>520.574698</td>\n      <td>494.189799</td>\n      <td>497.637066</td>\n      <td>509.934038</td>\n      <td>510.466283</td>\n      <td>506.270304</td>\n      <td>503.402322</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400011755</th>\n      <td>564.444009</td>\n      <td>553.189850</td>\n      <td>546.676839</td>\n      <td>545.389134</td>\n      <td>543.951730</td>\n      <td>556.857700</td>\n      <td>552.409089</td>\n      <td>559.785748</td>\n      <td>551.837955</td>\n      <td>554.837759</td>\n      <td>550.503730</td>\n      <td>561.177930</td>\n      <td>553.761947</td>\n      <td>539.041351</td>\n      <td>542.309656</td>\n      <td>543.853671</td>\n      <td>548.696056</td>\n      <td>545.134762</td>\n      <td>540.182484</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010352</th>\n      <td>509.551592</td>\n      <td>501.181799</td>\n      <td>491.832787</td>\n      <td>493.722468</td>\n      <td>494.759142</td>\n      <td>507.035132</td>\n      <td>498.694661</td>\n      <td>517.818537</td>\n      <td>491.611237</td>\n      <td>508.359131</td>\n      <td>500.773588</td>\n      <td>513.361570</td>\n      <td>511.525629</td>\n      <td>481.955786</td>\n      <td>481.891787</td>\n      <td>496.708530</td>\n      <td>496.161511</td>\n      <td>503.096208</td>\n      <td>497.693959</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400007996</th>\n      <td>504.175142</td>\n      <td>495.784529</td>\n      <td>489.857588</td>\n      <td>491.170970</td>\n      <td>489.220219</td>\n      <td>502.619685</td>\n      <td>495.572548</td>\n      <td>508.803808</td>\n      <td>490.665353</td>\n      <td>500.640127</td>\n      <td>495.863432</td>\n      <td>507.356903</td>\n      <td>509.346870</td>\n      <td>478.528016</td>\n      <td>484.090911</td>\n      <td>491.223736</td>\n      <td>490.668783</td>\n      <td>490.608826</td>\n      <td>493.742622</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004850</th>\n      <td>484.997404</td>\n      <td>487.153397</td>\n      <td>451.456256</td>\n      <td>482.279436</td>\n      <td>469.999586</td>\n      <td>485.523631</td>\n      <td>481.105462</td>\n      <td>495.159942</td>\n      <td>478.876774</td>\n      <td>483.054496</td>\n      <td>483.135788</td>\n      <td>496.730896</td>\n      <td>502.512729</td>\n      <td>444.622105</td>\n      <td>451.619080</td>\n      <td>452.742992</td>\n      <td>479.077717</td>\n      <td>477.712043</td>\n      <td>475.224581</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010337</th>\n      <td>475.481973</td>\n      <td>482.757579</td>\n      <td>423.842961</td>\n      <td>477.607190</td>\n      <td>464.195834</td>\n      <td>473.934574</td>\n      <td>469.370365</td>\n      <td>473.545688</td>\n      <td>476.126278</td>\n      <td>474.148137</td>\n      <td>478.633391</td>\n      <td>479.490321</td>\n      <td>494.054570</td>\n      <td>466.436651</td>\n      <td>432.107032</td>\n      <td>441.154316</td>\n      <td>471.937621</td>\n      <td>475.286969</td>\n      <td>455.941913</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400008879</th>\n      <td>473.000779</td>\n      <td>479.593725</td>\n      <td>430.429066</td>\n      <td>472.965813</td>\n      <td>469.316728</td>\n      <td>477.245322</td>\n      <td>459.450837</td>\n      <td>476.794236</td>\n      <td>477.664237</td>\n      <td>470.348740</td>\n      <td>472.191278</td>\n      <td>481.256098</td>\n      <td>490.865165</td>\n      <td>469.645157</td>\n      <td>423.882979</td>\n      <td>438.889834</td>\n      <td>466.550128</td>\n      <td>468.182090</td>\n      <td>461.628005</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004457</th>\n      <td>482.066856</td>\n      <td>485.844861</td>\n      <td>443.333986</td>\n      <td>484.460604</td>\n      <td>467.505422</td>\n      <td>485.081167</td>\n      <td>483.132374</td>\n      <td>491.201997</td>\n      <td>477.718749</td>\n      <td>481.870984</td>\n      <td>483.173043</td>\n      <td>496.106864</td>\n      <td>501.102991</td>\n      <td>438.825152</td>\n      <td>444.976096</td>\n      <td>451.657545</td>\n      <td>476.677755</td>\n      <td>476.303059</td>\n      <td>470.164198</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400005924</th>\n      <td>478.103658</td>\n      <td>485.468504</td>\n      <td>435.507130</td>\n      <td>482.883556</td>\n      <td>461.210466</td>\n      <td>478.689286</td>\n      <td>477.094741</td>\n      <td>484.974631</td>\n      <td>475.984779</td>\n      <td>478.832972</td>\n      <td>480.536786</td>\n      <td>490.866367</td>\n      <td>497.288233</td>\n      <td>444.013029</td>\n      <td>438.265750</td>\n      <td>445.608104</td>\n      <td>474.754330</td>\n      <td>471.987825</td>\n      <td>463.714536</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004455</th>\n      <td>490.843163</td>\n      <td>488.031708</td>\n      <td>455.239659</td>\n      <td>486.764625</td>\n      <td>471.112494</td>\n      <td>487.524519</td>\n      <td>481.886031</td>\n      <td>493.923468</td>\n      <td>480.029365</td>\n      <td>487.341816</td>\n      <td>485.337057</td>\n      <td>496.918620</td>\n      <td>499.986261</td>\n      <td>448.828650</td>\n      <td>456.618872</td>\n      <td>462.515358</td>\n      <td>476.844836</td>\n      <td>477.910791</td>\n      <td>474.398831</td>\n    </tr>\n  </tbody>\n</table>\n<p>99 rows  19 columns</p>\n</div>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for table in lcld_Ztables:\n",
    "    tblname = table[-16:]\n",
    "    print(tblname)\n",
    "    dfname = tblname + '_arr'\n",
    "    # Make df\n",
    "    dfname = pd.DataFrame()\n",
    "    lcld_field_list = []\n",
    "    for field in arcpy.ListFields(table):\n",
    "        lcld_field_list.append(field.name)\n",
    "        #print(f'{field.name}')\n",
    "    lcld_arr = arcpy.da.TableToNumPyArray(table, lcld_field_list)\n",
    "    dfname = pd.DataFrame(lcld_arr)\n",
    "    dfname = dfname.drop(['OBJECTID','ZONE_CODE', 'AREA', 'COUNT'],axis=1)\n",
    "    dfname = dfname.set_index('cat_ID_con')\n",
    "    dfs.append(dfname)\n",
    "\n",
    "# Merge all data frames together\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "lcld_df = reduce(lambda left,right: pd.merge(left,right,on='cat_ID_con',how=\"outer\"), dfs)\n",
    "lcld_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export dataframe to csv complete\n"
     ]
    }
   ],
   "source": [
    "# Export merged dataframe to csv\n",
    "outdir = r\"C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\"\n",
    "lcld_csv_out = os.path.join(outdir,'AKSSF_huc12_wtd_lcld_mn.csv')\n",
    "lcld_df.to_csv(lcld_csv_out, encoding = 'utf-8')\n",
    "print('Export dataframe to csv complete')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables merged\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Table names/paths\n",
    "wtd_per_glac_table_out = os.path.join(outgdb, 'AKSSF_huc12_wtd_glacier_per')\n",
    "wtd_per_lp_table_out = os.path.join(outgdb, 'AKSSF_huc12_wtd_lakepond_per')\n",
    "wtd_slope_table_out = os.path.join(outgdb, 'AKSSF_huc12_wtd_slope')\n",
    "wtd_lcld_table_out = os.path.join(outgdb, 'AKSSF_huc12_wtd_lcld')\n",
    "\n",
    "\n",
    "# Merge all regional tables together\n",
    "outtables = []\n",
    "wtd_slope = arcpy.Merge_management(wtd_slope_ztables, wtd_slope_table_out)\n",
    "outtables.append(wtd_slope)\n",
    "wtd_glac = arcpy.Merge_management(wtd_glac_tabint_tables, wtd_per_glac_table_out)\n",
    "outtables.append(wtd_glac)\n",
    "wtd_lp = arcpy.Merge_management(wtd_lp_tabint_tables, wtd_per_lp_table_out)\n",
    "outtables.append(wtd_lp)\n",
    "print ('Tables merged')\n",
    "print('----------')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZONE_CODE wtd_slope_ZONE_CODE\n",
      "COUNT wtd_slope_COUNT\n",
      "AREA wtd_slope_AREA\n",
      "MIN wtd_slope_MIN\n",
      "MAX wtd_slope_MAX\n",
      "RANGE wtd_slope_RANGE\n",
      "MEAN wtd_slope_MEAN\n",
      "STD wtd_slope_STD\n",
      "SUM wtd_slope_SUM\n",
      "MEDIAN wtd_slope_MEDIAN\n",
      "PCT90 wtd_slope_PCT90\n"
     ]
    }
   ],
   "source": [
    "slopeDict = { 'ZONE_CODE': ('cat_slope_ZONE_CODE', 'wtd_slope_ZONE_CODE'),\n",
    "         'COUNT': ('cat_slope_COUNT', 'wtd_slope_COUNT'),\n",
    "          'AREA': ('cat_slope_AREA', 'wtd_slope_AREA'),\n",
    "          'MIN': ('cat_slope_MIN', 'wtd_slope_MIN'),\n",
    "          'MAX': ('cat_slope_MAX', 'wtd_slope_MAX'),\n",
    "          'RANGE': ('cat_slope_RANGE', 'wtd_slope_RANGE'),\n",
    "          'MEAN': ('cat_slope_MEAN', 'wtd_slope_MEAN'),\n",
    "          'STD': ('cat_slope_STD', 'wtd_slope_STD'),\n",
    "          'SUM': ('cat_slope_SUM', 'wtd_slope_SUM'),\n",
    "          'VARIETY': ('cat_slope_VARIETY', 'wtd_slope_VARIETY'),\n",
    "          'MAJORITY': ('cat_slope_MAJORITY', 'wtd_slope_MAJORITY'),\n",
    "          'MINORITY': ('cat_slope_MINORITY', 'wtd_slope_MINORITY'),\n",
    "          'MEDIAN': ('cat_slope_MEDIAN', 'wtd_slope_MEDIAN'),\n",
    "          'PCT90': ('cat_slope_PCT90', 'wtd_slope_PCT90')\n",
    "         }\n",
    "# Rename fields for slope tables\n",
    "for field in arcpy.ListFields(wtd_slope):\n",
    "    keyval = field.name\n",
    "    if keyval in slopeDict:\n",
    "        newname = slopeDict[keyval][1]\n",
    "        newalias = slopeDict[keyval][1]\n",
    "        print (keyval, newname)\n",
    "        arcpy.AlterField_management(wtd_slope, keyval, newname, newalias)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_huc12_wtd_slope.csv\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_huc12_wtd_glacier_per.csv\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_huc12_wtd_lakepond_per.csv\n"
     ]
    }
   ],
   "source": [
    "# Export copies of dbf tables as csv\n",
    "outdir = r\"C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\"\n",
    "for table in outtables:\n",
    "    tablename = arcpy.Describe(table).basename + \".csv\"\n",
    "    tablepath = os.path.join(outdir,tablename)\n",
    "    print( tablepath)\n",
    "    arcpy.conversion.TableToTable(table, outdir, tablename)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.2f}'.format # only display 2 decimal places\n",
    "# list to store covariate data frames\n",
    "dfs = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "                               cat_ID_txt  wtd_slope_COUNT  wtd_slope_AREA  \\\ncat_ID_con                                                                   \nCook_Inlet_75004400005344  75004400005344        450061.00     45006100.00   \nCook_Inlet_75004400011755  75004400011755       1055899.00    105589900.00   \nCook_Inlet_75004400010352  75004400010352        535581.00     53558100.00   \nCook_Inlet_75004400007996  75004400007996       2825727.00    282572700.00   \nCook_Inlet_75004400004850  75004400004850       1563074.00    156307400.00   \n...                                   ...              ...             ...   \nCook_Inlet_75004400010337  75004400010337        344724.00     34472400.00   \nCook_Inlet_75004400008879  75004400008879        233265.00     23326500.00   \nCook_Inlet_75004400004457  75004400004457       1026297.00    102629700.00   \nCook_Inlet_75004400005924  75004400005924       7720743.00    772074300.00   \nCook_Inlet_75004400004455  75004400004455       1755781.00    175578100.00   \n\n                           wtd_slope_MIN  wtd_slope_MAX  wtd_slope_RANGE  \\\ncat_ID_con                                                                 \nCook_Inlet_75004400005344           0.00          70.87            70.87   \nCook_Inlet_75004400011755           0.00          76.85            76.85   \nCook_Inlet_75004400010352           0.00          67.02            67.02   \nCook_Inlet_75004400007996           0.00          65.51            65.51   \nCook_Inlet_75004400004850           0.00          67.16            67.16   \n...                                  ...            ...              ...   \nCook_Inlet_75004400010337           0.00          35.96            35.96   \nCook_Inlet_75004400008879           0.00          30.82            30.82   \nCook_Inlet_75004400004457           0.00          59.70            59.70   \nCook_Inlet_75004400005924           0.00          65.72            65.72   \nCook_Inlet_75004400004455           0.00          59.42            59.42   \n\n                           wtd_slope_MEAN  wtd_slope_STD  wtd_slope_SUM  \\\ncat_ID_con                                                                \nCook_Inlet_75004400005344           25.38          13.03    11421329.52   \nCook_Inlet_75004400011755           24.02          15.07    25364061.16   \nCook_Inlet_75004400010352           26.18          10.23    14019013.53   \nCook_Inlet_75004400007996           22.75           9.80    64285852.09   \nCook_Inlet_75004400004850           18.79          10.87    29374364.09   \n...                                   ...            ...            ...   \nCook_Inlet_75004400010337            4.01           4.34     1380818.20   \nCook_Inlet_75004400008879            1.95           2.25      455340.88   \nCook_Inlet_75004400004457           16.52          10.14    16950039.30   \nCook_Inlet_75004400005924           11.12          10.59    85865495.84   \nCook_Inlet_75004400004455           19.17          10.86    33650778.59   \n\n                           wtd_slope_MEDIAN  wtd_slope_PCT90      region  \ncat_ID_con                                                                \nCook_Inlet_75004400005344             26.37            41.61  Cook_Inlet  \nCook_Inlet_75004400011755             24.16            44.20  Cook_Inlet  \nCook_Inlet_75004400010352             28.10            37.79  Cook_Inlet  \nCook_Inlet_75004400007996             23.95            34.55  Cook_Inlet  \nCook_Inlet_75004400004850             18.87            33.13  Cook_Inlet  \n...                                     ...              ...         ...  \nCook_Inlet_75004400010337              3.03             9.43  Cook_Inlet  \nCook_Inlet_75004400008879              1.92             3.44  Cook_Inlet  \nCook_Inlet_75004400004457             14.77            31.31  Cook_Inlet  \nCook_Inlet_75004400005924              6.74            28.51  Cook_Inlet  \nCook_Inlet_75004400004455             19.24            33.62  Cook_Inlet  \n\n[99 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat_ID_txt</th>\n      <th>wtd_slope_COUNT</th>\n      <th>wtd_slope_AREA</th>\n      <th>wtd_slope_MIN</th>\n      <th>wtd_slope_MAX</th>\n      <th>wtd_slope_RANGE</th>\n      <th>wtd_slope_MEAN</th>\n      <th>wtd_slope_STD</th>\n      <th>wtd_slope_SUM</th>\n      <th>wtd_slope_MEDIAN</th>\n      <th>wtd_slope_PCT90</th>\n      <th>region</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Cook_Inlet_75004400005344</th>\n      <td>75004400005344</td>\n      <td>450061.00</td>\n      <td>45006100.00</td>\n      <td>0.00</td>\n      <td>70.87</td>\n      <td>70.87</td>\n      <td>25.38</td>\n      <td>13.03</td>\n      <td>11421329.52</td>\n      <td>26.37</td>\n      <td>41.61</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400011755</th>\n      <td>75004400011755</td>\n      <td>1055899.00</td>\n      <td>105589900.00</td>\n      <td>0.00</td>\n      <td>76.85</td>\n      <td>76.85</td>\n      <td>24.02</td>\n      <td>15.07</td>\n      <td>25364061.16</td>\n      <td>24.16</td>\n      <td>44.20</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010352</th>\n      <td>75004400010352</td>\n      <td>535581.00</td>\n      <td>53558100.00</td>\n      <td>0.00</td>\n      <td>67.02</td>\n      <td>67.02</td>\n      <td>26.18</td>\n      <td>10.23</td>\n      <td>14019013.53</td>\n      <td>28.10</td>\n      <td>37.79</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400007996</th>\n      <td>75004400007996</td>\n      <td>2825727.00</td>\n      <td>282572700.00</td>\n      <td>0.00</td>\n      <td>65.51</td>\n      <td>65.51</td>\n      <td>22.75</td>\n      <td>9.80</td>\n      <td>64285852.09</td>\n      <td>23.95</td>\n      <td>34.55</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004850</th>\n      <td>75004400004850</td>\n      <td>1563074.00</td>\n      <td>156307400.00</td>\n      <td>0.00</td>\n      <td>67.16</td>\n      <td>67.16</td>\n      <td>18.79</td>\n      <td>10.87</td>\n      <td>29374364.09</td>\n      <td>18.87</td>\n      <td>33.13</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010337</th>\n      <td>75004400010337</td>\n      <td>344724.00</td>\n      <td>34472400.00</td>\n      <td>0.00</td>\n      <td>35.96</td>\n      <td>35.96</td>\n      <td>4.01</td>\n      <td>4.34</td>\n      <td>1380818.20</td>\n      <td>3.03</td>\n      <td>9.43</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400008879</th>\n      <td>75004400008879</td>\n      <td>233265.00</td>\n      <td>23326500.00</td>\n      <td>0.00</td>\n      <td>30.82</td>\n      <td>30.82</td>\n      <td>1.95</td>\n      <td>2.25</td>\n      <td>455340.88</td>\n      <td>1.92</td>\n      <td>3.44</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004457</th>\n      <td>75004400004457</td>\n      <td>1026297.00</td>\n      <td>102629700.00</td>\n      <td>0.00</td>\n      <td>59.70</td>\n      <td>59.70</td>\n      <td>16.52</td>\n      <td>10.14</td>\n      <td>16950039.30</td>\n      <td>14.77</td>\n      <td>31.31</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400005924</th>\n      <td>75004400005924</td>\n      <td>7720743.00</td>\n      <td>772074300.00</td>\n      <td>0.00</td>\n      <td>65.72</td>\n      <td>65.72</td>\n      <td>11.12</td>\n      <td>10.59</td>\n      <td>85865495.84</td>\n      <td>6.74</td>\n      <td>28.51</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004455</th>\n      <td>75004400004455</td>\n      <td>1755781.00</td>\n      <td>175578100.00</td>\n      <td>0.00</td>\n      <td>59.42</td>\n      <td>59.42</td>\n      <td>19.17</td>\n      <td>10.86</td>\n      <td>33650778.59</td>\n      <td>19.24</td>\n      <td>33.62</td>\n      <td>Cook_Inlet</td>\n    </tr>\n  </tbody>\n</table>\n<p>99 rows  12 columns</p>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make watershed slope df\n",
    "wtd_sl_df = pd.DataFrame()\n",
    "wtd_sl_field_list = []\n",
    "for field in arcpy.ListFields(wtd_slope):\n",
    "    wtd_sl_field_list.append(field.name)\n",
    "wtd_sl_arr = arcpy.da.TableToNumPyArray(wtd_slope, wtd_sl_field_list)\n",
    "wtd_sl_df = pd.DataFrame(wtd_sl_arr)\n",
    "wtd_sl_df = wtd_sl_df.drop([\"OBJECTID\", \"wtd_slope_ZONE_CODE\"],axis=1)\n",
    "wtd_sl_df = wtd_sl_df.set_index('cat_ID_con')\n",
    "dfs.append(wtd_sl_df)\n",
    "wtd_sl_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "                               cat_ID_txt  FType  wtd_lake_area_sqm  \\\ncat_ID_con                                                            \nCook_Inlet_75004400000141  75004400000141    390         1576148.40   \nCook_Inlet_75004400000153  75004400000153    390        58646462.08   \nCook_Inlet_75004400000171  75004400000171    390         8422188.78   \nCook_Inlet_75004400000334  75004400000334    390       104986117.89   \nCook_Inlet_75004400000370  75004400000370    390         7821176.39   \n...                                   ...    ...                ...   \nCook_Inlet_75004400011230  75004400011230    390          161218.08   \nCook_Inlet_75004400011320  75004400011320    390          553571.26   \nCook_Inlet_75004400011322  75004400011322    390           17707.12   \nCook_Inlet_75004400011676  75004400011676    390         5588557.47   \nCook_Inlet_75004400011755  75004400011755    390         5262557.61   \n\n                           wtd_lake_per      region          cat_ID  \ncat_ID_con                                                           \nCook_Inlet_75004400000141          3.57  Cook_Inlet  75004400000141  \nCook_Inlet_75004400000153         11.14  Cook_Inlet  75004400000153  \nCook_Inlet_75004400000171          7.60  Cook_Inlet  75004400000171  \nCook_Inlet_75004400000334          4.68  Cook_Inlet  75004400000334  \nCook_Inlet_75004400000370          1.61  Cook_Inlet  75004400000370  \n...                                 ...         ...             ...  \nCook_Inlet_75004400011230          0.18  Cook_Inlet  75004400011230  \nCook_Inlet_75004400011320          0.40  Cook_Inlet  75004400011320  \nCook_Inlet_75004400011322          0.03  Cook_Inlet  75004400011322  \nCook_Inlet_75004400011676          3.96  Cook_Inlet  75004400011676  \nCook_Inlet_75004400011755          4.98  Cook_Inlet  75004400011755  \n\n[95 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat_ID_txt</th>\n      <th>FType</th>\n      <th>wtd_lake_area_sqm</th>\n      <th>wtd_lake_per</th>\n      <th>region</th>\n      <th>cat_ID</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Cook_Inlet_75004400000141</th>\n      <td>75004400000141</td>\n      <td>390</td>\n      <td>1576148.40</td>\n      <td>3.57</td>\n      <td>Cook_Inlet</td>\n      <td>75004400000141</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400000153</th>\n      <td>75004400000153</td>\n      <td>390</td>\n      <td>58646462.08</td>\n      <td>11.14</td>\n      <td>Cook_Inlet</td>\n      <td>75004400000153</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400000171</th>\n      <td>75004400000171</td>\n      <td>390</td>\n      <td>8422188.78</td>\n      <td>7.60</td>\n      <td>Cook_Inlet</td>\n      <td>75004400000171</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400000334</th>\n      <td>75004400000334</td>\n      <td>390</td>\n      <td>104986117.89</td>\n      <td>4.68</td>\n      <td>Cook_Inlet</td>\n      <td>75004400000334</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400000370</th>\n      <td>75004400000370</td>\n      <td>390</td>\n      <td>7821176.39</td>\n      <td>1.61</td>\n      <td>Cook_Inlet</td>\n      <td>75004400000370</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400011230</th>\n      <td>75004400011230</td>\n      <td>390</td>\n      <td>161218.08</td>\n      <td>0.18</td>\n      <td>Cook_Inlet</td>\n      <td>75004400011230</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400011320</th>\n      <td>75004400011320</td>\n      <td>390</td>\n      <td>553571.26</td>\n      <td>0.40</td>\n      <td>Cook_Inlet</td>\n      <td>75004400011320</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400011322</th>\n      <td>75004400011322</td>\n      <td>390</td>\n      <td>17707.12</td>\n      <td>0.03</td>\n      <td>Cook_Inlet</td>\n      <td>75004400011322</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400011676</th>\n      <td>75004400011676</td>\n      <td>390</td>\n      <td>5588557.47</td>\n      <td>3.96</td>\n      <td>Cook_Inlet</td>\n      <td>75004400011676</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400011755</th>\n      <td>75004400011755</td>\n      <td>390</td>\n      <td>5262557.61</td>\n      <td>4.98</td>\n      <td>Cook_Inlet</td>\n      <td>75004400011755</td>\n    </tr>\n  </tbody>\n</table>\n<p>95 rows  6 columns</p>\n</div>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make watershed lakes df\n",
    "wtd_lp_df = pd.DataFrame()\n",
    "wtd_lp_field_list = []\n",
    "for field in arcpy.ListFields(wtd_lp):\n",
    "    wtd_lp_field_list.append(field.name)\n",
    "wtd_lp_arr = arcpy.da.TableToNumPyArray(wtd_lp, wtd_lp_field_list)\n",
    "wtd_lp_df = pd.DataFrame(wtd_lp_arr)\n",
    "wtd_lp_df = wtd_lp_df.drop(\"OBJECTID\",axis=1)\n",
    "wtd_lp_df = wtd_lp_df.set_index('cat_ID_con')\n",
    "dfs.append(wtd_lp_df)\n",
    "wtd_lp_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "                               cat_ID_txt O1Region  wtd_glacier_area_sqm  \\\ncat_ID_con                                                                 \nCook_Inlet_75004400000334  75004400000334        1          193821283.66   \nCook_Inlet_75004400000370  75004400000370        1          291918580.25   \nCook_Inlet_75004400000627  75004400000627        1             221275.02   \nCook_Inlet_75004400000862  75004400000862        1            1216847.56   \nCook_Inlet_75004400001134  75004400001134        1             455445.73   \nCook_Inlet_75004400001136  75004400001136        1           12854221.71   \nCook_Inlet_75004400001464  75004400001464        1            3207932.66   \nCook_Inlet_75004400001569  75004400001569        1          528443895.03   \nCook_Inlet_75004400001616  75004400001616        1           42704031.11   \nCook_Inlet_75004400001652  75004400001652        1          485739863.92   \nCook_Inlet_75004400002041  75004400002041        1             306704.72   \nCook_Inlet_75004400002258  75004400002258        1            1596147.03   \nCook_Inlet_75004400002279  75004400002279        1           15172383.52   \nCook_Inlet_75004400002718  75004400002718        1          108007080.91   \nCook_Inlet_75004400003165  75004400003165        1           42704031.11   \nCook_Inlet_75004400003230  75004400003230        1            7054838.52   \nCook_Inlet_75004400003768  75004400003768        1            1140719.32   \nCook_Inlet_75004400003815  75004400003815        1            1257401.04   \nCook_Inlet_75004400003876  75004400003876        1           78431958.17   \nCook_Inlet_75004400004166  75004400004166        1            1207589.70   \nCook_Inlet_75004400004213  75004400004213        1           19137821.00   \nCook_Inlet_75004400004344  75004400004344        1           53113238.87   \nCook_Inlet_75004400004680  75004400004680        1           35649192.58   \nCook_Inlet_75004400005312  75004400005312        1           85900124.19   \nCook_Inlet_75004400005344  75004400005344        1            1588148.90   \nCook_Inlet_75004400005660  75004400005660        1            1497385.85   \nCook_Inlet_75004400005909  75004400005909        1          528443895.03   \nCook_Inlet_75004400005985  75004400005985        1          528443895.03   \nCook_Inlet_75004400006692  75004400006692        1             229598.13   \nCook_Inlet_75004400007224  75004400007224        1          123036003.22   \nCook_Inlet_75004400007351  75004400007351        1           30625849.79   \nCook_Inlet_75004400007996  75004400007996        1              67318.95   \nCook_Inlet_75004400008192  75004400008192        1           11654573.42   \nCook_Inlet_75004400008216  75004400008216        1           92143575.76   \nCook_Inlet_75004400008242  75004400008242        1           10833692.54   \nCook_Inlet_75004400008539  75004400008539        1           42840366.78   \nCook_Inlet_75004400008856  75004400008856        1            5678474.54   \nCook_Inlet_75004400008899  75004400008899        1          528443895.03   \nCook_Inlet_75004400009308  75004400009308        1            1224936.41   \nCook_Inlet_75004400009331  75004400009331        1             601336.23   \nCook_Inlet_75004400009412  75004400009412        1             764952.90   \nCook_Inlet_75004400009562  75004400009562        1             152609.67   \nCook_Inlet_75004400009792  75004400009792        1           63828583.71   \nCook_Inlet_75004400010175  75004400010175        1           98778742.07   \nCook_Inlet_75004400010221  75004400010221        1           42656486.90   \nCook_Inlet_75004400010270  75004400010270        1           19828291.33   \nCook_Inlet_75004400010328  75004400010328        1          191995011.02   \nCook_Inlet_75004400010352  75004400010352        1             153956.07   \nCook_Inlet_75004400010386  75004400010386        1          528443895.03   \nCook_Inlet_75004400010754  75004400010754        1            1224936.41   \nCook_Inlet_75004400011230  75004400011230        1           21204673.75   \nCook_Inlet_75004400011320  75004400011320        1            7817873.95   \nCook_Inlet_75004400011322  75004400011322        1            3462838.89   \nCook_Inlet_75004400011676  75004400011676        1           50872836.36   \nCook_Inlet_75004400011755  75004400011755        1           47695107.47   \n\n                           wtd_glacier_per      region          cat_ID  \ncat_ID_con                                                              \nCook_Inlet_75004400000334             8.64  Cook_Inlet  75004400000334  \nCook_Inlet_75004400000370            60.11  Cook_Inlet  75004400000370  \nCook_Inlet_75004400000627             0.05  Cook_Inlet  75004400000627  \nCook_Inlet_75004400000862             4.21  Cook_Inlet  75004400000862  \nCook_Inlet_75004400001134             0.98  Cook_Inlet  75004400001134  \nCook_Inlet_75004400001136             8.40  Cook_Inlet  75004400001136  \nCook_Inlet_75004400001464             4.28  Cook_Inlet  75004400001464  \nCook_Inlet_75004400001569            11.56  Cook_Inlet  75004400001569  \nCook_Inlet_75004400001616             7.99  Cook_Inlet  75004400001616  \nCook_Inlet_75004400001652            15.33  Cook_Inlet  75004400001652  \nCook_Inlet_75004400002041             0.37  Cook_Inlet  75004400002041  \nCook_Inlet_75004400002258             0.81  Cook_Inlet  75004400002258  \nCook_Inlet_75004400002279             2.22  Cook_Inlet  75004400002279  \nCook_Inlet_75004400002718            53.68  Cook_Inlet  75004400002718  \nCook_Inlet_75004400003165             9.51  Cook_Inlet  75004400003165  \nCook_Inlet_75004400003230             4.44  Cook_Inlet  75004400003230  \nCook_Inlet_75004400003768             0.46  Cook_Inlet  75004400003768  \nCook_Inlet_75004400003815             2.75  Cook_Inlet  75004400003815  \nCook_Inlet_75004400003876            28.60  Cook_Inlet  75004400003876  \nCook_Inlet_75004400004166             6.64  Cook_Inlet  75004400004166  \nCook_Inlet_75004400004213            31.38  Cook_Inlet  75004400004213  \nCook_Inlet_75004400004344            32.34  Cook_Inlet  75004400004344  \nCook_Inlet_75004400004680            24.41  Cook_Inlet  75004400004680  \nCook_Inlet_75004400005312            23.22  Cook_Inlet  75004400005312  \nCook_Inlet_75004400005344             3.53  Cook_Inlet  75004400005344  \nCook_Inlet_75004400005660             2.67  Cook_Inlet  75004400005660  \nCook_Inlet_75004400005909            13.80  Cook_Inlet  75004400005909  \nCook_Inlet_75004400005985            10.50  Cook_Inlet  75004400005985  \nCook_Inlet_75004400006692             0.33  Cook_Inlet  75004400006692  \nCook_Inlet_75004400007224            38.17  Cook_Inlet  75004400007224  \nCook_Inlet_75004400007351            31.59  Cook_Inlet  75004400007351  \nCook_Inlet_75004400007996             0.02  Cook_Inlet  75004400007996  \nCook_Inlet_75004400008192             3.64  Cook_Inlet  75004400008192  \nCook_Inlet_75004400008216            16.69  Cook_Inlet  75004400008216  \nCook_Inlet_75004400008242             9.61  Cook_Inlet  75004400008242  \nCook_Inlet_75004400008539            41.59  Cook_Inlet  75004400008539  \nCook_Inlet_75004400008856             6.47  Cook_Inlet  75004400008856  \nCook_Inlet_75004400008899             9.67  Cook_Inlet  75004400008899  \nCook_Inlet_75004400009308             1.81  Cook_Inlet  75004400009308  \nCook_Inlet_75004400009331             0.48  Cook_Inlet  75004400009331  \nCook_Inlet_75004400009412             0.27  Cook_Inlet  75004400009412  \nCook_Inlet_75004400009562             0.33  Cook_Inlet  75004400009562  \nCook_Inlet_75004400009792            26.33  Cook_Inlet  75004400009792  \nCook_Inlet_75004400010175            23.10  Cook_Inlet  75004400010175  \nCook_Inlet_75004400010221            21.52  Cook_Inlet  75004400010221  \nCook_Inlet_75004400010270            20.25  Cook_Inlet  75004400010270  \nCook_Inlet_75004400010328            11.39  Cook_Inlet  75004400010328  \nCook_Inlet_75004400010352             0.29  Cook_Inlet  75004400010352  \nCook_Inlet_75004400010386             9.66  Cook_Inlet  75004400010386  \nCook_Inlet_75004400010754             0.75  Cook_Inlet  75004400010754  \nCook_Inlet_75004400011230            24.00  Cook_Inlet  75004400011230  \nCook_Inlet_75004400011320             5.62  Cook_Inlet  75004400011320  \nCook_Inlet_75004400011322             6.24  Cook_Inlet  75004400011322  \nCook_Inlet_75004400011676            36.02  Cook_Inlet  75004400011676  \nCook_Inlet_75004400011755            45.17  Cook_Inlet  75004400011755  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat_ID_txt</th>\n      <th>O1Region</th>\n      <th>wtd_glacier_area_sqm</th>\n      <th>wtd_glacier_per</th>\n      <th>region</th>\n      <th>cat_ID</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Cook_Inlet_75004400000334</th>\n      <td>75004400000334</td>\n      <td>1</td>\n      <td>193821283.66</td>\n      <td>8.64</td>\n      <td>Cook_Inlet</td>\n      <td>75004400000334</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400000370</th>\n      <td>75004400000370</td>\n      <td>1</td>\n      <td>291918580.25</td>\n      <td>60.11</td>\n      <td>Cook_Inlet</td>\n      <td>75004400000370</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400000627</th>\n      <td>75004400000627</td>\n      <td>1</td>\n      <td>221275.02</td>\n      <td>0.05</td>\n      <td>Cook_Inlet</td>\n      <td>75004400000627</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400000862</th>\n      <td>75004400000862</td>\n      <td>1</td>\n      <td>1216847.56</td>\n      <td>4.21</td>\n      <td>Cook_Inlet</td>\n      <td>75004400000862</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400001134</th>\n      <td>75004400001134</td>\n      <td>1</td>\n      <td>455445.73</td>\n      <td>0.98</td>\n      <td>Cook_Inlet</td>\n      <td>75004400001134</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400001136</th>\n      <td>75004400001136</td>\n      <td>1</td>\n      <td>12854221.71</td>\n      <td>8.40</td>\n      <td>Cook_Inlet</td>\n      <td>75004400001136</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400001464</th>\n      <td>75004400001464</td>\n      <td>1</td>\n      <td>3207932.66</td>\n      <td>4.28</td>\n      <td>Cook_Inlet</td>\n      <td>75004400001464</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400001569</th>\n      <td>75004400001569</td>\n      <td>1</td>\n      <td>528443895.03</td>\n      <td>11.56</td>\n      <td>Cook_Inlet</td>\n      <td>75004400001569</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400001616</th>\n      <td>75004400001616</td>\n      <td>1</td>\n      <td>42704031.11</td>\n      <td>7.99</td>\n      <td>Cook_Inlet</td>\n      <td>75004400001616</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400001652</th>\n      <td>75004400001652</td>\n      <td>1</td>\n      <td>485739863.92</td>\n      <td>15.33</td>\n      <td>Cook_Inlet</td>\n      <td>75004400001652</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400002041</th>\n      <td>75004400002041</td>\n      <td>1</td>\n      <td>306704.72</td>\n      <td>0.37</td>\n      <td>Cook_Inlet</td>\n      <td>75004400002041</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400002258</th>\n      <td>75004400002258</td>\n      <td>1</td>\n      <td>1596147.03</td>\n      <td>0.81</td>\n      <td>Cook_Inlet</td>\n      <td>75004400002258</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400002279</th>\n      <td>75004400002279</td>\n      <td>1</td>\n      <td>15172383.52</td>\n      <td>2.22</td>\n      <td>Cook_Inlet</td>\n      <td>75004400002279</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400002718</th>\n      <td>75004400002718</td>\n      <td>1</td>\n      <td>108007080.91</td>\n      <td>53.68</td>\n      <td>Cook_Inlet</td>\n      <td>75004400002718</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400003165</th>\n      <td>75004400003165</td>\n      <td>1</td>\n      <td>42704031.11</td>\n      <td>9.51</td>\n      <td>Cook_Inlet</td>\n      <td>75004400003165</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400003230</th>\n      <td>75004400003230</td>\n      <td>1</td>\n      <td>7054838.52</td>\n      <td>4.44</td>\n      <td>Cook_Inlet</td>\n      <td>75004400003230</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400003768</th>\n      <td>75004400003768</td>\n      <td>1</td>\n      <td>1140719.32</td>\n      <td>0.46</td>\n      <td>Cook_Inlet</td>\n      <td>75004400003768</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400003815</th>\n      <td>75004400003815</td>\n      <td>1</td>\n      <td>1257401.04</td>\n      <td>2.75</td>\n      <td>Cook_Inlet</td>\n      <td>75004400003815</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400003876</th>\n      <td>75004400003876</td>\n      <td>1</td>\n      <td>78431958.17</td>\n      <td>28.60</td>\n      <td>Cook_Inlet</td>\n      <td>75004400003876</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004166</th>\n      <td>75004400004166</td>\n      <td>1</td>\n      <td>1207589.70</td>\n      <td>6.64</td>\n      <td>Cook_Inlet</td>\n      <td>75004400004166</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004213</th>\n      <td>75004400004213</td>\n      <td>1</td>\n      <td>19137821.00</td>\n      <td>31.38</td>\n      <td>Cook_Inlet</td>\n      <td>75004400004213</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004344</th>\n      <td>75004400004344</td>\n      <td>1</td>\n      <td>53113238.87</td>\n      <td>32.34</td>\n      <td>Cook_Inlet</td>\n      <td>75004400004344</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004680</th>\n      <td>75004400004680</td>\n      <td>1</td>\n      <td>35649192.58</td>\n      <td>24.41</td>\n      <td>Cook_Inlet</td>\n      <td>75004400004680</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400005312</th>\n      <td>75004400005312</td>\n      <td>1</td>\n      <td>85900124.19</td>\n      <td>23.22</td>\n      <td>Cook_Inlet</td>\n      <td>75004400005312</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400005344</th>\n      <td>75004400005344</td>\n      <td>1</td>\n      <td>1588148.90</td>\n      <td>3.53</td>\n      <td>Cook_Inlet</td>\n      <td>75004400005344</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400005660</th>\n      <td>75004400005660</td>\n      <td>1</td>\n      <td>1497385.85</td>\n      <td>2.67</td>\n      <td>Cook_Inlet</td>\n      <td>75004400005660</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400005909</th>\n      <td>75004400005909</td>\n      <td>1</td>\n      <td>528443895.03</td>\n      <td>13.80</td>\n      <td>Cook_Inlet</td>\n      <td>75004400005909</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400005985</th>\n      <td>75004400005985</td>\n      <td>1</td>\n      <td>528443895.03</td>\n      <td>10.50</td>\n      <td>Cook_Inlet</td>\n      <td>75004400005985</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400006692</th>\n      <td>75004400006692</td>\n      <td>1</td>\n      <td>229598.13</td>\n      <td>0.33</td>\n      <td>Cook_Inlet</td>\n      <td>75004400006692</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400007224</th>\n      <td>75004400007224</td>\n      <td>1</td>\n      <td>123036003.22</td>\n      <td>38.17</td>\n      <td>Cook_Inlet</td>\n      <td>75004400007224</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400007351</th>\n      <td>75004400007351</td>\n      <td>1</td>\n      <td>30625849.79</td>\n      <td>31.59</td>\n      <td>Cook_Inlet</td>\n      <td>75004400007351</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400007996</th>\n      <td>75004400007996</td>\n      <td>1</td>\n      <td>67318.95</td>\n      <td>0.02</td>\n      <td>Cook_Inlet</td>\n      <td>75004400007996</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400008192</th>\n      <td>75004400008192</td>\n      <td>1</td>\n      <td>11654573.42</td>\n      <td>3.64</td>\n      <td>Cook_Inlet</td>\n      <td>75004400008192</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400008216</th>\n      <td>75004400008216</td>\n      <td>1</td>\n      <td>92143575.76</td>\n      <td>16.69</td>\n      <td>Cook_Inlet</td>\n      <td>75004400008216</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400008242</th>\n      <td>75004400008242</td>\n      <td>1</td>\n      <td>10833692.54</td>\n      <td>9.61</td>\n      <td>Cook_Inlet</td>\n      <td>75004400008242</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400008539</th>\n      <td>75004400008539</td>\n      <td>1</td>\n      <td>42840366.78</td>\n      <td>41.59</td>\n      <td>Cook_Inlet</td>\n      <td>75004400008539</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400008856</th>\n      <td>75004400008856</td>\n      <td>1</td>\n      <td>5678474.54</td>\n      <td>6.47</td>\n      <td>Cook_Inlet</td>\n      <td>75004400008856</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400008899</th>\n      <td>75004400008899</td>\n      <td>1</td>\n      <td>528443895.03</td>\n      <td>9.67</td>\n      <td>Cook_Inlet</td>\n      <td>75004400008899</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400009308</th>\n      <td>75004400009308</td>\n      <td>1</td>\n      <td>1224936.41</td>\n      <td>1.81</td>\n      <td>Cook_Inlet</td>\n      <td>75004400009308</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400009331</th>\n      <td>75004400009331</td>\n      <td>1</td>\n      <td>601336.23</td>\n      <td>0.48</td>\n      <td>Cook_Inlet</td>\n      <td>75004400009331</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400009412</th>\n      <td>75004400009412</td>\n      <td>1</td>\n      <td>764952.90</td>\n      <td>0.27</td>\n      <td>Cook_Inlet</td>\n      <td>75004400009412</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400009562</th>\n      <td>75004400009562</td>\n      <td>1</td>\n      <td>152609.67</td>\n      <td>0.33</td>\n      <td>Cook_Inlet</td>\n      <td>75004400009562</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400009792</th>\n      <td>75004400009792</td>\n      <td>1</td>\n      <td>63828583.71</td>\n      <td>26.33</td>\n      <td>Cook_Inlet</td>\n      <td>75004400009792</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010175</th>\n      <td>75004400010175</td>\n      <td>1</td>\n      <td>98778742.07</td>\n      <td>23.10</td>\n      <td>Cook_Inlet</td>\n      <td>75004400010175</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010221</th>\n      <td>75004400010221</td>\n      <td>1</td>\n      <td>42656486.90</td>\n      <td>21.52</td>\n      <td>Cook_Inlet</td>\n      <td>75004400010221</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010270</th>\n      <td>75004400010270</td>\n      <td>1</td>\n      <td>19828291.33</td>\n      <td>20.25</td>\n      <td>Cook_Inlet</td>\n      <td>75004400010270</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010328</th>\n      <td>75004400010328</td>\n      <td>1</td>\n      <td>191995011.02</td>\n      <td>11.39</td>\n      <td>Cook_Inlet</td>\n      <td>75004400010328</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010352</th>\n      <td>75004400010352</td>\n      <td>1</td>\n      <td>153956.07</td>\n      <td>0.29</td>\n      <td>Cook_Inlet</td>\n      <td>75004400010352</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010386</th>\n      <td>75004400010386</td>\n      <td>1</td>\n      <td>528443895.03</td>\n      <td>9.66</td>\n      <td>Cook_Inlet</td>\n      <td>75004400010386</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010754</th>\n      <td>75004400010754</td>\n      <td>1</td>\n      <td>1224936.41</td>\n      <td>0.75</td>\n      <td>Cook_Inlet</td>\n      <td>75004400010754</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400011230</th>\n      <td>75004400011230</td>\n      <td>1</td>\n      <td>21204673.75</td>\n      <td>24.00</td>\n      <td>Cook_Inlet</td>\n      <td>75004400011230</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400011320</th>\n      <td>75004400011320</td>\n      <td>1</td>\n      <td>7817873.95</td>\n      <td>5.62</td>\n      <td>Cook_Inlet</td>\n      <td>75004400011320</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400011322</th>\n      <td>75004400011322</td>\n      <td>1</td>\n      <td>3462838.89</td>\n      <td>6.24</td>\n      <td>Cook_Inlet</td>\n      <td>75004400011322</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400011676</th>\n      <td>75004400011676</td>\n      <td>1</td>\n      <td>50872836.36</td>\n      <td>36.02</td>\n      <td>Cook_Inlet</td>\n      <td>75004400011676</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400011755</th>\n      <td>75004400011755</td>\n      <td>1</td>\n      <td>47695107.47</td>\n      <td>45.17</td>\n      <td>Cook_Inlet</td>\n      <td>75004400011755</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make watershed glacier df\n",
    "wtd_glac_df = pd.DataFrame()\n",
    "wtd_glac_field_list = []\n",
    "for field in arcpy.ListFields(wtd_glac):\n",
    "    wtd_glac_field_list.append(field.name)\n",
    "wtd_glac_arr = arcpy.da.TableToNumPyArray(wtd_glac, wtd_glac_field_list)\n",
    "wtd_glac_df = pd.DataFrame(wtd_glac_arr)\n",
    "wtd_glac_df = wtd_glac_df.drop(\"OBJECTID\",axis=1)\n",
    "wtd_glac_df = wtd_glac_df.set_index('cat_ID_con')\n",
    "dfs.append(wtd_glac_df)\n",
    "wtd_glac_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['cat_ID_txt_x', 'wtd_slope_COUNT', 'wtd_slope_AREA', 'wtd_slope_MIN',\n       'wtd_slope_MAX', 'wtd_slope_RANGE', 'wtd_slope_MEAN', 'wtd_slope_STD',\n       'wtd_slope_SUM', 'wtd_slope_MEDIAN', 'wtd_slope_PCT90', 'region_x',\n       'cat_ID_txt_y', 'FType', 'wtd_lake_area_sqm', 'wtd_lake_per',\n       'region_y', 'cat_ID_x', 'cat_ID_txt', 'O1Region',\n       'wtd_glacier_area_sqm', 'wtd_glacier_per', 'region', 'cat_ID_y'],\n      dtype='object')"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge all data frames together\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "df_final = reduce(lambda left,right: pd.merge(left,right,on='cat_ID_con',how=\"outer\"), dfs)\n",
    "#Generate unique column names\n",
    "def uniquify(df_final):\n",
    "    seen = set()\n",
    "    for item in df_final:\n",
    "        fudge = 1\n",
    "        newitem = item\n",
    "        while newitem in seen:\n",
    "            fudge += 1\n",
    "            newitem = \"{}_{}\".format(item, fudge)\n",
    "        yield newitem\n",
    "        seen.add(newitem)\n",
    "df_final.columns = list(uniquify(df_final))\n",
    "\n",
    "#List of final columns in the order to output\n",
    "final_cols = ['cat_ID_txt', 'wtd_slope_COUNT', 'wtd_slope_AREA', 'wtd_slope_MIN', 'wtd_slope_MAX','wtd_slope_RANGE', 'wtd_slope_MEAN', 'wtd_slope_STD', 'wtd_slope_SUM', 'wtd_slope_MEDIAN', 'wtd_slope_PCT90',\n",
    "              'wtd_lake_area_sqm', 'wtd_lake_per', 'wtd_glacier_area_sqm', 'wtd_glacier_per' ]\n",
    "#Create list of duplicate column names and drop\n",
    "drop_cols = ['cat_ID_txt_y', 'region_y','FType', 'O1Region','cat_ID_y','region','cat_ID_x','cat_ID_txt']\n",
    "df_final.drop(columns=drop_cols, axis = 1, inplace=True)\n",
    "\n",
    "#rename columns\n",
    "df_final.rename({'cat_ID_txt_x':'cat_ID_txt','region_x':'region'},axis=1, inplace=True)\n",
    "#Recalculate cat_ID\n",
    "df_final['cat_ID'] = df_final['cat_ID_txt'].astype(np.float64)\n",
    "df_final.index.is_unique\n",
    "# reorder cols\n",
    "df_final = df_final.reindex(columns=final_cols)\n",
    "df_final"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export all covariates dataframe to csv complete\n"
     ]
    }
   ],
   "source": [
    "# Export merged dataframe to csv\n",
    "huccov_csv_out = os.path.join(outdir,'AKSSF_HUC12_Covariates.csv')\n",
    "df_final.to_csv(huccov_csv_out, encoding = 'utf-8')\n",
    "print('Export all covariates dataframe to csv complete')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}