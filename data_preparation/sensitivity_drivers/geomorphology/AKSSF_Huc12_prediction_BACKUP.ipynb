{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Huc 12 Predictors\n",
    "## Test 19020302 HUC 8 incl chugach nforest\n",
    "All Huc 12s- Intersect w/catchments and find catchment (find downstream most catchment) with most upstream contribution and build watersheds for all ds catchments\n",
    "\n",
    "Keep -\n",
    "mnwtd_slope\n",
    "% lake\n",
    "summer precip - Runs in R but need downstream point (centroid of ds catchment)\n",
    "predict for huc8\n",
    "\n",
    "Visualize by HUC12 - Join data back to Huc12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section\n",
    "Import modules\n",
    "Set/Create Workspaces\n",
    " * Create Huc12 Catchment dataset to store catchments that will have watersheds generated\n",
    " * Crate Catchment point dataset to store catchment centroids\n",
    "Collect Data\n",
    " * Set up data dictionary with VPU as key and store path to source data\n",
    "    * Slope - Can link to already created slope rasters from original covariates worflow\n",
    "    * NHDPlus Waterbodies - Can link to waterbody feature clase from original covariate workflow\n",
    "Merge Data\n",
    " * Merge data together and or copy to local/in_memory and check that all projections match\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports complete\n",
      "sys paths ['C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\Github\\\\AKSSF\\\\data_preparation\\\\sensitivity_drivers\\\\geomorphology', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\Resources\\\\ArcPy', 'C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\Github\\\\AKSSF', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\python37.zip', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\DLLs', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3', '', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\Resources\\\\ArcToolbox\\\\Scripts', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\future-0.18.2-py3.7.egg', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\pytz-2020.1-py3.7.egg', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\pywin32_ctypes-0.2.0-py3.7.egg', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\pywin32security', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\sympy-1.5.1-py3.7.egg', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\dwmerrigan\\\\.ipython']\n",
      "2022-02-02 14:44:42.389501\n"
     ]
    }
   ],
   "source": [
    "import os, arcpy, sys,datetime\n",
    "arcpy.env.overwriteOutput = True\n",
    "sr = arcpy.SpatialReference(3338)  #'NAD_1983_Alaska_Albers'\n",
    "arcpy.env.outputCoordinateSystem = sr\n",
    "\n",
    "print('imports complete')\n",
    "print(f'sys paths {sys.path}')\n",
    "print (datetime.datetime.now())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Function to add key, value pairs to dictionary\n",
    "def append_value(dict_obj, key, value):\n",
    "    # Check if key exist in dict or not\n",
    "    if key in dict_obj:\n",
    "        # Key exist in dict.\n",
    "        # Check if type of value of key is list or not\n",
    "        if not isinstance(dict_obj[key], list):\n",
    "            # If type is not list then make it list\n",
    "            dict_obj[key] = [dict_obj[key]]\n",
    "        # Append the value in list\n",
    "        dict_obj[key].append(value)\n",
    "    else:\n",
    "        # As key is not in dict,\n",
    "        # so, add key-value pair\n",
    "        dict_obj[key] = value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Collect NHDPlus Datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "{'19020202': ['D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020202_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020202_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020202_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020202_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020202_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020202_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Cook_Inlet'],\n '19020301': ['D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020301_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020301_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020301_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020301_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020301_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020301_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Cook_Inlet'],\n '19020302': ['D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020302_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020302_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020302_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020302_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020302_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020302_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Cook_Inlet'],\n '19020401': ['D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020401_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020401_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020401_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020401_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020401_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020401_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Cook_Inlet'],\n '19020402': ['D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020402_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020402_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020402_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020402_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020402_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020402_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Cook_Inlet'],\n '19020501': ['D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020501_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020501_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020501_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020501_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020501_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020501_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Cook_Inlet'],\n '19020502': ['D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020502_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020502_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020502_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020502_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020502_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020502_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Cook_Inlet'],\n '19020503': ['D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020503_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020503_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020503_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020503_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020503_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020503_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Cook_Inlet'],\n '19020504': ['D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020504_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020504_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020504_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020504_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020504_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020504_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Cook_Inlet'],\n '19020505': ['D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020505_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020505_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020505_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020505_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020505_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020505_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Cook_Inlet'],\n '19020601': ['D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020601_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020601_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020601_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020601_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020601_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020601_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Cook_Inlet'],\n '19020602': ['D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020602_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020602_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020602_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020602_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020602_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020602_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Cook_Inlet'],\n '19020800': ['D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020800_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020800_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020800_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020800_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020800_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Cook_Inlet\\\\NHDPLUS_H_19020800_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Cook_Inlet'],\n '19020101': ['D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020101_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020101_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020101_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020101_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020101_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020101_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Copper_River'],\n '19020102': ['D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020102_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020102_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020102_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020102_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020102_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020102_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Copper_River'],\n '19020103': ['D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020103_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020103_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020103_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020103_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020103_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020103_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Copper_River'],\n '19020104': ['D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020104_HU8_GDB.gdb',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020104_HU8_GDB.gdb\\\\NHDPlus\\\\NHDPlusCatchment',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020104_HU8_GDB.gdb\\\\Hydrography\\\\NHDFlowline',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020104_HU8_GDB.gdb\\\\Hydrography\\\\NHDWaterbody',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020104_HU8_GDB.gdb\\\\WBD\\\\WBDHU12',\n  'D:\\\\Basedata\\\\NHDPlus\\\\Copper_River\\\\NHDPLUS_H_19020104_HU8_GDB.gdb\\\\NHDPlusFlowlineVAA',\n  'Copper_River']}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Dictionary to relate datasets to vpu\n",
    "vpuDict = {}\n",
    "\n",
    "#Path to folder with NHDPlus data separated by vpu\n",
    "nhdPlusfol = r'D:\\Basedata\\NHDPlus'\n",
    "rois = ['Cook_Inlet','Copper_River']\n",
    "vpuList = []\n",
    "regDict = {}\n",
    "\n",
    "#NHD folders - Update to new data downloaded Nov 8, 2021\n",
    "for roi in rois:\n",
    "    arcpy.env.workspace = os.path.join(nhdPlusfol,roi)\n",
    "    gdbs = arcpy.ListWorkspaces('NHDPLUS*','FileGDB')\n",
    "    #print(gdbs)\n",
    "    Cats = []\n",
    "    VAA = []\n",
    "    waterbodies = []\n",
    "    flowlines = []\n",
    "\n",
    "    for gdb in gdbs:\n",
    "        arcpy.env.workspace = gdb\n",
    "        huc = gdb[-20:-12]\n",
    "        append_value(regDict,huc,roi)\n",
    "        #print(huc)\n",
    "        vpuList.append(huc)\n",
    "        append_value(vpuDict,huc,gdb)\n",
    "        datasets = arcpy.ListDatasets(feature_type='feature')\n",
    "        for ds in datasets:\n",
    "            for fc in arcpy.ListFeatureClasses(feature_dataset=ds):\n",
    "                if fc == \"NHDFlowline\":\n",
    "                    flowpath = os.path.join(arcpy.env.workspace, ds, fc)\n",
    "                    flowname = 'flowline_' + str(huc)\n",
    "                    append_value(vpuDict,huc,flowpath)\n",
    "                #     print(f'Copying {flowname}...')\n",
    "                #     flowcopypath = os.path.join(scratch, flowname)\n",
    "                #     arcpy.management.CopyFeatures(flowpath, flowcopypath)\n",
    "                #     flowlines.append(flowcopypath)\n",
    "                elif fc == \"NHDWaterbody\":\n",
    "                    waterbodyname = 'waterbody_' + str(huc)\n",
    "                    #waterbodycopypath = os.path.join(scratch, waterbodyname)\n",
    "                    waterpath = os.path.join(arcpy.env.workspace, ds, fc)\n",
    "                    #print(f'Copying {waterbodyname}...')\n",
    "                    append_value(vpuDict,huc,waterpath)\n",
    "                    # arcpy.management.CopyFeatures(waterpath, waterbodycopypath)\n",
    "                    # waterbodies.append(waterbodycopypath)\n",
    "                elif fc == \"NHDPlusCatchment\":\n",
    "                    catchpath = os.path.join(arcpy.env.workspace, ds, fc)\n",
    "                    append_value(vpuDict, huc, catchpath)\n",
    "                elif fc == \"WBDHU12\":\n",
    "                    hucpath = os.path.join(arcpy.env.workspace, ds, fc)\n",
    "                    append_value(vpuDict, huc, hucpath)\n",
    "\n",
    "        vaapath = os.path.join(arcpy.env.workspace, \"NHDPlusFlowlineVAA\")\n",
    "        #print(f'Vaa table at {vaapath} exists = {arcpy.Exists(vaapath)}')\n",
    "        append_value(vpuDict,huc,vaapath)\n",
    "        append_value(vpuDict,huc,roi)\n",
    "\n",
    "vpuDict\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Collect TauDEM data and build input dictionaries\n",
    "* Only focusing on Prince of Wales right now."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# #TauDEM data\n",
    "# #Create Dictionary to relate datasets to vpu\n",
    "# tauvpuDict = {}\n",
    "#\n",
    "# # Path to network folder with TauDEM outputs\n",
    "# taufol = r\"T:\\\\Aquatic\\\\AKSSF\\\\TauDEM\"\n",
    "#\n",
    "# # Path to local folder with TauDEM outputs\n",
    "# #taufol = r\"\"\n",
    "#\n",
    "# # All rois\n",
    "# #taurois = ['Bristol_Bay', 'Kodiak','Prince_William_Sound']\n",
    "# taurois = ['Prince_William_Sound']\n",
    "#\n",
    "# # Lists and dictionaries to organize input datasets\n",
    "# tauvpuList = []\n",
    "# tauregDict = {}\n",
    "#\n",
    "# #NHD folders - Update to new data downloaded Nov 8, 2021\n",
    "# for roi in taurois:\n",
    "#     arcpy.env.workspace = os.path.join(taufol,roi)\n",
    "#     taufols = arcpy.ListWorkspaces('*','Folder')\n",
    "#     print(taufol)\n",
    "#     tauCats = []\n",
    "#     taustreams = []\n",
    "#\n",
    "#\n",
    "#     for fol in taufols:\n",
    "#         with arcpy.da.Walk(fol,)\n",
    "#         arcpy.env.workspace = fol\n",
    "#         tauvpuList.append(roi)\n",
    "#         for fc in arcpy.ListFeatureClasses():\n",
    "#             print(fc)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scratch folder will be created W:\\GIS\\huc12_Outputs\n",
      "Scratch GDB at W:\\GIS\\huc12_Outputs\\huc12_scratch.gdb \n",
      "Path specified does not exist!\n",
      "Please re-enter a valid path\n",
      "Using AWC events from J:\\\\GIS_data\\\\biota\\\\Aquatic\\\\Fauna\\\\AWC\\\\2021_Species_LifeStage.gdb\\\\AWC_2021_SpeciesEvents.gdb\\\\awcEventArcs\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Creating scratch folder W:\\GIS\\huc12_Outputs\n",
      "----------\n",
      "Creating scratch gdb W:\\GIS\\huc12_Outputs\\huc12_scratch.gdb\n",
      "----------\n",
      "Creating scratch gdb for vpu 19020202 at W:\\GIS\\huc12_Outputs\\h12_19020202.gdb\n",
      "----------\n",
      "Creating scratch gdb for vpu 19020301 at W:\\GIS\\huc12_Outputs\\h12_19020301.gdb\n",
      "----------\n",
      "Creating scratch gdb for vpu 19020302 at W:\\GIS\\huc12_Outputs\\h12_19020302.gdb\n",
      "----------\n",
      "Creating scratch gdb for vpu 19020401 at W:\\GIS\\huc12_Outputs\\h12_19020401.gdb\n",
      "----------\n",
      "Creating scratch gdb for vpu 19020402 at W:\\GIS\\huc12_Outputs\\h12_19020402.gdb\n",
      "----------\n",
      "Creating scratch gdb for vpu 19020501 at W:\\GIS\\huc12_Outputs\\h12_19020501.gdb\n",
      "----------\n",
      "Creating scratch gdb for vpu 19020502 at W:\\GIS\\huc12_Outputs\\h12_19020502.gdb\n",
      "----------\n",
      "Creating scratch gdb for vpu 19020503 at W:\\GIS\\huc12_Outputs\\h12_19020503.gdb\n",
      "----------\n",
      "Creating scratch gdb for vpu 19020504 at W:\\GIS\\huc12_Outputs\\h12_19020504.gdb\n",
      "----------\n",
      "Creating scratch gdb for vpu 19020505 at W:\\GIS\\huc12_Outputs\\h12_19020505.gdb\n",
      "----------\n",
      "Creating scratch gdb for vpu 19020601 at W:\\GIS\\huc12_Outputs\\h12_19020601.gdb\n",
      "----------\n",
      "Creating scratch gdb for vpu 19020602 at W:\\GIS\\huc12_Outputs\\h12_19020602.gdb\n",
      "----------\n",
      "Creating scratch gdb for vpu 19020800 at W:\\GIS\\huc12_Outputs\\h12_19020800.gdb\n",
      "----------\n",
      "Creating scratch gdb for vpu 19020101 at W:\\GIS\\huc12_Outputs\\h12_19020101.gdb\n",
      "----------\n",
      "Creating scratch gdb for vpu 19020102 at W:\\GIS\\huc12_Outputs\\h12_19020102.gdb\n",
      "----------\n",
      "Creating scratch gdb for vpu 19020103 at W:\\GIS\\huc12_Outputs\\h12_19020103.gdb\n",
      "----------\n",
      "Creating scratch gdb for vpu 19020104 at W:\\GIS\\huc12_Outputs\\h12_19020104.gdb\n",
      "----------\n",
      "All scratch workspaces set\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'19020202': 'W:\\\\GIS\\\\huc12_Outputs\\\\h12_19020202.gdb',\n '19020301': 'W:\\\\GIS\\\\huc12_Outputs\\\\h12_19020301.gdb',\n '19020302': 'W:\\\\GIS\\\\huc12_Outputs\\\\h12_19020302.gdb',\n '19020401': 'W:\\\\GIS\\\\huc12_Outputs\\\\h12_19020401.gdb',\n '19020402': 'W:\\\\GIS\\\\huc12_Outputs\\\\h12_19020402.gdb',\n '19020501': 'W:\\\\GIS\\\\huc12_Outputs\\\\h12_19020501.gdb',\n '19020502': 'W:\\\\GIS\\\\huc12_Outputs\\\\h12_19020502.gdb',\n '19020503': 'W:\\\\GIS\\\\huc12_Outputs\\\\h12_19020503.gdb',\n '19020504': 'W:\\\\GIS\\\\huc12_Outputs\\\\h12_19020504.gdb',\n '19020505': 'W:\\\\GIS\\\\huc12_Outputs\\\\h12_19020505.gdb',\n '19020601': 'W:\\\\GIS\\\\huc12_Outputs\\\\h12_19020601.gdb',\n '19020602': 'W:\\\\GIS\\\\huc12_Outputs\\\\h12_19020602.gdb',\n '19020800': 'W:\\\\GIS\\\\huc12_Outputs\\\\h12_19020800.gdb',\n '19020101': 'W:\\\\GIS\\\\huc12_Outputs\\\\h12_19020101.gdb',\n '19020102': 'W:\\\\GIS\\\\huc12_Outputs\\\\h12_19020102.gdb',\n '19020103': 'W:\\\\GIS\\\\huc12_Outputs\\\\h12_19020103.gdb',\n '19020104': 'W:\\\\GIS\\\\huc12_Outputs\\\\h12_19020104.gdb'}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set data dir equal to directory containing the AKSSF regional sub-folders.\n",
    "akssf_data_dir = r'D:\\\\GIS\\\\AKSSF'\n",
    "nhd_data_dir = r'D:\\\\Basedata\\\\NHDPlus'\n",
    "\n",
    "# Create dictionaries\n",
    "inputDict = {\"'\":\"\",'\"':\"\"}\n",
    "scrDict = {}\n",
    "\n",
    "def replace_all(userinput, dic):\n",
    "    for i, j in dic.items():\n",
    "        userinput = userinput.replace(i, j)\n",
    "    return userinput\n",
    "\n",
    "\n",
    "# Create scratch workspace\n",
    "while True:\n",
    "    try:\n",
    "        userinput = replace_all((input('Input drive or directory to create scratch workspaces ex. \\'W:\\\\GIS\\\\\\'\\n') or 'D:\\\\GIS\\\\'),inputDict)\n",
    "        if not arcpy.Exists(userinput):\n",
    "            print('Path specified does not exist!\\nPlease re-enter a valid path')\n",
    "            continue\n",
    "        else:\n",
    "            scratchdrive = userinput\n",
    "            break\n",
    "    except arcpy.ExecuteError:\n",
    "            print(arcpy.GetMessages())\n",
    "\n",
    "huc12cv_scratchgdb = os.path.normpath(os.path.join(scratchdrive,r\"huc12_Outputs\\\\huc12_scratch.gdb\"))\n",
    "huc12cv_scratchfol = os.path.dirname(huc12cv_scratchgdb)\n",
    "print(f'Scratch folder will be created {huc12cv_scratchfol}\\nScratch GDB at {huc12cv_scratchgdb} ')\n",
    "\n",
    "# Specify path to AWC events fc\n",
    "while True:\n",
    "    try:\n",
    "        userinput2 = replace_all((input('Input path to awc events feature class or shapefile. \\'\"J:\\\\GIS_data\\\\biota\\\\Aquatic\\\\Fauna\\\\AWC\\\\2021_Species_LifeStage.gdb\\\\AWC_2021_SpeciesEvents.gdb\\\\awcEventArcs\"\\'\\n') or\n",
    "                                  'D:\\\\Basedata\\\\AWC\\\\AWC_2021_SpeciesEvents.gdb\\\\awcEventArcs'), inputDict)\n",
    "        if not arcpy.Exists(userinput2):\n",
    "            print('Path specified does not exist!\\nPlease re-enter a valid path')\n",
    "            continue\n",
    "        else:\n",
    "            awc_events = userinput2\n",
    "            break\n",
    "    except arcpy.ExecuteError:\n",
    "            print(arcpy.GetMessages())\n",
    "\n",
    "print(f'Using AWC events from {awc_events}\\n {\"-\"*100}')\n",
    "\n",
    "# Create Scratch Workspaces and add to dictionary\n",
    "if not arcpy.Exists(huc12cv_scratchfol):\n",
    "    os.mkdir(huc12cv_scratchfol)\n",
    "    print(f'Creating scratch folder {huc12cv_scratchfol}')\n",
    "else:\n",
    "    print(f'Scratch folder {huc12cv_scratchfol} already exists')\n",
    "print('----------')\n",
    "\n",
    "if not arcpy.Exists(huc12cv_scratchgdb):\n",
    "    arcpy.CreateFileGDB_management(huc12cv_scratchfol,\"huc12_scratch.gdb\")\n",
    "    print(f'Creating scratch gdb {huc12cv_scratchgdb}')\n",
    "else:\n",
    "    print(f'Scratch folder {huc12cv_scratchgdb} already exists')\n",
    "print('----------')\n",
    "\n",
    "\n",
    "# Create VPU output gdbs\n",
    "for vpu in vpuList:\n",
    "    vpu_name = os.path.basename(vpu)\n",
    "    hucscratchgdbname = 'h12_'+ vpu_name + '.gdb'\n",
    "    hucscratchgdbpath = os.path.join(huc12cv_scratchfol, hucscratchgdbname)\n",
    "    append_value(scrDict,vpu_name,hucscratchgdbpath)\n",
    "    if not arcpy.Exists(hucscratchgdbpath):\n",
    "        arcpy.CreateFileGDB_management(huc12cv_scratchfol,hucscratchgdbname)\n",
    "        print(f'Creating scratch gdb for vpu {vpu_name} at {hucscratchgdbpath}')\n",
    "    else:\n",
    "        print(f'Scratch gdb for {vpu_name} already created at {hucscratchgdbpath}')\n",
    "\n",
    "    print('----------')\n",
    "print(f'All scratch workspaces set')\n",
    "scrDict\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 2\n",
    "### By Vector Processing Unit\n",
    "Identify downstream-most catchment for each Huc 12\n",
    " * Select by location and select catchment with most us contributing area\n",
    "    * NHDPlus\n",
    "        * Use update cursor to join TotalDrainageAreaSqKm from vaa table to catchment\n",
    "        * Find max value from selection and save as outlet catchment for that HUC12\n",
    "    * TauDEM\n",
    "        * DSContArea - Drainage area at the downstream end of the link. Generally this is one grid cell upstream of the downstream end because the drainage area at the downstream end grid cell includes the area of the stream being joined.\n",
    " * Generate Centroid point and append to centroid dataset\n",
    "    * Retain cat_id and Huc12-id\n",
    " * Append to HUC12 catchment dataset\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020202 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020301 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "****************************************************************************************************\n",
      "Huc 19020302 will be processed\n",
      "INPUTS:\\cats = D:\\Basedata\\NHDPlus\\Cook_Inlet\\NHDPLUS_H_19020302_HU8_GDB.gdb\\NHDPlus\\NHDPlusCatchment\n",
      "hucs = D:\\Basedata\\NHDPlus\\Cook_Inlet\\NHDPLUS_H_19020302_HU8_GDB.gdb\\WBD\\WBDHU12\n",
      "streams = D:\\Basedata\\NHDPlus\\Cook_Inlet\\NHDPLUS_H_19020302_HU8_GDB.gdb\\Hydrography\\NHDFlowline\n",
      "lakes = D:\\Basedata\\NHDPlus\\Cook_Inlet\\NHDPLUS_H_19020302_HU8_GDB.gdb\\Hydrography\\NHDWaterbody\n",
      "vaas =  D:\\Basedata\\NHDPlus\\Cook_Inlet\\NHDPLUS_H_19020302_HU8_GDB.gdb\\NHDPlusFlowlineVAA\n",
      "region = Cook_Inlet\n",
      "\n",
      "****************************************************************************************************\n",
      "99 of 112 HUC12s in 19020302 intersect awc events input\n",
      "****************************************************************************************************\n",
      "Processing HUC 190203021004\n",
      "1. Finding outlet for HUC 190203021004 out of 80 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020303\n",
      "2. Finding outlet for HUC 190203020303 out of 134 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020502\n",
      "3. Finding outlet for HUC 190203020502 out of 93 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020503\n",
      "4. Finding outlet for HUC 190203020503 out of 204 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203022002\n",
      "5. Finding outlet for HUC 190203022002 out of 158 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020904\n",
      "6. Finding outlet for HUC 190203020904 out of 115 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021601\n",
      "7. Finding outlet for HUC 190203021601 out of 37 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021701\n",
      "8. Finding outlet for HUC 190203021701 out of 71 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021104\n",
      "9. Finding outlet for HUC 190203021104 out of 81 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021908\n",
      "10. Finding outlet for HUC 190203021908 out of 43 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021405\n",
      "11. Finding outlet for HUC 190203021405 out of 174 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203022004\n",
      "12. Finding outlet for HUC 190203022004 out of 8 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021007\n",
      "13. Finding outlet for HUC 190203021007 out of 151 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203022001\n",
      "14. Finding outlet for HUC 190203022001 out of 23 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203022005\n",
      "15. Finding outlet for HUC 190203022005 out of 26 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021602\n",
      "16. Finding outlet for HUC 190203021602 out of 46 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021201\n",
      "17. Finding outlet for HUC 190203021201 out of 129 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021406\n",
      "18. Finding outlet for HUC 190203021406 out of 223 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020603\n",
      "19. Finding outlet for HUC 190203020603 out of 50 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020702\n",
      "20. Finding outlet for HUC 190203020702 out of 276 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020305\n",
      "21. Finding outlet for HUC 190203020305 out of 451 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021103\n",
      "22. Finding outlet for HUC 190203021103 out of 136 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020404\n",
      "23. Finding outlet for HUC 190203020404 out of 80 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020501\n",
      "24. Finding outlet for HUC 190203020501 out of 97 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021802\n",
      "25. Finding outlet for HUC 190203021802 out of 47 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021801\n",
      "26. Finding outlet for HUC 190203021801 out of 71 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020802\n",
      "27. Finding outlet for HUC 190203020802 out of 24 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021505\n",
      "28. Finding outlet for HUC 190203021505 out of 96 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021006\n",
      "29. Finding outlet for HUC 190203021006 out of 47 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021806\n",
      "30. Finding outlet for HUC 190203021806 out of 121 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021805\n",
      "31. Finding outlet for HUC 190203021805 out of 71 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020806\n",
      "32. Finding outlet for HUC 190203020806 out of 144 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021003\n",
      "33. Finding outlet for HUC 190203021003 out of 309 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020903\n",
      "34. Finding outlet for HUC 190203020903 out of 219 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020703\n",
      "35. Finding outlet for HUC 190203020703 out of 111 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021808\n",
      "36. Finding outlet for HUC 190203021808 out of 24 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021803\n",
      "37. Finding outlet for HUC 190203021803 out of 48 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020804\n",
      "38. Finding outlet for HUC 190203020804 out of 86 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021904\n",
      "39. Finding outlet for HUC 190203021904 out of 100 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020205\n",
      "40. Finding outlet for HUC 190203020205 out of 177 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020202\n",
      "41. Finding outlet for HUC 190203020202 out of 259 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020701\n",
      "42. Finding outlet for HUC 190203020701 out of 103 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020902\n",
      "43. Finding outlet for HUC 190203020902 out of 196 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020101\n",
      "44. Finding outlet for HUC 190203020101 out of 105 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020604\n",
      "45. Finding outlet for HUC 190203020604 out of 20 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020406\n",
      "46. Finding outlet for HUC 190203020406 out of 122 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021804\n",
      "47. Finding outlet for HUC 190203021804 out of 27 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021604\n",
      "48. Finding outlet for HUC 190203021604 out of 23 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021905\n",
      "49. Finding outlet for HUC 190203021905 out of 25 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021205\n",
      "50. Finding outlet for HUC 190203021205 out of 292 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020801\n",
      "51. Finding outlet for HUC 190203020801 out of 27 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021606\n",
      "52. Finding outlet for HUC 190203021606 out of 44 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020201\n",
      "53. Finding outlet for HUC 190203020201 out of 84 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021605\n",
      "54. Finding outlet for HUC 190203021605 out of 56 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021607\n",
      "55. Finding outlet for HUC 190203021607 out of 24 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020803\n",
      "56. Finding outlet for HUC 190203020803 out of 61 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020302\n",
      "57. Finding outlet for HUC 190203020302 out of 42 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021504\n",
      "58. Finding outlet for HUC 190203021504 out of 135 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021303\n",
      "59. Finding outlet for HUC 190203021303 out of 185 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021005\n",
      "60. Finding outlet for HUC 190203021005 out of 68 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020407\n",
      "61. Finding outlet for HUC 190203020407 out of 292 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020408\n",
      "62. Finding outlet for HUC 190203020408 out of 259 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021203\n",
      "63. Finding outlet for HUC 190203021203 out of 206 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021403\n",
      "64. Finding outlet for HUC 190203021403 out of 96 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021704\n",
      "65. Finding outlet for HUC 190203021704 out of 26 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021102\n",
      "66. Finding outlet for HUC 190203021102 out of 133 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021409\n",
      "67. Finding outlet for HUC 190203021409 out of 195 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021407\n",
      "68. Finding outlet for HUC 190203021407 out of 36 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020304\n",
      "69. Finding outlet for HUC 190203020304 out of 113 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021501\n",
      "70. Finding outlet for HUC 190203021501 out of 81 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021002\n",
      "71. Finding outlet for HUC 190203021002 out of 45 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021902\n",
      "72. Finding outlet for HUC 190203021902 out of 24 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021401\n",
      "73. Finding outlet for HUC 190203021401 out of 206 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203022003\n",
      "74. Finding outlet for HUC 190203022003 out of 36 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020601\n",
      "75. Finding outlet for HUC 190203020601 out of 56 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020607\n",
      "76. Finding outlet for HUC 190203020607 out of 31 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020504\n",
      "77. Finding outlet for HUC 190203020504 out of 68 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020301\n",
      "78. Finding outlet for HUC 190203020301 out of 77 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020102\n",
      "79. Finding outlet for HUC 190203020102 out of 206 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021503\n",
      "80. Finding outlet for HUC 190203021503 out of 112 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021408\n",
      "81. Finding outlet for HUC 190203021408 out of 29 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020203\n",
      "82. Finding outlet for HUC 190203020203 out of 167 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021903\n",
      "83. Finding outlet for HUC 190203021903 out of 50 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020705\n",
      "84. Finding outlet for HUC 190203020705 out of 430 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020606\n",
      "85. Finding outlet for HUC 190203020606 out of 43 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021807\n",
      "86. Finding outlet for HUC 190203021807 out of 21 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020605\n",
      "87. Finding outlet for HUC 190203020605 out of 41 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020405\n",
      "88. Finding outlet for HUC 190203020405 out of 70 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020704\n",
      "89. Finding outlet for HUC 190203020704 out of 86 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020204\n",
      "90. Finding outlet for HUC 190203020204 out of 90 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021204\n",
      "91. Finding outlet for HUC 190203021204 out of 267 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020403\n",
      "92. Finding outlet for HUC 190203020403 out of 85 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021901\n",
      "93. Finding outlet for HUC 190203021901 out of 79 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021404\n",
      "94. Finding outlet for HUC 190203021404 out of 62 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021603\n",
      "95. Finding outlet for HUC 190203021603 out of 10 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203021809\n",
      "96. Finding outlet for HUC 190203021809 out of 63 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020608\n",
      "97. Finding outlet for HUC 190203020608 out of 33 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020609\n",
      "98. Finding outlet for HUC 190203020609 out of 50 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190203020602\n",
      "99. Finding outlet for HUC 190203020602 out of 60 catchments.\n",
      "************************************************************\n",
      "Creating copy of 99 outlet catchments for Huc 19020302 at W:\\GIS\\huc12_Outputs\\h12_19020302.gdb\\HUC_19020302_out_cats\n",
      "****************************************************************************************************\n",
      "19020302 Elapsed time: (0:00:48)\n",
      "************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020401 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020402 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020501 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020502 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020503 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020504 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020505 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020601 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020602 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020800 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020101 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020102 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020103 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Huc 19020104 will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "Process completed at 2022-02-02 14:56 (Elapsed time: 0:00:48)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# List of HUC12s to be processed\n",
    "import arcpy, operator, time, datetime\n",
    "\n",
    "outletDict = {}\n",
    "outletList = []\n",
    "outletcats = []\n",
    "outletcatpts = []\n",
    "\n",
    "# Uncomment to run all\n",
    "# proclist = vpuList\n",
    "\n",
    "# Run subset\n",
    "proclist = ['19020302']\n",
    "\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "\n",
    "for vpu in vpuList:\n",
    "    if vpu in proclist:\n",
    "        try:\n",
    "            # Start vpu timing function\n",
    "            vpu_start = time.time()\n",
    "            print(('*'*100))\n",
    "            print(f'Huc {vpu} will be processed')\n",
    "\n",
    "            # Must match names because some items in dictionary are out of order\n",
    "            for v in vpuDict[vpu]:\n",
    "                # Inputs\n",
    "                if 'NHDPlusCatchment' in v:\n",
    "                    cats = v\n",
    "                elif 'NHDFlowline' in v:\n",
    "                    streams = v\n",
    "                elif 'NHDWaterbody'in v:\n",
    "                    lakes = v\n",
    "                elif 'WBDHU12' in v:\n",
    "                    hucs = v\n",
    "                elif 'NHDPlusFlowlineVAA' in v:\n",
    "                    vaas = v\n",
    "                elif ':' not in v:\n",
    "                    region = v\n",
    "            print(f'INPUTS:\\cats = {cats}\\nhucs = {hucs}\\nstreams = {streams}\\nlakes = {lakes}\\nvaas =  {vaas}\\nregion = {region}\\n')\n",
    "            #Output names and paths\n",
    "            outletcatsname = 'HUC_' + str(vpu) +'_out_cats'\n",
    "            outcatspath = os.path.join(scrDict[vpu],outletcatsname)\n",
    "            outletcatptsname = 'HUC_' + str(vpu) +'_out_catspts'\n",
    "            outcatptspath = os.path.join(scrDict[vpu],outletcatptsname)\n",
    "\n",
    "            # Build Value dictionary to relate NHDPlus id to contributing area\n",
    "            fields = ['NHDPlusID','TotDASqKm']\n",
    "            fields2 = fields + ['cat_ID_con']\n",
    "            valueDict = {r[0]:(r[1:]) for r in arcpy.da.SearchCursor(vaas, fields)}\n",
    "            hucselect = arcpy.SelectLayerByLocation_management(hucs,'INTERSECT',awc_events,'','NEW_SELECTION')\n",
    "            print(('*'*100))\n",
    "            print(f'{arcpy.GetCount_management(hucselect)} of {arcpy.GetCount_management(hucs)} HUC12s in {vpu} intersect awc events input')\n",
    "            print(('*'*100))\n",
    "            hucFields = [f for f in arcpy.ListFields(hucselect)]\n",
    "            # for f in hucFields:\n",
    "            #     print (f'{f.name} is of {f.type} type')\n",
    "            vcount =1\n",
    "            with arcpy.da.SearchCursor(hucselect,['HUC12','SHAPE@']) as cur:\n",
    "                for row in cur:\n",
    "                    print(f'Processing HUC {row[0]}')\n",
    "                    inhuc = row[1]\n",
    "                    cat_layer = arcpy.MakeFeatureLayer_management(cats,'cat_layer')\n",
    "                    # Select by location using awc and huc 12\n",
    "                    arcpy.SelectLayerByLocation_management(cat_layer,'HAVE_THEIR_CENTER_IN',inhuc,'','NEW_SELECTION')\n",
    "                    print(f'{vcount}. Finding outlet for HUC {row[0]} out of {arcpy.GetCount_management(cat_layer)} catchments.\\n{(\"*\" * 60)}')\n",
    "                    catList = [r[0] for r in arcpy.da.SearchCursor(cat_layer, 'NHDPlusID')]\n",
    "                    intersect = list(set(catList).intersection(valueDict))\n",
    "                    catDict = {int(i):(valueDict[i]) for i in intersect}\n",
    "                    # Find Catchment with max drainage area\n",
    "                    outcatch = max(catDict.items(), key = operator.itemgetter(1))[0]\n",
    "                    append_value(outletDict, row[0], int(outcatch))\n",
    "                    append_value(outletDict, row[0], vpu)\n",
    "                    outletList.append(int(outcatch))\n",
    "                    vcount+=1\n",
    "                del(row)\n",
    "            del(cur)\n",
    "\n",
    "            outlet_cats = arcpy.MakeFeatureLayer_management(cats,'outlet_cats')\n",
    "            out_expression ='\"NHDPlusID\" IN ' + str(tuple(outletList))\n",
    "            #print(out_expression)\n",
    "            outlet_cats_select = arcpy.SelectLayerByAttribute_management(outlet_cats,'NEW_SELECTION', out_expression)\n",
    "            print(f'Creating copy of {arcpy.GetCount_management(outlet_cats)} outlet catchments for Huc {vpu} at {outcatspath}')\n",
    "            print(('*'*100))\n",
    "\n",
    "            # Copy outputs\n",
    "            arcpy.FeatureClassToFeatureClass_conversion(outlet_cats_select,scrDict[vpu],outletcatsname)\n",
    "            arcpy.FeatureToPoint_management(outcatspath, outcatptspath, 'INSIDE')\n",
    "\n",
    "            # Add total drainage km from value dict to feature classes and cat_ID_con from regDict\n",
    "            upfcs = [outcatspath, outcatptspath]\n",
    "            for upfc in upfcs:\n",
    "                arcpy.AddField_management(upfc,fields[1],'TEXT')\n",
    "                arcpy.AddField_management(upfc,fields2[2],'TEXT')\n",
    "                with arcpy.da.UpdateCursor(upfc,fields2) as cur:\n",
    "                    for row in cur:\n",
    "                        row[1] = valueDict[row[0]][0]\n",
    "                        row[2] = regDict[vpu] + '_' + str(int(row[0]))\n",
    "                        cur.updateRow(row)\n",
    "                    del(row)\n",
    "                del(cur)\n",
    "\n",
    "            outletcats.append(outcatspath)\n",
    "            outletcatpts.append(outcatptspath)\n",
    "\n",
    "            # End Vpu time\n",
    "            vpu_stop = time.time()\n",
    "            vpu_time = int (vpu_stop - vpu_start)\n",
    "            print(f'{vpu} Elapsed time: ({datetime.timedelta(seconds=vpu_time)})')\n",
    "            print(f'{\"*\"*60}')\n",
    "\n",
    "        except Exception:\n",
    "            e = sys.exc_info()[1]\n",
    "            print(e.args[0])\n",
    "            arcpy.AddError(e.args[0])\n",
    "\n",
    "    else:\n",
    "        print(('-'*100))\n",
    "        print(f'Huc {vpu} will not be processed')\n",
    "        print(('-'*100),'\\n')\n",
    "\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "\n",
    "# Report success\n",
    "print(f'Process completed at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "      f'(Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print('----------')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 2.1\n",
    "Calculate Distance to Coast from outlet catchment point to the nearest coastline as a straight line distance\n",
    " * Generate near table and export as seperate csv\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting distance to coast 2022-02-02 15:13:32.691017...\n",
      "Process complete at 2022-02-02 15:13:58.877378 time elapsed: 0:00:26.186361 \n"
     ]
    }
   ],
   "source": [
    "import arcpy, datetime\n",
    "import numpy as pd\n",
    "\n",
    "# Input path to coastline\n",
    "coast = r\"T:\\\\Aquatic\\\\AKSSF\\\\AKSSF_Hydrography.gdb\\\\AKSSF_NHD_Coastline\"\n",
    "\n",
    "# Merge all catchment outlet centroids together\n",
    "outletsname = 'AKSSF_NHDPlus_awcHuc12_outlet_cats_points'\n",
    "outletspath = os.path.join(hucscratchgdbpath, outletsname)\n",
    "all_nhd_outlet_pts = arcpy.Merge_management(outletcatpts,outletspath)\n",
    "\n",
    "# Start timing function\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "print(f'Getting distance to coast {datetime.datetime.now()}...')\n",
    "arcpy.analysis.Near(all_nhd_outlet_pts, coast, None, \"NO_LOCATION\", \"NO_ANGLE\", \"GEODESIC\", \"NEAR_DIST NEAR_DIST\")\n",
    "arcpy.AlterField_management(all_nhd_outlet_pts,'NEAR_DIST','dist_catch_coast_km','dist_catch_coast_km' )\n",
    "\n",
    "# Convert distance in meters to km\n",
    "with arcpy.da.UpdateCursor(all_nhd_outlet_pts,['dist_catch_coast_km']) as cur:\n",
    "    for row in cur:\n",
    "        row[0] = row[0] * 0.001\n",
    "        cur.updateRow(row)\n",
    "    del(row)\n",
    "del(cur)\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "elapsed  = stop - start\n",
    "print (f'Process complete at {datetime.datetime.now()} time elapsed: {elapsed} ')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Convert to df and examine"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "                              NHDPlusID  dist_catch_coast_km     TotDASqKm\ncat_ID_con                                                                \nCook_Inlet_75004400008879  7.500440e+13             0.129134   23.32322502\nCook_Inlet_75004400008242  7.500440e+13            33.035154  112.78277531\nCook_Inlet_75004400007224  7.500440e+13             0.018925  322.32710002\nCook_Inlet_75004400008539  7.500440e+13            23.968173  103.00622492\nCook_Inlet_75004400011230  7.500440e+13            16.691152   88.33480009\n...                                 ...                  ...           ...\nCook_Inlet_75004400004344  7.500440e+13             6.468900  164.24760023\nCook_Inlet_75004400004213  7.500440e+13            14.543668   60.98154999\nCook_Inlet_75004400007351  7.500440e+13            12.646195   96.95405006\nCook_Inlet_75004400002957  7.500440e+13            33.044556  108.87004986\nCook_Inlet_75004400000171  7.500440e+13             0.589786  110.75582486\n\n[99 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NHDPlusID</th>\n      <th>dist_catch_coast_km</th>\n      <th>TotDASqKm</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Cook_Inlet_75004400008879</th>\n      <td>7.500440e+13</td>\n      <td>0.129134</td>\n      <td>23.32322502</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400008242</th>\n      <td>7.500440e+13</td>\n      <td>33.035154</td>\n      <td>112.78277531</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400007224</th>\n      <td>7.500440e+13</td>\n      <td>0.018925</td>\n      <td>322.32710002</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400008539</th>\n      <td>7.500440e+13</td>\n      <td>23.968173</td>\n      <td>103.00622492</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400011230</th>\n      <td>7.500440e+13</td>\n      <td>16.691152</td>\n      <td>88.33480009</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004344</th>\n      <td>7.500440e+13</td>\n      <td>6.468900</td>\n      <td>164.24760023</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004213</th>\n      <td>7.500440e+13</td>\n      <td>14.543668</td>\n      <td>60.98154999</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400007351</th>\n      <td>7.500440e+13</td>\n      <td>12.646195</td>\n      <td>96.95405006</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400002957</th>\n      <td>7.500440e+13</td>\n      <td>33.044556</td>\n      <td>108.87004986</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400000171</th>\n      <td>7.500440e+13</td>\n      <td>0.589786</td>\n      <td>110.75582486</td>\n    </tr>\n  </tbody>\n</table>\n<p>99 rows  3 columns</p>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "\n",
    "# Make catchment points df\n",
    "cat_df = pd.DataFrame()\n",
    "cat_field_list = []\n",
    "\n",
    "for field in arcpy.ListFields(all_nhd_outlet_pts):\n",
    "    cat_field_list.append(field.name)\n",
    "cat_arr = arcpy.da.TableToNumPyArray(all_nhd_outlet_pts, ['cat_ID_con', 'NHDPlusID','dist_catch_coast_km','TotDASqKm'])\n",
    "cat_df = pd.DataFrame(cat_arr)\n",
    "cat_df = cat_df.set_index('cat_ID_con')\n",
    "cat_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Export csv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV export complete\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#Export CSV to read into R\n",
    "outdir = r\"C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\"\n",
    "nhd_catpts_outname = 'AKSSF_NHDPlus_awcHuc12_19020302_dist_catch_coast_km.csv'\n",
    "arcpy.da.NumPyArrayToTable(cat_arr,os.path.join(outdir,nhd_catpts_outname))\n",
    "print('CSV export complete')\n",
    "print('----------')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 3\n",
    "### Generate watersheds\n",
    "Iterate over HUC12 catchment dataset and create watersheds\n",
    " * Append output wtd to wtd dataset - Link back to catchment using catID (create catIDcon for unique identifier field)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Huc 19020302 will be processed\n",
      "19020302\n",
      "cats = D:\\Basedata\\NHDPlus\\Cook_Inlet\\NHDPLUS_H_19020302_HU8_GDB.gdb\\NHDPlus\\NHDPlusCatchment\n",
      "hucs = D:\\Basedata\\NHDPlus\\Cook_Inlet\\NHDPLUS_H_19020302_HU8_GDB.gdb\\WBD\\WBDHU12\n",
      "streams = D:\\Basedata\\NHDPlus\\Cook_Inlet\\NHDPLUS_H_19020302_HU8_GDB.gdb\\Hydrography\\NHDFlowline\n",
      "lakes = D:\\Basedata\\NHDPlus\\Cook_Inlet\\NHDPLUS_H_19020302_HU8_GDB.gdb\\Hydrography\\NHDWaterbody\n",
      "vaas =  D:\\Basedata\\NHDPlus\\Cook_Inlet\\NHDPLUS_H_19020302_HU8_GDB.gdb\\NHDPlusFlowlineVAA\n",
      "region = Cook_Inlet\n",
      "\n",
      "Creating index for W:\\GIS\\huc12_Outputs\\h12_19020302.gdb\\huc_19020302_cats\n",
      "Starting watershed for: 75004400005344 -(1 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400011755 -(2 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400010352 -(3 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400007996 -(4 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400004850 -(5 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400005312 -(6 of 99)\n",
      "Elapsed time: (0:00:04)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400004652 -(7 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400006033 -(8 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400009412 -(9 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400008887 -(10 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400010754 -(11 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400006170 -(12 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400008216 -(13 of 99)\n",
      "Elapsed time: (0:00:05)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400007830 -(14 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400009109 -(15 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400007550 -(16 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400003815 -(17 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400000334 -(18 of 99)\n",
      "Elapsed time: (0:00:14)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400010699 -(19 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400001136 -(20 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400007224 -(21 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400002041 -(22 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400011320 -(23 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400006433 -(24 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400005985 -(25 of 99)\n",
      "Elapsed time: (0:00:23)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400005909 -(26 of 99)\n",
      "Elapsed time: (0:00:22)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400008859 -(27 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400001616 -(28 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400000862 -(29 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400010386 -(30 of 99)\n",
      "Elapsed time: (0:00:44)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400008899 -(31 of 99)\n",
      "Elapsed time: (0:00:34)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400010422 -(32 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400003876 -(33 of 99)\n",
      "Elapsed time: (0:00:04)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400009792 -(34 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400005660 -(35 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400010402 -(36 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400001521 -(37 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400000153 -(38 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400007465 -(39 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400010175 -(40 of 99)\n",
      "Elapsed time: (0:00:04)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400010221 -(41 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400011086 -(42 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400011230 -(43 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400006692 -(44 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400010610 -(45 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400001464 -(46 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400010320 -(47 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400002957 -(48 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400000141 -(49 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400010328 -(50 of 99)\n",
      "Elapsed time: (0:00:10)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400003189 -(51 of 99)\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400007512 -(52 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400010270 -(53 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400002954 -(54 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400004450 -(55 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400002953 -(56 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400002718 -(57 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400003165 -(58 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400000370 -(59 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400008242 -(60 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400008192 -(61 of 99)\n",
      "Elapsed time: (0:00:04)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400002279 -(62 of 99)\n",
      "Elapsed time: (0:00:05)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400008856 -(63 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400009331 -(64 of 99)\n",
      "Elapsed time: (0:00:04)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400007493 -(65 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400010351 -(66 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400001652 -(67 of 99)\n",
      "Elapsed time: (0:00:21)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400010639 -(68 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400011676 -(69 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400004680 -(70 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400008539 -(71 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400001443 -(72 of 99)\n",
      "Elapsed time: (0:00:04)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400002950 -(73 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400004743 -(74 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400009198 -(75 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400007686 -(76 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400000627 -(77 of 99)\n",
      "Elapsed time: (0:00:04)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400004213 -(78 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400002258 -(79 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400003230 -(80 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400001670 -(81 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400007351 -(82 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400001656 -(83 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400004166 -(84 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400010627 -(85 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400001569 -(86 of 99)\n",
      "Elapsed time: (0:00:25)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400004707 -(87 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400011322 -(88 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400001134 -(89 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400004344 -(90 of 99)\n",
      "Elapsed time: (0:00:04)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400009562 -(91 of 99)\n",
      "Elapsed time: (0:00:04)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400003768 -(92 of 99)\n",
      "Elapsed time: (0:00:04)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400000171 -(93 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400009308 -(94 of 99)\n",
      "Elapsed time: (0:00:04)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400010337 -(95 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400008879 -(96 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400004457 -(97 of 99)\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400005924 -(98 of 99)\n",
      "Elapsed time: (0:00:05)\n",
      "************************************************************\n",
      "Starting watershed for: 75004400004455 -(99 of 99)\n",
      "Elapsed time: (0:00:04)\n",
      "************************************************************\n",
      "19020302 Elapsed time: (0:09:01)\n",
      "************************************************************\n",
      "Process completed at 2022-02-02 15:32 (Elapsed time: 0:09:01)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Begin generating watersheds\n",
    "# List of HUC12s to be processed\n",
    "import arcpy, time, datetime, os\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "# steps 4-9 for loop to create watersheds\n",
    "arcpy.env.workspace = huc12cv_scratchgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.qualifiedFieldNames = False\n",
    "sr = arcpy.SpatialReference(3338)  #'NAD_1983_Alaska_Albers'\n",
    "arcpy.env.outputCoordinateSystem = sr\n",
    "\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "\n",
    "proclist = ['19020302']\n",
    "# proclist = vpuList\n",
    "wtdDict = {}\n",
    "\n",
    "for vpu in vpuList:\n",
    "    if vpu in proclist:\n",
    "        try:\n",
    "            # Start vpu timing function\n",
    "            vpu_start = time.time()\n",
    "            wtdList=[]\n",
    "            print(f'Huc {vpu} will be processed')\n",
    "            outgdb = scrDict[vpu]\n",
    "            # Must match names because some items in dictionary are out of order\n",
    "            for v in vpuDict[vpu]:\n",
    "                # Inputs\n",
    "                if 'NHDPlusCatchment' in v:\n",
    "                    cats = v\n",
    "                elif 'NHDFlowline' in v:\n",
    "                    streams = v\n",
    "                elif 'NHDWaterbody'in v:\n",
    "                    lakes = v\n",
    "                elif 'WBDHU12' in v:\n",
    "                    hucs = v\n",
    "                elif 'NHDPlusFlowlineVAA' in v:\n",
    "                    vaas = v\n",
    "                elif ':' not in v:\n",
    "                    region = v\n",
    "            print(vpu)\n",
    "            print(f'cats = {cats}\\nhucs = {hucs}\\nstreams = {streams}\\nlakes = {lakes}\\nvaas =  {vaas}\\nregion = {region}\\n')\n",
    "\n",
    "            catscopy = arcpy.CopyFeatures_management(cats,os.path.join(outgdb,'huc_'+str(vpu)+'_cats'))\n",
    "            # Get list of index names for cats merge and add index if not already created\n",
    "            index_names = [i.name for i in arcpy.ListIndexes(catscopy)]\n",
    "\n",
    "            if 'NHDPlusID_index' not in index_names:\n",
    "                print (f'Creating index for {catscopy}')\n",
    "                arcpy.AddIndex_management(catscopy,'NHDPlusID','NHDPlusID_index')\n",
    "            else:\n",
    "                print(f'{catscopy} Indexed')\n",
    "\n",
    "            #watersheds feature dataset for storing fcs\n",
    "            fdatname = 'Huc_' + str(vpu) + '_Watersheds'\n",
    "            fdat = os.path.join(outgdb, fdatname)\n",
    "            if not arcpy.Exists(fdat):\n",
    "                arcpy.management.CreateFeatureDataset(outgdb, fdatname, sr)\n",
    "            else:\n",
    "                print(f'{fdat} exists for {vpu}')\n",
    "\n",
    "            vaa_df1 = pd.DataFrame(arcpy.da.TableToNumPyArray(vaas, (\"NHDPlusID\", \"FromNode\", \"ToNode\", \"StartFlag\")))\n",
    "            stream_df = pd.DataFrame(arcpy.da.TableToNumPyArray(streams, (\"NHDPlusID\", \"FType\")))\n",
    "            dfs = [vaa_df1, stream_df]\n",
    "            vaa_df = reduce(lambda left,right: pd.merge(left,right,on='NHDPlusID',how=\"outer\"), dfs)\n",
    "            # remove pipelines\n",
    "            vaa_df = vaa_df[(vaa_df['FType'] != 428 )]\n",
    "            vaa_df\n",
    "\n",
    "            c=1\n",
    "\n",
    "            for id in outletList:\n",
    "                # Start iter timing function\n",
    "                iteration_start = time.time()\n",
    "\n",
    "                print(f\"{c}. Identifying watershed for: {str(id)} ({int(len(outletList))} - {c} Remain)\")\n",
    "                rec = [id]\n",
    "                up_ids = []\n",
    "                up_ids.append(rec)\n",
    "                rec_len = len(rec)\n",
    "                hws_sum = 0\n",
    "\n",
    "                while rec_len != hws_sum:\n",
    "                    fromnode = vaa_df.loc[vaa_df[\"NHDPlusID\"].isin(rec), \"FromNode\"]\n",
    "                    rec = vaa_df.loc[vaa_df[\"ToNode\"].isin(fromnode), \"NHDPlusID\"]\n",
    "                    rec_len = len(rec)\n",
    "                    rec_hws = vaa_df.loc[vaa_df[\"ToNode\"].isin(fromnode), \"StartFlag\"]\n",
    "                    hws_sum = sum(rec_hws)\n",
    "                    up_ids.append(rec)\n",
    "                #up_ids is a list with more than numbers, use extend to only keep numeric nhdplusids\n",
    "                newup_ids = []\n",
    "                for x in up_ids:\n",
    "                    newup_ids.extend(x)\n",
    "\n",
    "                tempLayer = \"catsLyr\"\n",
    "                expression = '\"NHDPlusID\" IN ({0})'.format(', '.join(map(str, newup_ids)) or 'NULL')\n",
    "                arcpy.MakeFeatureLayer_management(cats, tempLayer, where_clause=expression)\n",
    "                outdis = \"memory/wtd_\" + str(round(id))\n",
    "                outwtd = os.path.join(fdat,'wtd_'+ str(id))\n",
    "\n",
    "                dis = arcpy.Dissolve_management(tempLayer, outdis)\n",
    "                watershed = arcpy.EliminatePolygonPart_management(dis, outwtd,\"PERCENT\", \"0 SquareKilometers\", 90, \"CONTAINED_ONLY\")\n",
    "                wtdList.append(outwtd)\n",
    "                append_value(wtdDict,vpu,outwtd)\n",
    "                c=c+1\n",
    "\n",
    "                # Stop iteration timer\n",
    "                iteration_stop = time.time()\n",
    "                iter_time = int (iteration_stop - iteration_start)\n",
    "                print(f'Elapsed time: ({datetime.timedelta(seconds=iter_time)})')\n",
    "                print(f'{\"*\"*60}')\n",
    "\n",
    "            wtd_merge = arcpy.Merge_management(wtdList, os.path.join(huc12cv_scratchgdb,'AKSSF_HUC_'+str(vpu)+'_wtds_merge'),'','ADD_SOURCE_INFO')\n",
    "            arcpy.AddField_management(wtd_merge,'cat_ID_con','TEXT')\n",
    "            arcpy.AddField_management(wtd_merge,'cat_ID','DOUBLE')\n",
    "            arcpy.AddField_management(wtd_merge,'cat_ID_txt','TEXT')\n",
    "            arcpy.AddField_management(wtd_merge,'NHDPlusID','DOUBLE')\n",
    "            with arcpy.da.UpdateCursor(wtd_merge,['MERGE_SRC','NHDPlusID','cat_ID_con','cat_ID','cat_ID_txt']) as cur:\n",
    "                for row in cur:\n",
    "                    # Pull nhdplus id from merge source and calculate fields\n",
    "                    nhdplusid= int(row[0].split('\\\\')[-1:][0].split('_')[1])\n",
    "                    row[1] = nhdplusid\n",
    "                    row[2] = region + '_' + str(nhdplusid)\n",
    "                    row[3] = nhdplusid\n",
    "                    row[4] = str(nhdplusid)\n",
    "                    cur.updateRow(row)\n",
    "                del(row)\n",
    "            del(cur)\n",
    "\n",
    "            # Stop iteration timer\n",
    "            vpu_stop = time.time()\n",
    "            vpu_time = int (vpu_stop - vpu_start)\n",
    "            print(f'{vpu} Elapsed time: ({datetime.timedelta(seconds=vpu_time)})')\n",
    "            print(f'{\"*\"*60}')\n",
    "\n",
    "        except:\n",
    "            e = sys.exc_info()[1]\n",
    "            print(e.args[0])\n",
    "            arcpy.AddError(e.args[0])\n",
    "\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "\n",
    "# Report success\n",
    "print(f'Process completed at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "      f'(Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print('----------')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 4\n",
    "###Calculate covariates\n",
    "Iterate over watersheds and calculate the following:\n",
    "* Mean wtd slope\n",
    "* % Lake Cover\n",
    "* Mean LCLD\n",
    "* % Glacier Cover\n",
    "* % North"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19020302\n",
      "cats = D:\\Basedata\\NHDPlus\\Cook_Inlet\\NHDPLUS_H_19020302_HU8_GDB.gdb\\NHDPlus\\NHDPlusCatchment\n",
      "hucs = D:\\Basedata\\NHDPlus\\Cook_Inlet\\NHDPLUS_H_19020302_HU8_GDB.gdb\\WBD\\WBDHU12\n",
      "streams = D:\\Basedata\\NHDPlus\\Cook_Inlet\\NHDPLUS_H_19020302_HU8_GDB.gdb\\Hydrography\\NHDFlowline\n",
      "lakes = D:\\Basedata\\NHDPlus\\Cook_Inlet\\NHDPLUS_H_19020302_HU8_GDB.gdb\\Hydrography\\NHDWaterbody\n",
      "vaas =  D:\\Basedata\\NHDPlus\\Cook_Inlet\\NHDPLUS_H_19020302_HU8_GDB.gdb\\NHDPlusFlowlineVAA\n",
      "region = Cook_Inlet\n",
      "\n",
      "Cook_Inlet_19020302\n",
      "Begin Slope zonal statistics min/mean/max std dev for watersheds and catchments in Cook_Inlet region\n",
      "Calculating Cook_Inlet watershed slope zonal stats...\n",
      "Begin tabulate intersection between T:\\\\Aquatic\\\\AKSSF\\\\AKSSF_Hydrography.gdb\\\\AKSSF_NHDPlus_LakePond and watersheds in Cook_Inlet region\n",
      "----------\n",
      "['OBJECTID', 'cat_ID_txt', 'FType', 'wtd_lake_area_sqm', 'wtd_lake_per', 'region', 'cat_ID', 'cat_ID_con']\n",
      "Begin tabulate intersection between D:\\\\GIS\\\\AKSSF\\\\Cook_Inlet\\\\Cook_Inlet.gdb\\\\glaciers and watersheds in Cook_Inlet region\n",
      "----------\n",
      "['OBJECTID', 'cat_ID_txt', 'O1Region', 'wtd_glacier_area_sqm', 'wtd_glacier_per', 'region', 'cat_ID', 'cat_ID_con']\n",
      "Begin tabulate area between D:\\GIS\\AKSSF\\Cook_Inlet\\north.tif and watersheds in Cook_Inlet region\n",
      "----------\n",
      "['OBJECTID', 'CAT_ID_TXT_DEL', 'VALUE_0', 'VALUE_1', 'region', 'wtd_north_per', 'cat_ID_txt', 'cat_ID_con']\n",
      "Year: 2001 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2001_lcld_32.tif\n",
      "Calculating 2001_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2001_lcld_32.tif\n",
      "Zonal Stats for 2001_lcld_32.tif Elapsed time: (0:00:15)\n",
      "Year: 2002 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2002_lcld_32.tif\n",
      "Calculating 2002_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2002_lcld_32.tif\n",
      "Zonal Stats for 2002_lcld_32.tif Elapsed time: (0:00:19)\n",
      "Year: 2003 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2003_lcld_32.tif\n",
      "Calculating 2003_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2003_lcld_32.tif\n",
      "Zonal Stats for 2003_lcld_32.tif Elapsed time: (0:00:18)\n",
      "Year: 2004 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2004_lcld_32.tif\n",
      "Calculating 2004_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2004_lcld_32.tif\n",
      "Zonal Stats for 2004_lcld_32.tif Elapsed time: (0:00:16)\n",
      "Year: 2005 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2005_lcld_32.tif\n",
      "Calculating 2005_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2005_lcld_32.tif\n",
      "Zonal Stats for 2005_lcld_32.tif Elapsed time: (0:00:15)\n",
      "Year: 2006 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2006_lcld_32.tif\n",
      "Calculating 2006_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2006_lcld_32.tif\n",
      "Zonal Stats for 2006_lcld_32.tif Elapsed time: (0:00:16)\n",
      "Year: 2007 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2007_lcld_32.tif\n",
      "Calculating 2007_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2007_lcld_32.tif\n",
      "Zonal Stats for 2007_lcld_32.tif Elapsed time: (0:00:15)\n",
      "Year: 2008 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2008_lcld_32.tif\n",
      "Calculating 2008_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2008_lcld_32.tif\n",
      "Zonal Stats for 2008_lcld_32.tif Elapsed time: (0:00:15)\n",
      "Year: 2009 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2009_lcld_32.tif\n",
      "Calculating 2009_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2009_lcld_32.tif\n",
      "Zonal Stats for 2009_lcld_32.tif Elapsed time: (0:00:17)\n",
      "Year: 2010 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2010_lcld_32.tif\n",
      "Calculating 2010_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2010_lcld_32.tif\n",
      "Zonal Stats for 2010_lcld_32.tif Elapsed time: (0:00:16)\n",
      "Year: 2011 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2011_lcld_32.tif\n",
      "Calculating 2011_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2011_lcld_32.tif\n",
      "Zonal Stats for 2011_lcld_32.tif Elapsed time: (0:00:15)\n",
      "Year: 2012 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2012_lcld_32.tif\n",
      "Calculating 2012_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2012_lcld_32.tif\n",
      "Zonal Stats for 2012_lcld_32.tif Elapsed time: (0:00:14)\n",
      "Year: 2013 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2013_lcld_32.tif\n",
      "Calculating 2013_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2013_lcld_32.tif\n",
      "Zonal Stats for 2013_lcld_32.tif Elapsed time: (0:00:16)\n",
      "Year: 2014 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2014_lcld_32.tif\n",
      "Calculating 2014_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2014_lcld_32.tif\n",
      "Zonal Stats for 2014_lcld_32.tif Elapsed time: (0:00:15)\n",
      "Year: 2015 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2015_lcld_32.tif\n",
      "Calculating 2015_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2015_lcld_32.tif\n",
      "Zonal Stats for 2015_lcld_32.tif Elapsed time: (0:00:16)\n",
      "Year: 2016 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2016_lcld_32.tif\n",
      "Calculating 2016_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2016_lcld_32.tif\n",
      "Zonal Stats for 2016_lcld_32.tif Elapsed time: (0:00:15)\n",
      "Year: 2017 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2017_lcld_32.tif\n",
      "Calculating 2017_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2017_lcld_32.tif\n",
      "Zonal Stats for 2017_lcld_32.tif Elapsed time: (0:00:15)\n",
      "Year: 2018 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2018_lcld_32.tif\n",
      "Calculating 2018_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2018_lcld_32.tif\n",
      "Zonal Stats for 2018_lcld_32.tif Elapsed time: (0:00:14)\n",
      "Year: 2019 - raster path D:\\\\Basedata\\\\LCLD_rasters_archive\\2019_lcld_32.tif\n",
      "Calculating 2019_lcld_32.tif zonal stats for all AKSSF watersheds...\n",
      "Begin zonal stats for 2019_lcld_32.tif\n",
      "Zonal Stats for 2019_lcld_32.tif Elapsed time: (0:00:15)\n",
      "Process completed at 2022-02-02 15:47 (Elapsed time: 0:06:46)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "from arcpy.sa import *\n",
    "\n",
    "# Path to lcld rasters\n",
    "lcld_folder = r'D:\\\\Basedata\\\\LCLD_rasters_archive'\n",
    "\n",
    "# Create Dictionary to link input raster/fc data from original covariate workflow\n",
    "dataDict={'Cook_Inlet':[r\"D:\\\\GIS\\\\AKSSF\\\\Cook_Inlet\\\\slope.tif\",\n",
    "                        r\"D:\\\\GIS\\\\AKSSF\\\\Cook_Inlet\\\\Cook_Inlet.gdb\\\\glaciers\",\n",
    "                        \"D:\\\\GIS\\\\AKSSF\\\\Cook_Inlet\\\\north.tif\"],\n",
    "          'Copper_River':[r\"D:\\\\GIS\\\\AKSSF\\\\Copper_River\\\\slope.tif\",\n",
    "                          r\"D:\\\\GIS\\\\AKSSF\\\\Copper_River\\\\Copper_River.gdb\\\\glaciers\",\n",
    "                          r\"D:\\\\GIS\\\\AKSSF\\\\Copper_River\\\\north.tif\"],\n",
    "          'Prince_William_Sound':[r\"D:\\\\GIS\\\\AKSSF\\\\Prince_William_Sound\\\\slope.tif\",\n",
    "                                  r\"D:\\\\GIS\\\\AKSSF\\\\Prince_William_Sound\\\\Prince_William_Sound.gdb\\\\glaciers\",\n",
    "                                  r\"D:\\\\GIS\\\\AKSSF\\\\Prince_William_Sound\\\\north.tif\"]\n",
    "          }\n",
    "# Separate data by\n",
    "nhdplus_dat = ['Cook_Inlet','Copper_River']\n",
    "tauDem_dat = ['Bristol_Bay', 'Kodiak', 'Prince_William_Sound']\n",
    "\n",
    "# Lists to store output tables\n",
    "wtd_lp_tabint_tables = []\n",
    "wtd_glac_tabint_tables = []\n",
    "wtd_pernorth_taba_tables = []\n",
    "wtd_slope_ztables = []\n",
    "lcld_Ztables = []\n",
    "\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "\n",
    "# Iterate over merged watersheds and calculate covariates\n",
    "arcpy.env.workspace = huc12cv_scratchgdb\n",
    "for fc in arcpy.ListFeatureClasses('*wtds_merge'):\n",
    "    vpu = fc[10:18]\n",
    "    outgdb = scrDict[vpu]\n",
    "    # Must match names because some items in dictionary are out of order\n",
    "    for v in vpuDict[vpu]:\n",
    "        # Inputs\n",
    "        if 'NHDPlusCatchment' in v:\n",
    "            cats = v\n",
    "        elif 'NHDFlowline' in v:\n",
    "            streams = v\n",
    "        elif 'NHDWaterbody'in v:\n",
    "            lakes = v\n",
    "        elif 'WBDHU12' in v:\n",
    "            hucs = v\n",
    "        elif 'NHDPlusFlowlineVAA' in v:\n",
    "            vaas = v\n",
    "        elif ':' not in v:\n",
    "            region = v\n",
    "    print(vpu)\n",
    "    print(f'cats = {cats}\\nhucs = {hucs}\\nstreams = {streams}\\nlakes = {lakes}\\nvaas =  {vaas}\\nregion = {region}\\n')\n",
    "    roi = region\n",
    "    tableid = roi + '_' + str(vpu)\n",
    "    print(tableid)\n",
    "    # Set Slope raster from data dictionary\n",
    "    slope_rast = dataDict[region][0]\n",
    "    # Set glacier fc from data dictionary\n",
    "    glac_fc = dataDict[region][1]\n",
    "    # Set North raster from data dictionary\n",
    "    north_rast = dataDict[region][2]\n",
    "\n",
    "    wtd_cur_fields = ['cat_ID_txt', 'cat_ID',\"cat_ID_con\"]\n",
    "    if roi in nhdplus_dat:\n",
    "        #lakes_fc = r\"D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\AKSSF_NHDPlus_LakePond_alb\" - local\n",
    "        lakes_fc = r\"T:\\\\Aquatic\\\\AKSSF\\\\AKSSF_Hydrography.gdb\\\\AKSSF_NHDPlus_LakePond\" # network copy\n",
    "    # Set data and variables unique to regions with TauDEM Data\n",
    "    elif roi in tauDem_dat:\n",
    "        lakes_fc = r\"D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\AKSSF_NHD_LakesPonds_alb\"\n",
    "\n",
    "\n",
    "    wtds = []\n",
    "\n",
    "    # Slope variables\n",
    "    wtd_merge_slope_table_name = tableid + \"_Watershed_Merge_SlopeZstats\"\n",
    "    wtd_merge_slope_table_path = os.path.join(outgdb, wtd_merge_slope_table_name)\n",
    "    # Lakes Ponds variables\n",
    "    wtd_merge_lp_table_name = tableid + \"_Watershed_Merge_LakesPonds\"\n",
    "    wtd_merge_lp_table_path = os.path.join(outgdb, wtd_merge_lp_table_name)\n",
    "    # Glaciers\n",
    "    wtd_merge_glac_table_name = tableid + \"_Watershed_Merge_Glaciers\"\n",
    "    wtd_merge_glac_table_path = os.path.join(outgdb, wtd_merge_glac_table_name)\n",
    "    # North facing\n",
    "    wtd_merge_north_table_name = tableid + \"_Watershed_Merge_North\"\n",
    "    wtd_merge_north_table_path = os.path.join(outgdb, wtd_merge_north_table_name)\n",
    "\n",
    "\n",
    "    # Watershed slope Zonal Statistics\n",
    "    print(f'Begin Slope zonal statistics min/mean/max std dev for watersheds and catchments in {roi}'\n",
    "          f' region')\n",
    "\n",
    "    # Slope Zonal statistics  for watersheds\n",
    "    print(f'Calculating {roi} watershed slope zonal stats...')\n",
    "    arcpy.env.snapRaster = slope_rast\n",
    "    arcpy.env.cellSize = slope_rast\n",
    "    wtd_slope_metrics_table = ZonalStatisticsAsTable(in_zone_data = wtd_merge,\n",
    "                                                    zone_field = wtd_cur_fields[0],\n",
    "                                                    in_value_raster = slope_rast,\n",
    "                                                    out_table = wtd_merge_slope_table_path,\n",
    "                                                    statistics_type='ALL'\n",
    "                                                    )\n",
    "\n",
    "    # Add region identifier field for watershed tables                                                )\n",
    "    arcpy.AddField_management(wtd_slope_metrics_table,'region',field_type='TEXT')\n",
    "    # Add cat_ID_Con field\n",
    "    arcpy.AddField_management(wtd_slope_metrics_table,'cat_ID_con',field_type='TEXT')\n",
    "\n",
    "    # Update region field\n",
    "    with arcpy.da.UpdateCursor(wtd_slope_metrics_table,['region','cat_ID_txt','cat_ID_con']) as cur:\n",
    "        for row in cur:\n",
    "            row[0] = roi\n",
    "            strval = str(row[1])\n",
    "            row[2] = roi+\"_\"+strval.replace(\".0\",\"\")\n",
    "            # Update\n",
    "            cur.updateRow(row)\n",
    "        del(row)\n",
    "    del(cur)\n",
    "    # Append watershed slope table to list\n",
    "    wtd_slope_ztables.append(wtd_slope_metrics_table)\n",
    "\n",
    "    # Percent Lakes Ponds using Tabulate Intersection for watersheds\n",
    "    print(f'Begin tabulate intersection between {lakes_fc} and watersheds in {roi} region')\n",
    "    print('----------')\n",
    "    wtd_lp_tabint = arcpy.TabulateIntersection_analysis(wtd_merge,\n",
    "                                                        zone_fields=wtd_cur_fields[0],\n",
    "                                                        in_class_features=lakes_fc,\n",
    "                                                        out_table=wtd_merge_lp_table_path,\n",
    "                                                        class_fields='Ftype',\n",
    "                                                        out_units=\"SQUARE_METERS\"\n",
    "                                                        )\n",
    "    # Add region and cat id fields\n",
    "    arcpy.AlterField_management(wtd_lp_tabint,'PERCENTAGE','wtd_lake_per','wtd_lake_per')\n",
    "    arcpy.AlterField_management(wtd_lp_tabint,'AREA','wtd_lake_area_sqm','wtd_lake_area_sqm')\n",
    "    arcpy.AddField_management(wtd_lp_tabint, 'region', field_type='TEXT')\n",
    "    arcpy.AddField_management(wtd_lp_tabint, wtd_cur_fields[1], field_type='TEXT')\n",
    "    arcpy.AddField_management(wtd_lp_tabint, wtd_cur_fields[2], field_type='TEXT')\n",
    "    wtdlpfields = [f.name for f in arcpy.ListFields(wtd_lp_tabint)]\n",
    "    print (wtdlpfields)\n",
    "    with arcpy.da.UpdateCursor(wtd_lp_tabint, wtdlpfields) as cur:\n",
    "        for row in cur:\n",
    "            strval = str(row[1])\n",
    "            row[5] = roi\n",
    "            row[6] = strval.replace('.0','')\n",
    "            row[7] = roi +'_'+ strval.replace(\".0\",\"\")\n",
    "            # Update\n",
    "            cur.updateRow(row)\n",
    "        del(row)\n",
    "    del(cur)\n",
    "\n",
    "    # Append watershed lakes ponds table to list\n",
    "    wtd_lp_tabint_tables.append(wtd_lp_tabint)\n",
    "\n",
    "    # Percent glaciers using Tabulate Intersection for watersheds\n",
    "    print(f'Begin tabulate intersection between {glac_fc} and watersheds in {roi} region')\n",
    "    print('----------')\n",
    "    wtd_glac_tabint = arcpy.TabulateIntersection_analysis(wtd_merge,\n",
    "                                                        zone_fields=wtd_cur_fields[0],\n",
    "                                                        in_class_features=glac_fc,\n",
    "                                                        out_table=wtd_merge_glac_table_path,\n",
    "                                                        class_fields='O1Region',\n",
    "                                                        out_units=\"SQUARE_METERS\"\n",
    "                                                        )\n",
    "    # Add region and cat id fields\n",
    "    arcpy.AlterField_management(wtd_glac_tabint,'PERCENTAGE','wtd_glacier_per','wtd_glacier_per')\n",
    "    arcpy.AlterField_management(wtd_glac_tabint,'AREA','wtd_glacier_area_sqm','wtd_glacier_area_sqm')\n",
    "    arcpy.AddField_management(wtd_glac_tabint, 'region', field_type='TEXT')\n",
    "    arcpy.AddField_management(wtd_glac_tabint, wtd_cur_fields[1], field_type='TEXT')\n",
    "    arcpy.AddField_management(wtd_glac_tabint, wtd_cur_fields[2], field_type='TEXT')\n",
    "    wtdglacfields = [f.name for f in arcpy.ListFields(wtd_glac_tabint)]\n",
    "    print (wtdglacfields)\n",
    "    with arcpy.da.UpdateCursor(wtd_glac_tabint, wtdglacfields) as cur:\n",
    "        for row in cur:\n",
    "            strval = str(row[1])\n",
    "            row[5] = roi\n",
    "            row[6] = strval.replace('.0','')\n",
    "            row[7] = roi +'_'+ strval.replace(\".0\",\"\")\n",
    "            # Update\n",
    "            cur.updateRow(row)\n",
    "        del(row)\n",
    "    del(cur)\n",
    "    # Append watershed percent glacier table to list\n",
    "    wtd_glac_tabint_tables.append(wtd_glac_tabint)\n",
    "\n",
    "    # Tabulate Area with north grid and watersheds\n",
    "\n",
    "    print(f'Begin tabulate area between {north_rast} and watersheds in {roi} region')\n",
    "    print('----------')\n",
    "    # Percent North Tabulate area for watersheds\n",
    "    wtd_per_north_tabarea = arcpy.sa.TabulateArea(in_zone_data= wtd_merge,\n",
    "                                                  zone_field= wtd_cur_fields[0],\n",
    "                                                  in_class_data=north_rast,\n",
    "                                                  class_field=\"Value\",\n",
    "                                                  out_table=wtd_merge_north_table_path\n",
    "                                                  )\n",
    "    # Add region and percent north fields\n",
    "    arcpy.AlterField_management(wtd_per_north_tabarea,'CAT_ID_TXT','CAT_ID_TXT_DEL','CAT_ID_TXT_DEL')\n",
    "    arcpy.AddField_management(wtd_per_north_tabarea, 'region', field_type='TEXT')\n",
    "    arcpy.AddField_management(wtd_per_north_tabarea, 'wtd_north_per', field_type='Float')\n",
    "    arcpy.AddField_management(wtd_per_north_tabarea, wtd_cur_fields[0], field_type='TEXT')\n",
    "    arcpy.AddField_management(wtd_per_north_tabarea, wtd_cur_fields[2], field_type='TEXT')\n",
    "    wtdnorfields = [f.name for f in arcpy.ListFields(wtd_per_north_tabarea)]\n",
    "    print (wtdnorfields)\n",
    "    with arcpy.da.UpdateCursor(wtd_per_north_tabarea, wtdnorfields) as cur:\n",
    "        for row in cur:\n",
    "            strval = str(row[1])\n",
    "            row[4] = roi\n",
    "            row[5] = row[3]/(row[3]+row[2])*100\n",
    "            row[6] = strval.replace('.0','')\n",
    "            row[7] = roi +'_'+ strval.replace(\".0\",\"\")\n",
    "            # Update\n",
    "            cur.updateRow(row)\n",
    "        del(row)\n",
    "    del(cur)\n",
    "    # Drop UPPERCASE field form tab area\n",
    "    arcpy.DeleteField_management(wtd_per_north_tabarea,'CAT_ID_TXT_DEL')\n",
    "    # Append watershed percent north table to list\n",
    "    wtd_pernorth_taba_tables.append(wtd_per_north_tabarea)\n",
    "\n",
    "    # Begin LCLD calculations\n",
    "    walk = arcpy.da.Walk(lcld_folder, datatype='RasterDataset')\n",
    "    for dirpath, dirnames, filenames in walk:\n",
    "        for filename in filenames:\n",
    "            raspath = os.path.join(dirpath, filename)\n",
    "            year = filename[0:4]\n",
    "            lcld_outname = 'lcld_'+str(year)+'_zStats'\n",
    "            lcld_outpath = os.path.join(outgdb, lcld_outname)\n",
    "            print(f'Year: {year} - raster path {raspath}')\n",
    "            colname = 'wtd_lcld_mn_' + str(year)\n",
    "            # lcld zonal statistics as table for all akssf watersheds\n",
    "            print(f'Calculating {filename} zonal stats for all AKSSF watersheds...')\n",
    "            #arcpy.env.snapRaster = raspath\n",
    "            #arcpy.env.cellSize = raspath\n",
    "            try:\n",
    "                # Begin Zonal Stats\n",
    "                zstat_start = time.time()\n",
    "                print(f'Begin zonal stats for {filename}')\n",
    "                lcld_table = ZonalStatisticsAsTable(in_zone_data = fc,\n",
    "                                                                zone_field = 'cat_ID_con',\n",
    "                                                                in_value_raster = raspath,\n",
    "                                                                out_table = lcld_outpath,\n",
    "                                                                statistics_type='MEAN'\n",
    "                                                                )\n",
    "                # Append zTable to table list\n",
    "                lcld_Ztables.append(lcld_outpath)\n",
    "                arcpy.AlterField_management(lcld_table,'MEAN', colname,colname)\n",
    "                proc_list = [row[0] for row in arcpy.da.SearchCursor(lcld_table,'cat_ID_con')]\n",
    "                zstat_stop = time.time()\n",
    "                zstat_time = int (zstat_stop - zstat_start)\n",
    "                print(f'Zonal Stats for {filename} Elapsed time: ({datetime.timedelta(seconds=zstat_time)})')\n",
    "\n",
    "\n",
    "            except:\n",
    "                e = sys.exc_info()[1]\n",
    "                print(e.args[0])\n",
    "                arcpy.AddError(e.args[0])\n",
    "\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "\n",
    "# Report success\n",
    "print(f'Process completed at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "      f'(Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print('----------')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Examine tables and merge/export"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lcld_2001_zStats\n",
      "lcld_2002_zStats\n",
      "lcld_2003_zStats\n",
      "lcld_2004_zStats\n",
      "lcld_2005_zStats\n",
      "lcld_2006_zStats\n",
      "lcld_2007_zStats\n",
      "lcld_2008_zStats\n",
      "lcld_2009_zStats\n",
      "lcld_2010_zStats\n",
      "lcld_2011_zStats\n",
      "lcld_2012_zStats\n",
      "lcld_2013_zStats\n",
      "lcld_2014_zStats\n",
      "lcld_2015_zStats\n",
      "lcld_2016_zStats\n",
      "lcld_2017_zStats\n",
      "lcld_2018_zStats\n",
      "lcld_2019_zStats\n"
     ]
    },
    {
     "data": {
      "text/plain": "                           wtd_lcld_mn_2001  wtd_lcld_mn_2002  \\\ncat_ID_con                                                      \nCook_Inlet_75004400005344        520.509051        508.405433   \nCook_Inlet_75004400011755        564.444009        553.189850   \nCook_Inlet_75004400010352        509.551592        501.181799   \nCook_Inlet_75004400007996        504.175142        495.784529   \nCook_Inlet_75004400004850        484.997404        487.153397   \n...                                     ...               ...   \nCook_Inlet_75004400010337        475.481973        482.757579   \nCook_Inlet_75004400008879        473.000779        479.593725   \nCook_Inlet_75004400004457        482.066856        485.844861   \nCook_Inlet_75004400005924        478.103658        485.468504   \nCook_Inlet_75004400004455        490.843163        488.031708   \n\n                           wtd_lcld_mn_2003  wtd_lcld_mn_2004  \\\ncat_ID_con                                                      \nCook_Inlet_75004400005344        505.377240        500.963714   \nCook_Inlet_75004400011755        546.676839        545.389134   \nCook_Inlet_75004400010352        491.832787        493.722468   \nCook_Inlet_75004400007996        489.857588        491.170970   \nCook_Inlet_75004400004850        451.456256        482.279436   \n...                                     ...               ...   \nCook_Inlet_75004400010337        423.842961        477.607190   \nCook_Inlet_75004400008879        430.429066        472.965813   \nCook_Inlet_75004400004457        443.333986        484.460604   \nCook_Inlet_75004400005924        435.507130        482.883556   \nCook_Inlet_75004400004455        455.239659        486.764625   \n\n                           wtd_lcld_mn_2005  wtd_lcld_mn_2006  \\\ncat_ID_con                                                      \nCook_Inlet_75004400005344        500.532097        515.671108   \nCook_Inlet_75004400011755        543.951730        556.857700   \nCook_Inlet_75004400010352        494.759142        507.035132   \nCook_Inlet_75004400007996        489.220219        502.619685   \nCook_Inlet_75004400004850        469.999586        485.523631   \n...                                     ...               ...   \nCook_Inlet_75004400010337        464.195834        473.934574   \nCook_Inlet_75004400008879        469.316728        477.245322   \nCook_Inlet_75004400004457        467.505422        485.081167   \nCook_Inlet_75004400005924        461.210466        478.689286   \nCook_Inlet_75004400004455        471.112494        487.524519   \n\n                           wtd_lcld_mn_2007  wtd_lcld_mn_2008  \\\ncat_ID_con                                                      \nCook_Inlet_75004400005344        509.995206        522.716878   \nCook_Inlet_75004400011755        552.409089        559.785748   \nCook_Inlet_75004400010352        498.694661        517.818537   \nCook_Inlet_75004400007996        495.572548        508.803808   \nCook_Inlet_75004400004850        481.105462        495.159942   \n...                                     ...               ...   \nCook_Inlet_75004400010337        469.370365        473.545688   \nCook_Inlet_75004400008879        459.450837        476.794236   \nCook_Inlet_75004400004457        483.132374        491.201997   \nCook_Inlet_75004400005924        477.094741        484.974631   \nCook_Inlet_75004400004455        481.886031        493.923468   \n\n                           wtd_lcld_mn_2009  wtd_lcld_mn_2010  \\\ncat_ID_con                                                      \nCook_Inlet_75004400005344        505.710495        519.811718   \nCook_Inlet_75004400011755        551.837955        554.837759   \nCook_Inlet_75004400010352        491.611237        508.359131   \nCook_Inlet_75004400007996        490.665353        500.640127   \nCook_Inlet_75004400004850        478.876774        483.054496   \n...                                     ...               ...   \nCook_Inlet_75004400010337        476.126278        474.148137   \nCook_Inlet_75004400008879        477.664237        470.348740   \nCook_Inlet_75004400004457        477.718749        481.870984   \nCook_Inlet_75004400005924        475.984779        478.832972   \nCook_Inlet_75004400004455        480.029365        487.341816   \n\n                           wtd_lcld_mn_2011  wtd_lcld_mn_2012  \\\ncat_ID_con                                                      \nCook_Inlet_75004400005344        507.799762        520.476156   \nCook_Inlet_75004400011755        550.503730        561.177930   \nCook_Inlet_75004400010352        500.773588        513.361570   \nCook_Inlet_75004400007996        495.863432        507.356903   \nCook_Inlet_75004400004850        483.135788        496.730896   \n...                                     ...               ...   \nCook_Inlet_75004400010337        478.633391        479.490321   \nCook_Inlet_75004400008879        472.191278        481.256098   \nCook_Inlet_75004400004457        483.173043        496.106864   \nCook_Inlet_75004400005924        480.536786        490.866367   \nCook_Inlet_75004400004455        485.337057        496.918620   \n\n                           wtd_lcld_mn_2013  wtd_lcld_mn_2014  \\\ncat_ID_con                                                      \nCook_Inlet_75004400005344        520.574698        494.189799   \nCook_Inlet_75004400011755        553.761947        539.041351   \nCook_Inlet_75004400010352        511.525629        481.955786   \nCook_Inlet_75004400007996        509.346870        478.528016   \nCook_Inlet_75004400004850        502.512729        444.622105   \n...                                     ...               ...   \nCook_Inlet_75004400010337        494.054570        466.436651   \nCook_Inlet_75004400008879        490.865165        469.645157   \nCook_Inlet_75004400004457        501.102991        438.825152   \nCook_Inlet_75004400005924        497.288233        444.013029   \nCook_Inlet_75004400004455        499.986261        448.828650   \n\n                           wtd_lcld_mn_2015  wtd_lcld_mn_2016  \\\ncat_ID_con                                                      \nCook_Inlet_75004400005344        497.637066        509.934038   \nCook_Inlet_75004400011755        542.309656        543.853671   \nCook_Inlet_75004400010352        481.891787        496.708530   \nCook_Inlet_75004400007996        484.090911        491.223736   \nCook_Inlet_75004400004850        451.619080        452.742992   \n...                                     ...               ...   \nCook_Inlet_75004400010337        432.107032        441.154316   \nCook_Inlet_75004400008879        423.882979        438.889834   \nCook_Inlet_75004400004457        444.976096        451.657545   \nCook_Inlet_75004400005924        438.265750        445.608104   \nCook_Inlet_75004400004455        456.618872        462.515358   \n\n                           wtd_lcld_mn_2017  wtd_lcld_mn_2018  \\\ncat_ID_con                                                      \nCook_Inlet_75004400005344        510.466283        506.270304   \nCook_Inlet_75004400011755        548.696056        545.134762   \nCook_Inlet_75004400010352        496.161511        503.096208   \nCook_Inlet_75004400007996        490.668783        490.608826   \nCook_Inlet_75004400004850        479.077717        477.712043   \n...                                     ...               ...   \nCook_Inlet_75004400010337        471.937621        475.286969   \nCook_Inlet_75004400008879        466.550128        468.182090   \nCook_Inlet_75004400004457        476.677755        476.303059   \nCook_Inlet_75004400005924        474.754330        471.987825   \nCook_Inlet_75004400004455        476.844836        477.910791   \n\n                           wtd_lcld_mn_2019  \ncat_ID_con                                   \nCook_Inlet_75004400005344        503.402322  \nCook_Inlet_75004400011755        540.182484  \nCook_Inlet_75004400010352        497.693959  \nCook_Inlet_75004400007996        493.742622  \nCook_Inlet_75004400004850        475.224581  \n...                                     ...  \nCook_Inlet_75004400010337        455.941913  \nCook_Inlet_75004400008879        461.628005  \nCook_Inlet_75004400004457        470.164198  \nCook_Inlet_75004400005924        463.714536  \nCook_Inlet_75004400004455        474.398831  \n\n[99 rows x 19 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>wtd_lcld_mn_2001</th>\n      <th>wtd_lcld_mn_2002</th>\n      <th>wtd_lcld_mn_2003</th>\n      <th>wtd_lcld_mn_2004</th>\n      <th>wtd_lcld_mn_2005</th>\n      <th>wtd_lcld_mn_2006</th>\n      <th>wtd_lcld_mn_2007</th>\n      <th>wtd_lcld_mn_2008</th>\n      <th>wtd_lcld_mn_2009</th>\n      <th>wtd_lcld_mn_2010</th>\n      <th>wtd_lcld_mn_2011</th>\n      <th>wtd_lcld_mn_2012</th>\n      <th>wtd_lcld_mn_2013</th>\n      <th>wtd_lcld_mn_2014</th>\n      <th>wtd_lcld_mn_2015</th>\n      <th>wtd_lcld_mn_2016</th>\n      <th>wtd_lcld_mn_2017</th>\n      <th>wtd_lcld_mn_2018</th>\n      <th>wtd_lcld_mn_2019</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Cook_Inlet_75004400005344</th>\n      <td>520.509051</td>\n      <td>508.405433</td>\n      <td>505.377240</td>\n      <td>500.963714</td>\n      <td>500.532097</td>\n      <td>515.671108</td>\n      <td>509.995206</td>\n      <td>522.716878</td>\n      <td>505.710495</td>\n      <td>519.811718</td>\n      <td>507.799762</td>\n      <td>520.476156</td>\n      <td>520.574698</td>\n      <td>494.189799</td>\n      <td>497.637066</td>\n      <td>509.934038</td>\n      <td>510.466283</td>\n      <td>506.270304</td>\n      <td>503.402322</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400011755</th>\n      <td>564.444009</td>\n      <td>553.189850</td>\n      <td>546.676839</td>\n      <td>545.389134</td>\n      <td>543.951730</td>\n      <td>556.857700</td>\n      <td>552.409089</td>\n      <td>559.785748</td>\n      <td>551.837955</td>\n      <td>554.837759</td>\n      <td>550.503730</td>\n      <td>561.177930</td>\n      <td>553.761947</td>\n      <td>539.041351</td>\n      <td>542.309656</td>\n      <td>543.853671</td>\n      <td>548.696056</td>\n      <td>545.134762</td>\n      <td>540.182484</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010352</th>\n      <td>509.551592</td>\n      <td>501.181799</td>\n      <td>491.832787</td>\n      <td>493.722468</td>\n      <td>494.759142</td>\n      <td>507.035132</td>\n      <td>498.694661</td>\n      <td>517.818537</td>\n      <td>491.611237</td>\n      <td>508.359131</td>\n      <td>500.773588</td>\n      <td>513.361570</td>\n      <td>511.525629</td>\n      <td>481.955786</td>\n      <td>481.891787</td>\n      <td>496.708530</td>\n      <td>496.161511</td>\n      <td>503.096208</td>\n      <td>497.693959</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400007996</th>\n      <td>504.175142</td>\n      <td>495.784529</td>\n      <td>489.857588</td>\n      <td>491.170970</td>\n      <td>489.220219</td>\n      <td>502.619685</td>\n      <td>495.572548</td>\n      <td>508.803808</td>\n      <td>490.665353</td>\n      <td>500.640127</td>\n      <td>495.863432</td>\n      <td>507.356903</td>\n      <td>509.346870</td>\n      <td>478.528016</td>\n      <td>484.090911</td>\n      <td>491.223736</td>\n      <td>490.668783</td>\n      <td>490.608826</td>\n      <td>493.742622</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004850</th>\n      <td>484.997404</td>\n      <td>487.153397</td>\n      <td>451.456256</td>\n      <td>482.279436</td>\n      <td>469.999586</td>\n      <td>485.523631</td>\n      <td>481.105462</td>\n      <td>495.159942</td>\n      <td>478.876774</td>\n      <td>483.054496</td>\n      <td>483.135788</td>\n      <td>496.730896</td>\n      <td>502.512729</td>\n      <td>444.622105</td>\n      <td>451.619080</td>\n      <td>452.742992</td>\n      <td>479.077717</td>\n      <td>477.712043</td>\n      <td>475.224581</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010337</th>\n      <td>475.481973</td>\n      <td>482.757579</td>\n      <td>423.842961</td>\n      <td>477.607190</td>\n      <td>464.195834</td>\n      <td>473.934574</td>\n      <td>469.370365</td>\n      <td>473.545688</td>\n      <td>476.126278</td>\n      <td>474.148137</td>\n      <td>478.633391</td>\n      <td>479.490321</td>\n      <td>494.054570</td>\n      <td>466.436651</td>\n      <td>432.107032</td>\n      <td>441.154316</td>\n      <td>471.937621</td>\n      <td>475.286969</td>\n      <td>455.941913</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400008879</th>\n      <td>473.000779</td>\n      <td>479.593725</td>\n      <td>430.429066</td>\n      <td>472.965813</td>\n      <td>469.316728</td>\n      <td>477.245322</td>\n      <td>459.450837</td>\n      <td>476.794236</td>\n      <td>477.664237</td>\n      <td>470.348740</td>\n      <td>472.191278</td>\n      <td>481.256098</td>\n      <td>490.865165</td>\n      <td>469.645157</td>\n      <td>423.882979</td>\n      <td>438.889834</td>\n      <td>466.550128</td>\n      <td>468.182090</td>\n      <td>461.628005</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004457</th>\n      <td>482.066856</td>\n      <td>485.844861</td>\n      <td>443.333986</td>\n      <td>484.460604</td>\n      <td>467.505422</td>\n      <td>485.081167</td>\n      <td>483.132374</td>\n      <td>491.201997</td>\n      <td>477.718749</td>\n      <td>481.870984</td>\n      <td>483.173043</td>\n      <td>496.106864</td>\n      <td>501.102991</td>\n      <td>438.825152</td>\n      <td>444.976096</td>\n      <td>451.657545</td>\n      <td>476.677755</td>\n      <td>476.303059</td>\n      <td>470.164198</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400005924</th>\n      <td>478.103658</td>\n      <td>485.468504</td>\n      <td>435.507130</td>\n      <td>482.883556</td>\n      <td>461.210466</td>\n      <td>478.689286</td>\n      <td>477.094741</td>\n      <td>484.974631</td>\n      <td>475.984779</td>\n      <td>478.832972</td>\n      <td>480.536786</td>\n      <td>490.866367</td>\n      <td>497.288233</td>\n      <td>444.013029</td>\n      <td>438.265750</td>\n      <td>445.608104</td>\n      <td>474.754330</td>\n      <td>471.987825</td>\n      <td>463.714536</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004455</th>\n      <td>490.843163</td>\n      <td>488.031708</td>\n      <td>455.239659</td>\n      <td>486.764625</td>\n      <td>471.112494</td>\n      <td>487.524519</td>\n      <td>481.886031</td>\n      <td>493.923468</td>\n      <td>480.029365</td>\n      <td>487.341816</td>\n      <td>485.337057</td>\n      <td>496.918620</td>\n      <td>499.986261</td>\n      <td>448.828650</td>\n      <td>456.618872</td>\n      <td>462.515358</td>\n      <td>476.844836</td>\n      <td>477.910791</td>\n      <td>474.398831</td>\n    </tr>\n  </tbody>\n</table>\n<p>99 rows  19 columns</p>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for table in lcld_Ztables:\n",
    "    tblname = table[-16:]\n",
    "    print(tblname)\n",
    "    dfname = tblname + '_arr'\n",
    "    # Make df\n",
    "    dfname = pd.DataFrame()\n",
    "    lcld_field_list = []\n",
    "    for field in arcpy.ListFields(table):\n",
    "        lcld_field_list.append(field.name)\n",
    "        #print(f'{field.name}')\n",
    "    lcld_arr = arcpy.da.TableToNumPyArray(table, lcld_field_list)\n",
    "    dfname = pd.DataFrame(lcld_arr)\n",
    "    dfname = dfname.drop(['OBJECTID','ZONE_CODE', 'AREA', 'COUNT'],axis=1)\n",
    "    dfname = dfname.set_index('cat_ID_con')\n",
    "    dfs.append(dfname)\n",
    "\n",
    "# Merge all data frames together\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "lcld_df = reduce(lambda left,right: pd.merge(left,right,on='cat_ID_con',how=\"outer\"), dfs)\n",
    "lcld_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export dataframe to csv complete\n"
     ]
    }
   ],
   "source": [
    "# Export merged dataframe to csv\n",
    "outdir = r\"C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\"\n",
    "lcld_csv_out = os.path.join(outdir,'AKSSF_NHDPlus_awcHuc12_19020302_wtd_lcld_mn.csv')\n",
    "lcld_df.to_csv(lcld_csv_out, encoding = 'utf-8')\n",
    "print('Export dataframe to csv complete')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables merged\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "outgdb = huc12cv_scratchgdb\n",
    "\n",
    "# Table names/paths\n",
    "wtd_per_glac_table_out = os.path.join(outgdb, 'AKSSF_NHDPlus_awcHuc12_19020302_huc12_wtd_glacier_per')\n",
    "wtd_per_lp_table_out = os.path.join(outgdb, 'AKSSF_NHDPlus_awcHuc12_19020302_huc12_wtd_lakepond_per')\n",
    "wtd_slope_table_out = os.path.join(outgdb, 'AKSSF_NHDPlus_awcHuc12_19020302_huc12_wtd_slope')\n",
    "wtd_lcld_table_out = os.path.join(outgdb, 'AKSSF_NHDPlus_awcHuc12_19020302_huc12_wtd_lcld')\n",
    "wtd_per_north_table_out = os.path.join(outgdb, 'AKSSF_NHDPlus_awcHuc12_19020302_wtd_north_per')\n",
    "\n",
    "# Merge all regional tables together\n",
    "outtables = []\n",
    "wtd_per_north = arcpy.Merge_management(wtd_pernorth_taba_tables, wtd_per_north_table_out)\n",
    "arcpy.AlterField_management(wtd_per_north,\"VALUE_0\",\"non_north_area\",\"non_north_area\")\n",
    "arcpy.AlterField_management(wtd_per_north,\"VALUE_1\",\"north_area\",\"north_area\")\n",
    "outtables.append(wtd_per_north)\n",
    "wtd_slope = arcpy.Merge_management(wtd_slope_ztables, wtd_slope_table_out)\n",
    "outtables.append(wtd_slope)\n",
    "wtd_glac = arcpy.Merge_management(wtd_glac_tabint_tables, wtd_per_glac_table_out)\n",
    "outtables.append(wtd_glac)\n",
    "wtd_lp = arcpy.Merge_management(wtd_lp_tabint_tables, wtd_per_lp_table_out)\n",
    "outtables.append(wtd_lp)\n",
    "print ('Tables merged')\n",
    "print('----------')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZONE_CODE wtd_slope_ZONE_CODE\n",
      "COUNT wtd_slope_COUNT\n",
      "AREA wtd_slope_AREA\n",
      "MIN wtd_slope_MIN\n",
      "MAX wtd_slope_MAX\n",
      "RANGE wtd_slope_RANGE\n",
      "MEAN wtd_slope_MEAN\n",
      "STD wtd_slope_STD\n",
      "SUM wtd_slope_SUM\n",
      "MEDIAN wtd_slope_MEDIAN\n",
      "PCT90 wtd_slope_PCT90\n"
     ]
    }
   ],
   "source": [
    "slopeDict = { 'ZONE_CODE': ('cat_slope_ZONE_CODE', 'wtd_slope_ZONE_CODE'),\n",
    "         'COUNT': ('cat_slope_COUNT', 'wtd_slope_COUNT'),\n",
    "          'AREA': ('cat_slope_AREA', 'wtd_slope_AREA'),\n",
    "          'MIN': ('cat_slope_MIN', 'wtd_slope_MIN'),\n",
    "          'MAX': ('cat_slope_MAX', 'wtd_slope_MAX'),\n",
    "          'RANGE': ('cat_slope_RANGE', 'wtd_slope_RANGE'),\n",
    "          'MEAN': ('cat_slope_MEAN', 'wtd_slope_MEAN'),\n",
    "          'STD': ('cat_slope_STD', 'wtd_slope_STD'),\n",
    "          'SUM': ('cat_slope_SUM', 'wtd_slope_SUM'),\n",
    "          'VARIETY': ('cat_slope_VARIETY', 'wtd_slope_VARIETY'),\n",
    "          'MAJORITY': ('cat_slope_MAJORITY', 'wtd_slope_MAJORITY'),\n",
    "          'MINORITY': ('cat_slope_MINORITY', 'wtd_slope_MINORITY'),\n",
    "          'MEDIAN': ('cat_slope_MEDIAN', 'wtd_slope_MEDIAN'),\n",
    "          'PCT90': ('cat_slope_PCT90', 'wtd_slope_PCT90')\n",
    "         }\n",
    "# Rename fields for slope tables\n",
    "for field in arcpy.ListFields(wtd_slope):\n",
    "    keyval = field.name\n",
    "    if keyval in slopeDict:\n",
    "        newname = slopeDict[keyval][1]\n",
    "        newalias = slopeDict[keyval][1]\n",
    "        print (keyval, newname)\n",
    "        arcpy.AlterField_management(wtd_slope, keyval, newname, newalias)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_NHDPlus_awcHuc12_19020302_wtd_north_per.csv\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_NHDPlus_awcHuc12_19020302_huc12_wtd_slope.csv\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_NHDPlus_awcHuc12_19020302_huc12_wtd_glacier_per.csv\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_NHDPlus_awcHuc12_19020302_huc12_wtd_lakepond_per.csv\n"
     ]
    }
   ],
   "source": [
    "# Export copies of dbf tables as csv\n",
    "outdir = r\"C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\"\n",
    "for table in outtables:\n",
    "    tablename = arcpy.Describe(table).basename + \".csv\"\n",
    "    tablepath = os.path.join(outdir,tablename)\n",
    "    print(tablepath)\n",
    "    arcpy.conversion.TableToTable(table, outdir, tablename)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.2f}'.format # only display 2 decimal places\n",
    "# list to store covariate data frames\n",
    "dfs = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "                               cat_ID_txt  wtd_slope_COUNT  wtd_slope_AREA  \\\ncat_ID_con                                                                   \nCook_Inlet_75004400005344  75004400005344        450061.00     45006100.00   \nCook_Inlet_75004400011755  75004400011755       1055899.00    105589900.00   \nCook_Inlet_75004400010352  75004400010352        535581.00     53558100.00   \nCook_Inlet_75004400007996  75004400007996       2825727.00    282572700.00   \nCook_Inlet_75004400004850  75004400004850       1563074.00    156307400.00   \n...                                   ...              ...             ...   \nCook_Inlet_75004400010337  75004400010337        344724.00     34472400.00   \nCook_Inlet_75004400008879  75004400008879        233265.00     23326500.00   \nCook_Inlet_75004400004457  75004400004457       1026297.00    102629700.00   \nCook_Inlet_75004400005924  75004400005924       7720743.00    772074300.00   \nCook_Inlet_75004400004455  75004400004455       1755781.00    175578100.00   \n\n                           wtd_slope_MIN  wtd_slope_MAX  wtd_slope_RANGE  \\\ncat_ID_con                                                                 \nCook_Inlet_75004400005344           0.00          70.87            70.87   \nCook_Inlet_75004400011755           0.00          76.85            76.85   \nCook_Inlet_75004400010352           0.00          67.02            67.02   \nCook_Inlet_75004400007996           0.00          65.51            65.51   \nCook_Inlet_75004400004850           0.00          67.16            67.16   \n...                                  ...            ...              ...   \nCook_Inlet_75004400010337           0.00          35.96            35.96   \nCook_Inlet_75004400008879           0.00          30.82            30.82   \nCook_Inlet_75004400004457           0.00          59.70            59.70   \nCook_Inlet_75004400005924           0.00          65.72            65.72   \nCook_Inlet_75004400004455           0.00          59.42            59.42   \n\n                           wtd_slope_MEAN  wtd_slope_STD  wtd_slope_SUM  \\\ncat_ID_con                                                                \nCook_Inlet_75004400005344           25.38          13.03    11421329.52   \nCook_Inlet_75004400011755           24.02          15.07    25364061.16   \nCook_Inlet_75004400010352           26.18          10.23    14019013.53   \nCook_Inlet_75004400007996           22.75           9.80    64285852.09   \nCook_Inlet_75004400004850           18.79          10.87    29374364.09   \n...                                   ...            ...            ...   \nCook_Inlet_75004400010337            4.01           4.34     1380818.20   \nCook_Inlet_75004400008879            1.95           2.25      455340.88   \nCook_Inlet_75004400004457           16.52          10.14    16950039.30   \nCook_Inlet_75004400005924           11.12          10.59    85865495.84   \nCook_Inlet_75004400004455           19.17          10.86    33650778.59   \n\n                           wtd_slope_MEDIAN  wtd_slope_PCT90      region  \ncat_ID_con                                                                \nCook_Inlet_75004400005344             26.37            41.61  Cook_Inlet  \nCook_Inlet_75004400011755             24.16            44.20  Cook_Inlet  \nCook_Inlet_75004400010352             28.10            37.79  Cook_Inlet  \nCook_Inlet_75004400007996             23.95            34.55  Cook_Inlet  \nCook_Inlet_75004400004850             18.87            33.13  Cook_Inlet  \n...                                     ...              ...         ...  \nCook_Inlet_75004400010337              3.03             9.43  Cook_Inlet  \nCook_Inlet_75004400008879              1.92             3.44  Cook_Inlet  \nCook_Inlet_75004400004457             14.77            31.31  Cook_Inlet  \nCook_Inlet_75004400005924              6.74            28.51  Cook_Inlet  \nCook_Inlet_75004400004455             19.24            33.62  Cook_Inlet  \n\n[99 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat_ID_txt</th>\n      <th>wtd_slope_COUNT</th>\n      <th>wtd_slope_AREA</th>\n      <th>wtd_slope_MIN</th>\n      <th>wtd_slope_MAX</th>\n      <th>wtd_slope_RANGE</th>\n      <th>wtd_slope_MEAN</th>\n      <th>wtd_slope_STD</th>\n      <th>wtd_slope_SUM</th>\n      <th>wtd_slope_MEDIAN</th>\n      <th>wtd_slope_PCT90</th>\n      <th>region</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Cook_Inlet_75004400005344</th>\n      <td>75004400005344</td>\n      <td>450061.00</td>\n      <td>45006100.00</td>\n      <td>0.00</td>\n      <td>70.87</td>\n      <td>70.87</td>\n      <td>25.38</td>\n      <td>13.03</td>\n      <td>11421329.52</td>\n      <td>26.37</td>\n      <td>41.61</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400011755</th>\n      <td>75004400011755</td>\n      <td>1055899.00</td>\n      <td>105589900.00</td>\n      <td>0.00</td>\n      <td>76.85</td>\n      <td>76.85</td>\n      <td>24.02</td>\n      <td>15.07</td>\n      <td>25364061.16</td>\n      <td>24.16</td>\n      <td>44.20</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010352</th>\n      <td>75004400010352</td>\n      <td>535581.00</td>\n      <td>53558100.00</td>\n      <td>0.00</td>\n      <td>67.02</td>\n      <td>67.02</td>\n      <td>26.18</td>\n      <td>10.23</td>\n      <td>14019013.53</td>\n      <td>28.10</td>\n      <td>37.79</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400007996</th>\n      <td>75004400007996</td>\n      <td>2825727.00</td>\n      <td>282572700.00</td>\n      <td>0.00</td>\n      <td>65.51</td>\n      <td>65.51</td>\n      <td>22.75</td>\n      <td>9.80</td>\n      <td>64285852.09</td>\n      <td>23.95</td>\n      <td>34.55</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004850</th>\n      <td>75004400004850</td>\n      <td>1563074.00</td>\n      <td>156307400.00</td>\n      <td>0.00</td>\n      <td>67.16</td>\n      <td>67.16</td>\n      <td>18.79</td>\n      <td>10.87</td>\n      <td>29374364.09</td>\n      <td>18.87</td>\n      <td>33.13</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010337</th>\n      <td>75004400010337</td>\n      <td>344724.00</td>\n      <td>34472400.00</td>\n      <td>0.00</td>\n      <td>35.96</td>\n      <td>35.96</td>\n      <td>4.01</td>\n      <td>4.34</td>\n      <td>1380818.20</td>\n      <td>3.03</td>\n      <td>9.43</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400008879</th>\n      <td>75004400008879</td>\n      <td>233265.00</td>\n      <td>23326500.00</td>\n      <td>0.00</td>\n      <td>30.82</td>\n      <td>30.82</td>\n      <td>1.95</td>\n      <td>2.25</td>\n      <td>455340.88</td>\n      <td>1.92</td>\n      <td>3.44</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004457</th>\n      <td>75004400004457</td>\n      <td>1026297.00</td>\n      <td>102629700.00</td>\n      <td>0.00</td>\n      <td>59.70</td>\n      <td>59.70</td>\n      <td>16.52</td>\n      <td>10.14</td>\n      <td>16950039.30</td>\n      <td>14.77</td>\n      <td>31.31</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400005924</th>\n      <td>75004400005924</td>\n      <td>7720743.00</td>\n      <td>772074300.00</td>\n      <td>0.00</td>\n      <td>65.72</td>\n      <td>65.72</td>\n      <td>11.12</td>\n      <td>10.59</td>\n      <td>85865495.84</td>\n      <td>6.74</td>\n      <td>28.51</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004455</th>\n      <td>75004400004455</td>\n      <td>1755781.00</td>\n      <td>175578100.00</td>\n      <td>0.00</td>\n      <td>59.42</td>\n      <td>59.42</td>\n      <td>19.17</td>\n      <td>10.86</td>\n      <td>33650778.59</td>\n      <td>19.24</td>\n      <td>33.62</td>\n      <td>Cook_Inlet</td>\n    </tr>\n  </tbody>\n</table>\n<p>99 rows  12 columns</p>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make watershed slope df\n",
    "wtd_sl_df = pd.DataFrame()\n",
    "wtd_sl_field_list = []\n",
    "for field in arcpy.ListFields(wtd_slope):\n",
    "    wtd_sl_field_list.append(field.name)\n",
    "wtd_sl_arr = arcpy.da.TableToNumPyArray(wtd_slope, wtd_sl_field_list)\n",
    "wtd_sl_df = pd.DataFrame(wtd_sl_arr)\n",
    "wtd_sl_df = wtd_sl_df.drop([\"OBJECTID\", \"wtd_slope_ZONE_CODE\"],axis=1)\n",
    "wtd_sl_df = wtd_sl_df.set_index('cat_ID_con')\n",
    "dfs.append(wtd_sl_df)\n",
    "wtd_sl_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "                               cat_ID_txt  FType  wtd_lake_area_sqm  \\\ncat_ID_con                                                            \nCook_Inlet_75004400000141  75004400000141    390         1576148.40   \nCook_Inlet_75004400000153  75004400000153    390        58646461.98   \nCook_Inlet_75004400000171  75004400000171    390         8422188.80   \nCook_Inlet_75004400000334  75004400000334    390       104986117.90   \nCook_Inlet_75004400000370  75004400000370    390         7821176.38   \n...                                   ...    ...                ...   \nCook_Inlet_75004400011230  75004400011230    390          161218.08   \nCook_Inlet_75004400011320  75004400011320    390          553571.25   \nCook_Inlet_75004400011322  75004400011322    390           17707.12   \nCook_Inlet_75004400011676  75004400011676    390         5588557.50   \nCook_Inlet_75004400011755  75004400011755    390         5262557.61   \n\n                           wtd_lake_per      region          cat_ID  \ncat_ID_con                                                           \nCook_Inlet_75004400000141          3.57  Cook_Inlet  75004400000141  \nCook_Inlet_75004400000153         11.14  Cook_Inlet  75004400000153  \nCook_Inlet_75004400000171          7.60  Cook_Inlet  75004400000171  \nCook_Inlet_75004400000334          4.68  Cook_Inlet  75004400000334  \nCook_Inlet_75004400000370          1.61  Cook_Inlet  75004400000370  \n...                                 ...         ...             ...  \nCook_Inlet_75004400011230          0.18  Cook_Inlet  75004400011230  \nCook_Inlet_75004400011320          0.40  Cook_Inlet  75004400011320  \nCook_Inlet_75004400011322          0.03  Cook_Inlet  75004400011322  \nCook_Inlet_75004400011676          3.96  Cook_Inlet  75004400011676  \nCook_Inlet_75004400011755          4.98  Cook_Inlet  75004400011755  \n\n[95 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat_ID_txt</th>\n      <th>FType</th>\n      <th>wtd_lake_area_sqm</th>\n      <th>wtd_lake_per</th>\n      <th>region</th>\n      <th>cat_ID</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Cook_Inlet_75004400000141</th>\n      <td>75004400000141</td>\n      <td>390</td>\n      <td>1576148.40</td>\n      <td>3.57</td>\n      <td>Cook_Inlet</td>\n      <td>75004400000141</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400000153</th>\n      <td>75004400000153</td>\n      <td>390</td>\n      <td>58646461.98</td>\n      <td>11.14</td>\n      <td>Cook_Inlet</td>\n      <td>75004400000153</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400000171</th>\n      <td>75004400000171</td>\n      <td>390</td>\n      <td>8422188.80</td>\n      <td>7.60</td>\n      <td>Cook_Inlet</td>\n      <td>75004400000171</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400000334</th>\n      <td>75004400000334</td>\n      <td>390</td>\n      <td>104986117.90</td>\n      <td>4.68</td>\n      <td>Cook_Inlet</td>\n      <td>75004400000334</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400000370</th>\n      <td>75004400000370</td>\n      <td>390</td>\n      <td>7821176.38</td>\n      <td>1.61</td>\n      <td>Cook_Inlet</td>\n      <td>75004400000370</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400011230</th>\n      <td>75004400011230</td>\n      <td>390</td>\n      <td>161218.08</td>\n      <td>0.18</td>\n      <td>Cook_Inlet</td>\n      <td>75004400011230</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400011320</th>\n      <td>75004400011320</td>\n      <td>390</td>\n      <td>553571.25</td>\n      <td>0.40</td>\n      <td>Cook_Inlet</td>\n      <td>75004400011320</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400011322</th>\n      <td>75004400011322</td>\n      <td>390</td>\n      <td>17707.12</td>\n      <td>0.03</td>\n      <td>Cook_Inlet</td>\n      <td>75004400011322</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400011676</th>\n      <td>75004400011676</td>\n      <td>390</td>\n      <td>5588557.50</td>\n      <td>3.96</td>\n      <td>Cook_Inlet</td>\n      <td>75004400011676</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400011755</th>\n      <td>75004400011755</td>\n      <td>390</td>\n      <td>5262557.61</td>\n      <td>4.98</td>\n      <td>Cook_Inlet</td>\n      <td>75004400011755</td>\n    </tr>\n  </tbody>\n</table>\n<p>95 rows  6 columns</p>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make watershed lakes df\n",
    "wtd_lp_df = pd.DataFrame()\n",
    "wtd_lp_field_list = []\n",
    "for field in arcpy.ListFields(wtd_lp):\n",
    "    wtd_lp_field_list.append(field.name)\n",
    "wtd_lp_arr = arcpy.da.TableToNumPyArray(wtd_lp, wtd_lp_field_list)\n",
    "wtd_lp_df = pd.DataFrame(wtd_lp_arr)\n",
    "wtd_lp_df = wtd_lp_df.drop(\"OBJECTID\",axis=1)\n",
    "wtd_lp_df = wtd_lp_df.set_index('cat_ID_con')\n",
    "dfs.append(wtd_lp_df)\n",
    "wtd_lp_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "                               cat_ID_txt O1Region  wtd_glacier_area_sqm  \\\ncat_ID_con                                                                 \nCook_Inlet_75004400000334  75004400000334        1          193799125.72   \nCook_Inlet_75004400000370  75004400000370        1          291900930.05   \nCook_Inlet_75004400000627  75004400000627        1             221275.03   \nCook_Inlet_75004400000862  75004400000862        1            1216847.53   \nCook_Inlet_75004400001134  75004400001134        1             455445.69   \nCook_Inlet_75004400001136  75004400001136        1           12852242.35   \nCook_Inlet_75004400001464  75004400001464        1            3207932.70   \nCook_Inlet_75004400001569  75004400001569        1          528404086.60   \nCook_Inlet_75004400001616  75004400001616        1           42704030.84   \nCook_Inlet_75004400001652  75004400001652        1          485700055.77   \nCook_Inlet_75004400002041  75004400002041        1             306704.74   \nCook_Inlet_75004400002258  75004400002258        1            1596007.16   \nCook_Inlet_75004400002279  75004400002279        1           15172383.46   \nCook_Inlet_75004400002718  75004400002718        1          107993026.72   \nCook_Inlet_75004400003165  75004400003165        1           42704030.84   \nCook_Inlet_75004400003230  75004400003230        1            7054838.44   \nCook_Inlet_75004400003768  75004400003768        1            1140719.29   \nCook_Inlet_75004400003815  75004400003815        1            1257343.57   \nCook_Inlet_75004400003876  75004400003876        1           78427255.38   \nCook_Inlet_75004400004166  75004400004166        1            1207589.75   \nCook_Inlet_75004400004213  75004400004213        1           19137820.87   \nCook_Inlet_75004400004344  75004400004344        1           53098504.34   \nCook_Inlet_75004400004680  75004400004680        1           35649192.40   \nCook_Inlet_75004400005312  75004400005312        1           85883047.59   \nCook_Inlet_75004400005344  75004400005344        1            1588148.84   \nCook_Inlet_75004400005660  75004400005660        1            1497385.92   \nCook_Inlet_75004400005909  75004400005909        1          528404086.60   \nCook_Inlet_75004400005985  75004400005985        1          528404086.60   \nCook_Inlet_75004400006692  75004400006692        1             229598.13   \nCook_Inlet_75004400007224  75004400007224        1          123021949.02   \nCook_Inlet_75004400007351  75004400007351        1           30618058.79   \nCook_Inlet_75004400007996  75004400007996        1              67318.94   \nCook_Inlet_75004400008192  75004400008192        1           11654573.45   \nCook_Inlet_75004400008216  75004400008216        1           92138872.84   \nCook_Inlet_75004400008242  75004400008242        1           10833692.51   \nCook_Inlet_75004400008539  75004400008539        1           42836377.96   \nCook_Inlet_75004400008856  75004400008856        1            5678474.65   \nCook_Inlet_75004400008899  75004400008899        1          528404086.60   \nCook_Inlet_75004400009308  75004400009308        1            1224717.78   \nCook_Inlet_75004400009331  75004400009331        1             601336.23   \nCook_Inlet_75004400009412  75004400009412        1             764952.93   \nCook_Inlet_75004400009562  75004400009562        1             152507.16   \nCook_Inlet_75004400009792  75004400009792        1           63817517.99   \nCook_Inlet_75004400010175  75004400010175        1           98759476.94   \nCook_Inlet_75004400010221  75004400010221        1           42651956.40   \nCook_Inlet_75004400010270  75004400010270        1           19826681.75   \nCook_Inlet_75004400010328  75004400010328        1          191973071.71   \nCook_Inlet_75004400010352  75004400010352        1             153956.09   \nCook_Inlet_75004400010386  75004400010386        1          528404086.60   \nCook_Inlet_75004400010754  75004400010754        1            1224717.78   \nCook_Inlet_75004400011230  75004400011230        1           21198662.86   \nCook_Inlet_75004400011320  75004400011320        1            7817873.91   \nCook_Inlet_75004400011322  75004400011322        1            3462838.92   \nCook_Inlet_75004400011676  75004400011676        1           50863690.12   \nCook_Inlet_75004400011755  75004400011755        1           47685961.13   \n\n                           wtd_glacier_per      region          cat_ID  \ncat_ID_con                                                              \nCook_Inlet_75004400000334             8.64  Cook_Inlet  75004400000334  \nCook_Inlet_75004400000370            60.11  Cook_Inlet  75004400000370  \nCook_Inlet_75004400000627             0.05  Cook_Inlet  75004400000627  \nCook_Inlet_75004400000862             4.21  Cook_Inlet  75004400000862  \nCook_Inlet_75004400001134             0.98  Cook_Inlet  75004400001134  \nCook_Inlet_75004400001136             8.40  Cook_Inlet  75004400001136  \nCook_Inlet_75004400001464             4.28  Cook_Inlet  75004400001464  \nCook_Inlet_75004400001569            11.56  Cook_Inlet  75004400001569  \nCook_Inlet_75004400001616             7.99  Cook_Inlet  75004400001616  \nCook_Inlet_75004400001652            15.33  Cook_Inlet  75004400001652  \nCook_Inlet_75004400002041             0.37  Cook_Inlet  75004400002041  \nCook_Inlet_75004400002258             0.81  Cook_Inlet  75004400002258  \nCook_Inlet_75004400002279             2.22  Cook_Inlet  75004400002279  \nCook_Inlet_75004400002718            53.67  Cook_Inlet  75004400002718  \nCook_Inlet_75004400003165             9.51  Cook_Inlet  75004400003165  \nCook_Inlet_75004400003230             4.44  Cook_Inlet  75004400003230  \nCook_Inlet_75004400003768             0.46  Cook_Inlet  75004400003768  \nCook_Inlet_75004400003815             2.75  Cook_Inlet  75004400003815  \nCook_Inlet_75004400003876            28.60  Cook_Inlet  75004400003876  \nCook_Inlet_75004400004166             6.64  Cook_Inlet  75004400004166  \nCook_Inlet_75004400004213            31.38  Cook_Inlet  75004400004213  \nCook_Inlet_75004400004344            32.33  Cook_Inlet  75004400004344  \nCook_Inlet_75004400004680            24.41  Cook_Inlet  75004400004680  \nCook_Inlet_75004400005312            23.22  Cook_Inlet  75004400005312  \nCook_Inlet_75004400005344             3.53  Cook_Inlet  75004400005344  \nCook_Inlet_75004400005660             2.67  Cook_Inlet  75004400005660  \nCook_Inlet_75004400005909            13.80  Cook_Inlet  75004400005909  \nCook_Inlet_75004400005985            10.50  Cook_Inlet  75004400005985  \nCook_Inlet_75004400006692             0.33  Cook_Inlet  75004400006692  \nCook_Inlet_75004400007224            38.17  Cook_Inlet  75004400007224  \nCook_Inlet_75004400007351            31.58  Cook_Inlet  75004400007351  \nCook_Inlet_75004400007996             0.02  Cook_Inlet  75004400007996  \nCook_Inlet_75004400008192             3.64  Cook_Inlet  75004400008192  \nCook_Inlet_75004400008216            16.69  Cook_Inlet  75004400008216  \nCook_Inlet_75004400008242             9.61  Cook_Inlet  75004400008242  \nCook_Inlet_75004400008539            41.59  Cook_Inlet  75004400008539  \nCook_Inlet_75004400008856             6.47  Cook_Inlet  75004400008856  \nCook_Inlet_75004400008899             9.67  Cook_Inlet  75004400008899  \nCook_Inlet_75004400009308             1.81  Cook_Inlet  75004400009308  \nCook_Inlet_75004400009331             0.48  Cook_Inlet  75004400009331  \nCook_Inlet_75004400009412             0.27  Cook_Inlet  75004400009412  \nCook_Inlet_75004400009562             0.33  Cook_Inlet  75004400009562  \nCook_Inlet_75004400009792            26.33  Cook_Inlet  75004400009792  \nCook_Inlet_75004400010175            23.10  Cook_Inlet  75004400010175  \nCook_Inlet_75004400010221            21.51  Cook_Inlet  75004400010221  \nCook_Inlet_75004400010270            20.25  Cook_Inlet  75004400010270  \nCook_Inlet_75004400010328            11.39  Cook_Inlet  75004400010328  \nCook_Inlet_75004400010352             0.29  Cook_Inlet  75004400010352  \nCook_Inlet_75004400010386             9.66  Cook_Inlet  75004400010386  \nCook_Inlet_75004400010754             0.75  Cook_Inlet  75004400010754  \nCook_Inlet_75004400011230            24.00  Cook_Inlet  75004400011230  \nCook_Inlet_75004400011320             5.62  Cook_Inlet  75004400011320  \nCook_Inlet_75004400011322             6.24  Cook_Inlet  75004400011322  \nCook_Inlet_75004400011676            36.01  Cook_Inlet  75004400011676  \nCook_Inlet_75004400011755            45.16  Cook_Inlet  75004400011755  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat_ID_txt</th>\n      <th>O1Region</th>\n      <th>wtd_glacier_area_sqm</th>\n      <th>wtd_glacier_per</th>\n      <th>region</th>\n      <th>cat_ID</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Cook_Inlet_75004400000334</th>\n      <td>75004400000334</td>\n      <td>1</td>\n      <td>193799125.72</td>\n      <td>8.64</td>\n      <td>Cook_Inlet</td>\n      <td>75004400000334</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400000370</th>\n      <td>75004400000370</td>\n      <td>1</td>\n      <td>291900930.05</td>\n      <td>60.11</td>\n      <td>Cook_Inlet</td>\n      <td>75004400000370</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400000627</th>\n      <td>75004400000627</td>\n      <td>1</td>\n      <td>221275.03</td>\n      <td>0.05</td>\n      <td>Cook_Inlet</td>\n      <td>75004400000627</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400000862</th>\n      <td>75004400000862</td>\n      <td>1</td>\n      <td>1216847.53</td>\n      <td>4.21</td>\n      <td>Cook_Inlet</td>\n      <td>75004400000862</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400001134</th>\n      <td>75004400001134</td>\n      <td>1</td>\n      <td>455445.69</td>\n      <td>0.98</td>\n      <td>Cook_Inlet</td>\n      <td>75004400001134</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400001136</th>\n      <td>75004400001136</td>\n      <td>1</td>\n      <td>12852242.35</td>\n      <td>8.40</td>\n      <td>Cook_Inlet</td>\n      <td>75004400001136</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400001464</th>\n      <td>75004400001464</td>\n      <td>1</td>\n      <td>3207932.70</td>\n      <td>4.28</td>\n      <td>Cook_Inlet</td>\n      <td>75004400001464</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400001569</th>\n      <td>75004400001569</td>\n      <td>1</td>\n      <td>528404086.60</td>\n      <td>11.56</td>\n      <td>Cook_Inlet</td>\n      <td>75004400001569</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400001616</th>\n      <td>75004400001616</td>\n      <td>1</td>\n      <td>42704030.84</td>\n      <td>7.99</td>\n      <td>Cook_Inlet</td>\n      <td>75004400001616</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400001652</th>\n      <td>75004400001652</td>\n      <td>1</td>\n      <td>485700055.77</td>\n      <td>15.33</td>\n      <td>Cook_Inlet</td>\n      <td>75004400001652</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400002041</th>\n      <td>75004400002041</td>\n      <td>1</td>\n      <td>306704.74</td>\n      <td>0.37</td>\n      <td>Cook_Inlet</td>\n      <td>75004400002041</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400002258</th>\n      <td>75004400002258</td>\n      <td>1</td>\n      <td>1596007.16</td>\n      <td>0.81</td>\n      <td>Cook_Inlet</td>\n      <td>75004400002258</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400002279</th>\n      <td>75004400002279</td>\n      <td>1</td>\n      <td>15172383.46</td>\n      <td>2.22</td>\n      <td>Cook_Inlet</td>\n      <td>75004400002279</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400002718</th>\n      <td>75004400002718</td>\n      <td>1</td>\n      <td>107993026.72</td>\n      <td>53.67</td>\n      <td>Cook_Inlet</td>\n      <td>75004400002718</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400003165</th>\n      <td>75004400003165</td>\n      <td>1</td>\n      <td>42704030.84</td>\n      <td>9.51</td>\n      <td>Cook_Inlet</td>\n      <td>75004400003165</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400003230</th>\n      <td>75004400003230</td>\n      <td>1</td>\n      <td>7054838.44</td>\n      <td>4.44</td>\n      <td>Cook_Inlet</td>\n      <td>75004400003230</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400003768</th>\n      <td>75004400003768</td>\n      <td>1</td>\n      <td>1140719.29</td>\n      <td>0.46</td>\n      <td>Cook_Inlet</td>\n      <td>75004400003768</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400003815</th>\n      <td>75004400003815</td>\n      <td>1</td>\n      <td>1257343.57</td>\n      <td>2.75</td>\n      <td>Cook_Inlet</td>\n      <td>75004400003815</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400003876</th>\n      <td>75004400003876</td>\n      <td>1</td>\n      <td>78427255.38</td>\n      <td>28.60</td>\n      <td>Cook_Inlet</td>\n      <td>75004400003876</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004166</th>\n      <td>75004400004166</td>\n      <td>1</td>\n      <td>1207589.75</td>\n      <td>6.64</td>\n      <td>Cook_Inlet</td>\n      <td>75004400004166</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004213</th>\n      <td>75004400004213</td>\n      <td>1</td>\n      <td>19137820.87</td>\n      <td>31.38</td>\n      <td>Cook_Inlet</td>\n      <td>75004400004213</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004344</th>\n      <td>75004400004344</td>\n      <td>1</td>\n      <td>53098504.34</td>\n      <td>32.33</td>\n      <td>Cook_Inlet</td>\n      <td>75004400004344</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004680</th>\n      <td>75004400004680</td>\n      <td>1</td>\n      <td>35649192.40</td>\n      <td>24.41</td>\n      <td>Cook_Inlet</td>\n      <td>75004400004680</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400005312</th>\n      <td>75004400005312</td>\n      <td>1</td>\n      <td>85883047.59</td>\n      <td>23.22</td>\n      <td>Cook_Inlet</td>\n      <td>75004400005312</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400005344</th>\n      <td>75004400005344</td>\n      <td>1</td>\n      <td>1588148.84</td>\n      <td>3.53</td>\n      <td>Cook_Inlet</td>\n      <td>75004400005344</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400005660</th>\n      <td>75004400005660</td>\n      <td>1</td>\n      <td>1497385.92</td>\n      <td>2.67</td>\n      <td>Cook_Inlet</td>\n      <td>75004400005660</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400005909</th>\n      <td>75004400005909</td>\n      <td>1</td>\n      <td>528404086.60</td>\n      <td>13.80</td>\n      <td>Cook_Inlet</td>\n      <td>75004400005909</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400005985</th>\n      <td>75004400005985</td>\n      <td>1</td>\n      <td>528404086.60</td>\n      <td>10.50</td>\n      <td>Cook_Inlet</td>\n      <td>75004400005985</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400006692</th>\n      <td>75004400006692</td>\n      <td>1</td>\n      <td>229598.13</td>\n      <td>0.33</td>\n      <td>Cook_Inlet</td>\n      <td>75004400006692</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400007224</th>\n      <td>75004400007224</td>\n      <td>1</td>\n      <td>123021949.02</td>\n      <td>38.17</td>\n      <td>Cook_Inlet</td>\n      <td>75004400007224</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400007351</th>\n      <td>75004400007351</td>\n      <td>1</td>\n      <td>30618058.79</td>\n      <td>31.58</td>\n      <td>Cook_Inlet</td>\n      <td>75004400007351</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400007996</th>\n      <td>75004400007996</td>\n      <td>1</td>\n      <td>67318.94</td>\n      <td>0.02</td>\n      <td>Cook_Inlet</td>\n      <td>75004400007996</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400008192</th>\n      <td>75004400008192</td>\n      <td>1</td>\n      <td>11654573.45</td>\n      <td>3.64</td>\n      <td>Cook_Inlet</td>\n      <td>75004400008192</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400008216</th>\n      <td>75004400008216</td>\n      <td>1</td>\n      <td>92138872.84</td>\n      <td>16.69</td>\n      <td>Cook_Inlet</td>\n      <td>75004400008216</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400008242</th>\n      <td>75004400008242</td>\n      <td>1</td>\n      <td>10833692.51</td>\n      <td>9.61</td>\n      <td>Cook_Inlet</td>\n      <td>75004400008242</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400008539</th>\n      <td>75004400008539</td>\n      <td>1</td>\n      <td>42836377.96</td>\n      <td>41.59</td>\n      <td>Cook_Inlet</td>\n      <td>75004400008539</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400008856</th>\n      <td>75004400008856</td>\n      <td>1</td>\n      <td>5678474.65</td>\n      <td>6.47</td>\n      <td>Cook_Inlet</td>\n      <td>75004400008856</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400008899</th>\n      <td>75004400008899</td>\n      <td>1</td>\n      <td>528404086.60</td>\n      <td>9.67</td>\n      <td>Cook_Inlet</td>\n      <td>75004400008899</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400009308</th>\n      <td>75004400009308</td>\n      <td>1</td>\n      <td>1224717.78</td>\n      <td>1.81</td>\n      <td>Cook_Inlet</td>\n      <td>75004400009308</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400009331</th>\n      <td>75004400009331</td>\n      <td>1</td>\n      <td>601336.23</td>\n      <td>0.48</td>\n      <td>Cook_Inlet</td>\n      <td>75004400009331</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400009412</th>\n      <td>75004400009412</td>\n      <td>1</td>\n      <td>764952.93</td>\n      <td>0.27</td>\n      <td>Cook_Inlet</td>\n      <td>75004400009412</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400009562</th>\n      <td>75004400009562</td>\n      <td>1</td>\n      <td>152507.16</td>\n      <td>0.33</td>\n      <td>Cook_Inlet</td>\n      <td>75004400009562</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400009792</th>\n      <td>75004400009792</td>\n      <td>1</td>\n      <td>63817517.99</td>\n      <td>26.33</td>\n      <td>Cook_Inlet</td>\n      <td>75004400009792</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010175</th>\n      <td>75004400010175</td>\n      <td>1</td>\n      <td>98759476.94</td>\n      <td>23.10</td>\n      <td>Cook_Inlet</td>\n      <td>75004400010175</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010221</th>\n      <td>75004400010221</td>\n      <td>1</td>\n      <td>42651956.40</td>\n      <td>21.51</td>\n      <td>Cook_Inlet</td>\n      <td>75004400010221</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010270</th>\n      <td>75004400010270</td>\n      <td>1</td>\n      <td>19826681.75</td>\n      <td>20.25</td>\n      <td>Cook_Inlet</td>\n      <td>75004400010270</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010328</th>\n      <td>75004400010328</td>\n      <td>1</td>\n      <td>191973071.71</td>\n      <td>11.39</td>\n      <td>Cook_Inlet</td>\n      <td>75004400010328</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010352</th>\n      <td>75004400010352</td>\n      <td>1</td>\n      <td>153956.09</td>\n      <td>0.29</td>\n      <td>Cook_Inlet</td>\n      <td>75004400010352</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010386</th>\n      <td>75004400010386</td>\n      <td>1</td>\n      <td>528404086.60</td>\n      <td>9.66</td>\n      <td>Cook_Inlet</td>\n      <td>75004400010386</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010754</th>\n      <td>75004400010754</td>\n      <td>1</td>\n      <td>1224717.78</td>\n      <td>0.75</td>\n      <td>Cook_Inlet</td>\n      <td>75004400010754</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400011230</th>\n      <td>75004400011230</td>\n      <td>1</td>\n      <td>21198662.86</td>\n      <td>24.00</td>\n      <td>Cook_Inlet</td>\n      <td>75004400011230</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400011320</th>\n      <td>75004400011320</td>\n      <td>1</td>\n      <td>7817873.91</td>\n      <td>5.62</td>\n      <td>Cook_Inlet</td>\n      <td>75004400011320</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400011322</th>\n      <td>75004400011322</td>\n      <td>1</td>\n      <td>3462838.92</td>\n      <td>6.24</td>\n      <td>Cook_Inlet</td>\n      <td>75004400011322</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400011676</th>\n      <td>75004400011676</td>\n      <td>1</td>\n      <td>50863690.12</td>\n      <td>36.01</td>\n      <td>Cook_Inlet</td>\n      <td>75004400011676</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400011755</th>\n      <td>75004400011755</td>\n      <td>1</td>\n      <td>47685961.13</td>\n      <td>45.16</td>\n      <td>Cook_Inlet</td>\n      <td>75004400011755</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make watershed glacier df\n",
    "wtd_glac_df = pd.DataFrame()\n",
    "wtd_glac_field_list = []\n",
    "for field in arcpy.ListFields(wtd_glac):\n",
    "    wtd_glac_field_list.append(field.name)\n",
    "wtd_glac_arr = arcpy.da.TableToNumPyArray(wtd_glac, wtd_glac_field_list)\n",
    "wtd_glac_df = pd.DataFrame(wtd_glac_arr)\n",
    "wtd_glac_df = wtd_glac_df.drop(\"OBJECTID\",axis=1)\n",
    "wtd_glac_df = wtd_glac_df.set_index('cat_ID_con')\n",
    "dfs.append(wtd_glac_df)\n",
    "wtd_glac_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "                           non_north_area   north_area      region  \\\ncat_ID_con                                                           \nCook_Inlet_75004400005344     38049800.00   6956300.00  Cook_Inlet   \nCook_Inlet_75004400011755     77518800.00  28071100.00  Cook_Inlet   \nCook_Inlet_75004400010352     42064400.00  11493700.00  Cook_Inlet   \nCook_Inlet_75004400007996    208771000.00  73801700.00  Cook_Inlet   \nCook_Inlet_75004400004850    117098200.00  39209200.00  Cook_Inlet   \n...                                   ...          ...         ...   \nCook_Inlet_75004400010337     28343000.00   6129400.00  Cook_Inlet   \nCook_Inlet_75004400008879     19775200.00   3551300.00  Cook_Inlet   \nCook_Inlet_75004400004457     72416200.00  30213500.00  Cook_Inlet   \nCook_Inlet_75004400005924    572761300.00 199313000.00  Cook_Inlet   \nCook_Inlet_75004400004455    126821700.00  48756400.00  Cook_Inlet   \n\n                           wtd_north_per      cat_ID_txt  \ncat_ID_con                                                \nCook_Inlet_75004400005344          15.46  75004400005344  \nCook_Inlet_75004400011755          26.59  75004400011755  \nCook_Inlet_75004400010352          21.46  75004400010352  \nCook_Inlet_75004400007996          26.12  75004400007996  \nCook_Inlet_75004400004850          25.08  75004400004850  \n...                                  ...             ...  \nCook_Inlet_75004400010337          17.78  75004400010337  \nCook_Inlet_75004400008879          15.22  75004400008879  \nCook_Inlet_75004400004457          29.44  75004400004457  \nCook_Inlet_75004400005924          25.82  75004400005924  \nCook_Inlet_75004400004455          27.77  75004400004455  \n\n[99 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>non_north_area</th>\n      <th>north_area</th>\n      <th>region</th>\n      <th>wtd_north_per</th>\n      <th>cat_ID_txt</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Cook_Inlet_75004400005344</th>\n      <td>38049800.00</td>\n      <td>6956300.00</td>\n      <td>Cook_Inlet</td>\n      <td>15.46</td>\n      <td>75004400005344</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400011755</th>\n      <td>77518800.00</td>\n      <td>28071100.00</td>\n      <td>Cook_Inlet</td>\n      <td>26.59</td>\n      <td>75004400011755</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010352</th>\n      <td>42064400.00</td>\n      <td>11493700.00</td>\n      <td>Cook_Inlet</td>\n      <td>21.46</td>\n      <td>75004400010352</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400007996</th>\n      <td>208771000.00</td>\n      <td>73801700.00</td>\n      <td>Cook_Inlet</td>\n      <td>26.12</td>\n      <td>75004400007996</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004850</th>\n      <td>117098200.00</td>\n      <td>39209200.00</td>\n      <td>Cook_Inlet</td>\n      <td>25.08</td>\n      <td>75004400004850</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010337</th>\n      <td>28343000.00</td>\n      <td>6129400.00</td>\n      <td>Cook_Inlet</td>\n      <td>17.78</td>\n      <td>75004400010337</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400008879</th>\n      <td>19775200.00</td>\n      <td>3551300.00</td>\n      <td>Cook_Inlet</td>\n      <td>15.22</td>\n      <td>75004400008879</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004457</th>\n      <td>72416200.00</td>\n      <td>30213500.00</td>\n      <td>Cook_Inlet</td>\n      <td>29.44</td>\n      <td>75004400004457</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400005924</th>\n      <td>572761300.00</td>\n      <td>199313000.00</td>\n      <td>Cook_Inlet</td>\n      <td>25.82</td>\n      <td>75004400005924</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004455</th>\n      <td>126821700.00</td>\n      <td>48756400.00</td>\n      <td>Cook_Inlet</td>\n      <td>27.77</td>\n      <td>75004400004455</td>\n    </tr>\n  </tbody>\n</table>\n<p>99 rows  5 columns</p>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make watershed north df\n",
    "wtd_n_df = pd.DataFrame()\n",
    "wtd_n_field_list = []\n",
    "for field in arcpy.ListFields(wtd_per_north):\n",
    "    wtd_n_field_list.append(field.name)\n",
    "wtd_n_arr = arcpy.da.TableToNumPyArray(wtd_per_north,wtd_n_field_list)\n",
    "wtd_n_df = pd.DataFrame(wtd_n_arr)\n",
    "wtd_n_df = wtd_n_df.drop(\"OBJECTID\",axis=1)\n",
    "wtd_n_df = wtd_n_df.set_index('cat_ID_con')\n",
    "dfs.append(wtd_n_df)\n",
    "wtd_n_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "                             cat_ID_txt_x  wtd_slope_COUNT  wtd_slope_AREA  \\\ncat_ID_con                                                                   \nCook_Inlet_75004400005344  75004400005344        450061.00     45006100.00   \nCook_Inlet_75004400011755  75004400011755       1055899.00    105589900.00   \nCook_Inlet_75004400010352  75004400010352        535581.00     53558100.00   \nCook_Inlet_75004400007996  75004400007996       2825727.00    282572700.00   \nCook_Inlet_75004400004850  75004400004850       1563074.00    156307400.00   \n...                                   ...              ...             ...   \nCook_Inlet_75004400010337  75004400010337        344724.00     34472400.00   \nCook_Inlet_75004400008879  75004400008879        233265.00     23326500.00   \nCook_Inlet_75004400004457  75004400004457       1026297.00    102629700.00   \nCook_Inlet_75004400005924  75004400005924       7720743.00    772074300.00   \nCook_Inlet_75004400004455  75004400004455       1755781.00    175578100.00   \n\n                           wtd_slope_MIN  wtd_slope_MAX  wtd_slope_RANGE  \\\ncat_ID_con                                                                 \nCook_Inlet_75004400005344           0.00          70.87            70.87   \nCook_Inlet_75004400011755           0.00          76.85            76.85   \nCook_Inlet_75004400010352           0.00          67.02            67.02   \nCook_Inlet_75004400007996           0.00          65.51            65.51   \nCook_Inlet_75004400004850           0.00          67.16            67.16   \n...                                  ...            ...              ...   \nCook_Inlet_75004400010337           0.00          35.96            35.96   \nCook_Inlet_75004400008879           0.00          30.82            30.82   \nCook_Inlet_75004400004457           0.00          59.70            59.70   \nCook_Inlet_75004400005924           0.00          65.72            65.72   \nCook_Inlet_75004400004455           0.00          59.42            59.42   \n\n                           wtd_slope_MEAN  wtd_slope_STD  wtd_slope_SUM  \\\ncat_ID_con                                                                \nCook_Inlet_75004400005344           25.38          13.03    11421329.52   \nCook_Inlet_75004400011755           24.02          15.07    25364061.16   \nCook_Inlet_75004400010352           26.18          10.23    14019013.53   \nCook_Inlet_75004400007996           22.75           9.80    64285852.09   \nCook_Inlet_75004400004850           18.79          10.87    29374364.09   \n...                                   ...            ...            ...   \nCook_Inlet_75004400010337            4.01           4.34     1380818.20   \nCook_Inlet_75004400008879            1.95           2.25      455340.88   \nCook_Inlet_75004400004457           16.52          10.14    16950039.30   \nCook_Inlet_75004400005924           11.12          10.59    85865495.84   \nCook_Inlet_75004400004455           19.17          10.86    33650778.59   \n\n                           wtd_slope_MEDIAN  ...  O1Region  \\\ncat_ID_con                                   ...             \nCook_Inlet_75004400005344             26.37  ...         1   \nCook_Inlet_75004400011755             24.16  ...         1   \nCook_Inlet_75004400010352             28.10  ...         1   \nCook_Inlet_75004400007996             23.95  ...         1   \nCook_Inlet_75004400004850             18.87  ...       NaN   \n...                                     ...  ...       ...   \nCook_Inlet_75004400010337              3.03  ...       NaN   \nCook_Inlet_75004400008879              1.92  ...       NaN   \nCook_Inlet_75004400004457             14.77  ...       NaN   \nCook_Inlet_75004400005924              6.74  ...       NaN   \nCook_Inlet_75004400004455             19.24  ...       NaN   \n\n                          wtd_glacier_area_sqm wtd_glacier_per  region_x_2  \\\ncat_ID_con                                                                   \nCook_Inlet_75004400005344           1588148.84            3.53  Cook_Inlet   \nCook_Inlet_75004400011755          47685961.13           45.16  Cook_Inlet   \nCook_Inlet_75004400010352            153956.09            0.29  Cook_Inlet   \nCook_Inlet_75004400007996             67318.94            0.02  Cook_Inlet   \nCook_Inlet_75004400004850                  NaN             NaN         NaN   \n...                                        ...             ...         ...   \nCook_Inlet_75004400010337                  NaN             NaN         NaN   \nCook_Inlet_75004400008879                  NaN             NaN         NaN   \nCook_Inlet_75004400004457                  NaN             NaN         NaN   \nCook_Inlet_75004400005924                  NaN             NaN         NaN   \nCook_Inlet_75004400004455                  NaN             NaN         NaN   \n\n                                 cat_ID_y  non_north_area   north_area  \\\ncat_ID_con                                                               \nCook_Inlet_75004400005344  75004400005344     38049800.00   6956300.00   \nCook_Inlet_75004400011755  75004400011755     77518800.00  28071100.00   \nCook_Inlet_75004400010352  75004400010352     42064400.00  11493700.00   \nCook_Inlet_75004400007996  75004400007996    208771000.00  73801700.00   \nCook_Inlet_75004400004850             NaN    117098200.00  39209200.00   \n...                                   ...             ...          ...   \nCook_Inlet_75004400010337             NaN     28343000.00   6129400.00   \nCook_Inlet_75004400008879             NaN     19775200.00   3551300.00   \nCook_Inlet_75004400004457             NaN     72416200.00  30213500.00   \nCook_Inlet_75004400005924             NaN    572761300.00 199313000.00   \nCook_Inlet_75004400004455             NaN    126821700.00  48756400.00   \n\n                           region_y_2 wtd_north_per  cat_ID_txt_y_2  \ncat_ID_con                                                           \nCook_Inlet_75004400005344  Cook_Inlet         15.46  75004400005344  \nCook_Inlet_75004400011755  Cook_Inlet         26.59  75004400011755  \nCook_Inlet_75004400010352  Cook_Inlet         21.46  75004400010352  \nCook_Inlet_75004400007996  Cook_Inlet         26.12  75004400007996  \nCook_Inlet_75004400004850  Cook_Inlet         25.08  75004400004850  \n...                               ...           ...             ...  \nCook_Inlet_75004400010337  Cook_Inlet         17.78  75004400010337  \nCook_Inlet_75004400008879  Cook_Inlet         15.22  75004400008879  \nCook_Inlet_75004400004457  Cook_Inlet         29.44  75004400004457  \nCook_Inlet_75004400005924  Cook_Inlet         25.82  75004400005924  \nCook_Inlet_75004400004455  Cook_Inlet         27.77  75004400004455  \n\n[99 rows x 29 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat_ID_txt_x</th>\n      <th>wtd_slope_COUNT</th>\n      <th>wtd_slope_AREA</th>\n      <th>wtd_slope_MIN</th>\n      <th>wtd_slope_MAX</th>\n      <th>wtd_slope_RANGE</th>\n      <th>wtd_slope_MEAN</th>\n      <th>wtd_slope_STD</th>\n      <th>wtd_slope_SUM</th>\n      <th>wtd_slope_MEDIAN</th>\n      <th>...</th>\n      <th>O1Region</th>\n      <th>wtd_glacier_area_sqm</th>\n      <th>wtd_glacier_per</th>\n      <th>region_x_2</th>\n      <th>cat_ID_y</th>\n      <th>non_north_area</th>\n      <th>north_area</th>\n      <th>region_y_2</th>\n      <th>wtd_north_per</th>\n      <th>cat_ID_txt_y_2</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Cook_Inlet_75004400005344</th>\n      <td>75004400005344</td>\n      <td>450061.00</td>\n      <td>45006100.00</td>\n      <td>0.00</td>\n      <td>70.87</td>\n      <td>70.87</td>\n      <td>25.38</td>\n      <td>13.03</td>\n      <td>11421329.52</td>\n      <td>26.37</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1588148.84</td>\n      <td>3.53</td>\n      <td>Cook_Inlet</td>\n      <td>75004400005344</td>\n      <td>38049800.00</td>\n      <td>6956300.00</td>\n      <td>Cook_Inlet</td>\n      <td>15.46</td>\n      <td>75004400005344</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400011755</th>\n      <td>75004400011755</td>\n      <td>1055899.00</td>\n      <td>105589900.00</td>\n      <td>0.00</td>\n      <td>76.85</td>\n      <td>76.85</td>\n      <td>24.02</td>\n      <td>15.07</td>\n      <td>25364061.16</td>\n      <td>24.16</td>\n      <td>...</td>\n      <td>1</td>\n      <td>47685961.13</td>\n      <td>45.16</td>\n      <td>Cook_Inlet</td>\n      <td>75004400011755</td>\n      <td>77518800.00</td>\n      <td>28071100.00</td>\n      <td>Cook_Inlet</td>\n      <td>26.59</td>\n      <td>75004400011755</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010352</th>\n      <td>75004400010352</td>\n      <td>535581.00</td>\n      <td>53558100.00</td>\n      <td>0.00</td>\n      <td>67.02</td>\n      <td>67.02</td>\n      <td>26.18</td>\n      <td>10.23</td>\n      <td>14019013.53</td>\n      <td>28.10</td>\n      <td>...</td>\n      <td>1</td>\n      <td>153956.09</td>\n      <td>0.29</td>\n      <td>Cook_Inlet</td>\n      <td>75004400010352</td>\n      <td>42064400.00</td>\n      <td>11493700.00</td>\n      <td>Cook_Inlet</td>\n      <td>21.46</td>\n      <td>75004400010352</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400007996</th>\n      <td>75004400007996</td>\n      <td>2825727.00</td>\n      <td>282572700.00</td>\n      <td>0.00</td>\n      <td>65.51</td>\n      <td>65.51</td>\n      <td>22.75</td>\n      <td>9.80</td>\n      <td>64285852.09</td>\n      <td>23.95</td>\n      <td>...</td>\n      <td>1</td>\n      <td>67318.94</td>\n      <td>0.02</td>\n      <td>Cook_Inlet</td>\n      <td>75004400007996</td>\n      <td>208771000.00</td>\n      <td>73801700.00</td>\n      <td>Cook_Inlet</td>\n      <td>26.12</td>\n      <td>75004400007996</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004850</th>\n      <td>75004400004850</td>\n      <td>1563074.00</td>\n      <td>156307400.00</td>\n      <td>0.00</td>\n      <td>67.16</td>\n      <td>67.16</td>\n      <td>18.79</td>\n      <td>10.87</td>\n      <td>29374364.09</td>\n      <td>18.87</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>117098200.00</td>\n      <td>39209200.00</td>\n      <td>Cook_Inlet</td>\n      <td>25.08</td>\n      <td>75004400004850</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010337</th>\n      <td>75004400010337</td>\n      <td>344724.00</td>\n      <td>34472400.00</td>\n      <td>0.00</td>\n      <td>35.96</td>\n      <td>35.96</td>\n      <td>4.01</td>\n      <td>4.34</td>\n      <td>1380818.20</td>\n      <td>3.03</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>28343000.00</td>\n      <td>6129400.00</td>\n      <td>Cook_Inlet</td>\n      <td>17.78</td>\n      <td>75004400010337</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400008879</th>\n      <td>75004400008879</td>\n      <td>233265.00</td>\n      <td>23326500.00</td>\n      <td>0.00</td>\n      <td>30.82</td>\n      <td>30.82</td>\n      <td>1.95</td>\n      <td>2.25</td>\n      <td>455340.88</td>\n      <td>1.92</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>19775200.00</td>\n      <td>3551300.00</td>\n      <td>Cook_Inlet</td>\n      <td>15.22</td>\n      <td>75004400008879</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004457</th>\n      <td>75004400004457</td>\n      <td>1026297.00</td>\n      <td>102629700.00</td>\n      <td>0.00</td>\n      <td>59.70</td>\n      <td>59.70</td>\n      <td>16.52</td>\n      <td>10.14</td>\n      <td>16950039.30</td>\n      <td>14.77</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>72416200.00</td>\n      <td>30213500.00</td>\n      <td>Cook_Inlet</td>\n      <td>29.44</td>\n      <td>75004400004457</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400005924</th>\n      <td>75004400005924</td>\n      <td>7720743.00</td>\n      <td>772074300.00</td>\n      <td>0.00</td>\n      <td>65.72</td>\n      <td>65.72</td>\n      <td>11.12</td>\n      <td>10.59</td>\n      <td>85865495.84</td>\n      <td>6.74</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>572761300.00</td>\n      <td>199313000.00</td>\n      <td>Cook_Inlet</td>\n      <td>25.82</td>\n      <td>75004400005924</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004455</th>\n      <td>75004400004455</td>\n      <td>1755781.00</td>\n      <td>175578100.00</td>\n      <td>0.00</td>\n      <td>59.42</td>\n      <td>59.42</td>\n      <td>19.17</td>\n      <td>10.86</td>\n      <td>33650778.59</td>\n      <td>19.24</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>126821700.00</td>\n      <td>48756400.00</td>\n      <td>Cook_Inlet</td>\n      <td>27.77</td>\n      <td>75004400004455</td>\n    </tr>\n  </tbody>\n</table>\n<p>99 rows  29 columns</p>\n</div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge all data frames together\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "df_final = reduce(lambda left,right: pd.merge(left,right,on='cat_ID_con',how=\"outer\"), dfs)\n",
    "#Generate unique column names\n",
    "def uniquify(df_final):\n",
    "    seen = set()\n",
    "    for item in df_final:\n",
    "        fudge = 1\n",
    "        newitem = item\n",
    "        while newitem in seen:\n",
    "            fudge += 1\n",
    "            newitem = \"{}_{}\".format(item, fudge)\n",
    "        yield newitem\n",
    "        seen.add(newitem)\n",
    "df_final.columns = list(uniquify(df_final))\n",
    "\n",
    "#List of final columns in the order to output\n",
    "final_cols = ['cat_ID_txt', 'wtd_slope_COUNT', 'wtd_slope_AREA', 'wtd_slope_MIN', 'wtd_slope_MAX','wtd_slope_RANGE',\n",
    "              'wtd_slope_MEAN', 'wtd_slope_STD', 'wtd_slope_SUM', 'wtd_slope_MEDIAN', 'wtd_slope_PCT90',\n",
    "              'wtd_lake_area_sqm', 'wtd_lake_per', 'wtd_glacier_area_sqm', 'wtd_glacier_per','wtd_north_per' ]\n",
    "#Create list of duplicate column names and drop\n",
    "drop_cols = ['cat_ID_txt_y', 'region_y','FType', 'O1Region','cat_ID_y','cat_ID_x','non_north_area','north_area',\n",
    "             'region_x_2', 'region_y_2', 'cat_ID_txt_y_2','cat_ID_txt_x_2']\n",
    "df_final"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "                             cat_ID_txt_x  wtd_slope_COUNT  wtd_slope_AREA  \\\ncat_ID_con                                                                   \nCook_Inlet_75004400005344  75004400005344        450061.00     45006100.00   \nCook_Inlet_75004400011755  75004400011755       1055899.00    105589900.00   \nCook_Inlet_75004400010352  75004400010352        535581.00     53558100.00   \nCook_Inlet_75004400007996  75004400007996       2825727.00    282572700.00   \nCook_Inlet_75004400004850  75004400004850       1563074.00    156307400.00   \n...                                   ...              ...             ...   \nCook_Inlet_75004400010337  75004400010337        344724.00     34472400.00   \nCook_Inlet_75004400008879  75004400008879        233265.00     23326500.00   \nCook_Inlet_75004400004457  75004400004457       1026297.00    102629700.00   \nCook_Inlet_75004400005924  75004400005924       7720743.00    772074300.00   \nCook_Inlet_75004400004455  75004400004455       1755781.00    175578100.00   \n\n                           wtd_slope_MIN  wtd_slope_MAX  wtd_slope_RANGE  \\\ncat_ID_con                                                                 \nCook_Inlet_75004400005344           0.00          70.87            70.87   \nCook_Inlet_75004400011755           0.00          76.85            76.85   \nCook_Inlet_75004400010352           0.00          67.02            67.02   \nCook_Inlet_75004400007996           0.00          65.51            65.51   \nCook_Inlet_75004400004850           0.00          67.16            67.16   \n...                                  ...            ...              ...   \nCook_Inlet_75004400010337           0.00          35.96            35.96   \nCook_Inlet_75004400008879           0.00          30.82            30.82   \nCook_Inlet_75004400004457           0.00          59.70            59.70   \nCook_Inlet_75004400005924           0.00          65.72            65.72   \nCook_Inlet_75004400004455           0.00          59.42            59.42   \n\n                           wtd_slope_MEAN  wtd_slope_STD  wtd_slope_SUM  \\\ncat_ID_con                                                                \nCook_Inlet_75004400005344           25.38          13.03    11421329.52   \nCook_Inlet_75004400011755           24.02          15.07    25364061.16   \nCook_Inlet_75004400010352           26.18          10.23    14019013.53   \nCook_Inlet_75004400007996           22.75           9.80    64285852.09   \nCook_Inlet_75004400004850           18.79          10.87    29374364.09   \n...                                   ...            ...            ...   \nCook_Inlet_75004400010337            4.01           4.34     1380818.20   \nCook_Inlet_75004400008879            1.95           2.25      455340.88   \nCook_Inlet_75004400004457           16.52          10.14    16950039.30   \nCook_Inlet_75004400005924           11.12          10.59    85865495.84   \nCook_Inlet_75004400004455           19.17          10.86    33650778.59   \n\n                           wtd_slope_MEDIAN  wtd_slope_PCT90    region_x  \\\ncat_ID_con                                                                 \nCook_Inlet_75004400005344             26.37            41.61  Cook_Inlet   \nCook_Inlet_75004400011755             24.16            44.20  Cook_Inlet   \nCook_Inlet_75004400010352             28.10            37.79  Cook_Inlet   \nCook_Inlet_75004400007996             23.95            34.55  Cook_Inlet   \nCook_Inlet_75004400004850             18.87            33.13  Cook_Inlet   \n...                                     ...              ...         ...   \nCook_Inlet_75004400010337              3.03             9.43  Cook_Inlet   \nCook_Inlet_75004400008879              1.92             3.44  Cook_Inlet   \nCook_Inlet_75004400004457             14.77            31.31  Cook_Inlet   \nCook_Inlet_75004400005924              6.74            28.51  Cook_Inlet   \nCook_Inlet_75004400004455             19.24            33.62  Cook_Inlet   \n\n                           wtd_lake_area_sqm  wtd_lake_per  \\\ncat_ID_con                                                   \nCook_Inlet_75004400005344          202569.36          0.45   \nCook_Inlet_75004400011755         5262557.61          4.98   \nCook_Inlet_75004400010352           62396.23          0.12   \nCook_Inlet_75004400007996          201660.27          0.07   \nCook_Inlet_75004400004850          163496.46          0.10   \n...                                      ...           ...   \nCook_Inlet_75004400010337         8008947.94         23.23   \nCook_Inlet_75004400008879          213751.02          0.92   \nCook_Inlet_75004400004457           77577.74          0.08   \nCook_Inlet_75004400005924         8118783.98          1.05   \nCook_Inlet_75004400004455          456216.96          0.26   \n\n                           wtd_glacier_area_sqm  wtd_glacier_per  \\\ncat_ID_con                                                         \nCook_Inlet_75004400005344            1588148.84             3.53   \nCook_Inlet_75004400011755           47685961.13            45.16   \nCook_Inlet_75004400010352             153956.09             0.29   \nCook_Inlet_75004400007996              67318.94             0.02   \nCook_Inlet_75004400004850                   NaN              NaN   \n...                                         ...              ...   \nCook_Inlet_75004400010337                   NaN              NaN   \nCook_Inlet_75004400008879                   NaN              NaN   \nCook_Inlet_75004400004457                   NaN              NaN   \nCook_Inlet_75004400005924                   NaN              NaN   \nCook_Inlet_75004400004455                   NaN              NaN   \n\n                           wtd_north_per  \ncat_ID_con                                \nCook_Inlet_75004400005344          15.46  \nCook_Inlet_75004400011755          26.59  \nCook_Inlet_75004400010352          21.46  \nCook_Inlet_75004400007996          26.12  \nCook_Inlet_75004400004850          25.08  \n...                                  ...  \nCook_Inlet_75004400010337          17.78  \nCook_Inlet_75004400008879          15.22  \nCook_Inlet_75004400004457          29.44  \nCook_Inlet_75004400005924          25.82  \nCook_Inlet_75004400004455          27.77  \n\n[99 rows x 17 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat_ID_txt_x</th>\n      <th>wtd_slope_COUNT</th>\n      <th>wtd_slope_AREA</th>\n      <th>wtd_slope_MIN</th>\n      <th>wtd_slope_MAX</th>\n      <th>wtd_slope_RANGE</th>\n      <th>wtd_slope_MEAN</th>\n      <th>wtd_slope_STD</th>\n      <th>wtd_slope_SUM</th>\n      <th>wtd_slope_MEDIAN</th>\n      <th>wtd_slope_PCT90</th>\n      <th>region_x</th>\n      <th>wtd_lake_area_sqm</th>\n      <th>wtd_lake_per</th>\n      <th>wtd_glacier_area_sqm</th>\n      <th>wtd_glacier_per</th>\n      <th>wtd_north_per</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Cook_Inlet_75004400005344</th>\n      <td>75004400005344</td>\n      <td>450061.00</td>\n      <td>45006100.00</td>\n      <td>0.00</td>\n      <td>70.87</td>\n      <td>70.87</td>\n      <td>25.38</td>\n      <td>13.03</td>\n      <td>11421329.52</td>\n      <td>26.37</td>\n      <td>41.61</td>\n      <td>Cook_Inlet</td>\n      <td>202569.36</td>\n      <td>0.45</td>\n      <td>1588148.84</td>\n      <td>3.53</td>\n      <td>15.46</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400011755</th>\n      <td>75004400011755</td>\n      <td>1055899.00</td>\n      <td>105589900.00</td>\n      <td>0.00</td>\n      <td>76.85</td>\n      <td>76.85</td>\n      <td>24.02</td>\n      <td>15.07</td>\n      <td>25364061.16</td>\n      <td>24.16</td>\n      <td>44.20</td>\n      <td>Cook_Inlet</td>\n      <td>5262557.61</td>\n      <td>4.98</td>\n      <td>47685961.13</td>\n      <td>45.16</td>\n      <td>26.59</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010352</th>\n      <td>75004400010352</td>\n      <td>535581.00</td>\n      <td>53558100.00</td>\n      <td>0.00</td>\n      <td>67.02</td>\n      <td>67.02</td>\n      <td>26.18</td>\n      <td>10.23</td>\n      <td>14019013.53</td>\n      <td>28.10</td>\n      <td>37.79</td>\n      <td>Cook_Inlet</td>\n      <td>62396.23</td>\n      <td>0.12</td>\n      <td>153956.09</td>\n      <td>0.29</td>\n      <td>21.46</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400007996</th>\n      <td>75004400007996</td>\n      <td>2825727.00</td>\n      <td>282572700.00</td>\n      <td>0.00</td>\n      <td>65.51</td>\n      <td>65.51</td>\n      <td>22.75</td>\n      <td>9.80</td>\n      <td>64285852.09</td>\n      <td>23.95</td>\n      <td>34.55</td>\n      <td>Cook_Inlet</td>\n      <td>201660.27</td>\n      <td>0.07</td>\n      <td>67318.94</td>\n      <td>0.02</td>\n      <td>26.12</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004850</th>\n      <td>75004400004850</td>\n      <td>1563074.00</td>\n      <td>156307400.00</td>\n      <td>0.00</td>\n      <td>67.16</td>\n      <td>67.16</td>\n      <td>18.79</td>\n      <td>10.87</td>\n      <td>29374364.09</td>\n      <td>18.87</td>\n      <td>33.13</td>\n      <td>Cook_Inlet</td>\n      <td>163496.46</td>\n      <td>0.10</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>25.08</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010337</th>\n      <td>75004400010337</td>\n      <td>344724.00</td>\n      <td>34472400.00</td>\n      <td>0.00</td>\n      <td>35.96</td>\n      <td>35.96</td>\n      <td>4.01</td>\n      <td>4.34</td>\n      <td>1380818.20</td>\n      <td>3.03</td>\n      <td>9.43</td>\n      <td>Cook_Inlet</td>\n      <td>8008947.94</td>\n      <td>23.23</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17.78</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400008879</th>\n      <td>75004400008879</td>\n      <td>233265.00</td>\n      <td>23326500.00</td>\n      <td>0.00</td>\n      <td>30.82</td>\n      <td>30.82</td>\n      <td>1.95</td>\n      <td>2.25</td>\n      <td>455340.88</td>\n      <td>1.92</td>\n      <td>3.44</td>\n      <td>Cook_Inlet</td>\n      <td>213751.02</td>\n      <td>0.92</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>15.22</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004457</th>\n      <td>75004400004457</td>\n      <td>1026297.00</td>\n      <td>102629700.00</td>\n      <td>0.00</td>\n      <td>59.70</td>\n      <td>59.70</td>\n      <td>16.52</td>\n      <td>10.14</td>\n      <td>16950039.30</td>\n      <td>14.77</td>\n      <td>31.31</td>\n      <td>Cook_Inlet</td>\n      <td>77577.74</td>\n      <td>0.08</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>29.44</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400005924</th>\n      <td>75004400005924</td>\n      <td>7720743.00</td>\n      <td>772074300.00</td>\n      <td>0.00</td>\n      <td>65.72</td>\n      <td>65.72</td>\n      <td>11.12</td>\n      <td>10.59</td>\n      <td>85865495.84</td>\n      <td>6.74</td>\n      <td>28.51</td>\n      <td>Cook_Inlet</td>\n      <td>8118783.98</td>\n      <td>1.05</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>25.82</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004455</th>\n      <td>75004400004455</td>\n      <td>1755781.00</td>\n      <td>175578100.00</td>\n      <td>0.00</td>\n      <td>59.42</td>\n      <td>59.42</td>\n      <td>19.17</td>\n      <td>10.86</td>\n      <td>33650778.59</td>\n      <td>19.24</td>\n      <td>33.62</td>\n      <td>Cook_Inlet</td>\n      <td>456216.96</td>\n      <td>0.26</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>27.77</td>\n    </tr>\n  </tbody>\n</table>\n<p>99 rows  17 columns</p>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.drop(columns=drop_cols, axis = 1, inplace=True)\n",
    "df_final"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "                               cat_ID_txt  wtd_slope_COUNT  wtd_slope_AREA  \\\ncat_ID_con                                                                   \nCook_Inlet_75004400005344  75004400005344        450061.00     45006100.00   \nCook_Inlet_75004400011755  75004400011755       1055899.00    105589900.00   \nCook_Inlet_75004400010352  75004400010352        535581.00     53558100.00   \nCook_Inlet_75004400007996  75004400007996       2825727.00    282572700.00   \nCook_Inlet_75004400004850  75004400004850       1563074.00    156307400.00   \n...                                   ...              ...             ...   \nCook_Inlet_75004400010337  75004400010337        344724.00     34472400.00   \nCook_Inlet_75004400008879  75004400008879        233265.00     23326500.00   \nCook_Inlet_75004400004457  75004400004457       1026297.00    102629700.00   \nCook_Inlet_75004400005924  75004400005924       7720743.00    772074300.00   \nCook_Inlet_75004400004455  75004400004455       1755781.00    175578100.00   \n\n                           wtd_slope_MIN  wtd_slope_MAX  wtd_slope_RANGE  \\\ncat_ID_con                                                                 \nCook_Inlet_75004400005344           0.00          70.87            70.87   \nCook_Inlet_75004400011755           0.00          76.85            76.85   \nCook_Inlet_75004400010352           0.00          67.02            67.02   \nCook_Inlet_75004400007996           0.00          65.51            65.51   \nCook_Inlet_75004400004850           0.00          67.16            67.16   \n...                                  ...            ...              ...   \nCook_Inlet_75004400010337           0.00          35.96            35.96   \nCook_Inlet_75004400008879           0.00          30.82            30.82   \nCook_Inlet_75004400004457           0.00          59.70            59.70   \nCook_Inlet_75004400005924           0.00          65.72            65.72   \nCook_Inlet_75004400004455           0.00          59.42            59.42   \n\n                           wtd_slope_MEAN  wtd_slope_STD  wtd_slope_SUM  \\\ncat_ID_con                                                                \nCook_Inlet_75004400005344           25.38          13.03    11421329.52   \nCook_Inlet_75004400011755           24.02          15.07    25364061.16   \nCook_Inlet_75004400010352           26.18          10.23    14019013.53   \nCook_Inlet_75004400007996           22.75           9.80    64285852.09   \nCook_Inlet_75004400004850           18.79          10.87    29374364.09   \n...                                   ...            ...            ...   \nCook_Inlet_75004400010337            4.01           4.34     1380818.20   \nCook_Inlet_75004400008879            1.95           2.25      455340.88   \nCook_Inlet_75004400004457           16.52          10.14    16950039.30   \nCook_Inlet_75004400005924           11.12          10.59    85865495.84   \nCook_Inlet_75004400004455           19.17          10.86    33650778.59   \n\n                           wtd_slope_MEDIAN  wtd_slope_PCT90  \\\ncat_ID_con                                                     \nCook_Inlet_75004400005344             26.37            41.61   \nCook_Inlet_75004400011755             24.16            44.20   \nCook_Inlet_75004400010352             28.10            37.79   \nCook_Inlet_75004400007996             23.95            34.55   \nCook_Inlet_75004400004850             18.87            33.13   \n...                                     ...              ...   \nCook_Inlet_75004400010337              3.03             9.43   \nCook_Inlet_75004400008879              1.92             3.44   \nCook_Inlet_75004400004457             14.77            31.31   \nCook_Inlet_75004400005924              6.74            28.51   \nCook_Inlet_75004400004455             19.24            33.62   \n\n                           wtd_lake_area_sqm  wtd_lake_per  \\\ncat_ID_con                                                   \nCook_Inlet_75004400005344          202569.36          0.45   \nCook_Inlet_75004400011755         5262557.61          4.98   \nCook_Inlet_75004400010352           62396.23          0.12   \nCook_Inlet_75004400007996          201660.27          0.07   \nCook_Inlet_75004400004850          163496.46          0.10   \n...                                      ...           ...   \nCook_Inlet_75004400010337         8008947.94         23.23   \nCook_Inlet_75004400008879          213751.02          0.92   \nCook_Inlet_75004400004457           77577.74          0.08   \nCook_Inlet_75004400005924         8118783.98          1.05   \nCook_Inlet_75004400004455          456216.96          0.26   \n\n                           wtd_glacier_area_sqm  wtd_glacier_per  \\\ncat_ID_con                                                         \nCook_Inlet_75004400005344            1588148.84             3.53   \nCook_Inlet_75004400011755           47685961.13            45.16   \nCook_Inlet_75004400010352             153956.09             0.29   \nCook_Inlet_75004400007996              67318.94             0.02   \nCook_Inlet_75004400004850                   NaN              NaN   \n...                                         ...              ...   \nCook_Inlet_75004400010337                   NaN              NaN   \nCook_Inlet_75004400008879                   NaN              NaN   \nCook_Inlet_75004400004457                   NaN              NaN   \nCook_Inlet_75004400005924                   NaN              NaN   \nCook_Inlet_75004400004455                   NaN              NaN   \n\n                           wtd_north_per  \ncat_ID_con                                \nCook_Inlet_75004400005344          15.46  \nCook_Inlet_75004400011755          26.59  \nCook_Inlet_75004400010352          21.46  \nCook_Inlet_75004400007996          26.12  \nCook_Inlet_75004400004850          25.08  \n...                                  ...  \nCook_Inlet_75004400010337          17.78  \nCook_Inlet_75004400008879          15.22  \nCook_Inlet_75004400004457          29.44  \nCook_Inlet_75004400005924          25.82  \nCook_Inlet_75004400004455          27.77  \n\n[99 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat_ID_txt</th>\n      <th>wtd_slope_COUNT</th>\n      <th>wtd_slope_AREA</th>\n      <th>wtd_slope_MIN</th>\n      <th>wtd_slope_MAX</th>\n      <th>wtd_slope_RANGE</th>\n      <th>wtd_slope_MEAN</th>\n      <th>wtd_slope_STD</th>\n      <th>wtd_slope_SUM</th>\n      <th>wtd_slope_MEDIAN</th>\n      <th>wtd_slope_PCT90</th>\n      <th>wtd_lake_area_sqm</th>\n      <th>wtd_lake_per</th>\n      <th>wtd_glacier_area_sqm</th>\n      <th>wtd_glacier_per</th>\n      <th>wtd_north_per</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Cook_Inlet_75004400005344</th>\n      <td>75004400005344</td>\n      <td>450061.00</td>\n      <td>45006100.00</td>\n      <td>0.00</td>\n      <td>70.87</td>\n      <td>70.87</td>\n      <td>25.38</td>\n      <td>13.03</td>\n      <td>11421329.52</td>\n      <td>26.37</td>\n      <td>41.61</td>\n      <td>202569.36</td>\n      <td>0.45</td>\n      <td>1588148.84</td>\n      <td>3.53</td>\n      <td>15.46</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400011755</th>\n      <td>75004400011755</td>\n      <td>1055899.00</td>\n      <td>105589900.00</td>\n      <td>0.00</td>\n      <td>76.85</td>\n      <td>76.85</td>\n      <td>24.02</td>\n      <td>15.07</td>\n      <td>25364061.16</td>\n      <td>24.16</td>\n      <td>44.20</td>\n      <td>5262557.61</td>\n      <td>4.98</td>\n      <td>47685961.13</td>\n      <td>45.16</td>\n      <td>26.59</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010352</th>\n      <td>75004400010352</td>\n      <td>535581.00</td>\n      <td>53558100.00</td>\n      <td>0.00</td>\n      <td>67.02</td>\n      <td>67.02</td>\n      <td>26.18</td>\n      <td>10.23</td>\n      <td>14019013.53</td>\n      <td>28.10</td>\n      <td>37.79</td>\n      <td>62396.23</td>\n      <td>0.12</td>\n      <td>153956.09</td>\n      <td>0.29</td>\n      <td>21.46</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400007996</th>\n      <td>75004400007996</td>\n      <td>2825727.00</td>\n      <td>282572700.00</td>\n      <td>0.00</td>\n      <td>65.51</td>\n      <td>65.51</td>\n      <td>22.75</td>\n      <td>9.80</td>\n      <td>64285852.09</td>\n      <td>23.95</td>\n      <td>34.55</td>\n      <td>201660.27</td>\n      <td>0.07</td>\n      <td>67318.94</td>\n      <td>0.02</td>\n      <td>26.12</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004850</th>\n      <td>75004400004850</td>\n      <td>1563074.00</td>\n      <td>156307400.00</td>\n      <td>0.00</td>\n      <td>67.16</td>\n      <td>67.16</td>\n      <td>18.79</td>\n      <td>10.87</td>\n      <td>29374364.09</td>\n      <td>18.87</td>\n      <td>33.13</td>\n      <td>163496.46</td>\n      <td>0.10</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>25.08</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400010337</th>\n      <td>75004400010337</td>\n      <td>344724.00</td>\n      <td>34472400.00</td>\n      <td>0.00</td>\n      <td>35.96</td>\n      <td>35.96</td>\n      <td>4.01</td>\n      <td>4.34</td>\n      <td>1380818.20</td>\n      <td>3.03</td>\n      <td>9.43</td>\n      <td>8008947.94</td>\n      <td>23.23</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17.78</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400008879</th>\n      <td>75004400008879</td>\n      <td>233265.00</td>\n      <td>23326500.00</td>\n      <td>0.00</td>\n      <td>30.82</td>\n      <td>30.82</td>\n      <td>1.95</td>\n      <td>2.25</td>\n      <td>455340.88</td>\n      <td>1.92</td>\n      <td>3.44</td>\n      <td>213751.02</td>\n      <td>0.92</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>15.22</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004457</th>\n      <td>75004400004457</td>\n      <td>1026297.00</td>\n      <td>102629700.00</td>\n      <td>0.00</td>\n      <td>59.70</td>\n      <td>59.70</td>\n      <td>16.52</td>\n      <td>10.14</td>\n      <td>16950039.30</td>\n      <td>14.77</td>\n      <td>31.31</td>\n      <td>77577.74</td>\n      <td>0.08</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>29.44</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400005924</th>\n      <td>75004400005924</td>\n      <td>7720743.00</td>\n      <td>772074300.00</td>\n      <td>0.00</td>\n      <td>65.72</td>\n      <td>65.72</td>\n      <td>11.12</td>\n      <td>10.59</td>\n      <td>85865495.84</td>\n      <td>6.74</td>\n      <td>28.51</td>\n      <td>8118783.98</td>\n      <td>1.05</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>25.82</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004400004455</th>\n      <td>75004400004455</td>\n      <td>1755781.00</td>\n      <td>175578100.00</td>\n      <td>0.00</td>\n      <td>59.42</td>\n      <td>59.42</td>\n      <td>19.17</td>\n      <td>10.86</td>\n      <td>33650778.59</td>\n      <td>19.24</td>\n      <td>33.62</td>\n      <td>456216.96</td>\n      <td>0.26</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>27.77</td>\n    </tr>\n  </tbody>\n</table>\n<p>99 rows  16 columns</p>\n</div>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rename columns\n",
    "df_final.rename({'cat_ID_txt_x':'cat_ID_txt','region_x':'region'},axis=1, inplace=True)\n",
    "#Recalculate cat_ID\n",
    "df_final['cat_ID'] = df_final['cat_ID_txt'].astype(np.float64)\n",
    "df_final.index.is_unique\n",
    "# reorder cols\n",
    "df_final = df_final.reindex(columns=final_cols)\n",
    "df_final"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export all covariates dataframe to csv complete\n"
     ]
    }
   ],
   "source": [
    "# Export merged dataframe to csv\n",
    "huccov_csv_out = os.path.join(outdir,'AKSSF_NHDPlus_awcHuc12_19020302_Covariates.csv')\n",
    "df_final.to_csv(huccov_csv_out, encoding = 'utf-8')\n",
    "print('Export all covariates dataframe to csv complete')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}