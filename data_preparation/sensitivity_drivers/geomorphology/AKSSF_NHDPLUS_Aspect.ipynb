{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a id='top'></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Jump to bottom](#bottom)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Aspect Calculations\n",
    "\"Calculate aspect grid over the DEM used to create the flow network for each processing area (e.g. HUC8 in NHDPlus or\n",
    " region for BB, PWS, or Kodiak). We need the DEMs used for each flow direction grid or we can't calculate covariates at\n",
    " the watershed scale.\n",
    " * **aspect_rch = calculate mean aspect for stream reach (zonal statistics)**\n",
    " * **aspect_cat = calculate mean aspect over catchments (zonal statistics)**\n",
    " * **north_wtd = create 1/0 grid of north facing cells from aspect grid (north = aspects from 315-45 degrees), use\n",
    "  weighted flow accumulation to sum north facing cells, divide by flow accumulation grid to get % of north facing\n",
    "  cells in each watershed.\"**\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set environments and import modules"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20082021\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\geomorphology\n",
      "C:\\Users\\dwmerrigan\\AppData\\Local\\Programs\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\n"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "spref = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "today = datetime.datetime.now()\n",
    "# Make the time stamp.\n",
    "time_stamp = '{:%d%m%Y}'.format(today)\n",
    "print(time_stamp)\n",
    "\n",
    "path = os.getcwd()\n",
    "print (path)\n",
    "print (sys.base_exec_prefix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set variables and network data\n",
    "Can run individual hucs one at a time by manully entering in \"region\" list ex regions = ['1090201'] or set up to iterate using predefined lists for Cook Inlet or Copper River."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "#List of all Hucs in Cook Inlet\n",
    "ci_huc_list = ['19020202', '19020301','19020302','19020302','19020401','19020402','19020501','19020503','19020503',\n",
    " '19020504','19020505','19020601','19020602','19020800']#list of all cook inlet hucs to be processed (if we want to iterate)\n",
    "#List of all Hucs in Cook Inlet\n",
    "cr_huc_list = ['19020101','19020102','19020103','19020104']#list of all copper river hucs to be processed\n",
    "#Data folder for Cook Inlet\n",
    "ci_data_folder = r\"T:\\\\Aquatic\\\\AKSSF\\\\NHDPlus\\\\CookInlet_20201216\"#folder containing NHDPLUS data\n",
    "#Data folder for Copper River\n",
    "cr_data_folder = r\"T:\\\\Aquatic\\\\AKSSF\\\\NHDPlus\\\\CopperRiver_20210408\"#folder containing NHDPLUS data\n",
    "\n",
    "#Test Data Folder - hash out when running\n",
    "data_folder = r\"d:\\\\Basedata\\\\NHDPlus\"#Test\n",
    "roi = 'Test_' + str(time_stamp) + '_'\n",
    "\n",
    "# Unhash below if iterating Cook Inlet\n",
    "#roi = 'Cook_Inlet' + str(time_stamp) + \"_\"\n",
    "#region = ci_huc_list\n",
    "#data folder = ci_data_folder\n",
    "\n",
    "# Unhash below if iterating Copper River\n",
    "#roi = 'Copper_River_'+ str(time_stamp) + \"_\"\n",
    "#region = cr_huc_list\n",
    "#data folder = cr_data_folder\n",
    "\n",
    "#Manually set region/s in region list - Hash out if using predifined list above\n",
    "regions = [\"19020401\"] #8-digit HUC identifier for region to be processed (will be used as prefix for outputs)\n",
    "\n",
    "identifierfield = \"NHDPlusID\" #Name of field storing Catchment/RCA field in input stream layer ex. NHDPlus = \"NHDPLusID\", rca streams = \"reachid\"\n",
    "#Test network GDB\n",
    "networkgdb = r\"C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\AKSSF\\\\hydrography\\\\AKSSF_Hydrography.gdb\" #test output location\n",
    "\n",
    "#Network GDB to store outputs\n",
    "#networkgdb = r\"T:\\\\Aquatic\\\\AKSSF\\\\AKSSF_Hydrography.gdb\\\\Geomorphology\"#network location to save final copies"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create temporary working directory and geodatabase. Set temp path = to directory on local machine used to run operations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Folder already created... D:\\\\GIS_temp\\AKSSF_Working\n",
      "Output location already exists D:\\\\GIS_temp\\AKSSF_Working\\AKSSF_Working.gdb\n"
     ]
    }
   ],
   "source": [
    "temppath = r\"D:\\\\GIS_temp\"#Change to directory on local machine\n",
    "dirname = 'AKSSF_Working'\n",
    "tempgdbname = 'AKSSF_Working.gdb'\n",
    "temp_dir = os.path.join(temppath,dirname)\n",
    "if not arcpy.Exists(temp_dir):\n",
    "    os.makedirs(temp_dir)\n",
    "else:\n",
    "    print('Working Folder already created...', temp_dir)\n",
    "\n",
    "outcheck = os.path.join(temp_dir, tempgdbname)\n",
    "\n",
    "if arcpy.Exists(outcheck):\n",
    "    print ('Output location already exists', outcheck)\n",
    "    outgdb = outcheck\n",
    "if not arcpy.Exists(outcheck):\n",
    "    print('Creating output GDB')\n",
    "    tempgdb = arcpy.CreateFileGDB_management(temp_dir,tempgdbname)\n",
    "    print ('Output geodatabase created at', outcheck)\n",
    "    outgdb = tempgdb.getOutput(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Collect geodatabases in list that we can either iterate through or filter out using the region identifier\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "['d:\\\\Basedata\\\\NHDPlus\\\\NHDPLUS_H_19020401_HU8_GDB.gdb']"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import arcpy\n",
    "import os\n",
    "nhd_gdbs=[]\n",
    "arcpy.env.workspace = data_folder\n",
    "gdbs = arcpy.ListWorkspaces(\"*\", \"FileGDB\")\n",
    "for gdb in gdbs:\n",
    "    gdbpath = os.path.normpath(os.path.join(data_folder, gdb))\n",
    "    nhd_gdbs.append(gdbpath)\n",
    "\n",
    "nhd_gdbs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Collect watershed flowlines and catchments.\n",
    "Must copy NHDPlusID to new text field because zonal statistics as table does not allow 'double' type fields to be used\n",
    "for zone identification."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\\\GIS_temp\\AKSSF_Working\\AKSSF_Working.gdb\\NHDPlusCatchment_19020401\n",
      "\n",
      "D:\\\\GIS_temp\\AKSSF_Working\\AKSSF_Working.gdb\\NHDPlusFlowline_19020401\n",
      "\n",
      "d:\\Basedata\\NHDPlus\\NHDPLUS_H_19020401_HU8_GDB.gdb\\NHDPlus\\NHDPlusCatchment\n",
      "\n",
      "D:\\\\GIS_temp\\AKSSF_Working\\AKSSF_Working.gdb\\NHDPlusFlowline_19020401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.overwriteOutput = True\n",
    "catchments = []\n",
    "flowlines = []\n",
    "for region in regions:\n",
    "    for gdb in nhd_gdbs:\n",
    "        if region in gdb:\n",
    "            arcpy.env.workspace = gdb\n",
    "            datasets = arcpy.ListDatasets(feature_type='feature')\n",
    "            for ds in datasets:\n",
    "                for fc in arcpy.ListFeatureClasses(feature_dataset=ds):\n",
    "\n",
    "                    if fc == \"NHDPlusCatchment\": # Grab Catchments\n",
    "                        catchpath = os.path.join(arcpy.env.workspace, ds, fc)\n",
    "                        catchid= 'NHDPlusCatchment_'+str(region)\n",
    "                        catchcopy = arcpy.FeatureClassToFeatureClass_conversion(catchpath, outgdb, catchid)\n",
    "                        arcpy.AddField_management( catchcopy, field_name='NHDPlusID_txt', field_type='Text')\n",
    "                        arcpy.CalculateField_management( in_table=catchcopy, field = 'NHDPlusID_txt',\n",
    "                                                         expression_type='PYTHON3', expression='!NHDPlusID!')\n",
    "                        catchments.append(catchcopy)\n",
    "\n",
    "                        print (catchcopy)\n",
    "                        print (\"\")\n",
    "\n",
    "                    if fc == \"NHDFlowline\": # Grab Flowlines\n",
    "                        flowpath = os.path.join(arcpy.env.workspace, ds, fc)\n",
    "                        flowid= 'NHDPlusFlowline_'+str( region)\n",
    "                        flowcopy = arcpy.FeatureClassToFeatureClass_conversion( flowpath, outgdb, flowid)\n",
    "                        arcpy.AddField_management( flowcopy, field_name='NHDPlusID_txt', field_type='Text')\n",
    "                        arcpy.CalculateField_management(in_table=flowcopy,field = 'NHDPlusID_txt',\n",
    "                                                        expression_type='PYTHON3', expression='!NHDPlusID!')\n",
    "                        flowlines.append(flowcopy)\n",
    "\n",
    "                        print (flowcopy)\n",
    "                        print (\"\")\n",
    "\n",
    "print(catchpath)\n",
    "print (\"\")\n",
    "print(flowcopy)\n",
    "print (\"\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Collect watershed elevation, stream and flow accumulation rasters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d:\\\\\\\\Basedata\\\\\\\\NHDPlus\\\\HRNHDPlusRasters19020401', 'd:\\\\\\\\Basedata\\\\\\\\NHDPlus\\\\NHDPLUS_H_19020401_HU8_GDB.gdb', 'd:\\\\\\\\Basedata\\\\\\\\NHDPlus\\\\NHDPLUS_H_19020401_HU8_GDB.jpg', 'd:\\\\\\\\Basedata\\\\\\\\NHDPlus\\\\NHDPLUS_H_19020401_HU8_GDB.xml']\n",
      "['d:\\\\Basedata\\\\NHDPlus\\\\HRNHDPlusRasters19020401\\\\fac.tif']\n",
      "['d:\\\\Basedata\\\\NHDPlus\\\\HRNHDPlusRasters19020401\\\\swnet.tif']\n",
      "['d:\\\\Basedata\\\\NHDPlus\\\\HRNHDPlusRasters19020401\\\\elev_cm.tif']\n",
      "['d:\\\\Basedata\\\\NHDPlus\\\\HRNHDPlusRasters19020401\\\\fdr.tif']\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = data_folder\n",
    "elev_rasters = []\n",
    "stream_rasters = []\n",
    "flowacc_rasters = []\n",
    "flowdir_rasters = []\n",
    "raster_folders = arcpy.ListWorkspaces()\n",
    "for region in regions:\n",
    "    rasfol = \"Rasters\"+str(region)\n",
    "    for folder in raster_folders:\n",
    "        if rasfol in folder:\n",
    "            arcpy.env.workspace = folder\n",
    "            rasters = arcpy.ListRasters()\n",
    "            for raster in rasters:\n",
    "                if raster == 'elev_cm.tif': #Grab elevation raster\n",
    "                    elev_raspath = os.path.normpath(os.path.join(folder, raster))\n",
    "                    elev_rasters.append(elev_raspath)\n",
    "                if raster == 'swnet.tif': #Get stream raster\n",
    "                    stream_raspath = os.path.normpath(os.path.join(folder, raster))\n",
    "                    stream_rasters.append(stream_raspath)\n",
    "                if raster == 'fac.tif': #Get flow accumulation raster\n",
    "                    flowacc_raspath = os.path.normpath(os.path.join(folder, raster))\n",
    "                    flowacc_rasters.append(flowacc_raspath)\n",
    "                if raster == 'fdr.tif': #Get flow direction raster\n",
    "                    flowdir_raspath = os.path.normpath(os.path.join(folder, raster))\n",
    "                    flowdir_rasters.append(flowdir_raspath)\n",
    "print(raster_folders)\n",
    "print(flowacc_rasters)\n",
    "print(stream_rasters)\n",
    "print(elev_rasters)\n",
    "print(flowdir_rasters)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Merge data together\n",
    "UNK if we want to try merging all data together and then running all HUC8's together or run individually"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Insert code to Merge datasets together for entire AKKSSF Region of Interest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create Aspect raster"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aspect raster for 19020401 completed at 2021-08-20 10:11 (Elapsed time: 0:00:17)\n",
      "----------\n",
      "All Aspect Rasters(s) derived at 2021-08-20 10:11 (Elapsed time: 0:00:17)\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "text/plain": "[D:\\GIS_temp\\AKSSF_Working\\Aspect_19020401.tif]"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspect_rasters = []\n",
    "arcpy.env.snapRaster = elev_raspath\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = elev_raspath\n",
    "arcpy.env.workspace = temp_dir\n",
    "from arcpy.sa import Aspect\n",
    "\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "\n",
    "for region in regions:\n",
    "    print(\"\")\n",
    "    for elev_raster in elev_rasters:\n",
    "        if region in elev_raster:\n",
    "            # Start timing function\n",
    "            iteration_start = time.time()\n",
    "            asp_rasname = \"Aspect_\" + str(region)+'.tif'\n",
    "            asp_rast = Aspect(in_raster= elev_raspath, method='Planar')\n",
    "            asp_rast.save(os.path.join(temp_dir,asp_rasname))\n",
    "            aspect_rasters.append(asp_rast)\n",
    "            # End timing\n",
    "            iteration_end = time.time()\n",
    "            iteration_elapsed = int(iteration_end - iteration_start)\n",
    "            iteration_success_time = datetime.datetime.now()\n",
    "            # Report success\n",
    "            print(f'Aspect raster for {region} completed at {iteration_success_time.strftime(\"%Y-%m-%d %H:%M\")}'\n",
    "                  f' (Elapsed time: {datetime.timedelta(seconds=iteration_elapsed)})')\n",
    "            print('----------')\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "# Report success\n",
    "\n",
    "print(f'All Aspect Rasters(s) derived at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} (Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print('----------')\n",
    "\n",
    "aspect_rasters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculate mean catchment aspect"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Aspect table for catchments in 19020401 completed at 2021-08-20 10:42 (Elapsed time: 0:00:23)\n",
      "----------\n",
      "D:\\\\GIS_temp\\AKSSF_Working\\AKSSF_Working.gdb\\mn_cat_asp_19020401\n",
      "D:\\\\GIS_temp\\AKSSF_Working\\AKSSF_Working.gdb\\NHDPlusCatchment_19020401\n",
      "D:\\GIS_temp\\AKSSF_Working\\Aspect_19020401.tif\n",
      "----------\n",
      "Mean aspect for all catchments derived at 2021-08-20 10:42 (Elapsed time: 0:00:23)\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Result 'C:\\\\\\\\Users\\\\\\\\dwmerrigan\\\\\\\\Documents\\\\\\\\GitHub\\\\AKSSF\\\\\\\\hydrography\\\\\\\\AKSSF_Hydrography.gdb\\\\Test_20082021_cat_mn_asp'>",
      "text/html": "<h2>Output</h2>C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\AKSSF\\\\hydrography\\\\AKSSF_Hydrography.gdb\\Test_20082021_cat_mn_asp<h2>Messages</h2>Start Time: Friday, August 20, 2021 10:42:16<br/>Succeeded at Friday, August 20, 2021 10:42:16 (Elapsed Time: 0.46 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_cat_asp_tables = []\n",
    "arcpy.env.workspace = outgdb\n",
    "\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "\n",
    "for region in regions:\n",
    "    print(\"\")\n",
    "    # Start iter timing function\n",
    "    iteration_start = time.time()\n",
    "    for catchment in catchments:\n",
    "        if region in catchment:\n",
    "            for aspect_raster in aspect_rasters:\n",
    "                if region in aspect_raster:\n",
    "                    print(catchment)\n",
    "                    print(aspect_raster)\n",
    "    mn_cat_asp_name = \"mn_cat_asp_\" + str(region)\n",
    "    mn_cataspzon_table = arcpy.ia.ZonalStatisticsAsTable(catchment, \"NHDPlusID_txt\", aspect_raster,mn_cat_asp_name,\n",
    "                                                      \"DATA\", \"MEAN\", \"CURRENT_SLICE\", 90, \"AUTO_DETECT\")\n",
    "    mn_cat_asp_tables.append(mn_cataspzon_table)\n",
    "    # End iter timing\n",
    "    iteration_end = time.time()\n",
    "    iteration_elapsed = int(iteration_end - iteration_start)\n",
    "    iteration_success_time = datetime.datetime.now()\n",
    "    # Report success\n",
    "    print(f'Mean Aspect table for catchments in {region} completed at {iteration_success_time.strftime(\"%Y-%m-%d %H:%M\")}'\n",
    "          f' (Elapsed time: {datetime.timedelta(seconds=iteration_elapsed)})')\n",
    "    print('----------')\n",
    "    print(mn_cataspzon_table)\n",
    "    print(catchment)\n",
    "    print(aspect_raster)\n",
    "    print(\"----------\")\n",
    "\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "# Report success\n",
    "\n",
    "print(f'Mean aspect for all catchments derived at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} (Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print('----------')\n",
    "\n",
    "#Merge all catchment aspect tables together and save to network gdb\n",
    "arcpy.env.workspace = networkgdb\n",
    "cat_mn_asp_table_name = roi + \"cat_mn_asp\"\n",
    "cat_mn_asp = arcpy.management.Merge(mn_cat_asp_tables, cat_mn_asp_table_name)\n",
    "print(cat_mn_asp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculate mean stream reach aspect\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Aspect table for stream reaches in 19020401 completed at 2021-08-20 10:43 (Elapsed time: 0:00:06)\n",
      "D:\\\\GIS_temp\\AKSSF_Working\\AKSSF_Working.gdb\\mn_flow_asp_19020401\n",
      "D:\\\\GIS_temp\\AKSSF_Working\\AKSSF_Working.gdb\\NHDPlusFlowline_19020401\n",
      "D:\\GIS_temp\\AKSSF_Working\\Aspect_19020401.tif\n",
      "----------\n",
      "Mean aspect for all stream reaches derived at 2021-08-20 10:43 (Elapsed time: 0:00:06)\n",
      "----------\n",
      "C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\AKSSF\\\\hydrography\\\\AKSSF_Hydrography.gdb\\Test_20082021_str_mn_asp\n"
     ]
    }
   ],
   "source": [
    "mn_flow_asp_tables = []\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.workspace = outgdb\n",
    "\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "\n",
    "for region in regions:\n",
    "    # Start iter timing function\n",
    "    iteration_start = time.time()\n",
    "    for flowline in flowlines:\n",
    "        if region in flowline:\n",
    "            for aspect_raster in aspect_rasters:\n",
    "                if region in aspect_raster:\n",
    "                    print(flowline)\n",
    "                    print(aspect_raster)\n",
    "    mn_flow_asp_name = \"mn_flow_asp_\" + str(region)\n",
    "    mn_flowaspzon_table = arcpy.ia.ZonalStatisticsAsTable(flowline, \"NHDPlusID_txt\", aspect_raster,mn_flow_asp_name,\n",
    "                                                      \"DATA\", \"MEAN\", \"CURRENT_SLICE\", 90, \"AUTO_DETECT\")\n",
    "    mn_flow_asp_tables.append(mn_flowaspzon_table)\n",
    "    # End iter timing\n",
    "    iteration_end = time.time()\n",
    "    iteration_elapsed = int(iteration_end - iteration_start)\n",
    "    iteration_success_time = datetime.datetime.now()\n",
    "    # Report success\n",
    "    print(f'Mean Aspect table for stream reaches in {region} completed at {iteration_success_time.strftime(\"%Y-%m-%d %H:%M\")}'\n",
    "          f' (Elapsed time: {datetime.timedelta(seconds=iteration_elapsed)})')\n",
    "    print(mn_flowaspzon_table)\n",
    "    print(flowline)\n",
    "    print(aspect_raster)\n",
    "    print('----------')\n",
    "\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "# Report success\n",
    "\n",
    "print(f'Mean aspect for all stream reaches derived at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} (Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print('----------')\n",
    "\n",
    "#Merge all stream aspect tables together and save to network gdb\n",
    "arcpy.env.workspace = networkgdb\n",
    "str_mn_asp_table_name = roi + \"str_mn_asp\"\n",
    "str_mn_asp = arcpy.management.Merge(mn_flow_asp_tables, str_mn_asp_table_name)\n",
    "print(str_mn_asp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculate % North weighted"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Percent North Aspect for 19020401 completed at 2021-08-20 11:56 (Elapsed time: 0:00:20)\n",
      "Percent North Aspect for all regions completed at 2021-08-20 11:56 (Elapsed time: 0:00:20)\n",
      "----------\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "north_rasters = []\n",
    "north_wt_fdr_rasters = []\n",
    "per_nor_rasters = []\n",
    "\n",
    "arcpy.env.workspace = temp_dir\n",
    "\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "\n",
    "for region in regions:\n",
    "    # Start iter timing function\n",
    "    iteration_start = time.time()\n",
    "    for aspect_raster in aspect_rasters:\n",
    "        if region in aspect_raster:\n",
    "            norast_name='north_asp_' + str(region) + \".tif\"\n",
    "            norast_path = os.path.join(temp_dir, norast_name)\n",
    "            asp_rast = aspect_raster\n",
    "            per_nor_rast = arcpy.ia.RasterCalculator('Con((%s>=0)&(asp_rast<=45),1,Con((asp_rast<=360)&(asp_rast>=315),1,0))'); per_nor_rast.save(norast_path)\n",
    "\n",
    "            north_rasters.append(per_nor_rast)\n",
    "            # for flowdir_raster in flowdir_rasters:\n",
    "            #     if region in flowdir_raster:\n",
    "            #         nor_wt_rast_name = 'norwt_fdr_'+str(region)\n",
    "            #         nor_wt_fdr = arcpy.FlowAccumulation_ra(flowdir_raster, nor_wt_rast_name, nrast,\n",
    "            #                                                dataType = \"INTEGER\")\n",
    "            #         nor_wt_fdr.save(nor_wt_rast_name)\n",
    "            #         north_wt_fdr_rasters.append(nor_wt_fdr)\n",
    "            #         for flowacc_raster in flowacc_rasters:\n",
    "            #             if region in flowacc_raster:\n",
    "            #                 per_nor_ras_name = 'per_nor_fac_' + str(region)\n",
    "            #                 per_nor_ras = Raster(nor_wt_fdr) / Raster(flowacc_raster) * 100\n",
    "            #                 per_nor_ras.save(per_nor_ras_name)\n",
    "            #                 per_nor_rasters.append(per_nor_ras)\n",
    "    # End iter timing\n",
    "    iteration_end = time.time()\n",
    "    iteration_elapsed = int(iteration_end - iteration_start)\n",
    "    iteration_success_time = datetime.datetime.now()\n",
    "    # Report success\n",
    "    print(f' Percent North Aspect for {region} completed at {iteration_success_time.strftime(\"%Y-%m-%d %H:%M\")}'\n",
    "          f' (Elapsed time: {datetime.timedelta(seconds=iteration_elapsed)})')\n",
    "\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "# Report success\n",
    "\n",
    "print(f'Percent North Aspect for all regions completed at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} (Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print('----------')\n",
    "\n",
    "print(north_rasters)\n",
    "print(north_wt_fdr_rasters)\n",
    "print(per_nor_rasters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='bottom'></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8caab41e",
   "language": "python",
   "display_name": "PyCharm (AKSSF)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}