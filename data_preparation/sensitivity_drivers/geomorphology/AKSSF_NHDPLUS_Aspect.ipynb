{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a id='top'></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Aspect Calculations\n",
    "Calculate aspect grid over the DEM used to create the flow network for each processing area (e.g. HUC8 in NHDPlus or\n",
    " region for BB, PWS, or Kodiak). We need the DEMs used for each flow direction grid, or we can't calculate covariates at\n",
    " the watershed scale.\n",
    " * **aspect_rch = calculate mean aspect for stream reach (zonal statistics)**\n",
    " * **aspect_cat = calculate mean aspect over catchments (zonal statistics)**\n",
    " * **north_wtd = create 1/0 grid of north facing cells from aspect grid (north = aspects from 315-45 degrees), use\n",
    "  weighted flow accumulation to sum north facing cells, divide by flow accumulation grid to get % of north facing\n",
    "  cells in each watershed.**\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set environments and import modules"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01092021\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\geomorphology\n",
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\n"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "spref = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "today = datetime.datetime.now()\n",
    "# Make the time stamp.\n",
    "time_stamp = '{:%d%m%Y}'.format(today)\n",
    "print(time_stamp)\n",
    "\n",
    "path = os.getcwd()\n",
    "print (path)\n",
    "print (sys.base_exec_prefix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set variables and network data\n",
    "Can run individual hucs one at a time by manually entering in \"region\" list ex regions = ['19020201'] or set up to iterate using predefined lists for Cook Inlet or Copper River."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All variables set\n"
     ]
    }
   ],
   "source": [
    "#List of all Hucs in Cook Inlet\n",
    "ci_huc_list = ['19020202', '19020301','19020302','19020302','19020401','19020402','19020501','19020503','19020503',\n",
    " '19020504','19020505','19020601','19020602','19020800']#list of all cook inlet hucs to be processed (if we want to iterate)\n",
    "#List of all Hucs in Cook Inlet\n",
    "cr_huc_list = ['19020101','19020102','19020103','19020104']#list of all copper river hucs to be processed\n",
    "#Data folder for Cook Inlet\n",
    "ci_data_folder = r\"T:\\\\Aquatic\\\\AKSSF\\\\NHDPlus\\\\CookInlet_20201216\"#folder containing NHDPLUS data\n",
    "#Data folder for Copper River\n",
    "cr_data_folder = r\"T:\\\\Aquatic\\\\AKSSF\\\\NHDPlus\\\\CopperRiver_20210408\"#folder containing NHDPLUS data\n",
    "\n",
    "#Test Data Folder - hash out when running\n",
    "data_folder = r\"d:\\\\Basedata\\\\NHDPlus\"#Test\n",
    "roi = 'Test_' + str(time_stamp) + '_'\n",
    "\n",
    "# Unhash below if iterating Cook Inlet\n",
    "#roi = 'Cook_Inlet' + str(time_stamp) + \"_\"\n",
    "#region = ci_huc_list\n",
    "#data folder = ci_data_folder\n",
    "\n",
    "# Unhash below if iterating Copper River\n",
    "#roi = 'Copper_River_'+ str(time_stamp) + \"_\"\n",
    "#region = cr_huc_list\n",
    "#data folder = cr_data_folder\n",
    "\n",
    "#Manually set region/s in region list - Hash out if using predefined list above\n",
    "regions = [\"19020202\"] #8-digit HUC identifier for region to be processed (will be used as prefix for outputs)\n",
    "\n",
    "identifierfield = \"NHDPlusID\" #Name of field storing Catchment/RCA field in input stream layer ex. NHDPlus = \"NHDPLusID\", rca streams = \"reachid\"\n",
    "#Test network GDB\n",
    "networkgdb = r\"D:\\\\GIS_temp\\\\Temp_working.gdb\"#test output location\n",
    "\n",
    "#Network GDB to store outputs\n",
    "#networkgdb = r\"T:\\\\Aquatic\\\\AKSSF\\\\AKSSF_Hydrography.gdb\\\\Geomorphology\"#network location to save final copies\n",
    "print ('All variables set')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create temporary working directory and geodatabase. Set temp path = to directory on local machine used to run operations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Folder already created... D:\\\\GIS_temp\\AKSSF_Working\n",
      "Output location already exists D:\\\\GIS_temp\\AKSSF_Working\\AKSSF_Working.gdb\n"
     ]
    }
   ],
   "source": [
    "temppath = r\"D:\\\\GIS_temp\"#Change to directory on local machine\n",
    "dirname = 'AKSSF_Working'\n",
    "tempgdbname = 'AKSSF_Working.gdb'\n",
    "temp_dir = os.path.join(temppath,dirname)\n",
    "if not arcpy.Exists(temp_dir):\n",
    "    os.makedirs(temp_dir)\n",
    "else:\n",
    "    print('Working Folder already created...', temp_dir)\n",
    "\n",
    "outcheck = os.path.join(temp_dir, tempgdbname)\n",
    "\n",
    "if arcpy.Exists(outcheck):\n",
    "    print ('Output location already exists', outcheck)\n",
    "    outgdb = outcheck\n",
    "if not arcpy.Exists(outcheck):\n",
    "    print('Creating output GDB')\n",
    "    tempgdb = arcpy.CreateFileGDB_management(temp_dir,tempgdbname)\n",
    "    print ('Output geodatabase created at', outcheck)\n",
    "    outgdb = tempgdb.getOutput(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Collect geodatabases in list that we can either iterate through or filter out using the region identifier\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\n"
     ]
    },
    {
     "data": {
      "text/plain": "['d:\\\\Basedata\\\\NHDPlus\\\\NHDPLUS_H_19020202_HU8_GDB.gdb']"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import arcpy\n",
    "import os\n",
    "print(sys.base_prefix)\n",
    "nhd_gdbs=[]\n",
    "arcpy.env.workspace = data_folder\n",
    "gdbs = arcpy.ListWorkspaces(\"*\", \"FileGDB\")\n",
    "for gdb in gdbs:\n",
    "    gdbpath = os.path.normpath(os.path.join(data_folder, gdb))\n",
    "    nhd_gdbs.append(gdbpath)\n",
    "\n",
    "nhd_gdbs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Collect watershed flowlines and catchments.\n",
    "Must copy NHDPlusID to new text field because zonal statistics as table does not allow 'double' type fields to be used\n",
    "for zone identification."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\\\GIS_temp\\AKSSF_Working\\AKSSF_Working.gdb\\NHDPlusCatchment_19020202\n",
      "\n",
      "D:\\\\GIS_temp\\AKSSF_Working\\AKSSF_Working.gdb\\NHDPlusFlowline_19020202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.overwriteOutput = True\n",
    "catchments = []\n",
    "flowlines = []\n",
    "for region in regions:\n",
    "    for gdb in nhd_gdbs:\n",
    "        if region in gdb:\n",
    "            arcpy.env.workspace = gdb\n",
    "            datasets = arcpy.ListDatasets(feature_type='feature')\n",
    "            for ds in datasets:\n",
    "                for fc in arcpy.ListFeatureClasses(feature_dataset=ds):\n",
    "                    if fc == \"NHDPlusCatchment\": # Grab Catchments\n",
    "                        catchpath = os.path.normpath(os.path.join(arcpy.env.workspace, ds, fc))\n",
    "                        catchid= 'NHDPlusCatchment_'+str(region)\n",
    "                        catchcopy = arcpy.FeatureClassToFeatureClass_conversion(catchpath, outgdb, catchid)\n",
    "                        arcpy.AddField_management( catchcopy, field_name='NHDPlusID_txt', field_type='Text')\n",
    "                        arcpy.CalculateField_management( in_table=catchcopy, field = 'NHDPlusID_txt',\n",
    "                                                         expression_type='PYTHON3', expression='!NHDPlusID!')\n",
    "                        catchments.append(catchcopy)\n",
    "\n",
    "                        print (catchcopy)\n",
    "                        print (\"\")\n",
    "\n",
    "                    if fc == \"NHDFlowline\": # Grab Flowlines\n",
    "                        flowpath = os.path.normpath(os.path.join(arcpy.env.workspace, ds, fc))\n",
    "                        flowid= 'NHDPlusFlowline_'+str( region)\n",
    "                        flowcopy = arcpy.FeatureClassToFeatureClass_conversion( flowpath, outgdb, flowid)\n",
    "                        arcpy.AddField_management( flowcopy, field_name='NHDPlusID_txt', field_type='Text')\n",
    "                        arcpy.CalculateField_management(in_table=flowcopy,field = 'NHDPlusID_txt',\n",
    "                                                        expression_type='PYTHON3', expression='!NHDPlusID!')\n",
    "                        flowlines.append(flowcopy)\n",
    "\n",
    "                        print (flowcopy)\n",
    "                        print (\"\")\n",
    "        else:\n",
    "            print(region, \"not in directory\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Collect watershed elevation, stream and flow accumulation rasters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d:\\\\\\\\Basedata\\\\\\\\NHDPlus\\\\HRNHDPlusRasters19020202', 'd:\\\\\\\\Basedata\\\\\\\\NHDPlus\\\\NHDPLUS_H_19020202_HU8_GDB.gdb']\n",
      "['d:\\\\Basedata\\\\NHDPlus\\\\HRNHDPlusRasters19020202\\\\fac.tif']\n",
      "['d:\\\\Basedata\\\\NHDPlus\\\\HRNHDPlusRasters19020202\\\\swnet.tif']\n",
      "['d:\\\\Basedata\\\\NHDPlus\\\\HRNHDPlusRasters19020202\\\\elev_cm.tif']\n",
      "['d:\\\\Basedata\\\\NHDPlus\\\\HRNHDPlusRasters19020202\\\\fdr.tif']\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = data_folder\n",
    "elev_rasters = []\n",
    "stream_rasters = []\n",
    "flowacc_rasters = []\n",
    "flowdir_rasters = []\n",
    "raster_folders = arcpy.ListWorkspaces()\n",
    "for region in regions:\n",
    "    rasfol = \"Rasters\"+str(region)\n",
    "    for folder in raster_folders:\n",
    "        if rasfol in folder:\n",
    "            arcpy.env.workspace = folder\n",
    "            rasters = arcpy.ListRasters()\n",
    "            for raster in rasters:\n",
    "                if raster == 'elev_cm.tif': #Grab elevation raster\n",
    "                    elev_raspath = os.path.normpath(os.path.join(folder, raster))\n",
    "                    elev_rasters.append(elev_raspath)\n",
    "                if raster == 'swnet.tif': #Get stream raster\n",
    "                    stream_raspath = os.path.normpath(os.path.join(folder, raster))\n",
    "                    stream_rasters.append(stream_raspath)\n",
    "                if raster == 'fac.tif': #Get flow accumulation raster\n",
    "                    flowacc_raspath = os.path.normpath(os.path.join(folder, raster))\n",
    "                    flowacc_rasters.append(flowacc_raspath)\n",
    "                if raster == 'fdr.tif': #Get flow direction raster\n",
    "                    flowdir_raspath = os.path.normpath(os.path.join(folder, raster))\n",
    "                    flowdir_rasters.append(flowdir_raspath)\n",
    "print(raster_folders)\n",
    "print(flowacc_rasters)\n",
    "print(stream_rasters)\n",
    "print(elev_rasters)\n",
    "print(flowdir_rasters)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Merge data together\n",
    "UNK if we want to try merging all data together and then running all HUC8's together or run individually"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Insert code to Merge datasets together for entire AKKSSF Region of Interest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create Aspect raster"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aspect raster for 19020202 completed at 2021-09-01 14:01 (Elapsed time: 0:01:00)\n",
      "----------\n",
      "All Aspect Rasters(s) derived at 2021-09-01 14:01 (Elapsed time: 0:01:00)\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "text/plain": "[D:\\GIS_temp\\AKSSF_Working\\Aspect_19020202.tif]"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspect_rasters = []\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.workspace = temp_dir\n",
    "from arcpy.sa import Aspect\n",
    "\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "\n",
    "for region in regions:\n",
    "    print(\"\")\n",
    "    for elev_raster in elev_rasters:\n",
    "        if region in str(elev_raster):\n",
    "            # Set raster environments\n",
    "            arcpy.env.snapRaster = elev_raster\n",
    "            arcpy.env.outputCoordinateSystem = elev_raster\n",
    "            # Start timing function\n",
    "            iteration_start = time.time()\n",
    "            asp_rasname = \"Aspect_\" + str(region)+'.tif'\n",
    "            asp_rast = Aspect(in_raster= elev_raspath, method='Planar')\n",
    "            asp_rast.save(os.path.join(temp_dir,asp_rasname))\n",
    "            aspect_rasters.append(asp_rast)\n",
    "            # End timing\n",
    "            iteration_end = time.time()\n",
    "            iteration_elapsed = int(iteration_end - iteration_start)\n",
    "            iteration_success_time = datetime.datetime.now()\n",
    "            # Report success\n",
    "            print(f'Aspect raster for {region} completed at {iteration_success_time.strftime(\"%Y-%m-%d %H:%M\")}'\n",
    "                  f' (Elapsed time: {datetime.timedelta(seconds=iteration_elapsed)})')\n",
    "            print('----------')\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "# Report success\n",
    "\n",
    "print(f'All Aspect Rasters(s) derived at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} (Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print('----------')\n",
    "\n",
    "aspect_rasters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculate mean catchment aspect"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin mean catchment aspect calculations for 19020202 at 2021-09-01 16:18\n",
      "Catchment  D:\\\\GIS_temp\\AKSSF_Working\\AKSSF_Working.gdb\\NHDPlusCatchment_19020202  selected\n",
      "Mean aspect for all catchments derived at 2021-09-01 16:18 (Elapsed time: 0:00:00)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "mn_cat_asp_tables = []\n",
    "arcpy.env.workspace = outgdb\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "\n",
    "for region in regions:\n",
    "    iterprocessStartdt = datetime.datetime.now()\n",
    "    print(f'Begin mean catchment aspect calculations for {region} at {iterprocessStartdt.strftime(\"%Y-%m-%d %H:%M\")}')\n",
    "    # Start iter timing function\n",
    "    iteration_start = time.time()\n",
    "    for catchment in catchments:\n",
    "        if region in str(catchment):\n",
    "            print ('Catchment ', catchment, ' selected')\n",
    "        else:\n",
    "            print('Catchment for region ', region, ' not found.')\n",
    "            sys.exit(0)\n",
    "            for aspect_raster in aspect_rasters:\n",
    "                if region in str(aspect_raster):\n",
    "                    print(aspect_raster, ' selected')\n",
    "                    #asp_rast = Raster(aspect_raster)\n",
    "                    try:\n",
    "                        mn_cat_asp_name = \"mn_cat_asp_\" + str(region)\n",
    "                        mn_cataspzon_table = arcpy.ia.ZonalStatisticsAsTable(catchment, \"NHDPlusID_txt\", asp_rast,mn_cat_asp_name,\n",
    "                                                                             \"DATA\", \"MEAN\", \"CURRENT_SLICE\", 90, \"AUTO_DETECT\")\n",
    "                        mn_cat_asp_tables.append(mn_cataspzon_table)\n",
    "                        # End iter timing\n",
    "                        iteration_end = time.time()\n",
    "                        iteration_elapsed = int(iteration_end - iteration_start)\n",
    "                        iteration_success_time = datetime.datetime.now()\n",
    "                        # Report success\n",
    "                        print(f'Mean Aspect table for catchments in {region} completed at {iteration_success_time.strftime(\"%Y-%m-%d %H:%M\")}'\n",
    "                              f' (Elapsed time: {datetime.timedelta(seconds=iteration_elapsed)})')\n",
    "                        print('----------')\n",
    "                        print(mn_cataspzon_table)\n",
    "                        print(catchment)\n",
    "                        print(aspect_raster)\n",
    "                        print(\"----------\")\n",
    "                    except Exception:\n",
    "                        e = sys.exc_info()[1]\n",
    "                        print(e.args[0])\n",
    "                        arcpy.AddError(e.args[0])\n",
    "                else:\n",
    "                    print ('Aspect raster for region', region, ' not found.')\n",
    "                    sys.exit(0)\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "# Report success\n",
    "\n",
    "print(f'Mean aspect for all catchments derived at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} (Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print('----------')\n",
    "\n",
    "#Merge all catchment aspect tables together and save to network gdb\n",
    "# arcpy.env.workspace = networkgdb\n",
    "# cat_mn_asp_table_name = roi + \"cat_mn_asp\"\n",
    "# cat_mn_asp = arcpy.management.Merge(mn_cat_asp_tables, cat_mn_asp_table_name)\n",
    "# print(cat_mn_asp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculate mean stream reach aspect"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin mean stream reach aspect calculations for 19020202 at 2021-09-01 16:19\n",
      "Region 19020202 flowlines selected\n",
      "----------\n",
      "Mean aspect for all stream reaches derived at 2021-09-01 16:19 (Elapsed time: 0:00:00)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "mn_flow_asp_tables = []\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.workspace = outgdb\n",
    "\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "\n",
    "for region in regions:\n",
    "    # Start iter timing function\n",
    "    iteration_start = time.time()\n",
    "    iterprocessStartdt = datetime.datetime.now()\n",
    "    print(f'Begin mean stream reach aspect calculations for {region} at '\n",
    "          f'{iterprocessStartdt.strftime(\"%Y-%m-%d %H:%M\")}')\n",
    "    # Start iter timing function\n",
    "    for flowline in flowlines:\n",
    "        if region in str(flowline):\n",
    "            print(f'Region {region} flowlines selected')\n",
    "            print('----------')\n",
    "        else:\n",
    "            print(f'Raster dataset {aspect_raster} not in dataset for selection region')\n",
    "            sys.exit(0)\n",
    "            for aspect_raster in aspect_rasters:\n",
    "                if region in str(aspect_raster):\n",
    "                    print(f'Raster dataset {aspect_raster} selected')\n",
    "                    print('----------')\n",
    "                    mn_flow_asp_name = \"mn_flow_asp_\" + str(region)\n",
    "                    mn_flowaspzon_table = arcpy.ia.ZonalStatisticsAsTable(flowline, \"NHDPlusID_txt\", aspect_raster,\n",
    "                                                                          mn_flow_asp_name, \"DATA\", \"MEAN\",\n",
    "                                                                          \"CURRENT_SLICE\", 90, \"AUTO_DETECT\")\n",
    "                    mn_flow_asp_tables.append( mn_flowaspzon_table)\n",
    "                    # End iter timing\n",
    "                    iteration_end = time.time()\n",
    "                    iteration_elapsed = int(iteration_end - iteration_start)\n",
    "                    iteration_success_time = datetime.datetime.now()\n",
    "                    # Report success\n",
    "                    print(f'Mean Aspect table for stream reaches in {region} \\n completed at '\n",
    "                          f'{iteration_success_time.strftime(\"%Y-%m-%d %H:%M\")}'\n",
    "                          f' (Elapsed time: {datetime.timedelta(seconds=iteration_elapsed)}) & outputs stored \\n '\n",
    "                          f'in table {mn_flowaspzon_table}'\n",
    "                          )\n",
    "                    print('----------')\n",
    "                else:\n",
    "                    print (f'Region {region} flowlines not in dataset for selected region')\n",
    "                    sys.exit(0)\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "# Report success\n",
    "\n",
    "print(f'Mean aspect for all stream reaches derived at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} (Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print('----------')\n",
    "\n",
    "#Merge all stream aspect tables together and save to network gdb\n",
    "# arcpy.env.workspace = networkgdb\n",
    "# str_mn_asp_table_name = roi + \"str_mn_asp\"\n",
    "# str_mn_asp = arcpy.management.Merge(mn_flow_asp_tables, str_mn_asp_table_name)\n",
    "# print(str_mn_asp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculate % North weighted"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate % North weighted accumulation for 19020202 watersheds at 2021-09-01 16:40\n",
      "----------\n",
      " Percent North Aspect for 19020202 completed at 2021-09-01 16:41 (Elapsed time: 0:00:58)\n",
      "----------\n",
      "Process completed at 2021-09-01 16:41 (Elapsed time: 0:00:58)\n",
      "----------\n",
      "[D:\\GIS_temp\\AKSSF_Working\\north_asp_19020202.tif]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "north_rasters = []\n",
    "north_wt_fdr_rasters = []\n",
    "per_nor_rasters = []\n",
    "from arcpy.sa import *\n",
    "\n",
    "arcpy.env.workspace = temp_dir\n",
    "\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "from arcpy.sa import *\n",
    "\n",
    "for region in regions:\n",
    "    # Start iter timing function\n",
    "    iterprocessStartdt = datetime.datetime.now()\n",
    "    print(f'Calculate % North weighted accumulation for {region} watersheds at '\n",
    "          f'{iterprocessStartdt.strftime(\"%Y-%m-%d %H:%M\")}')\n",
    "    print('----------')\n",
    "    iteration_start = time.time()\n",
    "    for aspect_raster in aspect_rasters:\n",
    "        if region in str(aspect_raster):\n",
    "            try:\n",
    "                norast_name = 'north_asp_' + str(region) + \".tif\"\n",
    "                norast_path = os.path.normpath(os.path.join(temp_dir, norast_name))\n",
    "                asp_rast = Raster(aspect_raster)\n",
    "                per_nor_rast = Con((asp_rast>=0)&(asp_rast<=45),1,Con((asp_rast<=360)&(asp_rast>=315),1,0))\n",
    "                per_nor_rast.save(norast_path)\n",
    "                north_rasters.append(per_nor_rast)\n",
    "            except Exception:\n",
    "                e = sys.exc_info()[1]\n",
    "                print(e.args[0])\n",
    "                arcpy.AddError(e.args[0])\n",
    "        else:\n",
    "            print(f'Aspect raster for region {region} not in dataset')\n",
    "            sys.exit(0)\n",
    "            for flowdir_raster in flowdir_rasters:\n",
    "                if region in str(flowdir_raster):\n",
    "                    try:\n",
    "                        print(f'Create North weighted flow accumulation raster for region {region}')\n",
    "                        nor_wt_rast_name = 'norwt_fdr_'+str(region)\n",
    "                        nor_wt_fdr = arcpy.FlowAccumulation_ra(flowdir_raster, nor_wt_rast_name, nrast,\n",
    "                                                               dataType = \"INTEGER\")\n",
    "                        nor_wt_fdr.save(nor_wt_rast_name)\n",
    "                        north_wt_fdr_rasters.append(nor_wt_fdr)\n",
    "                    except:\n",
    "                        e = sys.exc_info()[1]\n",
    "                        print(e.args[0])\n",
    "                        arcpy.AddError(e.args[0])\n",
    "            else:\n",
    "                print(f'Flow Direction Raster for region {region} not in dataset')\n",
    "                sys.exit(0)\n",
    "                for flowacc_raster in flowacc_rasters:\n",
    "                    if region in flowacc_raster:\n",
    "                        try:\n",
    "                            print(f'Create percent north grid for region {region}')\n",
    "                            per_nor_ras_name = 'per_nor_fac_' + str(region)\n",
    "                            per_nor_ras = Raster(nor_wt_fdr) / Raster(flowacc_raster) * 100\n",
    "                            per_nor_ras.save(per_nor_ras_name)\n",
    "                            per_nor_rasters.append(per_nor_ras)\n",
    "                        except Exception:\n",
    "                            e = sys.exc_info()[1]\n",
    "                            print(e.args[0])\n",
    "                            arcpy.AddError(e.args[0])\n",
    "                    else:\n",
    "                        print(f'Flow Accumulation Raster for region {region} not in dataset')\n",
    "                        sys.exit(0)\n",
    "    # End iter timing\n",
    "    iteration_end = time.time()\n",
    "    iteration_elapsed = int(iteration_end - iteration_start)\n",
    "    iteration_success_time = datetime.datetime.now()\n",
    "    # Report success\n",
    "    print(f' Percent North Aspect for {region} completed at {iteration_success_time.strftime(\"%Y-%m-%d %H:%M\")}'\n",
    "          f' (Elapsed time: {datetime.timedelta(seconds=iteration_elapsed)})')\n",
    "    print('----------')\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "# Report success\n",
    "\n",
    "print(f'Process completed at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "      f'(Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print('----------')\n",
    "\n",
    "print(north_rasters)\n",
    "print(north_wt_fdr_rasters)\n",
    "print(per_nor_rasters)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}