{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Network/Flow Accumulation Covariates\n",
    "Covariates to be calculated along across the flow accumulation grids:\n",
    "1. fac_glacier_per - % Glacier along flow accumulation = glacier weighted fac/fac\n",
    "2. fac_lake_per\t- % Lake along flow accumulation = lake weighted fac/fac\n",
    "3. fac_mn_slope - Mean slope contributing area = slope weighted fac/fac\n",
    "4. fac_north_per - % North along flow accumulation\tnorth weighted fac/fac\n",
    "5. fac_wetland_per - % Wetland along flow accumulation = wetland weighted fac/fac\n",
    "6. fac_mn_lcld_xxxx - Mean day of year for LCLD (by year) along flow accumulation = mdy(year) weighted fac/fac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports complete\n",
      "sys paths ['C:\\\\Program Files\\\\JetBrains\\\\PyCharm 2020.2.3\\\\plugins\\\\python\\\\helpers-pro\\\\jupyter_debug', 'C:\\\\Program Files\\\\JetBrains\\\\PyCharm 2020.2.3\\\\plugins\\\\python\\\\helpers\\\\pydev', 'C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\AKSSF\\\\data_preparation\\\\sensitivity_drivers\\\\geomorphology', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\Resources\\\\ArcPy', 'C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\AKSSF', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\python37.zip', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\DLLs', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3', '', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\Resources\\\\ArcToolbox\\\\Scripts', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\Resources\\\\ArcToolBox\\\\Scripts', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\Resources\\\\ArcToolBox\\\\Scripts\\\\archydro', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\Resources\\\\ArcToolBox\\\\Scripts\\\\GRAIP', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\future-0.18.2-py3.7.egg', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\pytz-2020.1-py3.7.egg', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\pywin32_ctypes-0.2.0-py3.7.egg', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\pywin32security', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\sympy-1.5.1-py3.7.egg', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\dwmerrigan\\\\.ipython']\n",
      "ctime: Thu Jan 27 00:00:00 2022\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# Import modules\n",
    "import datetime\n",
    "import arcpy\n",
    "import sys\n",
    "import os\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "sr = arcpy.SpatialReference(3338)  #'NAD_1983_Alaska_Albers'\n",
    "arcpy.env.outputCoordinateSystem = sr\n",
    "\n",
    "print('imports complete')\n",
    "print(f'sys paths {sys.path}')\n",
    "today = datetime.date.today()\n",
    "print ('ctime:', today.ctime())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Collect datasets\n",
    "Store the following in a data dictionary using region as the key\n",
    "1. Flow accumulation grids\n",
    "2. Slope - Slope in degrees - float\n",
    "3. Wetlands - Binary raster data\n",
    "4. Lakes/Ponds - Feature class convert to raster and\n",
    "5. Glaciers - Binary raster data\n",
    "6. North - Binary raster data\n",
    "7. LCLD rasters - integertype\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Function to add key, value pairs to dictionary\n",
    "def append_value(dict_obj, key, value):\n",
    "    # Check if key exist in dict or not\n",
    "    if key in dict_obj:\n",
    "        # Key exist in dict.\n",
    "        # Check if type of value of key is list or not\n",
    "        if not isinstance(dict_obj[key], list):\n",
    "            # If type is not list then make it list\n",
    "            dict_obj[key] = [dict_obj[key]]\n",
    "        # Append the value in list\n",
    "        dict_obj[key].append(value)\n",
    "    else:\n",
    "        # As key is not in dict,\n",
    "        # so, add key-value pair\n",
    "        dict_obj[key] = value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\GIS\\\\AKSSF\\\\Bristol_Bay', 'D:\\\\GIS\\\\AKSSF\\\\Cook_Inlet', 'D:\\\\GIS\\\\AKSSF\\\\Copper_River', 'D:\\\\GIS\\\\AKSSF\\\\Kodiak', 'D:\\\\GIS\\\\AKSSF\\\\Prince_William_Sound']\n",
      "Scratch folder U:\\\\ca_Outputs already exists\n",
      "----------\n",
      "Scratch folder U:\\\\ca_Outputs\\\\ca_scratch.gdb already exists\n",
      "----------\n",
      "Scratch folder for Bristol_Bay already created at U:\\\\ca_Outputs\\Bristol_Bay_ca\n",
      "----------\n",
      "Scratch folder for Cook_Inlet already created at U:\\\\ca_Outputs\\Cook_Inlet_ca\n",
      "----------\n",
      "Scratch folder for Copper_River already created at U:\\\\ca_Outputs\\Copper_River_ca\n",
      "----------\n",
      "Scratch folder for Kodiak already created at U:\\\\ca_Outputs\\Kodiak_ca\n",
      "----------\n",
      "Scratch folder for Prince_William_Sound already created at U:\\\\ca_Outputs\\Prince_William_Sound_ca\n",
      "----------\n",
      "All scratch workspaces set\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'Bristol_Bay': 'U:\\\\\\\\ca_Outputs\\\\Bristol_Bay_ca',\n 'Cook_Inlet': 'U:\\\\\\\\ca_Outputs\\\\Cook_Inlet_ca',\n 'Copper_River': 'U:\\\\\\\\ca_Outputs\\\\Copper_River_ca',\n 'Kodiak': 'U:\\\\\\\\ca_Outputs\\\\Kodiak_ca',\n 'Prince_William_Sound': 'U:\\\\\\\\ca_Outputs\\\\Prince_William_Sound_ca'}"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "# Set data dir equal to directory containing the AKSSF regional sub-folders.\n",
    "data_dir = r\"D:\\\\GIS\\\\AKSSF\"\n",
    "arcpy.env.workspace = data_dir\n",
    "arcpy.env.overwriteOutput = True\n",
    "sr = arcpy.SpatialReference(3338)  #'NAD_1983_Alaska_Albers'\n",
    "arcpy.env.outputCoordinateSystem = sr\n",
    "# Create dictionary to store scratch workspaces\n",
    "scrDict = {}\n",
    "# Regions to be processed\n",
    "rList = ['Kodiak','Prince_William_Sound','Copper_River','Bristol_Bay','Cook_Inlet']\n",
    "regions = arcpy.ListWorkspaces(workspace_type=\"Folder\")\n",
    "regions = [os.path.normpath(r) for r in regions if os.path.basename(r) in rList]\n",
    "\n",
    "#working gdb to save intermediate outputs\n",
    "ca_scratchgdb = r\"U:\\\\ca_Outputs\\\\ca_scratch.gdb\"\n",
    "ca_scratchfol = r\"U:\\\\ca_Outputs\"\n",
    "print (regions)\n",
    "\n",
    "#Create rvbd scratch folders if they do not already exist\n",
    "import os, arcpy\n",
    "\n",
    "\n",
    "if not arcpy.Exists(ca_scratchfol):\n",
    "    os.mkdir(ca_scratchfol)\n",
    "    print(f'Creating scratch folder {ca_scratchfol}')\n",
    "else:\n",
    "    print(f'Scratch folder {ca_scratchfol} already exists')\n",
    "print('----------')\n",
    "\n",
    "if not arcpy.Exists(ca_scratchgdb):\n",
    "    arcpy.CreateFileGDB_management(ca_scratchfol,'ca_scratch.gdb')\n",
    "    print(f'Creating scratch gdb {ca_scratchgdb}')\n",
    "else:\n",
    "    print(f'Scratch folder {ca_scratchgdb} already exists')\n",
    "print('----------')\n",
    "\n",
    "#Create Regional output folders\n",
    "for region in regions:\n",
    "    rname = os.path.basename(region)\n",
    "    cascratchpath = os.path.join(ca_scratchfol, rname + '_ca')\n",
    "    append_value(scrDict,rname,cascratchpath)\n",
    "    if not arcpy.Exists(cascratchpath):\n",
    "        os.mkdir(cascratchpath)\n",
    "        print (f'{rname} does not have a scratch folder')\n",
    "        print (f'Creating contributing area scratch folder at  {cascratchpath}')\n",
    "    else:\n",
    "        print(f'Scratch folder for {rname} already created at {cascratchpath}')\n",
    "\n",
    "    print('----------')\n",
    "print(f'All scratch workspaces set')\n",
    "scrDict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Iterate through regions and pull out glacier polygons and nhd waterbodies and convert to raster.  Use elev raster as snap raster/mask for these processes\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set data dictionary and create/modify inputs as necessary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'regions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-30289b5dd1ab>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[0makssf_gdb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34mr'D:\\GIS\\AKSSF_land_met\\AKSSF_land_met.gdb'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[0mstart\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdatetime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdatetime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 21\u001B[1;33m \u001B[1;32mfor\u001B[0m \u001B[0mregion\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mregions\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     22\u001B[0m     \u001B[1;31m# Start iter timing function\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m     \u001B[0miteration_start\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'regions' is not defined"
     ]
    }
   ],
   "source": [
    "import arcpy, os, datetime, time\n",
    "from arcpy.sa import *\n",
    "arcpy.env.overwriteOutput = True\n",
    "sr = arcpy.SpatialReference(3338)  #'NAD_1983_Alaska_Albers'\n",
    "arcpy.env.outputCoordinateSystem = sr\n",
    "# set pp factor\n",
    "arcpy.env.parallelProcessingFactor = \"80%\"\n",
    "\n",
    "# Path to lakes data for regions without NHDPlus data\n",
    "sourcelakes = r\"D:\\\\Basedata\\\\NHD_H_Alaska_State_GDB.gdb\\\\Hydrography\\\\NHDWaterbody\"\n",
    "\n",
    "# List to store fac grids for data that need to be iterated on grid by grid basis (mdy LCLD)\n",
    "fdr_list = []\n",
    "fac_list = []\n",
    "\n",
    "caDict = {}\n",
    "\n",
    "# Walk through gdbs and set input data sets. Create necessary raster datasets if they do not already exist.\n",
    "akssf_gdb = r'D:\\GIS\\AKSSF_land_met\\AKSSF_land_met.gdb'\n",
    "start = datetime.datetime.now()\n",
    "for region in regions:\n",
    "    # Start iter timing function\n",
    "    iteration_start = time.time()\n",
    "    rname = os.path.basename(region)\n",
    "    print(rname)\n",
    "    arcpy.env.workspace = region\n",
    "    arcpy.env.snapRaster = os.path.join(region, 'fac.tif')\n",
    "    arcpy.env.cellSize = os.path.join(region, 'fac.tif')\n",
    "    arcpy.env.mask = os.path.join(region, 'fac.tif')\n",
    "    gdb = arcpy.ListWorkspaces(workspace_type='FileGDB')\n",
    "    outgdb = gdb[0]\n",
    "    walk = arcpy.da.Walk(region, topdown = True, datatype=['RasterDataset','FeatureClass'])\n",
    "    for dirpath, dirnames, filenames in walk:\n",
    "        for filename in filenames:\n",
    "            # Set glacier polygon fc\n",
    "            if 'glaciers' == filename:\n",
    "                glacfc_path = os.path.join(dirpath, filename)\n",
    "                append_value(caDict,rname,glacfc_path)\n",
    "\n",
    "            # Extract region buffer\n",
    "            elif 'region_buf' == filename:\n",
    "                rbuff_path = os.path.join(dirpath, filename)\n",
    "                append_value(caDict,rname,rbuff_path)\n",
    "\n",
    "            # Set watersheds - Dissolve watershed merge if not already created\n",
    "            elif 'wtds_merge' == filename:\n",
    "                wtdsource = os.path.join(dirpath, filename)\n",
    "                # Dissolve Watersheds - keep as single part\n",
    "                wtd_dis = os.path.join(outgdb,'wtds_dis')\n",
    "                append_value(caDict, rname, wtd_dis)\n",
    "                if not arcpy.Exists(os.path.join(outgdb,'wtds_dis')):\n",
    "                    print('Dissolving watersheds')\n",
    "                    arcpy.Dissolve_management(wtdsource,wtd_dis,None, None, \"SINGLE_PART\", \"DISSOLVE_LINES\")\n",
    "\n",
    "            # Extract cats intersect\n",
    "            elif 'cats_intersect' == filename:\n",
    "                cats_path = os.path.join(dirpath, filename)\n",
    "                append_value(caDict,rname,cats_path)\n",
    "\n",
    "            # Set stream polygon fc\n",
    "            elif 'streams_merge' == filename or 'NHDFlowline_merge' == filename:\n",
    "                strsource = os.path.join(dirpath, filename)\n",
    "                append_value(caDict,rname,strsource)\n",
    "\n",
    "            # Set merged watersheds dataset\n",
    "            elif 'wtds_merge' == filename:\n",
    "                wtdsource = os.path.join(dirpath, filename)\n",
    "                # Append watersheds to dictionary\n",
    "                append_value(caDict,rname,wtdsource)\n",
    "\n",
    "            # Set elev raster\n",
    "            elif 'elev.tif' == filename:\n",
    "                elev_path = os.path.join(dirpath, filename)\n",
    "                append_value(caDict,rname,elev_path)\n",
    "\n",
    "            # Set ca raster\n",
    "            elif 'fac.tif' == filename:\n",
    "                fac_path = os.path.join(dirpath, filename)\n",
    "                append_value(caDict,rname,fac_path)\n",
    "                fac_list.append(fac_path)\n",
    "\n",
    "            # Set flow direction raster\n",
    "            elif 'fdr.tif' == filename:\n",
    "                fdr_path = os.path.join(dirpath, filename)\n",
    "                append_value(caDict,rname,fdr_path)\n",
    "                fdr_list.append(fdr_path)\n",
    "\n",
    "            # Set slope raster\n",
    "            elif 'slope.tif' == filename:\n",
    "                slope_path = os.path.join(dirpath, filename)\n",
    "                append_value(caDict,rname,slope_path)\n",
    "\n",
    "            # Set North raster\n",
    "            elif 'north.tif' == filename:\n",
    "                nor_path = os.path.join(dirpath, filename)\n",
    "                append_value(caDict,rname,nor_path)\n",
    "\n",
    "            # Set wetland raster\n",
    "            elif 'wetlands.tif' == filename:\n",
    "                wras_path = os.path.join(dirpath, filename)\n",
    "                append_value(caDict,rname,wras_path)\n",
    "\n",
    "    # Check that waterbody feature class has been copied over to gdb, Originally never created for synthetic regions\n",
    "    lakefc_path = os.path.join(outgdb,'NHDWaterbody_merge')\n",
    "    if not arcpy.Exists(lakefc_path):\n",
    "        lakesubset = arcpy.SelectLayerByLocation_management(sourcelakes,'INTERSECT',rbuff_path,'','SUBSET_SELECTION')\n",
    "        print(f'{arcpy.GetCount_management(lakesubset)} Lake/ponds in {rname}...')\n",
    "        lakefc_path = arcpy.FeatureClassToFeatureClass_conversion(lakesubset, outgdb, 'NHDWaterbody_merge')\n",
    "    else:\n",
    "        print(f'Lake dataset {lakefc_path} set for {rname}')\n",
    "\n",
    "    # Check for lakes raster\n",
    "    lake_path = os.path.join(region, 'lakes.tif')\n",
    "    lakerast = os.path.join(region,'lakesras.tif')\n",
    "    if not arcpy.Exists(lake_path):\n",
    "        print('Lake raster not yet created')\n",
    "        lakeselect = arcpy.SelectLayerByAttribute_management(lakefc_path, 'NEW_SELECTION','FTYPE = 390')\n",
    "        print(f'{arcpy.GetCount_management(lakeselect)} Lake/ponds in source dataset...')\n",
    "        arcpy.PolygonToRaster_conversion(lakeselect,'FType',lakerast)\n",
    "        arcpy.ddd.Reclassify(lakerast, \"Value\", \"390 1;NODATA 0\", lake_path, \"DATA\")\n",
    "        append_value(caDict,rname,lake_path)\n",
    "    else:\n",
    "        print(f'Lakes raster {lake_path} already exists...')\n",
    "        append_value(caDict,rname,lake_path)\n",
    "\n",
    "    # Check for glacier raster\n",
    "    glac_path = os.path.join(region, 'glaciers.tif')\n",
    "    glacrast = os.path.join(region,'glacrast.tif')\n",
    "    if not arcpy.Exists(glac_path):\n",
    "        print('Glacier raster not yet created')\n",
    "        arcpy.PolygonToRaster_conversion(glacfc_path,'O1Region',glacrast)\n",
    "        arcpy.ddd.Reclassify(glacrast, \"Value\", \"1 1;NODATA 0\", glac_path, \"DATA\")\n",
    "        append_value(caDict,rname,glac_path)\n",
    "    else:\n",
    "        print(f'Glacier raster {glac_path} already...')\n",
    "        append_value(caDict,rname,glac_path)\n",
    "\n",
    "    print(f'Flow accumulation raster input = {fac_path} and exists = {arcpy.Exists(fac_path)}')\n",
    "    print(f'Flow direction raster input = {fdr_path} and exists = {arcpy.Exists(fdr_path)}')\n",
    "    print(f'Slope input = {slope_path} and exists = {arcpy.Exists(slope_path)}')\n",
    "    print(f'North raster input = {nor_path} and exists = {arcpy.Exists(nor_path)}')\n",
    "    print(f'Wetlands raster input = {wras_path} and exists = {arcpy.Exists(wras_path)}')\n",
    "    print(f'Lakes raster input = {lake_path} and exists = {arcpy.Exists(lake_path)}')\n",
    "    print(f'Glaciers raster input = {glac_path} and exists = {arcpy.Exists(glac_path)}')\n",
    "    print(f'Catchments input = {cats_path} and exists = {arcpy.Exists(cats_path)}')\n",
    "    print(f'Watersheds to process input = {wtd_dis} and exists = {arcpy.Exists(wtd_dis)}')\n",
    "\n",
    "\n",
    "    # Stop iteration timer\n",
    "    iteration_stop = time.time()\n",
    "    iter_time = int (iteration_stop - iteration_start)\n",
    "    print(f'Process time for {rname} complete - Elapsed time: ({datetime.timedelta(seconds=iter_time)})')\n",
    "    print('----------')\n",
    "# End timer\n",
    "stop = datetime.datetime.now()\n",
    "print(f'Process complete {stop-start}')\n",
    "print('----------')\n",
    "print('Data Dictionary created')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Begin Creating weighted fac grids\n",
    "\n",
    "Can these be run in parallel?\n",
    "\n",
    "Example from <a href = 'https://www.e-education.psu.edu/geog489/node/2282'>PSU sequential to multiprocessing</a> and <a href='https://www.esri.com/arcgis-blog/products/analytics/analytics/multiprocessing-with-arcgis-raster-analysis/#processing-a-workflow'>Esri talk</a>\n",
    "\n",
    "### Setup _very_ simple timing.\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "import arcpy\n",
    "from arcpy.sa import *\n",
    "\n",
    "import os\n",
    "import multiprocessing\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.workspace = r'C:\\489\\PSU_LiDAR'\n",
    "\n",
    "## If our rasters aren't in our filter list then drop them from our list.\n",
    "def filter_list(fileList,filterList):\n",
    "    return[i for i in fileList if any(j in i for j in filterList)]\n",
    "\n",
    "def worker(raster):\n",
    "    ## Note also for performance we're not saving any of the intermediate rasters - they will exist only in memory\n",
    "    ## Fill the DEM to remove any sinks\n",
    "    # This is the initial workspace but to prevent any file locking we'll create a scratch workspace\n",
    "    # just for this raster\n",
    "    arcpy.env.scratchWorkspace = os.path.join(arcpy.env.workspace,'f'+raster.replace(\".img\",\"\"))  # r'C:\\Users\\yourname\\PSU_LiDAR\\f'+raster.replace(\".img\",\"\")\n",
    "    ## and we'll check if that scratch folder exists and if not we'll create it.\n",
    "    if not os.path.exists(arcpy.env.scratchWorkspace):\n",
    "        os.makedirs(arcpy.env.scratchWorkspace)\n",
    "    try:\n",
    "        FilledRaster = Fill(raster)\n",
    "        ## Calculate the Flow Direction (how water runs across the surface)\n",
    "        FlowDirRaster = FlowDirection(FilledRaster)\n",
    "        ## Calculate the Flow Accumulation (where the water accumulates in the surface)\n",
    "        FlowAccRaster = FlowAccumulation(FlowDirRaster)\n",
    "        ## Convert the Flow Accumulation to a Stream Network\n",
    "        ## We're setting an arbitrary threshold of 100 cells flowing into another cell to set it as part of our stream\n",
    "        ## http://pro.arcgis.com/en/pro-app/tool-reference/spatial-analyst/identifying-stream-networks.htm\n",
    "        Streams = Con(FlowAccRaster,1,\"\",\"Value > 100\")\n",
    "        ## Convert the Raster Stream network to a feature class\n",
    "        output_Polyline = raster.replace(\".img\",\".shp\")\n",
    "        arcpy.CheckOutExtension(\"Spatial\")\n",
    "        arcpy.sa.StreamToFeature(Streams,FlowDirRaster,output_Polyline)\n",
    "        arcpy.CheckInExtension(\"Spatial\")\n",
    "    except:\n",
    "        print (\"Errors occured\")\n",
    "        print (arcpy.GetMessages())\n",
    "        arcpy.AddMessage (\"Errors occurred\")\n",
    "        arcpy.AddMessage(arcpy.GetMessages())\n",
    "\n",
    "def mp_handler():\n",
    "\n",
    "    # Ordinarily we would want all of the rasters I'm filtering by a small set for testing & efficiency\n",
    "    # I did this by manually looking up the tile index for the LiDAR and determining an area of interest\n",
    "    # tiles ending in 227, 228, 230, 231, 232, 233, 235, 236\n",
    "    wildCardList = set(['227','228','230','231','232','233','235','236'])\n",
    "\n",
    "    # Get a list of rasters in my folder\n",
    "    rasters = arcpy.ListRasters(\"*\")\n",
    "    new_rasters = filter_list(rasters,wildCardList)\n",
    "\n",
    "    # setup the multiprocessing pool with the number of cores in the current PC\n",
    "    with multiprocessing.Pool(multiprocessing.cpu_count()) as pool:\n",
    "        # use the map function of pool to call the function worker() and pass it a raster\n",
    "        pool.map(worker,new_rasters)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mp_handler()\n",
    "    # Output how long the process took.\n",
    "    arcpy.AddMessage(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    print (\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "### Extract input raster by mask and store in memory to reduce processing time - setting a mask will still process entire extent, just output those cells as No Data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. D:\\GIS\\AKSSF\\Bristol_Bay\\elev.tif\n",
      "1. D:\\GIS\\AKSSF\\Bristol_Bay\\fac.tif\n",
      "2. D:\\GIS\\AKSSF\\Bristol_Bay\\fdr.tif\n",
      "3. D:\\GIS\\AKSSF\\Bristol_Bay\\north.tif\n",
      "4. D:\\GIS\\AKSSF\\Bristol_Bay\\slope.tif\n",
      "5. D:\\GIS\\AKSSF\\Bristol_Bay\\wetlands.tif\n",
      "6. D:\\GIS\\AKSSF\\Bristol_Bay\\Bristol_Bay.gdb\\streams_merge\n",
      "7. D:\\GIS\\AKSSF\\Bristol_Bay\\Bristol_Bay.gdb\\region_buf\n",
      "8. D:\\GIS\\AKSSF\\Bristol_Bay\\Bristol_Bay.gdb\\glaciers\n",
      "9. D:\\GIS\\AKSSF\\Bristol_Bay\\Bristol_Bay.gdb\\wtds_merge\n",
      "10. D:\\GIS\\AKSSF\\Bristol_Bay\\lakes.tif\n",
      "11. D:\\GIS\\AKSSF\\Bristol_Bay\\glaciers.tif\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "for v in caDict['Bristol_Bay']:\n",
    "    print(f'{c}. {v}')\n",
    "    c+=1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cook_Inlet\n",
      "Begin Process (01-26-2022 12:03:57)\n",
      "\n",
      "Finish glacier weighted flow accumulation at 01-26-2022 13:14:03\n",
      "Finish percent glacier raster 01-26-2022 14:42:26\n",
      "Percent Glacier cover along FAC for Cook_Inlet complete - Elapsed time: (2:38:28)\n",
      "\n",
      "Begin Process (01-26-2022 14:42:26)\n",
      "\n",
      "Finish lake weighted flow accumulation at 01-26-2022 15:56:29\n",
      "Finish percent lake raster 01-26-2022 18:24:51\n",
      "Percent lake cover along FAC for Cook_Inlet complete - Elapsed time: (3:42:24)\n",
      "\n",
      "Begin Process (01-26-2022 18:24:51)\n",
      "\n",
      "Finish slope weighted flow accumulation at 01-26-2022 21:09:52\n",
      "Finish mean slope raster 01-27-2022 00:55:27\n",
      "Mean slope cover along FAC for Cook_Inlet complete - Elapsed time: (6:30:36)\n",
      "\n",
      "Begin Process (01-27-2022 00:55:27)\n",
      "\n",
      "Finish north weighted flow accumulation at 01-27-2022 04:08:03\n",
      "Finish percent north raster 01-27-2022 06:24:56\n",
      "Percent north cover along FAC for Cook_Inlet complete - Elapsed time: (5:29:29)\n",
      "\n",
      "Begin Process (01-27-2022 06:24:56)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Begin fac calculations\n",
    "import arcpy, os, datetime, time\n",
    "from time import strftime\n",
    "from arcpy.sa import *\n",
    "arcpy.env.overwriteOutput = True\n",
    "sr = arcpy.SpatialReference(3338)  #'NAD_1983_Alaska_Albers'\n",
    "arcpy.env.outputCoordinateSystem = sr\n",
    "# set pp factor\n",
    "arcpy.env.parallelProcessingFactor = \"100%\"\n",
    "\n",
    "# path to parent folder containing all lcld rasters - May run seperately\n",
    "lcldfol = r\"D:\\\\Basedata\\\\LCLD_rasters\"\n",
    "\n",
    "# Dictionary to fac covariate rasters to convert to table/merge\n",
    "facDict = {}\n",
    "\n",
    "# Walk through gdbs and set input data sets. Create necessary raster datasets if they do not already exist.\n",
    "akssf_gdb = r'D:\\GIS\\AKSSF_land_met\\AKSSF_land_met.gdb'\n",
    "process_start = time.time()\n",
    "\n",
    "# Test on pws first\n",
    "regions = [\"D:\\\\GIS\\\\AKSSF\\\\Cook_Inlet\"]\n",
    "\n",
    "# Set huc of interest to use as mask for testing\n",
    "test_huc = r\"U:\\\\ca_Outputs\\\\ca_scratch.gdb\\\\ci_test_huc12s\"\n",
    "\n",
    "for region in regions:\n",
    "    # Start iter timing function\n",
    "    iteration_start = time.time()\n",
    "\n",
    "    rname = os.path.basename(region)\n",
    "    print(rname)\n",
    "\n",
    "    # Set inputs from dictionaries\n",
    "    fac_in = caDict[rname][1]\n",
    "    fdr_in = caDict[rname][2]\n",
    "    north_in =caDict[rname][3]\n",
    "    slope_in = caDict[rname][4]\n",
    "    wetlands_in = caDict[rname][5]\n",
    "    glac_in = caDict[rname][11]\n",
    "    lake_in = caDict[rname][10]\n",
    "    scratch = scrDict[rname]\n",
    "\n",
    "    arcpy.env.workspace = region\n",
    "    arcpy.env.snapRaster = fdr_in\n",
    "    arcpy.env.cellSize = 10\n",
    "\n",
    "\n",
    "    # fac_glacier_per - % Glacier along flow accumulation = glacier weighted fac/fac\n",
    "    start = time.time()\n",
    "    print (f'Begin Process: Glacial weighting ({strftime(\"%m-%d-%Y %H:%M:%S\")})')\n",
    "    print (\"\")\n",
    "\n",
    "    glacw8name = \"glacw8fac.tif\"\n",
    "    glacpername = 'perglacfac.tif'\n",
    "    glacPer_path = os.path.join(scratch, glacpername)\n",
    "    append_value(facDict,rname,glacPer_path)\n",
    "    if not arcpy.Exists(glacPer_path):\n",
    "        glacw8flow = FlowAccumulation(fdr_in, glac_in, 'FLOAT', 'D8') # Create glacier weighted flow accumulation raster\n",
    "        glacw8flow.save(os.path.join(scratch,glacw8name)) # not sure if we need to save intermediates?\n",
    "        print(f'Finish glacier weighted flow accumulation at {strftime(\"%m-%d-%Y %H:%M:%S\")}')\n",
    "        glacPer = (glacw8flow/fac_in)\n",
    "        glacPer.save(os.path.join(scratch,glacpername))\n",
    "        print(f'Finish percent glacier raster {strftime(\"%m-%d-%Y %H:%M:%S\")}')\n",
    "    else:\n",
    "        print(f'Percent glacier along flow accumulation already created {glacPer_path}')\n",
    "    stop = time.time()\n",
    "    elapsed = int(stop - start)\n",
    "    print(f'Percent Glacier cover along FAC for {rname} complete - Elapsed time: ({datetime.timedelta(seconds=elapsed)})')\n",
    "    print (\"\")\n",
    "\n",
    "    # fac_lake_per - % Lake along flow accumulation = lake weighted fac/fac\n",
    "    start = time.time()\n",
    "    print (f'Begin Process: Lake Weighting ({strftime(\"%m-%d-%Y %H:%M:%S\")})')\n",
    "    print (\"\")\n",
    "\n",
    "    lakew8name = \"lakew8fac.tif\"\n",
    "    lakepername = 'perlakefac.tif'\n",
    "    lakePer_path = os.path.join(scratch, lakepername)\n",
    "    append_value(facDict,rname,lakePer_path)\n",
    "    if not arcpy.Exists(lakePer_path):\n",
    "        lakew8flow = FlowAccumulation(fdr_in, lake_in, 'FLOAT', 'D8') # Create lake weighted flow accumulation raster\n",
    "        lakew8flow.save(os.path.join(scratch,lakew8name)) #not sure if we need to save intermediates?\n",
    "        print(f'Finish lake weighted flow accumulation at {strftime(\"%m-%d-%Y %H:%M:%S\")}')\n",
    "        lakePer = (lakew8flow/fac_in)\n",
    "        lakePer.save(os.path.join(scratch,lakepername))\n",
    "        print(f'Finish percent lake raster {strftime(\"%m-%d-%Y %H:%M:%S\")}')\n",
    "    else:\n",
    "        print(f'Percent Lake cover along flow accumulation already created {lakePer_path}')\n",
    "    stop = time.time()\n",
    "    elapsed = int(stop - start)\n",
    "    print(f'Percent lake cover along FAC for {rname} complete - Elapsed time: ({datetime.timedelta(seconds=elapsed)})')\n",
    "    print (\"\")\n",
    "\n",
    "    # fac_mn_slope - Mean slope contributing area = slope weighted fac/fac\n",
    "    start = time.time()\n",
    "    print (f'Begin Process: Slope Weighting ({strftime(\"%m-%d-%Y %H:%M:%S\")})')\n",
    "    print (\"\")\n",
    "\n",
    "    slopew8name = \"slopew8fac.tif\"\n",
    "    slopepername = 'mnslopefac.tif'\n",
    "    slopePer_path = os.path.join(scratch, slopepername)\n",
    "    append_value(facDict,rname,slopePer_path)\n",
    "    if not arcpy.Exists(slopePer_path):\n",
    "        slopew8flow = FlowAccumulation(fdr_in, slope_in, 'FLOAT', 'D8') # Create slope weighted flow accumulation raster\n",
    "        slopew8flow.save(os.path.join(scratch,slopew8name)) #not sure if we need to save intermediates?\n",
    "        print(f'Finish slope weighted flow accumulation at {strftime(\"%m-%d-%Y %H:%M:%S\")}')\n",
    "        slopePer = (slopew8flow/fac_in)\n",
    "        slopePer.save(os.path.join(scratch,slopepername))\n",
    "        print(f'Finish mean slope raster {strftime(\"%m-%d-%Y %H:%M:%S\")}')\n",
    "    else:\n",
    "        print(f'Mean slope along flow accumulation already created {slopePer_path}')\n",
    "    stop = time.time()\n",
    "    elapsed = int(stop - start)\n",
    "    print(f'Mean slope cover along FAC for {rname} complete - Elapsed time: ({datetime.timedelta(seconds=elapsed)})')\n",
    "    print (\"\")\n",
    "\n",
    "    # fac_north_per - % North along flow accumulation north weighted fac/fac\n",
    "    start = time.time()\n",
    "    print (f'Begin Process: North Weighting ({strftime(\"%m-%d-%Y %H:%M:%S\")})')\n",
    "    print (\"\")\n",
    "\n",
    "    northw8name = \"northw8fac.tif\"\n",
    "    northpername = 'pernorthfac.tif'\n",
    "    northPer_path = os.path.join(scratch, northpername)\n",
    "    append_value(facDict,rname,northPer_path)\n",
    "    if not arcpy.Exists(northPer_path):\n",
    "        northw8flow = FlowAccumulation(fdr_in, north_in, 'FLOAT', 'D8') # Create north weighted flow accumulation raster\n",
    "        northw8flow.save(os.path.join(scratch,northw8name)) #not sure if we need to save intermediates?\n",
    "        print(f'Finish north weighted flow accumulation at {strftime(\"%m-%d-%Y %H:%M:%S\")}')\n",
    "        northPer = (northw8flow/fac_in)\n",
    "        northPer.save(os.path.join(scratch,northpername))\n",
    "        print(f'Finish percent north raster {strftime(\"%m-%d-%Y %H:%M:%S\")}')\n",
    "    else:\n",
    "        print(f'Percent north cover along flow accumulation already created {northPer_path}')\n",
    "    stop = time.time()\n",
    "    elapsed = int(stop - start)\n",
    "    print(f'Percent north cover along FAC for {rname} complete - Elapsed time: ({datetime.timedelta(seconds=elapsed)})')\n",
    "    print (\"\")\n",
    "\n",
    "    # fac_wetland_per - % Wetland along flow accumulation = wetland weighted fac/fac\n",
    "    start = time.time()\n",
    "    print (f'Begin Process: Wetland Weighting ({strftime(\"%m-%d-%Y %H:%M:%S\")})')\n",
    "    print (\"\")\n",
    "\n",
    "    wetlandsw8name = \"wetlandsw8fac.tif\"\n",
    "    wetlandspername = 'perwetlandsfac.tif'\n",
    "    wetlandsPer_path = os.path.join(scratch, wetlandspername)\n",
    "    append_value(facDict,rname,wetlandsPer_path)\n",
    "    if not arcpy.Exists(wetlandsPer_path):\n",
    "        wetlandsw8flow = FlowAccumulation(fdr_in, wetlands_in, 'FLOAT', 'D8') # Create wetlands weighted flow accumulation raster\n",
    "        wetlandsw8flow.save(os.path.join(scratch,wetlandsw8name)) #not sure if we need to save intermediates?\n",
    "        print(f'Finish wetlands weighted flow accumulation at {strftime(\"%m-%d-%Y %H:%M:%S\")}')\n",
    "        wetlandsPer = (wetlandsw8flow/fac_in)\n",
    "        wetlandsPer.save(os.path.join(scratch,wetlandspername))\n",
    "        print(f'Finish percent wetlands raster {strftime(\"%m-%d-%Y %H:%M:%S\")}')\n",
    "    else:\n",
    "        print(f'Percent wetlands cover along flow accumulation already created {wetlandsPer_path}')\n",
    "    stop = time.time()\n",
    "    elapsed = int(stop - start)\n",
    "    print(f'Percent wetlands cover along FAC for {rname} complete - Elapsed time: ({datetime.timedelta(seconds=elapsed)})')\n",
    "    print (\"\")\n",
    "\n",
    "    # fac_mn_lcld_xxxx - Mean day of year for LCLD (by year) along flow accumulation = mdy(year) weighted fac/fac\n",
    "\n",
    "    walk = arcpy.da.Walk(lcldfol, datatype = ['RasterDataset'])\n",
    "    for dirpath, dirnames, filenames in walk:\n",
    "        for filename in filenames:\n",
    "            start = time.time()\n",
    "            print (f'Begin Process: {filename} Weighting ({strftime(\"%m-%d-%Y %H:%M:%S\")})')\n",
    "            print (\"\")\n",
    "            print(filename[:-4])\n",
    "            rasname = filename[:-4]\n",
    "            lcldw8name =  rasname +\"_w8fac.tif\"\n",
    "            lcldpername = rasname + '_mnlcldfac.tif'\n",
    "            lcldPer_path = os.path.join(scratch, lcldpername)\n",
    "            lcld_in = os.path.join(dirpath,filename)\n",
    "            append_value(facDict,rname,lcldPer_path)\n",
    "            if not arcpy.Exists(lcldPer_path):\n",
    "                lcldw8flow = FlowAccumulation(fdr_in, lcld_in, 'FLOAT', 'D8') # Create lcld weighted flow accumulation raster\n",
    "                lcldw8flow.save(os.path.join(scratch,lcldw8name)) # not sure if we need to save intermediates?\n",
    "                print(f'Finish lcld weighted flow accumulation at {strftime(\"%m-%d-%Y %H:%M:%S\")}')\n",
    "                lcldPer = (lcldw8flow/fac_in)\n",
    "                lcldPer.save(os.path.join(scratch,lcldpername))\n",
    "                print(f'Finish mean lcld raster {strftime(\"%m-%d-%Y %H:%M:%S\")}')\n",
    "            else:\n",
    "                print(f'Mean lcld cover along flow accumulation already created {lcldPer_path}')\n",
    "            stop = time.time()\n",
    "            elapsed = int(stop - start)\n",
    "            print(f'{filename[:4]} Mean lcld along FAC for {rname} complete - Elapsed time: ({datetime.timedelta(seconds=elapsed)})')\n",
    "            print (\"\")\n",
    "    # End Timing\n",
    "    iter_time_stop = time.time()\n",
    "    iter_time = int(iter_time_stop-iteration_start)\n",
    "    print(f'{rname} fac weights complete - Elapsed time: ({datetime.timedelta(seconds=iter_time)})')\n",
    "    print('----------')\n",
    "process_stop = time.time()\n",
    "process_time = int(process_stop - process_start)\n",
    "print(f'All regions complete - Elapsed time: ({datetime.timedelta(seconds=process_time)})')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extract to outlets of catchments outlets for catchments with a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}