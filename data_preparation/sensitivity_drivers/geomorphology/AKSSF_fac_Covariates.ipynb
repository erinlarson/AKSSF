{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Network/Flow Accumulation Covariates\n",
    "Covariates to be calculated along across the flow accumulation grids:\n",
    "1. fac_glacier_per - % Glacier along flow accumulation = glacier weighted fac/fac\n",
    "2. fac_lake_per\t- % Lake along flow accumulation = lake weighted fac/fac\n",
    "3. fac_mn_slope - Mean slope contributing area = slope weighted fac/fac\n",
    "4. fac_north_per - % North along flow accumulation\tnorth weighted fac/fac\n",
    "5. fac_wetland_per - % Wetland along flow accumulation = wetland weighted fac/fac\n",
    "6. fac_mn_lcld_xxxx - Mean day of year for LCLD (by year) along flow accumulation = mdy(year) weighted fac/fac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports complete\n",
      "sys paths ['C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\Github\\\\AKSSF\\\\data_preparation\\\\sensitivity_drivers\\\\geomorphology', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\Resources\\\\ArcPy', 'C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\Github\\\\AKSSF', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\python37.zip', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\DLLs', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3', '', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\Resources\\\\ArcToolbox\\\\Scripts', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\future-0.18.2-py3.7.egg', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\pytz-2020.1-py3.7.egg', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\pywin32_ctypes-0.2.0-py3.7.egg', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\pywin32security', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\sympy-1.5.1-py3.7.egg', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\dwmerrigan\\\\.ipython']\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# Import modules\n",
    "import arcpy\n",
    "import sys\n",
    "import os\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "sr = arcpy.SpatialReference(3338)  #'NAD_1983_Alaska_Albers'\n",
    "arcpy.env.outputCoordinateSystem = sr\n",
    "\n",
    "print('imports complete')\n",
    "print(f'sys paths {sys.path}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Collect datasets\n",
    "Store the following in a data dictionary using region as the key\n",
    "1. Flow accumulation grids\n",
    "2. Slope - Slope in degrees - float\n",
    "3. Wetlands - Binary raster data\n",
    "4. Lakes/Ponds - Feature class convert to raster and\n",
    "5. Glaciers - Binary raster data\n",
    "6. North - Binary raster data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Function to add key, value pairs to dictionary\n",
    "def append_value(dict_obj, key, value):\n",
    "    # Check if key exist in dict or not\n",
    "    if key in dict_obj:\n",
    "        # Key exist in dict.\n",
    "        # Check if type of value of key is list or not\n",
    "        if not isinstance(dict_obj[key], list):\n",
    "            # If type is not list then make it list\n",
    "            dict_obj[key] = [dict_obj[key]]\n",
    "        # Append the value in list\n",
    "        dict_obj[key].append(value)\n",
    "    else:\n",
    "        # As key is not in dict,\n",
    "        # so, add key-value pair\n",
    "        dict_obj[key] = value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\GIS\\\\AKSSF\\\\Bristol_Bay', 'D:\\\\GIS\\\\AKSSF\\\\Cook_Inlet', 'D:\\\\GIS\\\\AKSSF\\\\Copper_River', 'D:\\\\GIS\\\\AKSSF\\\\Kodiak', 'D:\\\\GIS\\\\AKSSF\\\\Prince_William_Sound']\n",
      "Scratch folder D:\\\\ca_Outputs already exists\n",
      "----------\n",
      "Creating scratch gdb D:\\\\ca_Outputs\\\\ca_scratch.gdb\n",
      "----------\n",
      "Scratch folder for Bristol_Bay already created at D:\\\\ca_Outputs\\Bristol_Bay_RVBD\n",
      "----------\n",
      "Scratch folder for Cook_Inlet already created at D:\\\\ca_Outputs\\Cook_Inlet_RVBD\n",
      "----------\n",
      "Scratch folder for Copper_River already created at D:\\\\ca_Outputs\\Copper_River_RVBD\n",
      "----------\n",
      "Scratch folder for Kodiak already created at D:\\\\ca_Outputs\\Kodiak_RVBD\n",
      "----------\n",
      "Scratch folder for Prince_William_Sound already created at D:\\\\ca_Outputs\\Prince_William_Sound_RVBD\n",
      "----------\n",
      "All scratch workspaces set\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "# Set data dir equal to directory containing the AKSSF regional sub-folders.\n",
    "data_dir = r\"D:\\\\GIS\\\\AKSSF\"\n",
    "arcpy.env.workspace = data_dir\n",
    "arcpy.env.overwriteOutput = True\n",
    "sr = arcpy.SpatialReference(3338)  #'NAD_1983_Alaska_Albers'\n",
    "arcpy.env.outputCoordinateSystem = sr\n",
    "\n",
    "# Regions to be processed\n",
    "rList = ['Kodiak','Prince_William_Sound','Copper_River','Bristol_Bay','Cook_Inlet']\n",
    "regions = arcpy.ListWorkspaces(workspace_type=\"Folder\")\n",
    "regions = [os.path.normpath(r) for r in regions if os.path.basename(r) in rList]\n",
    "\n",
    "#working gdb to save intermediate outputs\n",
    "ca_scratchgdb = r\"D:\\\\ca_Outputs\\\\ca_scratch.gdb\"\n",
    "ca_scratchfol = r\"D:\\\\ca_Outputs\"\n",
    "print (regions)\n",
    "\n",
    "#Create rvbd scratch folders if they do not already exist\n",
    "import os, arcpy\n",
    "\n",
    "ca_scratchfol = r\"D:\\\\ca_Outputs\"\n",
    "if not arcpy.Exists(ca_scratchfol):\n",
    "    os.mkdir(ca_scratchfol)\n",
    "    print(f'Creating scratch folder {ca_scratchfol}')\n",
    "else:\n",
    "    print(f'Scratch folder {ca_scratchfol} already exists')\n",
    "print('----------')\n",
    "\n",
    "if not arcpy.Exists(ca_scratchgdb):\n",
    "    arcpy.CreateFileGDB_management(ca_scratchfol,'rvbd_scratch.gdb')\n",
    "    print(f'Creating scratch gdb {ca_scratchgdb}')\n",
    "else:\n",
    "    print(f'Scratch folder {ca_scratchgdb} already exists')\n",
    "print('----------')\n",
    "\n",
    "#Create Regional output folders\n",
    "for region in regions:\n",
    "    rname = os.path.basename(region)\n",
    "    cascratchpath = os.path.join(ca_scratchfol, rname + '_RVBD')\n",
    "    if not arcpy.Exists(cascratchpath):\n",
    "        os.mkdir(cascratchpath)\n",
    "        print (f'{rname} does not have a scratch folder')\n",
    "        print (f'Creating contributing area scratch folder at  {cascratchpath}')\n",
    "    else:\n",
    "        print(f'Scratch folder for {rname} already created at {cascratchpath}')\n",
    "\n",
    "    print('----------')\n",
    "print(f'All scratch workspaces set')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glacier raster exists at D:\\\\ca_Outputs\\glaciers_reclass.tif\n",
      "Lakes raster exists at D:\\\\ca_Outputs\\lakes_reclass.tif\n"
     ]
    }
   ],
   "source": [
    "import arcpy, os\n",
    "from arcpy.sa import *\n",
    "arcpy.env.overwriteOutput = True\n",
    "sr = arcpy.SpatialReference(3338)  #'NAD_1983_Alaska_Albers'\n",
    "arcpy.env.outputCoordinateSystem = sr\n",
    "# set pp factor\n",
    "arcpy.env.parallelProcessingFactor = \"80%\"\n",
    "\n",
    "# Create glacier and nhd lake pond rasters to extract from\n",
    "glacrast = os.path.join(ca_scratchfol,'glaciers.tif')\n",
    "lakerast = os.path.join(ca_scratchfol,'lakes.tif')\n",
    "lakereclass = os.path.join(ca_scratchfol,'lakes_reclass.tif')\n",
    "glacreclass = os.path.join(ca_scratchfol,'glaciers_reclass.tif')\n",
    "\n",
    "#list to store glacier fcs\n",
    "glaciers = []\n",
    "\n",
    "walk = arcpy.da.Walk(data_dir, topdown = True, datatype='FeatureClass')\n",
    "for dirpath, dirnames, filenames in walk:\n",
    "    for filename in filenames:\n",
    "        # Set glacier polygon fc\n",
    "        if 'glaciers' == filename:\n",
    "            glacfc_path = os.path.join(dirpath, filename)\n",
    "            glaciers.append(glacfc_path)\n",
    "\n",
    "# Merge glacier FCs in memory\n",
    "glac_merge = arcpy.Merge_management(glaciers,r'memory\\glac_merge')\n",
    "\n",
    "# Set NHD lakes ponds\n",
    "lakes = r\"T:\\\\Aquatic\\\\AKSSF\\\\AKSSF_Hydrography.gdb\\\\AKSSF_NHD_LakesPonds\"\n",
    "\n",
    "if not arcpy.Exists(glacreclass):\n",
    "    print(f'Creating glacier raster for entire region at {glacrast}')\n",
    "    arcpy.PolygonToRaster_conversion(glac_merge,'O1Region',glacrast)\n",
    "    arcpy.ddd.Reclassify(glacrast, \"Value\", \"1 1;NODATA 0\", glacreclass, \"DATA\")\n",
    "else:\n",
    "    print(f'Glacier raster exists at {glacreclass}')\n",
    "\n",
    "if not arcpy.Exists(lakereclass):\n",
    "    print(f'Creating Lakes raster for entire region at {lakerast}')\n",
    "    arcpy.PolygonToRaster_conversion(lakes,'FType',lakerast)\n",
    "    arcpy.ddd.Reclassify(lakerast, \"Value\", \"390 1;NODATA 0\", lakereclass, \"DATA\")\n",
    "else:\n",
    "    print(f'Lakes raster exists at {lakereclass}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set data dictionary and create/modify inputs as necessary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "['D:\\\\GIS\\\\AKSSF\\\\Bristol_Bay',\n 'D:\\\\GIS\\\\AKSSF\\\\Cook_Inlet',\n 'D:\\\\GIS\\\\AKSSF\\\\Copper_River',\n 'D:\\\\GIS\\\\AKSSF\\\\Kodiak',\n 'D:\\\\GIS\\\\AKSSF\\\\Prince_William_Sound']"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bristol_Bay\n",
      "Lake raster not yet created\n",
      "Glacier raster not yet created\n",
      "Flow accumulation raster input = D:\\GIS\\AKSSF\\Bristol_Bay\\fac.tif and exists = True\n",
      "Slope input = D:\\GIS\\AKSSF\\Bristol_Bay\\slope.tif and exists = True\n",
      "North raster input = D:\\GIS\\AKSSF\\Bristol_Bay\\north.tif and exists = True\n",
      "Wetlands raster input = D:\\GIS\\AKSSF\\Bristol_Bay\\wetlands.tif and exists = True\n",
      "Lakes raster input = D:\\GIS\\AKSSF\\Bristol_Bay\\lakes.tif and exists = True\n",
      "Glaciers raster input = D:\\GIS\\AKSSF\\Bristol_Bay\\glaciers.tif and exists = True\n",
      "----------\n",
      "Cook_Inlet\n",
      "Lake raster not yet created\n",
      "Glacier raster not yet created\n",
      "Flow accumulation raster input = D:\\GIS\\AKSSF\\Cook_Inlet\\fac.tif and exists = True\n",
      "Slope input = D:\\GIS\\AKSSF\\Cook_Inlet\\slope.tif and exists = True\n",
      "North raster input = D:\\GIS\\AKSSF\\Cook_Inlet\\north.tif and exists = True\n",
      "Wetlands raster input = D:\\GIS\\AKSSF\\Cook_Inlet\\wetlands.tif and exists = True\n",
      "Lakes raster input = D:\\GIS\\AKSSF\\Cook_Inlet\\lakes.tif and exists = True\n",
      "Glaciers raster input = D:\\GIS\\AKSSF\\Cook_Inlet\\glaciers.tif and exists = True\n",
      "----------\n",
      "Copper_River\n",
      "Lake raster not yet created\n",
      "Glacier raster not yet created\n",
      "Flow accumulation raster input = D:\\GIS\\AKSSF\\Copper_River\\fac.tif and exists = True\n",
      "Slope input = D:\\GIS\\AKSSF\\Copper_River\\slope.tif and exists = True\n",
      "North raster input = D:\\GIS\\AKSSF\\Copper_River\\north.tif and exists = True\n",
      "Wetlands raster input = D:\\GIS\\AKSSF\\Copper_River\\wetlands.tif and exists = True\n",
      "Lakes raster input = D:\\GIS\\AKSSF\\Copper_River\\lakes.tif and exists = True\n",
      "Glaciers raster input = D:\\GIS\\AKSSF\\Copper_River\\glaciers.tif and exists = True\n",
      "----------\n",
      "Kodiak\n",
      "Lake raster not yet created\n",
      "Glacier raster not yet created\n",
      "Flow accumulation raster input = D:\\GIS\\AKSSF\\Kodiak\\fac.tif and exists = True\n",
      "Slope input = D:\\GIS\\AKSSF\\Kodiak\\slope.tif and exists = True\n",
      "North raster input = D:\\GIS\\AKSSF\\Kodiak\\north.tif and exists = True\n",
      "Wetlands raster input = D:\\GIS\\AKSSF\\Kodiak\\wetlands.tif and exists = True\n",
      "Lakes raster input = D:\\GIS\\AKSSF\\Kodiak\\lakes.tif and exists = True\n",
      "Glaciers raster input = D:\\GIS\\AKSSF\\Kodiak\\glaciers.tif and exists = True\n",
      "----------\n",
      "Prince_William_Sound\n",
      "Lake raster not yet created\n",
      "Glacier raster not yet created\n",
      "Flow accumulation raster input = D:\\GIS\\AKSSF\\Prince_William_Sound\\fac.tif and exists = True\n",
      "Slope input = D:\\GIS\\AKSSF\\Prince_William_Sound\\slope.tif and exists = True\n",
      "North raster input = D:\\GIS\\AKSSF\\Prince_William_Sound\\north.tif and exists = True\n",
      "Wetlands raster input = D:\\GIS\\AKSSF\\Prince_William_Sound\\wetlands.tif and exists = True\n",
      "Lakes raster input = D:\\GIS\\AKSSF\\Prince_William_Sound\\lakes.tif and exists = True\n",
      "Glaciers raster input = D:\\GIS\\AKSSF\\Prince_William_Sound\\glaciers.tif and exists = True\n",
      "----------\n",
      "----------\n",
      "Data Dictionary created\n"
     ]
    }
   ],
   "source": [
    "from arcpy.sa import *\n",
    "\n",
    "lakereclass = os.path.join(ca_scratchfol,'lakes_reclass.tif')\n",
    "glacreclass = os.path.join(ca_scratchfol,'glaciers_reclass.tif')\n",
    "\n",
    "# List to store fac grids for data that need to be iterated on grid by grid basis (mdy LCLD)\n",
    "fac_list = []\n",
    "\n",
    "caDict = {}\n",
    "\n",
    "# Walk through gdbs and set input data sets. Create necessary raster datasets if they do not already exist.\n",
    "akssf_gdb = r'D:\\GIS\\AKSSF_land_met\\AKSSF_land_met.gdb'\n",
    "\n",
    "for region in regions:\n",
    "    rname = os.path.basename(region)\n",
    "    print(rname)\n",
    "    arcpy.env.workspace = region\n",
    "    arcpy.env.snapRaster = os.path.join(region, 'fac.tif')\n",
    "    arcpy.env.cellSize = os.path.join(region, 'fac.tif')\n",
    "    arcpy.env.mask = os.path.join(region, 'fac.tif')\n",
    "    gdb = arcpy.ListWorkspaces(workspace_type='FileGDB')\n",
    "    outgdb = gdb[0]\n",
    "    walk = arcpy.da.Walk(region, topdown = True, datatype=['RasterDataset','FeatureClass'])\n",
    "    for dirpath, dirnames, filenames in walk:\n",
    "        for filename in filenames:\n",
    "            # Set glacier polygon fc\n",
    "            if 'glaciers' == filename:\n",
    "                glacfc_path = os.path.join(dirpath, filename)\n",
    "                append_value(caDict,rname,glacfc_path)\n",
    "\n",
    "            # # Set stream polygon fc\n",
    "            # elif 'streams_merge' == filename or 'NHDFlowline_merge' == filename:\n",
    "            #     strsource = os.path.join(dirpath, filename)\n",
    "            #     append_value(caDict,rname,strsource)\n",
    "\n",
    "\n",
    "            # # Set merged watersheds dataset\n",
    "            # elif 'wtds_merge' == filename:\n",
    "            #     wtdsource = os.path.join(dirpath, filename)\n",
    "            #     # Dissolve Watersheds - keep as single part\n",
    "            #     wtd_dis = os.path.join(outgdb,rname + '_wtd_dis')\n",
    "            #     if not arcpy.Exists(os.path.join(outgdb,rname + '_wtd_dis')):\n",
    "            #         arcpy.Dissolve_management(wtdsource,wtd_dis,None, None, \"SINGLE_PART\", \"DISSOLVE_LINES\")\n",
    "            #         # Append dissolved watersheds to Dictionary to use as input for rvbd tool\n",
    "            #     append_value(caDict,rname,wtd_dis)\n",
    "\n",
    "            # # Set elev raster\n",
    "            # elif 'elev.tif' == filename:\n",
    "            #     elev_path = os.path.join(dirpath, filename)\n",
    "            #     append_value(caDict,rname,elev_path)\n",
    "\n",
    "            # Set ca raster\n",
    "            elif 'fac.tif' == filename:\n",
    "                fac_path = os.path.join(dirpath, filename)\n",
    "                append_value(caDict,rname,fac_path)\n",
    "                fac_list.append(fac_path)\n",
    "\n",
    "            # Set slope raster\n",
    "            elif 'slope.tif' == filename:\n",
    "                slope_path = os.path.join(dirpath, filename)\n",
    "                append_value(caDict,rname,slope_path)\n",
    "\n",
    "            # Set North raster\n",
    "            elif 'north.tif' == filename:\n",
    "                nor_path = os.path.join(dirpath, filename)\n",
    "                append_value(caDict,rname,nor_path)\n",
    "\n",
    "            # Set wetland raster\n",
    "            elif 'wetlands.tif' == filename:\n",
    "                wras_path = os.path.join(dirpath, filename)\n",
    "                append_value(caDict,rname,wras_path)\n",
    "\n",
    "    # Check for lakes raster\n",
    "    lake_path = os.path.join(region, 'lakes.tif')\n",
    "    if not arcpy.Exists(lake_path):\n",
    "        print('Lake raster not yet created')\n",
    "        lake_mask = arcpy.sa.ExtractByMask(lakereclass, fac_path)\n",
    "        lake_mask.save(lake_path)\n",
    "    else:\n",
    "        print(f'Lake raster {lake_path} already created...')\n",
    "\n",
    "    # Check for glacier raster\n",
    "    glac_path = os.path.join(region, 'glaciers.tif')\n",
    "    if not arcpy.Exists(os.path.join(region, 'glaciers.tif')):\n",
    "        print('Glacier raster not yet created')\n",
    "        glacier_mask = arcpy.sa.ExtractByMask(glacreclass, fac_path)\n",
    "        glacier_mask.save(glac_path)\n",
    "    else:\n",
    "        print(f'Glacier raster {glac_path} already created...')\n",
    "\n",
    "    print(f'Flow accumulation raster input = {fac_path} and exists = {arcpy.Exists(fac_path)}')\n",
    "    print(f'Slope input = {slope_path} and exists = {arcpy.Exists(slope_path)}')\n",
    "    print(f'North raster input = {nor_path} and exists = {arcpy.Exists(nor_path)}')\n",
    "    print(f'Wetlands raster input = {wras_path} and exists = {arcpy.Exists(wras_path)}')\n",
    "    print(f'Lakes raster input = {lake_path} and exists = {arcpy.Exists(lake_path)}')\n",
    "    print(f'Glaciers raster input = {glac_path} and exists = {arcpy.Exists(glac_path)}')\n",
    "    print('----------')\n",
    "print('----------')\n",
    "print('Data Dictionary created')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Begin Creating weighted fac grids\n",
    "Can these be run in parallel?\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}