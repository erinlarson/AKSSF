{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Can follow some code in timm's dem merging function.\n",
    "https://github.com/accs-uaa/beringian-vegetation/blob/master/package_GeospatialProcessing/mergeElevationTiles.py\n",
    "\n",
    "Recommended workflow for geoprocessing:\n",
    "- import arcpy\n",
    "- set environments\n",
    "- create lists of gis objects\n",
    "- iterate through list elements\n",
    "- execute geoprocessing tools\n",
    "\n",
    "Geoprocessing steps in this script\n",
    "1. create a set of folders and gdb for each region under a master AKSSF folder\n",
    "2. loop through regions and grids or feature classes (e.g. catchments or flowlines)\n",
    "3. merge grids or feature classes\n",
    "4. save in folder/gdb with consistent name (e.g. fac_merge)\n",
    "\n",
    "These seamed grids will enable us to use zonal statistics with the selected catchments\n",
    "and watersheds to get our environmental variables for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# step 1\n",
    "# Create folders for storing outputs\n",
    "\n",
    "#import modules\n",
    "import os\n",
    "import arcpy\n",
    "\n",
    "#user inputs\n",
    "baseFolder = \"W:\\\\GIS\\\\\"\n",
    "projectName = \"AKSSF\"\n",
    "\n",
    "#define folder paths\n",
    "ciFolder = baseFolder + \"\\\\\" + projectName + \"\\\\\"+ \"Cook_Inlet\"\n",
    "pwsFolder = baseFolder + \"\\\\\" + projectName + \"\\\\\"+ \"Prince_William_Sound\"\n",
    "bbFolder = baseFolder + \"\\\\\" + projectName + \"\\\\\"+ \"Bristol_Bay\"\n",
    "crFolder = baseFolder + \"\\\\\" + projectName + \"\\\\\"+ \"Copper_River\"\n",
    "kodFolder = baseFolder + \"\\\\\" + projectName + \"\\\\\"+ \"Kodiak\"\n",
    "\n",
    "#create list of folder paths\n",
    "folders = [ciFolder, pwsFolder, bbFolder, crFolder, kodFolder]\n",
    "\n",
    "#check if project folder exists\n",
    "if not os.path.exists(baseFolder + projectName):\n",
    "    #Create folder if it does not exist\n",
    "    for folder in folders:\n",
    "        os.makedirs(folder)\n",
    "        print(\"Created: \" + folder)\n",
    "else:\n",
    "    #if project folder exists, print error message\n",
    "    print (projectName + \" exists. Please provide a new project name.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# step 2\n",
    "# merge catchments and vaa tables\n",
    "#This code chunk is for NHDPlus regions -- Cook Inlet and Copper River\n",
    "\n",
    "import arcpy\n",
    "import os\n",
    "\n",
    "baseFolder = \"W:\\\\GIS\\\\\"\n",
    "region = \"Copper_River\"\n",
    "\n",
    "#NHD folders\n",
    "ciNHD = baseFolder + \"NHDPlus\\\\CookInlet_20201216\"\n",
    "crNHD = baseFolder + \"NHDPlus\\\\CopperRiver_20210408\"\n",
    "\n",
    "arcpy.env.workspace = crNHD\n",
    "gdbs = arcpy.ListWorkspaces('NHDPLUS*','FileGDB')\n",
    "print(gdbs)\n",
    "\n",
    "Cats = []\n",
    "VAA = []\n",
    "for gdb in gdbs:\n",
    "    arcpy.env.workspace = gdb\n",
    "    catpath = os.path.join(arcpy.env.workspace, \"NHDPlus\\\\NHDPlusCatchment\")\n",
    "    Cats.append(catpath)\n",
    "    vaapath = os.path.join(arcpy.env.workspace, \"NHDPlusFlowlineVAA\")\n",
    "    VAA.append(vaapath)\n",
    "\n",
    "arcpy.CreateFileGDB_management(r\"W:/GIS/AKSSF/\" + region, region + \".gdb\")\n",
    "arcpy.env.workspace =  r\"W:/GIS/AKSSF/\" + region + \"//\" + region + \".gdb\"\n",
    "arcpy.env.outputCoordinateSystem = arcpy.Describe(Cats[1]).spatialReference\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "arcpy.management.Merge(Cats, r\"W:/GIS/AKSSF/\" + region + \"//\" + region + \".gdb/cats_merge\")\n",
    "arcpy.management.Merge(VAA, r\"W:/GIS/AKSSF/\" + region + \"//\" + region + \".gdb/vaa_merge\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Merge catchments and streams for Bristol Bay\n",
    "\n",
    "This code chunk is for Bristol Bay, which had several processing units created\n",
    "with synthetic networks from TauDEM. The gridcodes all start from 1 so are not unique\n",
    "when combining the different VPUS. To create unique IDs across the VPUs,\n",
    "need to make a new catID with a prefix for each VPU: 10, 20, 30, 40, 50.\n",
    "Note that gridcode = LINKNO in the stream reach feature class.\n",
    "Also for the streams fc that we are using to create watersheds, the upstream\n",
    "links must be fixed so they are unique as well.\n",
    "\n",
    "For Kodiak and Prince William Sound, can just copy over catchments and streams since\n",
    "only one feature class for each."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eg\n",
      "La\n",
      "Na\n",
      "Nu\n",
      "To\n",
      "W:\\GIS\\AKSSF\\AKSSF_Hydrography.gdb\\TauDEM_Outputs\\Stream_Network_Egegik_stream_reach\n",
      "Eg\n",
      "W:\\GIS\\AKSSF\\AKSSF_Hydrography.gdb\\TauDEM_Outputs\\Stream_Network_Naknek_stream_reach\n",
      "Na\n",
      "W:\\GIS\\AKSSF\\AKSSF_Hydrography.gdb\\TauDEM_Outputs\\Stream_Network_Nushagak_stream_reach\n",
      "Nu\n",
      "W:\\GIS\\AKSSF\\AKSSF_Hydrography.gdb\\TauDEM_Outputs\\Stream_Network_Togiak_stream_reach\n",
      "To\n",
      "W:\\GIS\\AKSSF\\AKSSF_Hydrography.gdb\\TauDEM_Outputs\\Stream_Network_Lakes_stream_reach\n",
      "La\n",
      "Catchment feature classes to be merged: \n",
      "['W:\\\\GIS\\\\AKSSF\\\\AKSSF_Hydrography.gdb\\\\TauDEM_Outputs\\\\Catchments_Egegik_diss', 'W:\\\\GIS\\\\AKSSF\\\\AKSSF_Hydrography.gdb\\\\TauDEM_Outputs\\\\Catchments_Lakes_diss', 'W:\\\\GIS\\\\AKSSF\\\\AKSSF_Hydrography.gdb\\\\TauDEM_Outputs\\\\Catchments_Naknek_diss', 'W:\\\\GIS\\\\AKSSF\\\\AKSSF_Hydrography.gdb\\\\TauDEM_Outputs\\\\Catchments_Nushagak_diss', 'W:\\\\GIS\\\\AKSSF\\\\AKSSF_Hydrography.gdb\\\\TauDEM_Outputs\\\\Catchments_Togiak_diss']\n",
      "Stream feature classes to be merged: \n",
      "['W:\\\\GIS\\\\AKSSF\\\\AKSSF_Hydrography.gdb\\\\TauDEM_Outputs\\\\Stream_Network_Egegik_stream_reach', 'W:\\\\GIS\\\\AKSSF\\\\AKSSF_Hydrography.gdb\\\\TauDEM_Outputs\\\\Stream_Network_Naknek_stream_reach', 'W:\\\\GIS\\\\AKSSF\\\\AKSSF_Hydrography.gdb\\\\TauDEM_Outputs\\\\Stream_Network_Nushagak_stream_reach', 'W:\\\\GIS\\\\AKSSF\\\\AKSSF_Hydrography.gdb\\\\TauDEM_Outputs\\\\Stream_Network_Togiak_stream_reach', 'W:\\\\GIS\\\\AKSSF\\\\AKSSF_Hydrography.gdb\\\\TauDEM_Outputs\\\\Stream_Network_Lakes_stream_reach']\n",
      "Merged feature classes saved to: W:/GIS/AKSSF/Bristol_Bay.gdb\n"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "import os\n",
    "\n",
    "baseFolder = \"W:\\\\GIS\\\\\"\n",
    "ds = baseFolder + \"AKSSF\\\\AKSSF_Hydrography.gdb\\\\TauDEM_Outputs\"\n",
    "region = \"Bristol_Bay\"\n",
    "\n",
    "arcpy.env.workspace = ds\n",
    "arcpy.env.overwriteOutput = True\n",
    "cats = arcpy.ListFeatureClasses('Catchments*')\n",
    "streams = arcpy.ListFeatureClasses('Stream*')\n",
    "\n",
    "#For Bristol Bay - remove feature classes with Pws\n",
    "cats = [x for x in cats if 'Pws' not in x]\n",
    "streams = [x for x in streams if 'Pws' not in x]\n",
    "\n",
    "#get full path names onto lists\n",
    "cats = [ds + \"\\\\\" + x for x in cats]\n",
    "streams = [ds + \"\\\\\" + x for x in streams]\n",
    "\n",
    "#add a new field with the VPU prefix to the gridcode.\n",
    "for cat in cats:\n",
    "    if len(arcpy.ListFields(cat, \"catID\")) > 0:\n",
    "        arcpy.DeleteField_management(cat, \"catID\")\n",
    "        arcpy.AddField_management(cat, \"catID\", \"LONG\")\n",
    "    vpu = cat[61:63]\n",
    "    print(vpu)\n",
    "    options = {'Eg': 1000000, 'La': 2000000, 'Na': 3000000, 'Nu': 4000000, 'To': 5000000}\n",
    "    if vpu in options:\n",
    "        prefix = options[vpu]\n",
    "    else:\n",
    "        print(\"vpu not found\")\n",
    "    arcpy.management.CalculateField(cat, \"catID\", 'prefix + !gridcode!')\n",
    "\n",
    "for stream in streams:\n",
    "    print(stream)\n",
    "    if len(arcpy.ListFields(stream, \"catID\")) > 0:\n",
    "        arcpy.DeleteField_management(stream, [\"catID\", \"upCatID1\", \"upCatID2\"])\n",
    "        arcpy.management.AddFields(stream,[[\"catID\", \"LONG\"], [\"upCatID1\", \"LONG\"], [\"upCatID2\", \"LONG\"]])\n",
    "    vpu = stream[65:67]\n",
    "    print(vpu)\n",
    "    # options = {'Eg': 1000000, 'La': 2000000, 'Na': 3000000, 'Nu': 4000000, 'To': 5000000}\n",
    "    if vpu in options:\n",
    "        prefix = options[vpu]\n",
    "    else:\n",
    "        print(\"vpu not found\")\n",
    "    arcpy.management.CalculateField(stream, \"catID\", 'prefix + !LINKNO!')\n",
    "    arcpy.management.CalculateField(stream, \"upCatID1\", 'prefix + !USLINKNO1!')\n",
    "    arcpy.management.CalculateField(stream, \"upCatID2\", 'prefix + !USLINKNO2!')\n",
    "\n",
    "\n",
    "print(\"Catchment feature classes to be merged: \")\n",
    "print(cats)\n",
    "print(\"Stream feature classes to be merged: \")\n",
    "print(streams)\n",
    "\n",
    "arcpy.env.outputCoordinateSystem = arcpy.Describe(cats[1]).spatialReference\n",
    "arcpy.env.overwriteOutput = True\n",
    "#arcpy.CreateFileGDB_management(baseFolder + \"AKSSF\\\\\" + region, region + \".gdb\")\n",
    "arcpy.env.workspace =  r\"W:/GIS/AKSSF/\" + region + \".gdb\"\n",
    "\n",
    "arcpy.management.Merge(cats, r\"W:/GIS/AKSSF/\" + region + \"\\\\\" + region + \".gdb/cats_merge\")\n",
    "arcpy.management.Merge(streams, r\"W:/GIS/AKSSF/\" + region + \"\\\\\" + region + \".gdb/streams_merge\")\n",
    "\n",
    "print(\"Merged feature classes saved to: \" + arcpy.env.workspace)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Copy feature classes from AKSSF Hydrography geodb to new region specific geodb\n",
    "# for Kodiak and PWS. These will be used to create watersheds and run zonal\n",
    "# stats for catchments and watersheds.\n",
    "\n",
    "import arcpy\n",
    "import os\n",
    "\n",
    "# Create new geodb in each regional folder\n",
    "baseFolder = \"W:\\\\GIS\\\\\"\n",
    "region = \"Prince_William_Sound\"\n",
    "# region = \"Kodiak\"\n",
    "\n",
    "# TauDEM outputs\n",
    "pwsNet = baseFolder + \"AKSSF\\\\AKSSF_Hydrography.gdb\\\\TauDEM_Outputs\"\n",
    "kodNet = baseFolder + \"AKSSF\\\\AKSSF_Hydrography.gdb\\\\TauDEM_StreamBurn\"\n",
    "\n",
    "arcpy.env.workspace = pwsNet\n",
    "fcs = arcpy.ListFeatureClasses()\n",
    "fcs = [os.path.join(arcpy.env.workspace, x) for x in fcs]\n",
    "fcs = [x for x in fcs if \"Pws\" in x]\n",
    "print(fcs)\n",
    "\n",
    "# arcpy.CreateFileGDB_management(r\"W:/GIS/AKSSF/\" + region, region + \".gdb\")\n",
    "arcpy.env.workspace =  r\"W:/GIS/AKSSF/\" + region + \"//\" + region + \".gdb\"\n",
    "arcpy.env.outputCoordinateSystem = arcpy.Describe(fcs[0]).spatialReference\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "# Copy feature classes over from AKSSF_Hydrography geodb\n",
    "for fc in fcs:\n",
    "    if \"Cat\" in fc:\n",
    "        out_fc = \"cats_merge\"\n",
    "    else:\n",
    "        out_fc = \"streams_merge\"\n",
    "    arcpy.CopyFeatures_management(fc, out_fc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Merge raster datasets by region\n",
    "1. Create a regional boundary (maybe buffer by 10 km) for clipping statewide datasets and putting all grids into regional geodb\n",
    "2. Elevation grids: clip 10m DEM for synthetic flow networks (ask Dustin for this) and merge elevation rasters for each NHDPlus VPU\n",
    "3. Flow accumulation grids: copy and/or merge as needed by region\n",
    "4. Use elevation grids to create slope grids for each region\n",
    "5. Use elevation grids to create the aspect grid\n",
    "6. Use elevation grids to create a grid of north facing cells (Dustin has this code ready)\n",
    "7. Lake feature class: merge from NHPPlus VPUs or clip from regular NHD to region geodb\n",
    "8. Copy glims glacier inventory to local AKSSF folder and clip and create a 1/0 grid of glacier cover\n",
    "9. Copy NLCD to local AKSSF folder and clip create a 1/0 grid of wetland cover (Dustin should have this code in deshka repo)\n",
    "10. Create raster of MODIS LCLD by year, copy, and clip to each regional folder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# step 1, create regional boundaries with buffer for clipping grids\n",
    "# dissolve on cats_merge and buffer by 10 km\n",
    "\n",
    "import arcpy\n",
    "import os\n",
    "\n",
    "regions = [\"Kodiak\", \"Cook_Inlet\", \"Copper_River\", \"Bristol_Bay\", \"Prince_William_Sound\"]\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "for region in regions:\n",
    "    arcpy.env.workspace = \"W:\\\\GIS\\\\AKSSF\\\\\" + region + \"\\\\\" + region + \".gdb\"\n",
    "    cats = os.path.join(arcpy.env.workspace, \"cats_merge\")\n",
    "    arcpy.Buffer_analysis(cats, \"region_buf\", \"10 Kilometers\", \"FULL\", \"ROUND\", \"ALL\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Cook_Inlet\n",
      "W:\\GIS\\AKSSF\\Cook_Inlet\n",
      "['W:\\\\GIS\\\\NHDPlus\\\\CookInlet_20201216\\\\HRNHDPlusRasters19020202\\\\fac.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CookInlet_20201216\\\\HRNHDPlusRasters19020301\\\\fac.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CookInlet_20201216\\\\HRNHDPlusRasters19020302\\\\fac.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CookInlet_20201216\\\\HRNHDPlusRasters19020401\\\\fac.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CookInlet_20201216\\\\HRNHDPlusRasters19020402\\\\fac.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CookInlet_20201216\\\\HRNHDPlusRasters19020501\\\\fac.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CookInlet_20201216\\\\HRNHDPlusRasters19020502\\\\fac.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CookInlet_20201216\\\\HRNHDPlusRasters19020503\\\\fac.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CookInlet_20201216\\\\HRNHDPlusRasters19020504\\\\fac.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CookInlet_20201216\\\\HRNHDPlusRasters19020505\\\\fac.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CookInlet_20201216\\\\HRNHDPlusRasters19020601\\\\fac.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CookInlet_20201216\\\\HRNHDPlusRasters19020602\\\\fac.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CookInlet_20201216\\\\HRNHDPlusRasters19020800\\\\fac.tif']\n",
      "['W:\\\\GIS\\\\NHDPlus\\\\CookInlet_20201216\\\\HRNHDPlusRasters19020202\\\\elev_cm.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CookInlet_20201216\\\\HRNHDPlusRasters19020301\\\\elev_cm.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CookInlet_20201216\\\\HRNHDPlusRasters19020302\\\\elev_cm.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CookInlet_20201216\\\\HRNHDPlusRasters19020401\\\\elev_cm.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CookInlet_20201216\\\\HRNHDPlusRasters19020402\\\\elev_cm.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CookInlet_20201216\\\\HRNHDPlusRasters19020501\\\\elev_cm.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CookInlet_20201216\\\\HRNHDPlusRasters19020502\\\\elev_cm.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CookInlet_20201216\\\\HRNHDPlusRasters19020503\\\\elev_cm.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CookInlet_20201216\\\\HRNHDPlusRasters19020504\\\\elev_cm.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CookInlet_20201216\\\\HRNHDPlusRasters19020505\\\\elev_cm.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CookInlet_20201216\\\\HRNHDPlusRasters19020601\\\\elev_cm.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CookInlet_20201216\\\\HRNHDPlusRasters19020602\\\\elev_cm.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CookInlet_20201216\\\\HRNHDPlusRasters19020800\\\\elev_cm.tif']\n",
      "Processing Copper_River\n",
      "W:\\GIS\\AKSSF\\Copper_River\n",
      "['W:\\\\GIS\\\\NHDPlus\\\\CopperRiver_20210408\\\\HRNHDPlusRasters19020101\\\\fac.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CopperRiver_20210408\\\\HRNHDPlusRasters19020102\\\\fac.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CopperRiver_20210408\\\\HRNHDPlusRasters19020103\\\\fac.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CopperRiver_20210408\\\\HRNHDPlusRasters19020104\\\\fac.tif']\n",
      "['W:\\\\GIS\\\\NHDPlus\\\\CopperRiver_20210408\\\\HRNHDPlusRasters19020101\\\\elev_cm.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CopperRiver_20210408\\\\HRNHDPlusRasters19020102\\\\elev_cm.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CopperRiver_20210408\\\\HRNHDPlusRasters19020103\\\\elev_cm.tif', 'W:\\\\GIS\\\\NHDPlus\\\\CopperRiver_20210408\\\\HRNHDPlusRasters19020104\\\\elev_cm.tif']\n"
     ]
    }
   ],
   "source": [
    "# steps 2 and 3: merge elevation and flow accumulation rasters for regions with NHDPlus\n",
    "#CURRENTLY NOT WORKING, MOSAIC WAS EMPTY FOR FAC AND NEVER RAN FOR ELEV.\n",
    "\n",
    "import arcpy\n",
    "import os\n",
    "\n",
    "baseFolder = \"W:\\\\GIS\\\\\"\n",
    "regions = [\"Cook_Inlet\", \"Copper_River\"]\n",
    "\n",
    "#NHD folders\n",
    "ciNHD = baseFolder + \"NHDPlus\\\\CookInlet_20201216\"\n",
    "crNHD = baseFolder + \"NHDPlus\\\\CopperRiver_20210408\"\n",
    "\n",
    "for region in regions:\n",
    "    if region == \"Cook_Inlet\":\n",
    "        arcpy.env.workspace = ciNHD\n",
    "    else:\n",
    "        arcpy.env.workspace = crNHD\n",
    "    print(\"Processing \" + region)\n",
    "    flowacc_rasters = []\n",
    "    elev_rasters = []\n",
    "    raster_folders = arcpy.ListWorkspaces(\"*Rasters*\")\n",
    "    for folder in raster_folders:\n",
    "        arcpy.env.workspace = folder\n",
    "        rasters = arcpy.ListRasters()\n",
    "        for raster in rasters:\n",
    "            if raster == 'fac.tif':\n",
    "                flowacc_raspath = os.path.normpath(os.path.join(folder, raster))\n",
    "                flowacc_rasters.append(flowacc_raspath)\n",
    "            if raster == 'elev_cm.tif':\n",
    "                elev_raspath = os.path.normpath(os.path.join(folder, raster))\n",
    "                elev_rasters.append(elev_raspath)\n",
    "    dataset = flowacc_rasters[1]\n",
    "    spatial_ref = arcpy.Describe(dataset).spatialReference\n",
    "    outFolder = baseFolder + \"AKSSF\\\\\" + region\n",
    "    print(outFolder)\n",
    "    print(flowacc_rasters)\n",
    "    print(elev_rasters)\n",
    "    arcpy.MosaicToNewRaster_management(flowacc_rasters, outFolder, \"fac_merge.tif\", spatial_ref, \"32_BIT_SIGNED\", \"5\", \"1\", \"LAST\",\"FIRST\")\n",
    "    arcpy.MosaicToNewRaster_management(elev_rasters, outFolder, \"elev_merge.tif\", spatial_ref, \"32_BIT_SIGNED\", \"5\", \"1\", \"LAST\",\"FIRST\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# steps 2 and 3: clip elevation grid and copy flow accumulation raster for regions with synthetic networks\n",
    "# (ask Dustin to do this or supply these layers)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# steps 4-6, use elevation grids for each region to create slope, aspect, and north-facing grids\n",
    "import arcpy\n",
    "from arcpy import env\n",
    "from arcpy.sa import *\n",
    "\n",
    "baseFolder = \"W:\\\\GIS\\\\AKSSF\"\n",
    "arcpy.env.workspace = baseFolder\n",
    "region_folders = arcpy.ListWorkspaces()\n",
    "\n",
    "for folder in region_folders:\n",
    "    arcpy.env.workspace = folder\n",
    "    elev_raster = folder + \"elev_merge.tif\"\n",
    "    slope_raster = arcpy.sa.Slope(elev_raster, \"DEGREE\")\n",
    "    slope_raster.save(\"slope\")\n",
    "    aspect_raster = arcpy.sa.Aspect(elev_raster)\n",
    "    aspect_raster.save(\"aspect\")\n",
    "    north_raster = Con((aspect_raster >= 0) & (aspect_raster <= 45), 1, Con((aspect_raster <= 360) & (aspect_raster >= 315), 1, 0))\n",
    "    north_raster.save(\"north\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}