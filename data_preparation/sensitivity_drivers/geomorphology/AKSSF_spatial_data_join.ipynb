{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This script will be for linking the siteIDs to the catchment IDs - which are either NHDPlusIDs,\n",
    "gridcodes, or new catIDs made from the gridcodes for BB. This will give us a way to link the\n",
    "thermal sensitivity responses by year to the covariates. This script also includes code to\n",
    "check the watersheds. The watersheds are individual feature classes to avoid overlapping\n",
    "polygons so the best way to check they are correct is to 1) check that every siteID/catID\n",
    "has a watershed, and 2) check that the watershed area approximately matches the watershed\n",
    "area from the flow accumulation grid. They won't be exact for sites that are not close to\n",
    "the catchment outlet and could be quite different for very small watersheds in some cases.\n",
    "\n",
    "# Watershed Summaries\n",
    "\n",
    "1. read in all watersheds feature classes\n",
    "2. create a table with the NHDPlusID/catID of the watershed name, region, and watershed area\n",
    "3. merge original point feature classes (inside and outside bb)\n",
    "4. do a spatial join with merged catchments by region to get catID and region on the points dataset\n",
    "5. clip to the region and save in each regional gdb\n",
    "6. merge all point feature classes with siteIDs and catIDs into one table\n",
    "7. join the watershed area from the watershed fcs to the points table using the catID\n",
    "NOT DONE and not sure we need it: 8. join the watershed area from the fac grid to the points table using the catID\n",
    "9. compare the results to ensure that watersheds have been created correctly"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'123654'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import arcpy, os\n",
    "\n",
    "# Path to create output folder/gdb\n",
    "temppath = r\"D:\\\\GIS\\\\\" # Output folder\n",
    "dirname = 'AKSSF_land_met'\n",
    "tempgdbname = 'AKSSF_land_met.gdb'\n",
    "temp_dir = os.path.join(temppath, dirname)\n",
    "\n",
    "# Create temporary working gdb\n",
    "if not arcpy.Exists(temp_dir):\n",
    "    os.makedirs(temp_dir)\n",
    "else:\n",
    "    print('Working Folder already created...', temp_dir)\n",
    "\n",
    "outcheck = os.path.join(temp_dir, tempgdbname)\n",
    "\n",
    "if arcpy.Exists(outcheck):\n",
    "    print ('Output location already exists', outcheck)\n",
    "    outgdb = outcheck\n",
    "if not arcpy.Exists(outcheck):\n",
    "    print('Creating output GDB')\n",
    "    tempgdb = arcpy.CreateFileGDB_management(temp_dir,tempgdbname)\n",
    "    print ('Output geodatabase created at', outcheck)\n",
    "    outgdb = tempgdb.getOutput(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kodiak: 28 watersheds\n",
      "----------\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "1. 48267: [80.5581]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "2. 49617: [294.1329]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "3. 50197: [49.0722]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "4. 64593: [65.5676]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "5. 72144: [4.2088]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "6. 76954: [30.8766]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "7. 77794: [54.7985]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "8. 90346: [7.5286]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "9. 93176: [10.5872]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "10. 94216: [9.5218]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "11. 97276: [25.1611]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "12. 99516: [15.1699]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "13. 100826: [26.9231]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "14. 101556: [25.3449]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "15. 103096: [52.8504]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "16. 103196: [69.6273]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "17. 103296: [63.8678]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "18. 103456: [64.8608]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "19. 103496: [58.428]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "20. 106626: [184.9214]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "21. 106676: [185.1191]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "22. 107796: [431.4948]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "23. 107816: [467.6201]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "24. 108356: [519.8356]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "25. 128685: [103.3893]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "26. 129955: [277.461]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "27. 130295: [430.8143]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "28. 130735: [605.336]\n",
      "Copper_River: 28 watersheds\n",
      "----------\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "1. 75019800000406: [7.35572498100007]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "2. 75019800010313: [562.020949827]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "3. 75019800014348: [35.1819750030002]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "4. 75019800001957: [12.75060003825]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "5. 75019800019692: [1623.22927529275]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "6. 75019600118138: [4551.255525077]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "7. 75019700004190: [370.47150009425]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "8. 75019700004084: [33.5466249777501]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "9. 75019700017692: [700.42457513925]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "10. 75019700001794: [141.764799868]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "11. 75019700003889: [28.2315499447503]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "12. 75003900062338: [51100.7862998642]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "13. 75003900033524: [54.0521499752501]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "14. 75003900054316: [52.1643999492501]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "15. 75003900055039: [3.44030003900001]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "16. 75003900023942: [8.0190249755]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "17. 75003900058380: [5.2301000194999]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "18. 75003900028507: [2.12479999075003]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "19. 75003900027489: [20.9082749335002]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "20. 75003900044936: [5.18647501100007]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "21. 75003900023855: [0.764774991000045]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "22. 75003900044738: [6.04239994075009]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "23. 75003900055694: [0.210325000999973]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "24. 75003900023674: [3.88814998624989]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "25. 75003900062264: [22.1521251559997]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "26. 75003900055316: [7.33369992075021]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "27. 75003900039073: [5.76037498350005]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "28. 75003900027771: [1.61012501325003]\n",
      "Prince_William_Sound: 20 watersheds\n",
      "----------\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "1. 18457: [12.6534]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "2. 26464: [4.5097]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "3. 28086: [4.2285]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "4. 29854: [18.2419]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "5. 30884: [8.4223]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "6. 31865: [0.8897]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "7. 36645: [3.5947]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "8. 37815: [5.2671]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "9. 38993: [3.1686]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "10. 40285: [12.3775]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "11. 41515: [5.3127]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "12. 42563: [12.2628]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "13. 43055: [15.2785]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "14. 43185: [23.9529]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "15. 43383: [25.5571]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "16. 43933: [32.3575]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "17. 43973: [16.6989]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "18. 44553: [50.2923]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "19. 46055: [2.7634]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "20. 46513: [472.5486]\n",
      "Cook_Inlet: 240 watersheds\n",
      "----------\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "1. 75004300006312: [154.306524975027]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "2. 75004300001906: [91.870175120765]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "3. 75004300000100: [28.961324890473]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "4. 75004300004983: [15.2613751159444]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "5. 75004300004332: [330.1240747626]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "6. 75004300006239: [56.0308501025738]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "7. 75004300004304: [321.79309986178]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "8. 75004300002332: [310.727624846888]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "9. 75004300005437: [9.34964989214677]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "10. 75004300003464: [39.05965002492]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "11. 75004300005171: [8.04862502289959]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "12. 75004300004701: [154.661600009603]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "13. 75004300005303: [96.2434001069572]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "14. 75004300006440: [3.55284995515247]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "15. 75004300004254: [347.268774828552]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "16. 75004300001207: [14.9358500208013]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "17. 75004300005245: [177.062124937249]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "18. 75004300000311: [51.8118499666333]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "19. 75004300008012: [59.4149499598852]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "20. 75004300004192: [581.778649740426]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "21. 75004300007324: [89.0440250295134]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "22. 75004300001162: [183.04649992364]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "23. 75004300004217: [131.949049938799]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "24. 75004300002207: [398.294124805145]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "25. 75004300003409: [5.98590004553863]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "26. 75004300002142: [55.3421999378382]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "27. 75004300002314: [1.06192495338125]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "28. 75004300003171: [8.91457499826932]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "29. 75004300000101: [10.2498250040996]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "30. 75004300005352: [58.9958500208178]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "31. 75004300000856: [156.919096275364]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "32. 75004300004341: [268.456549910218]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "33. 75004300002289: [8.16919998404097]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "34. 75004300007331: [69.5340248327356]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "35. 75004300006376: [41.6300998783105]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "36. 75004300002278: [4.34527498661142]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "37. 75004300002352: [0.572200021105535]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "38. 75004300001210: [3.64997506843073]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "39. 75004300004452: [161.045675049111]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "40. 75004300000105: [117.520799971326]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "41. 75004300006071: [213.276349813864]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "42. 75004300004324: [570.917724990867]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "43. 75004300001288: [41.7343749989578]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "44. 75004300006013: [44.808675109818]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "45. 75004400004829: [125.552424951494]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "46. 75004400000576: [278.267925423806]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "47. 75004400006041: [645.732999907538]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "48. 75004400010402: [47.3331250785339]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "49. 75004400008856: [87.7250730577964]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "50. 75004400010754: [163.908949833661]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "51. 75004400010810: [33.9592499650158]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "52. 75004400002950: [141.631200096825]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "53. 75004400009144: [66.6914999458208]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "54. 75004400006357: [83.1506250499538]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "55. 75004400007385: [118.993599857851]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "56. 75004400007948: [131.659275112825]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "57. 75004400009261: [144.483024942008]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "58. 75004400001510: [98.8227250647972]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "59. 75004400007387: [96.0323499495381]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "60. 75004400010320: [66.4171249875312]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "61. 75004400001568: [352.446399319792]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "62. 75004400008917: [126.562850055719]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "63. 75004400001952: [1673.69265062306]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "64. 75004400009919: [74.831224923946]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "65. 75004400001498: [5158.83382470789]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "66. 75004400011711: [360.566400535551]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "67. 75004400003452: [15.3436497833864]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "68. 75004400007388: [43.5565999900558]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "69. 75004400000627: [410.589224966524]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "70. 75004400003042: [682.138525136464]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "71. 75004400002041: [83.9883502931417]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "72. 75004400011322: [55.5205501032957]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "73. 75004400001872: [101.07972507388]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "74. 75004400009331: [124.138425040732]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "75. 75004400009308: [67.6002000223301]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "76. 75004400006846: [78.9342001912424]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "77. 75004400003154: [3205.93695067461]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "78. 75004400002951: [37.3352500025437]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "79. 75004400009260: [143.811824939184]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "80. 75000100000981: [109.983349958]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "81. 75000100003094: [234.57054993775]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "82. 75000100003947: [79.0551749225006]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "83. 75000100002463: [319.489400008]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "84. 75000100001919: [72.9444250159999]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "85. 75000100004336: [80.870575001]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "86. 75000100000004: [171.531024892]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "87. 75000100000652: [323.050200045]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "88. 75000100004200: [57.4192750037499]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "89. 75000100002523: [182.2452501505]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "90. 75000100000059: [35.9268251207499]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "91. 75000400000173: [77.7938499320003]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "92. 75000400009620: [5326.81112514375]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "93. 75000400014405: [16.13084996975]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "94. 75000400014403: [130.46237492]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "95. 75000700036166: [16286.9933501912]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "96. 75000700030756: [13362.7330504702]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "97. 75000700032122: [2381.775150233]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "98. 75000500009621: [407.1570000505]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "99. 75000500011984: [99.8046998795003]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "100. 75000500009975: [126.10624999525]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "101. 75000500010609: [6528.89145008825]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "102. 75000300025361: [5212.2290001505]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "103. 75000600010189: [15794.3653997276]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "104. 75000600030148: [169.87782500175]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "105. 75000200008033: [359.15514994375]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "106. 75000200002920: [375.46257499]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "107. 75000200000411: [308.3031249575]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "108. 75000200008551: [399.677524938]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "109. 75000200007305: [62.550675013]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "110. 75000200015657: [51.2484999730002]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "111. 75000200003107: [413.550975164]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "112. 75000200008009: [32.26387496725]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "113. 75000200013536: [28668.7653250127]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "114. 75000200015867: [395.61577508275]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "115. 75000200010712: [17.9079750887497]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "116. 75000200003070: [17.9918499105003]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "117. 75000200006065: [381.50114999075]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "118. 75000200010532: [304.51692498875]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "119. 75000200005573: [376.6677001775]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "120. 75000200005575: [394.67542509125]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "121. 75000200018331: [1643.75800021975]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "122. 75000200005504: [1189.41742503]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "123. 75000200003013: [909.8220249955]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "124. 75000200015680: [350.77669997725]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "125. 75000200000416: [249.903524947001]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "126. 75000200005413: [60.77080005775]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "127. 75000200002930: [234.77997507375]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "128. 75000200010359: [3.47834998424999]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "129. 75000200010144: [49.4989500267498]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "130. 75000200018266: [158.24125010125]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "131. 75000200002753: [79.8248748232504]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "132. 75000200015505: [59.4859748385005]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "133. 75000200015584: [30.1823750190001]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "134. 75000200002806: [1.60382500125002]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "135. 75000200007853: [63.3565998197505]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "136. 75000200018577: [85.9000749330003]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "137. 75000200015695: [43.7374750602498]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "138. 75000200013033: [1.9217500264999]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "139. 75000200005075: [7.443249995]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "140. 75000200007839: [159.187424854]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "141. 75000200007958: [3.45362500474992]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "142. 75000200013189: [95.2182750095002]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "143. 75000200002934: [230.960400077]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "144. 75000200018235: [2.86357498724999]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "145. 75000200013258: [1.8278249932501]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "146. 75000200018069: [5.73922495300004]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "147. 75000200013187: [140.209200057]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "148. 75000200007646: [10.0682000424999]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "149. 75000200000010: [8.52552499399986]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "150. 75000200013185: [140.052125074]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "151. 75000200010344: [19.4881999770001]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "152. 75000200010538: [179.7024500995]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "153. 75000200010547: [140.33665006175]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "154. 75000200005606: [8.33517499099995]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "155. 75000200002554: [2.35274999724991]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "156. 75000200017518: [44.7527249537502]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "157. 75000200018332: [1567.7373502445]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "158. 75000200015469: [43.576099995]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "159. 75000200010540: [174.2213250835]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "160. 75000200018806: [912.3345499465]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "161. 75000200003094: [864.5141501375]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "162. 75000200014914: [116.1069749895]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "163. 75000200007639: [114.3665998495]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "164. 75000200013266: [909.7959250045]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "165. 75000200010391: [13.2891000005001]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "166. 75000200015860: [42.6489498927501]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "167. 75000200005503: [72.7732250432502]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "168. 75000200000213: [69.9096248025005]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "169. 75000200015782: [30.6506749537502]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "170. 75000200011141: [165.465349959]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "171. 75000200008051: [3.196350003]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "172. 75000200013319: [363.563275237749]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "173. 75000200007852: [72.8471498307505]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "174. 75000200000465: [233.3975499965]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "175. 75000200013237: [954.5713000085]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "176. 75000200007870: [3.95524997025001]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "177. 75000200000011: [6.29164998675002]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "178. 75000200013953: [412.71709998875]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "179. 75000200004615: [160.66304995925]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "180. 75000200010148: [15.2259000322499]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "181. 75000200013892: [85.6818249087504]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "182. 75000200013179: [15.941324992]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "183. 75000200002984: [942.15707498625]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "184. 75000200007660: [453.9741500215]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "185. 75000200005448: [236.65315002275]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "186. 75000200018581: [803.402799845]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "187. 75000200011336: [430.2868750425]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "188. 75000200012999: [860.24374987975]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "189. 75000200003732: [432.14192503]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "190. 75000200008734: [20.1270249037503]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "191. 75000200000021: [782.14647484125]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "192. 75000200005532: [1203.4901249995]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "193. 75000200018882: [550.02869988675]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "194. 75000200005404: [42.30899999875]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "195. 75000200015587: [24.7833999975001]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "196. 75000200015319: [57.5390999147504]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "197. 75000200015900: [1773.59767521775]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "198. 75000200005077: [22.4859249792501]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "199. 75000200008950: [345.21459982325]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "200. 75000200015320: [546.64872494925]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "201. 75000200012046: [16.8856250054998]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "202. 75000200002162: [107.954649947]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "203. 75000200011392: [17.7257250779997]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "204. 75000200000278: [232.3140499125]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "205. 75000200018259: [68.9904750749999]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "206. 75000200005444: [304.1866749645]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "207. 75000200018203: [28.326525091]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "208. 75000200008110: [311.622500131]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "209. 75000200018317: [59.9661000157497]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "210. 75000200000949: [388.32754999175]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "211. 75000200013249: [373.93840013575]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "212. 75000200013010: [53.2871250202497]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "213. 75000200000418: [305.90245010425]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "214. 75000200002552: [3.57724996000007]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "215. 75000200008508: [587.875574851]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "216. 75000200007670: [3.96435001525006]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "217. 75000200008676: [14.81074997225]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "218. 75000200018667: [645.99639993125]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "219. 75000200011572: [12.1452500882498]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "220. 75000200011623: [12.7518749602502]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "221. 75000200019765: [165.89392498525]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "222. 75000200016095: [21.1075499407501]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "223. 75000200014508: [209.836800004]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "224. 75000200015883: [1745.84072519675]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "225. 75000200014057: [9.68937496700011]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "226. 75000200019263: [4.92087494900005]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "227. 75000200003896: [305.410149972]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "228. 75000200005619: [69.6610249480002]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "229. 75000200003312: [658.739774982]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "230. 75000200014207: [260.93259995525]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "231. 75000200007927: [50138.586775259]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "232. 75000200011034: [56.0562500654999]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "233. 75000200015882: [1675.89852526975]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "234. 75000200016094: [707.52427485075]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "235. 75000200008452: [69.79484998675]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "236. 75005300022831: [350.518224904666]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "237. 75005300011378: [302.201700289278]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "238. 75005400001203: [282.44622527767]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "239. 75005400029139: [29.47359998857]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "240. 75005400013272: [10.8415499649418]\n",
      "Bristol_Bay: 114 watersheds\n",
      "----------\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "1. 1023044: [3265.2693]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "2. 2041471: [1188.83394165891]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "3. 2065755: [305.9274]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "4. 2065914: [12.9698]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "5. 2066924: [29.7025]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "6. 2066955: [315.312]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "7. 2067494: [62.7302]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "8. 2068072: [5.1499]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "9. 2068584: [93.536922261]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "10. 2070402: [17.8413]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "11. 2071934: [155.076111114]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "12. 2072993: [16.4381]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "13. 2073464: [331.712]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "14. 2074424: [221.1778]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "15. 2078232: [110.151911114]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "16. 2078282: [112.105411114]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "17. 2082373: [843.839377772]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "18. 2082393: [844.595977772]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "19. 2084713: [53.4479]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "20. 2085642: [2665.491811147]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "21. 2085962: [2864.098311147]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "22. 2087913: [7592.46903735782]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "23. 2088163: [8605.62943535774]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "24. 2088253: [8669.17433535774]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "25. 2088326: [492.0395]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "26. 2088586: [269.6706]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "27. 3023044: [148.7091]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "28. 3024343: [6754.2341]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "29. 3030955: [781.4748]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "30. 3033666: [83.1925]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "31. 3033956: [273.1076]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "32. 3034126: [79.2503]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "33. 4046617: [5.9778]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "34. 4048046: [2.2256]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "35. 4051055: [3.0883]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "36. 4051056: [3.314]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "37. 4051616: [3.2994]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "38. 4052076: [5.3765]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "39. 4054120: [25.8769]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "40. 4054200: [176.4666]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "41. 4055337: [9.0458]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "42. 4059016: [7.0866]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "43. 4059736: [11.9662]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "44. 4060036: [9.1895]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "45. 4061136: [9.1353]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "46. 4063606: [17.4968]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "47. 4063775: [6.779]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "48. 4064055: [2.4938]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "49. 4064845: [8.6642]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "50. 4068584: [1.8667]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "51. 4069455: [9.3439]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "52. 4069495: [10.9117]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "53. 4069586: [16.7362]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "54. 4071036: [105.6871]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "55. 4071256: [138.1613]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "56. 4071625: [10.2876]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "57. 4073375: [15.8738]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "58. 4074184: [3.1412]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "59. 4074505: [22.3844]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "60. 4074726: [94.8666]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "61. 4075225: [25.9738]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "62. 4075474: [9.5446]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "63. 4075715: [23.3416]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "64. 4076505: [38.0412]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "65. 4076575: [52.4802]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "66. 4076675: [22.3564]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "67. 4078235: [30.6554]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "68. 4079234: [3.3111]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "69. 4080045: [80.3923]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "70. 4080875: [164.2842]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "71. 4082225: [2.2765]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "72. 4084145: [164.6464]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "73. 4084351: [73.2784]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "74. 4084915: [80.8575]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "75. 4086815: [1528.3775]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "76. 4087015: [1174.8091]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "77. 4087224: [10.3069]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "78. 4088675: [2216.1895]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "79. 4088904: [13.5213]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "80. 4089074: [20.2415]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "81. 4089384: [10.8875]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "82. 4089394: [10.9771]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "83. 4089574: [15.4036]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "84. 4091164: [35.998]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "85. 4091424: [25.6329]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "86. 4092244: [22.1608]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "87. 4093084: [41.3073]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "88. 4095301: [186.5479]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "89. 4095374: [35.5411]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "90. 4096064: [30.2231]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "91. 4096454: [63.3384]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "92. 4098114: [97.0252]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "93. 4098704: [177.7584]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "94. 4099594: [296.4068]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "95. 4099694: [273.2782]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "96. 4101123: [3929.443]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "97. 4101274: [19.5802]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "98. 4102124: [125.2901]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "99. 4104574: [420.1106]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "100. 4105204: [692.7912]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "101. 4105594: [109.4471]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "102. 4105844: [268.5621]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "103. 4106904: [175.4414]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "104. 4107464: [9400.3065]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "105. 4115672: [906.4683]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "106. 5008707: [162.345]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "107. 5020796: [345.2735]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "108. 5021476: [394.0384]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "109. 5030363: [73.6221]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "110. 5030704: [44.4566]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "111. 5032474: [74.8338]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "112. 5033094: [247.9377]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "113. 5034893: [1332.0373]\n",
      "Area already calculated\n",
      "Adding cat_ID field\n",
      "114. 5038375: [452.8228]\n",
      "Process completed at 2021-12-03 09:51 (Elapsed time: 0:08:47)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# steps 1 and 2\n",
    "\n",
    "import arcpy,sys, os, time, datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "regions = [\"Kodiak\", \"Copper_River\", \"Prince_William_Sound\", \"Cook_Inlet\", \"Bristol_Bay\"]\n",
    "#regions = ['Copper_River', 'Cook_Inlet']\n",
    "wtdList = []\n",
    "\n",
    "for region in regions:\n",
    "    c=1\n",
    "    local_gdb = \"D:\\\\GIS\\\\AKSSF\\\\\" + region + \"\\\\\" + region + \".gdb\\\\Watersheds\"\n",
    "    arcpy.env.workspace = local_gdb\n",
    "    wtds = arcpy.ListFeatureClasses()\n",
    "    print(region + \": \" + str(len(wtds)) + \" watersheds\")\n",
    "    print('----------')\n",
    "    for wtd in wtds:\n",
    "        wtdName = wtd[4:]\n",
    "        #print(\"Starting wtd: \" + wtdName)\n",
    "        wtdPath = os.path.join(arcpy.env.workspace, wtd)\n",
    "        field_names = [f.name for f in arcpy.ListFields(wtdPath)]\n",
    "        #print(field_names)\n",
    "        if \"Area_km2\" in field_names:\n",
    "            print(\"Area already calculated\")\n",
    "        else:\n",
    "            arcpy.AddField_management(wtdPath, \"Area_km2\", \"DOUBLE\")\n",
    "            expression1 = \"{0}\".format(\"!SHAPE.area@SQUAREKILOMETERS!\")\n",
    "            arcpy.CalculateField_management(wtdPath, \"Area_km2\", expression1, \"PYTHON\", )\n",
    "        if \"cat_ID\" in field_names:\n",
    "            print(\"cat_ID field exists\")\n",
    "        else:\n",
    "            print('Adding cat_ID field')\n",
    "            arcpy.AddField_management(wtdPath, \"cat_ID\", \"DOUBLE\")\n",
    "            arcpy.CalculateField_management(wtdPath, \"cat_ID\", wtdName, \"PYTHON\")\n",
    "        wtdArea = [row[0] for row in arcpy.da.SearchCursor(wtdPath, ['Area_km2'])]\n",
    "        print(f\"{c}. {wtdName}: \" + str(wtdArea))\n",
    "        wtdList.append({'Region': region, 'cat_ID': {wtdName}, 'Area_km2': wtdArea})\n",
    "        c+=1\n",
    "\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "\n",
    "# Report success\n",
    "print(f'Process completed at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "      f'(Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print('----------')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Region     cat_ID     Area_km2\n",
      "0         Kodiak    {48267}    [80.5581]\n",
      "1         Kodiak    {49617}   [294.1329]\n",
      "2         Kodiak    {50197}    [49.0722]\n",
      "3         Kodiak    {64593}    [65.5676]\n",
      "4         Kodiak    {72144}     [4.2088]\n",
      "..           ...        ...          ...\n",
      "425  Bristol_Bay  {5030704}    [44.4566]\n",
      "426  Bristol_Bay  {5032474}    [74.8338]\n",
      "427  Bristol_Bay  {5033094}   [247.9377]\n",
      "428  Bristol_Bay  {5034893}  [1332.0373]\n",
      "429  Bristol_Bay  {5038375}   [452.8228]\n",
      "\n",
      "[430 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "wtdDf = pd.DataFrame(wtdList)\n",
    "print(wtdDf)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kodiak: 28 watersheds\n",
      "Copper_River: 28 watersheds\n",
      "Prince_William_Sound: 20 watersheds\n",
      "Cook_Inlet: 240 watersheds\n",
      "Bristol_Bay: 114 watersheds\n",
      "Process complete\n"
     ]
    }
   ],
   "source": [
    "#merge watersheds into one feature class for each region\n",
    "\n",
    "import arcpy\n",
    "arcpy.env.overwriteOutput = True\n",
    "regions = [\"Kodiak\", \"Copper_River\", \"Prince_William_Sound\", \"Cook_Inlet\", \"Bristol_Bay\"]\n",
    "c=1\n",
    "for region in regions:\n",
    "    local_gdb = \"D:\\\\GIS\\\\AKSSF\\\\\" + region + \"\\\\\" + region + \".gdb\"\n",
    "    arcpy.env.workspace = local_gdb + \"\\\\Watersheds\"\n",
    "    wtds = arcpy.ListFeatureClasses()\n",
    "    print(region + \": \" + str(len(wtds)) + \" watersheds\")\n",
    "    arcpy.env.workspace = local_gdb\n",
    "    wtdMerge = [local_gdb + \"\\\\Watersheds\\\\\" + s for s in wtds]\n",
    "    wtd_output = \"wtds_merge\"\n",
    "    wtd_merge = arcpy.Merge_management(wtdMerge, wtd_output)\n",
    "    #add region field\n",
    "    arcpy.AddField_management(wtd_merge,'region','TEXT')\n",
    "    calc =\"'\"+region+\"'\"\n",
    "    arcpy.CalculateField_management(wtd_merge,'region',calc)\n",
    "    c+=1\n",
    "print('Process complete')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430\n",
      "430\n"
     ]
    }
   ],
   "source": [
    "print(len(wtdDf))\n",
    "print(len(wtdList))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Also want to intersect sites with maximum flow accumulation in small (30 meters) buffer.  Buffers need to be generated\n",
    "iteratively and clipped to their respective catchment to ensure they don't pull values from an adjacent catchment.\n",
    "Need to join stream order, stream slope, and upstream downstream km info from vaa/streams merge datasets."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding cat_ID field..\n",
      "1. D:\\GIS\\AKSSF\\Kodiak\\Kodiak.gdb\\sites_sj has 33 records\n",
      "Adding cat_ID field..\n",
      "2. D:\\GIS\\AKSSF\\Copper_River\\Copper_River.gdb\\sites_sj has 31 records\n",
      "Adding cat_ID field..\n",
      "3. D:\\GIS\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\\sites_sj has 22 records\n",
      "Adding cat_ID field..\n",
      "4. D:\\GIS\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb\\sites_sj has 276 records\n",
      "Adding cat_ID field..\n",
      "5. D:\\GIS\\AKSSF\\Bristol_Bay\\Bristol_Bay.gdb\\sites_sj has 127 records\n",
      "Process completed at 2021-12-03 10:51 (Elapsed time: 0:00:30)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# steps 4-6\n",
    "import arcpy\n",
    "import os\n",
    "arcpy.env.overwriteOutput = True\n",
    "regions_dict = {\"Kodiak\": '!gridcode!', \"Copper_River\": '!NHDPlusID!', \"Prince_William_Sound\": '!gridcode!',\n",
    "                \"Cook_Inlet\": '!NHDPlusID!', \"Bristol_Bay\": '!catID!'}\n",
    "\n",
    "points = r\"C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\AKSSF\\\\hydrography\\\\AKSSF_Hydrography.gdb\\\\AKSSF_Sites_Shifted_2021202\"\n",
    "sites_lst = []\n",
    "cats_lst = []\n",
    "\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "c=1\n",
    "for key, value in regions_dict.items():\n",
    "    arcpy.env.workspace = \"D:\\\\GIS\\\\AKSSF\\\\\" + key + \"\\\\\" + key + \".gdb\"\n",
    "    cats = os.path.join(arcpy.env.workspace, \"cats_merge\")\n",
    "    pointlayer = arcpy.MakeFeatureLayer_management(points,'pointlayer')\n",
    "    pointselect = arcpy.SelectLayerByLocation_management(pointlayer,'INTERSECT',cats)\n",
    "    arcpy.SpatialJoin_analysis(pointselect, cats, \"sites_sj\")\n",
    "    # #note that catID is in the BB cats_merge, but only a LONG, need a DOUBLE to account for NHDPlusIDs\n",
    "    print('Adding cat_ID field..')\n",
    "    arcpy.AddField_management(\"sites_sj\", \"cat_ID\", \"DOUBLE\")\n",
    "    arcpy.CalculateField_management(\"sites_sj\", \"cat_ID\", value)\n",
    "    sites_fc = os.path.join(arcpy.env.workspace, \"sites_sj\")\n",
    "    count = arcpy.GetCount_management(sites_fc)\n",
    "    print('{}. {} has {} records'.format(c,sites_fc, count[0]))\n",
    "    sites_lst.append(sites_fc)\n",
    "    cats_lst.append(cats)\n",
    "    c+=1\n",
    "\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "\n",
    "# Report success\n",
    "print(f'Process completed at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "      f'(Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print('----------')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cook_Inlet in ['Cook_Inlet', 'Copper_River'] AKSSF list, using cat_fields ['cat_ID_txt', 'NHDPlusID', 'cat_ID_con'] and watershed fields ['cat_ID_txt', 'cat_ID', 'cat_ID_con']\n",
      "----------\n",
      "Cook_Inlet using data from D:\\\\GIS\\\\AKSSF\\Cook_Inlet folder\n",
      "Copying Cook_Inlet_cats_intersect...\n",
      "----------\n",
      "Adding cat_ID_txt field to catchment dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Cook_Inlet_cats_intersect\n",
      "----------\n",
      "Adding cat_ID_con field to catchment dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Cook_Inlet_cats_intersect\n",
      "----------\n",
      "Copying Cook_Inlet_wtds_merge...\n",
      "----------\n",
      "Adding cat_ID_txt field to watershed dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Cook_Inlet_wtds_merge\n",
      "----------\n",
      "Adding cat_ID_con field to watershed dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Cook_Inlet_wtds_merge\n",
      "----------\n",
      "D:\\GIS\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb,sites_sj\n",
      "Copying Cook_Inlet_sites_sj...\n",
      "----------\n",
      "Adding cat_ID_txt field to watershed dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Cook_Inlet_sites_sj\n",
      "----------\n",
      "Adding cat_ID_con field to watershed dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Cook_Inlet_sites_sj\n",
      "----------\n",
      "Copying Cook_Inlet_vaa_merge...\n",
      "----------\n",
      "Adding cat_ID_txt field to VAA Table dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Cook_Inlet_vaa_merge\n",
      "----------\n",
      "Adding cat_ID_con field to VAA Table dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Cook_Inlet_vaa_merge\n",
      "----------\n",
      "Copper_River in ['Cook_Inlet', 'Copper_River'] AKSSF list, using cat_fields ['cat_ID_txt', 'NHDPlusID', 'cat_ID_con'] and watershed fields ['cat_ID_txt', 'cat_ID', 'cat_ID_con']\n",
      "----------\n",
      "Copper_River using data from D:\\\\GIS\\\\AKSSF\\Copper_River folder\n",
      "Copying Copper_River_cats_intersect...\n",
      "----------\n",
      "Adding cat_ID_txt field to catchment dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Copper_River_cats_intersect\n",
      "----------\n",
      "Adding cat_ID_con field to catchment dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Copper_River_cats_intersect\n",
      "----------\n",
      "Copying Copper_River_wtds_merge...\n",
      "----------\n",
      "Adding cat_ID_txt field to watershed dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Copper_River_wtds_merge\n",
      "----------\n",
      "Adding cat_ID_con field to watershed dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Copper_River_wtds_merge\n",
      "----------\n",
      "D:\\GIS\\AKSSF\\Copper_River\\Copper_River.gdb,sites_sj\n",
      "Copying Copper_River_sites_sj...\n",
      "----------\n",
      "Adding cat_ID_txt field to watershed dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Copper_River_sites_sj\n",
      "----------\n",
      "Adding cat_ID_con field to watershed dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Copper_River_sites_sj\n",
      "----------\n",
      "Copying Copper_River_vaa_merge...\n",
      "----------\n",
      "Adding cat_ID_txt field to VAA Table dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Copper_River_vaa_merge\n",
      "----------\n",
      "Adding cat_ID_con field to VAA Table dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Copper_River_vaa_merge\n",
      "----------\n",
      "Bristol_Bay in ['Bristol_Bay', 'Kodiak', 'Prince_William_Sound'] TauDEM list, using cat_fields ['cat_ID_txt', 'catID', 'cat_ID_con'] and watershed fields ['cat_ID_txt', 'cat_ID', 'cat_ID_con']\n",
      "----------\n",
      "Bristol_Bay using data from D:\\\\GIS\\\\AKSSF\\Bristol_Bay folder\n",
      "Copying Bristol_Bay_streams_merge...\n",
      "----------\n",
      "Adding cat_ID_txt field to streams dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Bristol_Bay_streams_merge\n",
      "----------\n",
      "Adding cat_ID_con field to streams dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Bristol_Bay_streams_merge\n",
      "----------\n",
      "Copying Bristol_Bay_cats_intersect...\n",
      "----------\n",
      "Adding cat_ID_txt field to catchment dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Bristol_Bay_cats_intersect\n",
      "----------\n",
      "Adding cat_ID_con field to catchment dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Bristol_Bay_cats_intersect\n",
      "----------\n",
      "Copying Bristol_Bay_wtds_merge...\n",
      "----------\n",
      "Adding cat_ID_txt field to watershed dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Bristol_Bay_wtds_merge\n",
      "----------\n",
      "Adding cat_ID_con field to watershed dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Bristol_Bay_wtds_merge\n",
      "----------\n",
      "D:\\GIS\\AKSSF\\Bristol_Bay\\Bristol_Bay.gdb,sites_sj\n",
      "Copying Bristol_Bay_sites_sj...\n",
      "----------\n",
      "Adding cat_ID_txt field to watershed dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Bristol_Bay_sites_sj\n",
      "----------\n",
      "Adding cat_ID_con field to watershed dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Bristol_Bay_sites_sj\n",
      "----------\n",
      "Kodiak in ['Bristol_Bay', 'Kodiak', 'Prince_William_Sound'] TauDEM list, using cat_fields ['cat_ID_txt', 'gridcode', 'cat_ID_con'] and watershed fields ['cat_ID_txt', 'cat_ID', 'cat_ID_con']\n",
      "----------\n",
      "Kodiak using data from D:\\\\GIS\\\\AKSSF\\Kodiak folder\n",
      "Copying Kodiak_streams_merge...\n",
      "----------\n",
      "Adding cat_ID_txt field to streams dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Kodiak_streams_merge\n",
      "----------\n",
      "Adding cat_ID_con field to streams dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Kodiak_streams_merge\n",
      "----------\n",
      "Copying Kodiak_cats_intersect...\n",
      "----------\n",
      "Adding cat_ID_txt field to catchment dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Kodiak_cats_intersect\n",
      "----------\n",
      "Adding cat_ID_con field to catchment dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Kodiak_cats_intersect\n",
      "----------\n",
      "Copying Kodiak_wtds_merge...\n",
      "----------\n",
      "Adding cat_ID_txt field to watershed dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Kodiak_wtds_merge\n",
      "----------\n",
      "Adding cat_ID_con field to watershed dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Kodiak_wtds_merge\n",
      "----------\n",
      "D:\\GIS\\AKSSF\\Kodiak\\Kodiak.gdb,sites_sj\n",
      "Copying Kodiak_sites_sj...\n",
      "----------\n",
      "Adding cat_ID_txt field to watershed dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Kodiak_sites_sj\n",
      "----------\n",
      "Adding cat_ID_con field to watershed dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Kodiak_sites_sj\n",
      "----------\n",
      "Prince_William_Sound in ['Bristol_Bay', 'Kodiak', 'Prince_William_Sound'] TauDEM list, using cat_fields ['cat_ID_txt', 'gridcode', 'cat_ID_con'] and watershed fields ['cat_ID_txt', 'cat_ID', 'cat_ID_con']\n",
      "----------\n",
      "Prince_William_Sound using data from D:\\\\GIS\\\\AKSSF\\Prince_William_Sound folder\n",
      "Copying Prince_William_Sound_streams_merge...\n",
      "----------\n",
      "Adding cat_ID_txt field to streams dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Prince_William_Sound_streams_merge\n",
      "----------\n",
      "Adding cat_ID_con field to streams dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Prince_William_Sound_streams_merge\n",
      "----------\n",
      "Copying Prince_William_Sound_cats_intersect...\n",
      "----------\n",
      "Adding cat_ID_txt field to catchment dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Prince_William_Sound_cats_intersect\n",
      "----------\n",
      "Adding cat_ID_con field to catchment dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Prince_William_Sound_cats_intersect\n",
      "----------\n",
      "Copying Prince_William_Sound_wtds_merge...\n",
      "----------\n",
      "Adding cat_ID_txt field to watershed dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Prince_William_Sound_wtds_merge\n",
      "----------\n",
      "Adding cat_ID_con field to watershed dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Prince_William_Sound_wtds_merge\n",
      "----------\n",
      "D:\\GIS\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb,sites_sj\n",
      "Copying Prince_William_Sound_sites_sj...\n",
      "----------\n",
      "Adding cat_ID_txt field to watershed dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Prince_William_Sound_sites_sj\n",
      "----------\n",
      "Adding cat_ID_con field to watershed dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\Prince_William_Sound_sites_sj\n",
      "----------\n",
      "[<Result 'D:\\\\\\\\GIS\\\\\\\\AKSSF_land_met\\\\\\\\AKSSF_land_met.gdb\\\\Cook_Inlet_cats_intersect'>, <Result 'D:\\\\\\\\GIS\\\\\\\\AKSSF_land_met\\\\\\\\AKSSF_land_met.gdb\\\\Copper_River_cats_intersect'>, <Result 'D:\\\\\\\\GIS\\\\\\\\AKSSF_land_met\\\\\\\\AKSSF_land_met.gdb\\\\Bristol_Bay_cats_intersect'>, <Result 'D:\\\\\\\\GIS\\\\\\\\AKSSF_land_met\\\\\\\\AKSSF_land_met.gdb\\\\Kodiak_cats_intersect'>, <Result 'D:\\\\\\\\GIS\\\\\\\\AKSSF_land_met\\\\\\\\AKSSF_land_met.gdb\\\\Prince_William_Sound_cats_intersect'>]\n",
      "[<Result 'D:\\\\\\\\GIS\\\\\\\\AKSSF_land_met\\\\\\\\AKSSF_land_met.gdb\\\\Cook_Inlet_sites_sj'>, <Result 'D:\\\\\\\\GIS\\\\\\\\AKSSF_land_met\\\\\\\\AKSSF_land_met.gdb\\\\Copper_River_sites_sj'>, <Result 'D:\\\\\\\\GIS\\\\\\\\AKSSF_land_met\\\\\\\\AKSSF_land_met.gdb\\\\Bristol_Bay_sites_sj'>, <Result 'D:\\\\\\\\GIS\\\\\\\\AKSSF_land_met\\\\\\\\AKSSF_land_met.gdb\\\\Kodiak_sites_sj'>, <Result 'D:\\\\\\\\GIS\\\\\\\\AKSSF_land_met\\\\\\\\AKSSF_land_met.gdb\\\\Prince_William_Sound_sites_sj'>]\n",
      "[<Result 'D:\\\\\\\\GIS\\\\\\\\AKSSF_land_met\\\\\\\\AKSSF_land_met.gdb\\\\Cook_Inlet_vaa_merge'>, <Result 'D:\\\\\\\\GIS\\\\\\\\AKSSF_land_met\\\\\\\\AKSSF_land_met.gdb\\\\Copper_River_vaa_merge'>]\n",
      "[<Result 'D:\\\\\\\\GIS\\\\\\\\AKSSF_land_met\\\\\\\\AKSSF_land_met.gdb\\\\Bristol_Bay_streams_merge'>, <Result 'D:\\\\\\\\GIS\\\\\\\\AKSSF_land_met\\\\\\\\AKSSF_land_met.gdb\\\\Kodiak_streams_merge'>, <Result 'D:\\\\\\\\GIS\\\\\\\\AKSSF_land_met\\\\\\\\AKSSF_land_met.gdb\\\\Prince_William_Sound_streams_merge'>]\n",
      "[<Result 'D:\\\\\\\\GIS\\\\\\\\AKSSF_land_met\\\\\\\\AKSSF_land_met.gdb\\\\Cook_Inlet_wtds_merge'>, <Result 'D:\\\\\\\\GIS\\\\\\\\AKSSF_land_met\\\\\\\\AKSSF_land_met.gdb\\\\Copper_River_wtds_merge'>, <Result 'D:\\\\\\\\GIS\\\\\\\\AKSSF_land_met\\\\\\\\AKSSF_land_met.gdb\\\\Bristol_Bay_wtds_merge'>, <Result 'D:\\\\\\\\GIS\\\\\\\\AKSSF_land_met\\\\\\\\AKSSF_land_met.gdb\\\\Kodiak_wtds_merge'>, <Result 'D:\\\\\\\\GIS\\\\\\\\AKSSF_land_met\\\\\\\\AKSSF_land_met.gdb\\\\Prince_William_Sound_wtds_merge'>]\n"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Setting outgdb to location created in Covariate notebook but any temp gdb will work\n",
    "outgdb = r\"D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\"\n",
    "# Set data dir = to folder with regional subfolders and gdbs\n",
    "data_dir = r\"D:\\\\GIS\\\\AKSSF\"\n",
    "arcpy.env.workspace = data_dir\n",
    "arcpy.env.overwriteOutput = True\n",
    "sr = arcpy.SpatialReference(3338)  #'NAD_1983_Alaska_Albers'\n",
    "arcpy.env.outputCoordinateSystem = sr\n",
    "regions = arcpy.ListWorkspaces(workspace_type=\"Folder\")\n",
    "\n",
    "# Create lists to store paths to data copies to be merged\n",
    "site_lst = []\n",
    "cats_lst = []\n",
    "vaas_lst = []\n",
    "streams_lst = []\n",
    "wtds_lst = []\n",
    "\n",
    "# Walk through gdbs and select sites_sj, streams and vaas to merge into single fcs\n",
    "# Separate data by\n",
    "nhdplus_dat = ['Cook_Inlet', 'Copper_River']\n",
    "tauDem_dat = ['Bristol_Bay', 'Kodiak', 'Prince_William_Sound']\n",
    "# Loop through all processing areas\n",
    "rois = nhdplus_dat + tauDem_dat\n",
    "for roi in rois:\n",
    "    # Loop through regional folders\n",
    "    for region in regions:\n",
    "        if roi in str(region):\n",
    "            if roi in nhdplus_dat:\n",
    "                cat_cur_fields = ['cat_ID_txt', 'NHDPlusID', \"cat_ID_con\"]\n",
    "                sj_cur_fields = ['cat_ID_txt', 'cat_ID', \"cat_ID_con\"]\n",
    "                wtd_cur_fields = ['cat_ID_txt', 'cat_ID', \"cat_ID_con\"]\n",
    "                str_cur_fields = ['cat_ID_txt', 'NHDPlusID', \"cat_ID_con\"]\n",
    "                print(\n",
    "                    f'{roi} in {nhdplus_dat} AKSSF list, using cat_fields {cat_cur_fields} and watershed fields {sj_cur_fields}')\n",
    "                print('----------')\n",
    "            # Set data and variables unique to regions with TauDEM Data\n",
    "            elif roi in tauDem_dat:\n",
    "                if roi == 'Bristol_Bay':\n",
    "                    # Fields for update cursor\n",
    "                    cat_cur_fields = ['cat_ID_txt', 'catID', \"cat_ID_con\"]\n",
    "                    sj_cur_fields = ['cat_ID_txt', 'cat_ID', \"cat_ID_con\"]\n",
    "                    wtd_cur_fields = ['cat_ID_txt', 'cat_ID', \"cat_ID_con\"]\n",
    "                    str_cur_fields = ['cat_ID_txt', 'catID', \"cat_ID_con\"]\n",
    "                else:\n",
    "                    cat_cur_fields = ['cat_ID_txt', 'gridcode', \"cat_ID_con\"]\n",
    "                    wtd_cur_fields = ['cat_ID_txt', 'cat_ID', \"cat_ID_con\"]\n",
    "                    sj_cur_fields = ['cat_ID_txt', 'cat_ID', \"cat_ID_con\"]\n",
    "                    str_cur_fields = ['cat_ID_txt', 'LINKNO', \"cat_ID_con\"]\n",
    "\n",
    "                print(\n",
    "                    f'{roi} in {tauDem_dat} TauDEM list, using cat_fields {cat_cur_fields} and watershed fields {sj_cur_fields}')\n",
    "                print('----------')\n",
    "            print(f'{roi} using data from {region} folder')\n",
    "            arcpy.env.workspace = region\n",
    "            gdb = arcpy.ListWorkspaces(workspace_type='FileGDB')\n",
    "            walk = arcpy.da.Walk(region, datatype=['FeatureClass', 'Table'])\n",
    "            for dirpath, dirnames, filenames in walk:\n",
    "                for filename in filenames:\n",
    "                    # Grab sites\n",
    "                    if filename == 'sites_sj':\n",
    "                        print(f'{dirpath},{filename}')\n",
    "                        sitesource = os.path.join(dirpath, filename)\n",
    "                        sitename = roi + '_' + filename\n",
    "                        sitepath = os.path.join(outgdb, sitename)\n",
    "                        # Make local copy projected in AKAlbers\n",
    "                        if not arcpy.Exists(sitepath):\n",
    "                            print(f'Copying {sitename}...')\n",
    "                            print('----------')\n",
    "                            sitecopy = arcpy.FeatureClassToFeatureClass_conversion(sitesource, outgdb, sitename)\n",
    "                        else:\n",
    "                            print(f'{sitepath} already created')\n",
    "                            sitecopy = sitepath\n",
    "                            print('----------')\n",
    "                        site_lst.append(sitecopy)\n",
    "                        sitefieldnames = []\n",
    "                        sitelstFields = arcpy.ListFields(sitecopy)\n",
    "                        for field in sitelstFields:\n",
    "                            sitefieldnames.append(field.name)\n",
    "                        if str(sj_cur_fields[0]) in sitefieldnames:\n",
    "                            print(f'{sj_cur_fields[0]} field already in dataset')\n",
    "                            print('----------')\n",
    "                        else:\n",
    "                            print(f'Adding {sj_cur_fields[0]} field to watershed dataset {sitecopy}')\n",
    "                            print('----------')\n",
    "                            # add cat_ID_txt field and concat cat_ID + region\n",
    "                            arcpy.AddField_management(sitecopy, str(sj_cur_fields[0]), field_type='TEXT')\n",
    "                            # populate cat_ID_txt\n",
    "                            with arcpy.da.UpdateCursor(sitecopy, sj_cur_fields[0:2]) as cur:\n",
    "                                for row in cur:\n",
    "                                    strval = str(row[1])\n",
    "                                    row[0] = strval.replace('.0', '')\n",
    "                                    # Update rows\n",
    "                                    cur.updateRow(row)\n",
    "                                del (row)\n",
    "                            del (cur)\n",
    "                        if str(sj_cur_fields[2]) in sitefieldnames:\n",
    "                            print(f'{sj_cur_fields[2]} field already in dataset {sitecopy}')\n",
    "                            print('----------')\n",
    "                        else:\n",
    "                            print(f'Adding {sj_cur_fields[2]} field to watershed dataset {sitecopy}')\n",
    "                            print('----------')\n",
    "                            # add cat_ID_con field and concat cat_ID + region\n",
    "                            arcpy.AddField_management(sitecopy, str(sj_cur_fields[2]), field_type='TEXT')\n",
    "                            # populate cat_ID_txt\n",
    "                            with arcpy.da.UpdateCursor(sitecopy, sj_cur_fields) as cur:\n",
    "                                for row in cur:\n",
    "                                    strval = str(row[1])\n",
    "                                    row[2] = str(roi) + '_' + strval.replace('.0', '')\n",
    "                                    # Update rows\n",
    "                                    cur.updateRow(row)\n",
    "                                del (row)\n",
    "                            del (cur)\n",
    "                    # Set merged streams dataset\n",
    "                    elif 'streams_merge' == filename:\n",
    "                        strsource = os.path.join(dirpath, filename)\n",
    "                        strname = roi + '_' + filename\n",
    "                        strpath = os.path.join(outgdb, strname)\n",
    "\n",
    "                        if not arcpy.Exists(strpath):\n",
    "                            print(f'Copying {strname}...')\n",
    "                            print('----------')\n",
    "                            # Make local copy projected in AKAlbers\n",
    "                            str_merge = arcpy.FeatureClassToFeatureClass_conversion(strsource, outgdb, strname)\n",
    "                        else:\n",
    "                            print(f'Merged streams dataset {strpath} already created...')\n",
    "                            print('----------')\n",
    "                            str_merge = strpath\n",
    "                        streams_lst.append(str_merge)\n",
    "                        strfieldnames = []\n",
    "                        strlstFields = arcpy.ListFields(str_merge)\n",
    "                        for field in strlstFields:\n",
    "                            strfieldnames.append(field.name)\n",
    "                        if str(str_cur_fields[0]) in strfieldnames:\n",
    "                            print(f'{str_cur_fields[0]} field already in dataset')\n",
    "                            print('----------')\n",
    "                        else:\n",
    "                            print(f'Adding {str_cur_fields[0]} field to streams dataset {str_merge}')\n",
    "                            print('----------')\n",
    "                            # add cat_ID_txt field and concat cat_ID + region\n",
    "                            arcpy.AddField_management(str_merge, str(str_cur_fields[0]), field_type='TEXT')\n",
    "                            # populate cat_ID_txt\n",
    "                            with arcpy.da.UpdateCursor(str_merge, str_cur_fields[0:2]) as cur:\n",
    "                                for row in cur:\n",
    "                                    strval = str(row[1])\n",
    "                                    row[0] = strval.replace('.0', '')\n",
    "                                    # Update rows\n",
    "                                    cur.updateRow(row)\n",
    "                                del (row)\n",
    "                            del (cur)\n",
    "                        if str(str_cur_fields[2]) in strfieldnames:\n",
    "                            print(f'{str_cur_fields[2]} field already in dataset {str_merge}')\n",
    "                            print('----------')\n",
    "                        else:\n",
    "                            print(f'Adding {str_cur_fields[2]} field to streams dataset {str_merge}')\n",
    "                            print('----------')\n",
    "                            # add cat_ID_con field and concat cat_ID + region\n",
    "                            arcpy.AddField_management(str_merge, str(str_cur_fields[2]), field_type='TEXT')\n",
    "                            # populate cat_ID_txt\n",
    "                            with arcpy.da.UpdateCursor(str_merge, str_cur_fields) as cur:\n",
    "                                for row in cur:\n",
    "                                    strval = str(row[1])\n",
    "                                    row[2] = str(roi) + '_' + strval.replace(\".0\", \"\")\n",
    "                                    # Update rows\n",
    "                                    cur.updateRow(row)\n",
    "                                del (row)\n",
    "                            del (cur)\n",
    "\n",
    "                    # Set merged VAA Table dataset\n",
    "                    elif 'vaa_merge' == filename:\n",
    "                        vaasource = os.path.join(dirpath, filename)\n",
    "                        vaaname = roi + '_' + filename\n",
    "                        vaa_path = os.path.join(outgdb, vaaname)\n",
    "                        if not arcpy.Exists(vaa_path):\n",
    "                            print(f'Copying {vaaname}...')\n",
    "                            print('----------')\n",
    "                            # Make local copy projected in AKAlbers\n",
    "                            vaa_merge = arcpy.TableToTable_conversion(vaasource, outgdb, vaaname)\n",
    "                        else:\n",
    "                            print(f'Merged VAA Table dataset {vaa_path} already created...')\n",
    "                            print('----------')\n",
    "                            vaa_merge = vaa_path\n",
    "                        vaas_lst.append(vaa_merge)\n",
    "                        vaafieldnames = []\n",
    "                        vaalstFields = arcpy.ListFields(vaa_merge)\n",
    "                        for field in vaalstFields:\n",
    "                            vaafieldnames.append(field.name)\n",
    "                        if str(str_cur_fields[0]) in vaafieldnames:\n",
    "                            print(f'{str_cur_fields[0]} field already in dataset')\n",
    "                            print('----------')\n",
    "                        else:\n",
    "                            print(f'Adding {str_cur_fields[0]} field to VAA Table dataset {vaa_merge}')\n",
    "                            print('----------')\n",
    "                            # add cat_ID_txt field and concat cat_ID + region\n",
    "                            arcpy.AddField_management(vaa_merge, str(str_cur_fields[0]), field_type='TEXT')\n",
    "                            # populate cat_ID_txt\n",
    "                            with arcpy.da.UpdateCursor(vaa_merge, str_cur_fields[0:2]) as cur:\n",
    "                                for row in cur:\n",
    "                                    strval = str(row[1])\n",
    "                                    row[0] = strval.replace('.0', '')\n",
    "                                    # Update rows\n",
    "                                    cur.updateRow(row)\n",
    "                                del (row)\n",
    "                            del (cur)\n",
    "                        if str(str_cur_fields[2]) in vaafieldnames:\n",
    "                            print(f'{str_cur_fields[2]} field already in dataset {vaa_merge}')\n",
    "                            print('----------')\n",
    "                        else:\n",
    "                            print(f'Adding {str_cur_fields[2]} field to VAA Table dataset {vaa_merge}')\n",
    "                            print('----------')\n",
    "                            # add cat_ID_con field and concat cat_ID + region\n",
    "                            arcpy.AddField_management(vaa_merge, str(str_cur_fields[2]), field_type='TEXT')\n",
    "                            # populate cat_ID_txt\n",
    "                            with arcpy.da.UpdateCursor(vaa_merge, str_cur_fields) as cur:\n",
    "                                for row in cur:\n",
    "                                    strval = str(row[1])\n",
    "                                    row[2] = str(roi) + '_' + strval.replace(\".0\", \"\")\n",
    "                                    # Update rows\n",
    "                                    cur.updateRow(row)\n",
    "                                del (row)\n",
    "                            del (cur)\n",
    "                    # Set merged watersheds dataset\n",
    "                    elif 'wtds_merge' == filename:\n",
    "                        wtdsource = os.path.join(dirpath, filename)\n",
    "                        wtdname = roi + '_' + filename\n",
    "                        wtdpath = os.path.join(outgdb, wtdname)\n",
    "\n",
    "                        if not arcpy.Exists(wtdpath):\n",
    "                            print(f'Copying {wtdname}...')\n",
    "                            print('----------')\n",
    "                            # Make local copy projected in AKAlbers\n",
    "                            wtd_merge = arcpy.FeatureClassToFeatureClass_conversion(wtdsource, outgdb, wtdname)\n",
    "                        else:\n",
    "                            print(f'Merged watershed dataset {wtdpath} already created...')\n",
    "                            print('----------')\n",
    "                            wtd_merge = wtdpath\n",
    "                        wtds_lst.append(wtd_merge)\n",
    "                        wtdfieldnames = []\n",
    "                        wtdlstFields = arcpy.ListFields(wtd_merge)\n",
    "                        for field in wtdlstFields:\n",
    "                            wtdfieldnames.append(field.name)\n",
    "                        if str(wtd_cur_fields[0]) in wtdfieldnames:\n",
    "                            print(f'{wtd_cur_fields[0]} field already in dataset')\n",
    "                            print('----------')\n",
    "                        else:\n",
    "                            print(f'Adding {wtd_cur_fields[0]} field to watershed dataset {wtd_merge}')\n",
    "                            print('----------')\n",
    "                            # add cat_ID_txt field and concat cat_ID + region\n",
    "                            arcpy.AddField_management(wtd_merge, str(wtd_cur_fields[0]), field_type='TEXT')\n",
    "                            # populate cat_ID_txt\n",
    "                            with arcpy.da.UpdateCursor(wtd_merge, wtd_cur_fields[0:2]) as cur:\n",
    "                                for row in cur:\n",
    "                                    strval = str(row[1])\n",
    "                                    row[0] = strval.replace('.0', '')\n",
    "                                    # Update rows\n",
    "                                    cur.updateRow(row)\n",
    "                                del (row)\n",
    "                            del (cur)\n",
    "                        if str(wtd_cur_fields[2]) in wtdfieldnames:\n",
    "                            print(f'{wtd_cur_fields[2]} field already in dataset {wtd_merge}')\n",
    "                            print('----------')\n",
    "                        else:\n",
    "                            print(f'Adding {wtd_cur_fields[2]} field to watershed dataset {wtd_merge}')\n",
    "                            print('----------')\n",
    "                            # add cat_ID_con field and concat cat_ID + region\n",
    "                            arcpy.AddField_management(wtd_merge, str(wtd_cur_fields[2]), field_type='TEXT')\n",
    "                            # populate cat_ID_txt\n",
    "                            with arcpy.da.UpdateCursor(wtd_merge, wtd_cur_fields) as cur:\n",
    "                                for row in cur:\n",
    "                                    strval = str(row[1])\n",
    "                                    row[2] = str(roi) + '_' + strval.replace(\".0\", \"\")\n",
    "                                    # Update rows\n",
    "                                    cur.updateRow(row)\n",
    "                                del (row)\n",
    "                            del (cur)\n",
    "\n",
    "                    # Select catch_int fc (catchments of interest for region) and make a copy\n",
    "                    elif 'cats_intersect' == filename:\n",
    "                        # Make local copy projected in AKAlbers\n",
    "                        catssource = os.path.join(dirpath, filename)\n",
    "                        catsname = roi + \"_\" + filename\n",
    "                        catspath = os.path.join(outgdb, catsname)\n",
    "                        if not arcpy.Exists(catspath):\n",
    "                            print(f'Copying {catsname}...')\n",
    "                            print('----------')\n",
    "                            cats = arcpy.FeatureClassToFeatureClass_conversion(catssource, outgdb, catsname)\n",
    "                        else:\n",
    "                            print(f'{catspath} already created')\n",
    "                            print('----------')\n",
    "                            cats = catspath\n",
    "                        cats_lst.append(cats)\n",
    "                        catlstfields = arcpy.ListFields(cats)\n",
    "                        catfieldnames = []\n",
    "                        for field in catlstfields:\n",
    "                            catfieldnames.append(field.name)\n",
    "                        if str(cat_cur_fields[0]) in catfieldnames:\n",
    "                            print(f'{cat_cur_fields[0]} field already in dataset {cats}')\n",
    "                            print('----------')\n",
    "                        else:\n",
    "                            print(f'Adding {cat_cur_fields[0]} field to catchment dataset {cats}')\n",
    "                            print('----------')\n",
    "                            # add cat_ID_txt field\n",
    "                            arcpy.AddField_management(cats, str(cat_cur_fields[0]), field_type='TEXT')\n",
    "                            # populate cat_ID_txt\n",
    "                            with arcpy.da.UpdateCursor(cats, cat_cur_fields[0:2]) as cur:\n",
    "                                for row in cur:\n",
    "                                    strval = str(row[1])\n",
    "                                    row[0] = strval.replace('.0', '')\n",
    "                                    # Update rows\n",
    "                                    cur.updateRow(row)\n",
    "                                del (row)\n",
    "                            del (cur)\n",
    "                        if str(cat_cur_fields[2]) in catfieldnames:\n",
    "                            print(f'{cat_cur_fields[2]} field already in dataset {cats}')\n",
    "                            print('----------')\n",
    "                        else:\n",
    "                            print(f'Adding {cat_cur_fields[2]} field to catchment dataset {cats}')\n",
    "                            print('----------')\n",
    "                            # add cat_ID_txt field & cat_ID + region concat field\n",
    "                            arcpy.AddField_management(cats, str(cat_cur_fields[2]), field_type='TEXT')\n",
    "                            # populate cat_ID_con\n",
    "                            with arcpy.da.UpdateCursor(cats, cat_cur_fields) as cur:\n",
    "                                for row in cur:\n",
    "                                    strval = str(row[1])\n",
    "                                    row[2] = str(roi) + '_' + strval.replace(\".0\", \"\")\n",
    "                                    # Update rows\n",
    "                                    cur.updateRow(row)\n",
    "                                del (row)\n",
    "                            del (cur)\n",
    "print(cats_lst)\n",
    "print(site_lst)\n",
    "print(vaas_lst)\n",
    "print(streams_lst)\n",
    "print(wtds_lst)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Merge collected datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\all_sites_sj_merge...\n",
      " '----------' \n",
      "Merging dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\all_cats_int_merge...\n",
      " '----------' \n",
      "Merging dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\all_vaas_merge...\n",
      " '----------' \n",
      "Merging dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\all_taustreams_merge...\n",
      " '----------' \n",
      "Merging dataset D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\\all_wtds_merge...\n",
      " '----------' \n",
      "Process completed at 2021-12-03 10:58 (Elapsed time: 0:00:36)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "sr = arcpy.SpatialReference(3338)  #'NAD_1983_Alaska_Albers'\n",
    "arcpy.env.outputCoordinateSystem = sr\n",
    "\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "\n",
    "outcats = os.path.join(outgdb, \"all_cats_int_merge\")\n",
    "outsites = os.path.join(outgdb, \"all_sites_sj_merge\")\n",
    "outvaa = os.path.join(outgdb, \"all_vaas_merge\")\n",
    "outwtd = os.path.join(outgdb, \"all_wtds_merge\")\n",
    "outwtd1 = os.path.join(r'memory/', \"all_wtds_merge\")\n",
    "outstreams = os.path.join(outgdb, \"all_taustreams_merge\")\n",
    "print(f\"Merging dataset {outsites}...\\n '----------' \")\n",
    "sitesmerge = arcpy.Merge_management(site_lst, outsites, \"\", \"ADD_SOURCE_INFO\")\n",
    "print(f\"Merging dataset {outcats}...\\n '----------' \")\n",
    "catsmerge = arcpy.Merge_management(cats_lst, outcats, \"\", \"ADD_SOURCE_INFO\")\n",
    "print(f\"Merging dataset {outvaa}...\\n '----------' \")\n",
    "vaasmerge = arcpy.Merge_management(vaas_lst, outvaa, \"\", \"ADD_SOURCE_INFO\")\n",
    "print(f\"Merging dataset {outstreams}...\\n '----------' \")\n",
    "streamsmerge = arcpy.Merge_management(streams_lst, outstreams, \"\", \"ADD_SOURCE_INFO\")\n",
    "print(f\"Merging dataset {outwtd}...\\n '----------' \")\n",
    "wtdsmerge1 = arcpy.Merge_management(wtds_lst, outwtd1, \"\", \"ADD_SOURCE_INFO\")\n",
    "wtdsmerge = arcpy.EliminatePolygonPart_management(wtdsmerge1,outwtd,\"PERCENT\", \"0 SquareKilometers\", 90, \"CONTAINED_ONLY\")\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "\n",
    "# Report success\n",
    "print(f'Process completed at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "      f'(Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print('----------')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Buffer and clip sites\n",
    "Buffer sites by 30 meters and loop through each site and clip to its respective catchment.  Merge all clips together\n",
    "when complete"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489\n",
      "Site ID: APU1 OK\n",
      " 1 of 489 -  Clipping APU1 to Cook_Inlet_75004300004192...\n",
      "----------\n",
      "Site ID: APU10 OK\n",
      " 2 of 489 -  Clipping APU10 to Cook_Inlet_75004300004192...\n",
      "----------\n",
      "Site ID: APU11 OK\n",
      " 3 of 489 -  Clipping APU11 to Cook_Inlet_75004300004304...\n",
      "----------\n",
      "Site ID: APU12 OK\n",
      " 4 of 489 -  Clipping APU12 to Cook_Inlet_75004300005245...\n",
      "----------\n",
      "Site ID: APU2 OK\n",
      " 5 of 489 -  Clipping APU2 to Cook_Inlet_75004300003171...\n",
      "----------\n",
      "Site ID: APU3 OK\n",
      " 6 of 489 -  Clipping APU3 to Cook_Inlet_75004300006312...\n",
      "----------\n",
      "Site ID: APU5 OK\n",
      " 7 of 489 -  Clipping APU5 to Cook_Inlet_75004300002142...\n",
      "----------\n",
      "Site ID: APU6 OK\n",
      " 8 of 489 -  Clipping APU6 to Cook_Inlet_75004300007324...\n",
      "----------\n",
      "Site ID: APU7 OK\n",
      " 9 of 489 -  Clipping APU7 to Cook_Inlet_75004300001288...\n",
      "----------\n",
      "Site ID: APU8 OK\n",
      " 10 of 489 -  Clipping APU8 to Cook_Inlet_75004300002332...\n",
      "----------\n",
      "Site ID: APU9 OK\n",
      " 11 of 489 -  Clipping APU9 to Cook_Inlet_75004300004254...\n",
      "----------\n",
      "Site ID: AR2 OK\n",
      " 12 of 489 -  Clipping AR2 to Cook_Inlet_75004300004341...\n",
      "----------\n",
      "Site ID: CIK1 OK\n",
      " 13 of 489 -  Clipping CIK1 to Cook_Inlet_75004300000100...\n",
      "----------\n",
      "Site ID: CIK2 OK\n",
      " 14 of 489 -  Clipping CIK2 to Cook_Inlet_75004300002142...\n",
      "----------\n",
      "Site ID: CIK3 OK\n",
      " 15 of 489 -  Clipping CIK3 to Cook_Inlet_75004300002289...\n",
      "----------\n",
      "Site ID: CIK4 OK\n",
      " 16 of 489 -  Clipping CIK4 to Cook_Inlet_75004300005303...\n",
      "----------\n",
      "Site ID: CIK6 OK\n",
      " 17 of 489 -  Clipping CIK6 to Cook_Inlet_75004300006376...\n",
      "----------\n",
      "Site ID: CIK7 OK\n",
      " 18 of 489 -  Clipping CIK7 to Cook_Inlet_75004300000311...\n",
      "----------\n",
      "Site ID: CIK8 OK\n",
      " 19 of 489 -  Clipping CIK8 to Cook_Inlet_75004300004452...\n",
      "----------\n",
      "Site ID: COTT-A OK\n",
      " 20 of 489 -  Clipping COTT-A to Cook_Inlet_75004300003409...\n",
      "----------\n",
      "Site ID: COTT-C OK\n",
      " 21 of 489 -  Clipping COTT-C to Cook_Inlet_75004300005352...\n",
      "----------\n",
      "Site ID: COTT-W OK\n",
      " 22 of 489 -  Clipping COTT-W to Cook_Inlet_75004300003171...\n",
      "----------\n",
      "Site ID: NANC OK\n",
      " 23 of 489 -  Clipping NANC to Cook_Inlet_75004300001162...\n",
      "----------\n",
      "Site ID: NANC-44-L OK\n",
      " 24 of 489 -  Clipping NANC-44-L to Cook_Inlet_75004300003171...\n",
      "----------\n",
      "Site ID: NANC-44-M OK\n",
      " 25 of 489 -  Clipping NANC-44-M to Cook_Inlet_75004300003171...\n",
      "----------\n",
      "Site ID: NANC-44-U OK\n",
      " 26 of 489 -  Clipping NANC-44-U to Cook_Inlet_75004300003171...\n",
      "----------\n",
      "Site ID: PJ Lower OK\n",
      " 27 of 489 -  Clipping PJ Lower to Cook_Inlet_75004300001207...\n",
      "----------\n",
      "Site ID: PJ Mid OK\n",
      " 28 of 489 -  Clipping PJ Mid to Cook_Inlet_75004300002278...\n",
      "----------\n",
      "Site ID: SANC OK\n",
      " 29 of 489 -  Clipping SANC to Cook_Inlet_75004300002207...\n",
      "----------\n",
      "Site ID: SANC-1203-L OK\n",
      " 30 of 489 -  Clipping SANC-1203-L to Cook_Inlet_75004300005437...\n",
      "----------\n",
      "Site ID: SANC-1203-M OK\n",
      " 31 of 489 -  Clipping SANC-1203-M to Cook_Inlet_75004300006440...\n",
      "----------\n",
      "Site ID: SANC-1203-U OK\n",
      " 32 of 489 -  Clipping SANC-1203-U to Cook_Inlet_75004300006440...\n",
      "----------\n",
      "Site ID: STAR OK\n",
      " 33 of 489 -  Clipping STAR to Cook_Inlet_75004300004217...\n",
      "----------\n",
      "Site ID: STAR-171-M OK\n",
      " 34 of 489 -  Clipping STAR-171-M to Cook_Inlet_75004300000101...\n",
      "----------\n",
      "Site ID: STAR-171-U OK\n",
      " 35 of 489 -  Clipping STAR-171-U to Cook_Inlet_75004300001210...\n",
      "----------\n",
      "Site ID: STAR-69-L OK\n",
      " 36 of 489 -  Clipping STAR-69-L to Cook_Inlet_75004300005171...\n",
      "----------\n",
      "Site ID: STAR-69-M OK\n",
      " 37 of 489 -  Clipping STAR-69-M to Cook_Inlet_75004300005171...\n",
      "----------\n",
      "Site ID: STAR-69-U OK\n",
      " 38 of 489 -  Clipping STAR-69-U to Cook_Inlet_75004300002314...\n",
      "----------\n",
      "Site ID: STAR-A OK\n",
      " 39 of 489 -  Clipping STAR-A to Cook_Inlet_75004300003464...\n",
      "----------\n",
      "Site ID: STAR-W OK\n",
      " 40 of 489 -  Clipping STAR-W to Cook_Inlet_75004300002352...\n",
      "----------\n",
      "Site ID: STAR 171 Lower OK\n",
      " 41 of 489 -  Clipping STAR 171 Lower to Cook_Inlet_75004300000101...\n",
      "----------\n",
      "Site ID: STAR 171 Upper OK\n",
      " 42 of 489 -  Clipping STAR 171 Upper to Cook_Inlet_75004300000101...\n",
      "----------\n",
      "Site ID: CIK_0 OK\n",
      " 43 of 489 -  Clipping CIK_0 to Cook_Inlet_75000400014405...\n",
      "----------\n",
      "Site ID: CIK_1 OK\n",
      " 44 of 489 -  Clipping CIK_1 to Cook_Inlet_75000100002463...\n",
      "----------\n",
      "Site ID: CIK_10 OK\n",
      " 45 of 489 -  Clipping CIK_10 to Cook_Inlet_75004400008917...\n",
      "----------\n",
      "Site ID: CIK_11 OK\n",
      " 46 of 489 -  Clipping CIK_11 to Cook_Inlet_75004400007385...\n",
      "----------\n",
      "Site ID: CIK_12 OK\n",
      " 47 of 489 -  Clipping CIK_12 to Cook_Inlet_75004400010320...\n",
      "----------\n",
      "Site ID: CIK_13 OK\n",
      " 48 of 489 -  Clipping CIK_13 to Cook_Inlet_75004400007387...\n",
      "----------\n",
      "Site ID: CIK_14 OK\n",
      " 49 of 489 -  Clipping CIK_14 to Cook_Inlet_75004300004192...\n",
      "----------\n",
      "Site ID: CIK_15 OK\n",
      " 50 of 489 -  Clipping CIK_15 to Cook_Inlet_75004300004324...\n",
      "----------\n",
      "Site ID: CIK_16 OK\n",
      " 51 of 489 -  Clipping CIK_16 to Cook_Inlet_75004400000627...\n",
      "----------\n",
      "Site ID: CIK_17 OK\n",
      " 52 of 489 -  Clipping CIK_17 to Cook_Inlet_75004400009144...\n",
      "----------\n",
      "Site ID: CIK_18 OK\n",
      " 53 of 489 -  Clipping CIK_18 to Cook_Inlet_75004300006239...\n",
      "----------\n",
      "Site ID: CIK_19 OK\n",
      " 54 of 489 -  Clipping CIK_19 to Cook_Inlet_75004300007331...\n",
      "----------\n",
      "Site ID: CIK_2 OK\n",
      " 55 of 489 -  Clipping CIK_2 to Cook_Inlet_75000100000059...\n",
      "----------\n",
      "Site ID: CIK_20 OK\n",
      " 56 of 489 -  Clipping CIK_20 to Cook_Inlet_75004300000856...\n",
      "----------\n",
      "Site ID: CIK_21 OK\n",
      " 57 of 489 -  Clipping CIK_21 to Cook_Inlet_75004300006013...\n",
      "----------\n",
      "Site ID: CIK_22 OK\n",
      " 58 of 489 -  Clipping CIK_22 to Cook_Inlet_75004400000576...\n",
      "----------\n",
      "Site ID: CIK_23 OK\n",
      " 59 of 489 -  Clipping CIK_23 to Cook_Inlet_75004400001568...\n",
      "----------\n",
      "Site ID: CIK_24 OK\n",
      " 60 of 489 -  Clipping CIK_24 to Cook_Inlet_75004300001906...\n",
      "----------\n",
      "Site ID: CIK_25 OK\n",
      " 61 of 489 -  Clipping CIK_25 to Cook_Inlet_75000200002930...\n",
      "----------\n",
      "Site ID: CIK_26 OK\n",
      " 62 of 489 -  Clipping CIK_26 to Cook_Inlet_75000200010144...\n",
      "----------\n",
      "Site ID: CIK_27 OK\n",
      " 63 of 489 -  Clipping CIK_27 to Cook_Inlet_75000100002523...\n",
      "----------\n",
      "Site ID: CIK_28 OK\n",
      " 64 of 489 -  Clipping CIK_28 to Cook_Inlet_75000200015900...\n",
      "----------\n",
      "Site ID: CIK_29 OK\n",
      " 65 of 489 -  Clipping CIK_29 to Cook_Inlet_75000200018577...\n",
      "----------\n",
      "Site ID: CIK_3 OK\n",
      " 66 of 489 -  Clipping CIK_3 to Cook_Inlet_75000100004336...\n",
      "----------\n",
      "Site ID: CIK_30 OK\n",
      " 67 of 489 -  Clipping CIK_30 to Cook_Inlet_75000200008551...\n",
      "----------\n",
      "Site ID: CIK_31 OK\n",
      " 68 of 489 -  Clipping CIK_31 to Cook_Inlet_75000100003947...\n",
      "----------\n",
      "Site ID: CIK_32 OK\n",
      " 69 of 489 -  Clipping CIK_32 to Cook_Inlet_75000400000173...\n",
      "----------\n",
      "Site ID: CIK_33 OK\n",
      " 70 of 489 -  Clipping CIK_33 to Cook_Inlet_75000200006065...\n",
      "----------\n",
      "Site ID: CIK_34 OK\n",
      " 71 of 489 -  Clipping CIK_34 to Cook_Inlet_75000200003312...\n",
      "----------\n",
      "Site ID: CIK_35 OK\n",
      " 72 of 489 -  Clipping CIK_35 to Cook_Inlet_75000100000981...\n",
      "----------\n",
      "Site ID: CIK_36 OK\n",
      " 73 of 489 -  Clipping CIK_36 to Cook_Inlet_75000200011141...\n",
      "----------\n",
      "Site ID: CIK_37 OK\n",
      " 74 of 489 -  Clipping CIK_37 to Cook_Inlet_75000400014403...\n",
      "----------\n",
      "Site ID: CIK_38 OK\n",
      " 75 of 489 -  Clipping CIK_38 to Cook_Inlet_75000100000652...\n",
      "----------\n",
      "Site ID: CIK_39 OK\n",
      " 76 of 489 -  Clipping CIK_39 to Cook_Inlet_75000500011984...\n",
      "----------\n",
      "Site ID: CIK_4 OK\n",
      " 77 of 489 -  Clipping CIK_4 to Cook_Inlet_75000100000004...\n",
      "----------\n",
      "Site ID: CIK_40 OK\n",
      " 78 of 489 -  Clipping CIK_40 to Cook_Inlet_75000500009975...\n",
      "----------\n",
      "Site ID: CIK_41 OK\n",
      " 79 of 489 -  Clipping CIK_41 to Cook_Inlet_75000500009621...\n",
      "----------\n",
      "Site ID: CIK_42 OK\n",
      " 80 of 489 -  Clipping CIK_42 to Cook_Inlet_75000200012999...\n",
      "----------\n",
      "Site ID: CIK_43 OK\n",
      " 81 of 489 -  Clipping CIK_43 to Cook_Inlet_75000600030148...\n",
      "----------\n",
      "Site ID: CIK_44 OK\n",
      " 82 of 489 -  Clipping CIK_44 to Cook_Inlet_75005300011378...\n",
      "----------\n",
      "Site ID: CIK_45 OK\n",
      " 83 of 489 -  Clipping CIK_45 to Cook_Inlet_75005300022831...\n",
      "----------\n",
      "Site ID: CIK_46 OK\n",
      " 84 of 489 -  Clipping CIK_46 to Cook_Inlet_75005400029139...\n",
      "----------\n",
      "Site ID: CIK_47 OK\n",
      " 85 of 489 -  Clipping CIK_47 to Cook_Inlet_75005400013272...\n",
      "----------\n",
      "Site ID: CIK_48 OK\n",
      " 86 of 489 -  Clipping CIK_48 to Cook_Inlet_75005400001203...\n",
      "----------\n",
      "Site ID: CIK_5 OK\n",
      " 87 of 489 -  Clipping CIK_5 to Cook_Inlet_75004400006041...\n",
      "----------\n",
      "Site ID: CIK_6 OK\n",
      " 88 of 489 -  Clipping CIK_6 to Cook_Inlet_75004300004332...\n",
      "----------\n",
      "Site ID: CIK_7 OK\n",
      " 89 of 489 -  Clipping CIK_7 to Cook_Inlet_75004400003042...\n",
      "----------\n",
      "Site ID: CIK_8 OK\n",
      " 90 of 489 -  Clipping CIK_8 to Cook_Inlet_75004300000105...\n",
      "----------\n",
      "Site ID: CIK_9 OK\n",
      " 91 of 489 -  Clipping CIK_9 to Cook_Inlet_75004300004701...\n",
      "----------\n",
      "Site ID: Deshka 1 Downstream OK\n",
      " 92 of 489 -  Clipping Deshka 1 Downstream to Cook_Inlet_75000200013266...\n",
      "----------\n",
      "Site ID: Deshka 1 Tributary OK\n",
      " 93 of 489 -  Clipping Deshka 1 Tributary to Cook_Inlet_75000200015860...\n",
      "----------\n",
      "Site ID: Deshka 1 Upstream OK\n",
      " 94 of 489 -  Clipping Deshka 1 Upstream to Cook_Inlet_75000200003094...\n",
      "----------\n",
      "Site ID: Deshka 2 Downstream OK\n",
      " 95 of 489 -  Clipping Deshka 2 Downstream to Cook_Inlet_75000200002984...\n",
      "----------\n",
      "Site ID: Deshka 2 Tributary OK\n",
      " 96 of 489 -  Clipping Deshka 2 Tributary to Cook_Inlet_75000200015782...\n",
      "----------\n",
      "Site ID: Deshka 2 Upstream OK\n",
      " 97 of 489 -  Clipping Deshka 2 Upstream to Cook_Inlet_75000200003013...\n",
      "----------\n",
      "Site ID: Deshka 3 Downstream OK\n",
      " 98 of 489 -  Clipping Deshka 3 Downstream to Cook_Inlet_75000200005504...\n",
      "----------\n",
      "Site ID: Deshka 3 Tributary OK\n",
      " 99 of 489 -  Clipping Deshka 3 Tributary to Cook_Inlet_75000200000465...\n",
      "----------\n",
      "Site ID: Deshka 3 Upstream OK\n",
      " 100 of 489 -  Clipping Deshka 3 Upstream to Cook_Inlet_75000200013237...\n",
      "----------\n",
      "Site ID: Deshka 4 Downstream OK\n",
      " 101 of 489 -  Clipping Deshka 4 Downstream to Cook_Inlet_75000200018332...\n",
      "----------\n",
      "Site ID: Deshka 4 Tributary OK\n",
      " 102 of 489 -  Clipping Deshka 4 Tributary to Cook_Inlet_75000200013319...\n",
      "----------\n",
      "Site ID: Deshka 4 Upstream OK\n",
      " 103 of 489 -  Clipping Deshka 4 Upstream to Cook_Inlet_75000200005532...\n",
      "----------\n",
      "Site ID: Deshka 5 Downstream OK\n",
      " 104 of 489 -  Clipping Deshka 5 Downstream to Cook_Inlet_75000200018331...\n",
      "----------\n",
      "Site ID: Deshka 5 Tributary OK\n",
      " 105 of 489 -  Clipping Deshka 5 Tributary to Cook_Inlet_75000200005503...\n",
      "----------\n",
      "Site ID: Deshka 6 Downstream OK\n",
      " 106 of 489 -  Clipping Deshka 6 Downstream to Cook_Inlet_75000200015883...\n",
      "----------\n",
      "Site ID: Deshka 6 Tributary OK\n",
      " 107 of 489 -  Clipping Deshka 6 Tributary to Cook_Inlet_75000200005619...\n",
      "----------\n",
      "Site ID: Deshka 6 Upstream OK\n",
      " 108 of 489 -  Clipping Deshka 6 Upstream to Cook_Inlet_75000200015882...\n",
      "----------\n",
      "Site ID: Kroto 1 Downstream OK\n",
      " 109 of 489 -  Clipping Kroto 1 Downstream to Cook_Inlet_75000200000213...\n",
      "----------\n",
      "Site ID: Kroto 1 Tributary OK\n",
      " 110 of 489 -  Clipping Kroto 1 Tributary to Cook_Inlet_75000200000011...\n",
      "----------\n",
      "Site ID: Kroto 1 Upstream OK\n",
      " 111 of 489 -  Clipping Kroto 1 Upstream to Cook_Inlet_75000200007853...\n",
      "----------\n",
      "Site ID: Kroto 2 Downstream OK\n",
      " 112 of 489 -  Clipping Kroto 2 Downstream to Cook_Inlet_75000200002753...\n",
      "----------\n",
      "Site ID: Kroto 2 Tributary OK\n",
      " 113 of 489 -  Clipping Kroto 2 Tributary to Cook_Inlet_75000200018069...\n",
      "----------\n",
      "Site ID: Kroto 2 Upstream OK\n",
      " 114 of 489 -  Clipping Kroto 2 Upstream to Cook_Inlet_75000200007852...\n",
      "----------\n",
      "Site ID: Kroto 3 Downstream OK\n",
      " 115 of 489 -  Clipping Kroto 3 Downstream to Cook_Inlet_75000200007639...\n",
      "----------\n",
      "Site ID: Kroto 3 Tributary OK\n",
      " 116 of 489 -  Clipping Kroto 3 Tributary to Cook_Inlet_75000200010344...\n",
      "----------\n",
      "Site ID: Kroto 3 Upstream OK\n",
      " 117 of 489 -  Clipping Kroto 3 Upstream to Cook_Inlet_75000200002753...\n",
      "----------\n",
      "Site ID: Kroto 4 Downstream OK\n",
      " 118 of 489 -  Clipping Kroto 4 Downstream to Cook_Inlet_75000200007839...\n",
      "----------\n",
      "Site ID: Kroto 4 Tributary OK\n",
      " 119 of 489 -  Clipping Kroto 4 Tributary to Cook_Inlet_75000200015469...\n",
      "----------\n",
      "Site ID: Kroto 4 Upstream OK\n",
      " 120 of 489 -  Clipping Kroto 4 Upstream to Cook_Inlet_75000200007639...\n",
      "----------\n",
      "Site ID: Kroto 5 Downstream OK\n",
      " 121 of 489 -  Clipping Kroto 5 Downstream to Cook_Inlet_75000200000278...\n",
      "----------\n",
      "Site ID: Kroto 6 Downstream OK\n",
      " 122 of 489 -  Clipping Kroto 6 Downstream to Cook_Inlet_75000200010532...\n",
      "----------\n",
      "Site ID: Kroto 6 Tributary OK\n",
      " 123 of 489 -  Clipping Kroto 6 Tributary to Cook_Inlet_75000200005444...\n",
      "----------\n",
      "Site ID: Kroto 6 Upstream OK\n",
      " 124 of 489 -  Clipping Kroto 6 Upstream to Cook_Inlet_75000200000416...\n",
      "----------\n",
      "Site ID: Kroto 7 Downstream OK\n",
      " 125 of 489 -  Clipping Kroto 7 Downstream to Cook_Inlet_75000200015680...\n",
      "----------\n",
      "Site ID: Kroto 7 Tributary OK\n",
      " 126 of 489 -  Clipping Kroto 7 Tributary to Cook_Inlet_75000200005404...\n",
      "----------\n",
      "Site ID: Kroto 7 Upstream OK\n",
      " 127 of 489 -  Clipping Kroto 7 Upstream to Cook_Inlet_75000200000411...\n",
      "----------\n",
      "Site ID: Kroto 8 Downstream OK\n",
      " 128 of 489 -  Clipping Kroto 8 Downstream to Cook_Inlet_75000200002920...\n",
      "----------\n",
      "Site ID: Kroto 8 Tributary OK\n",
      " 129 of 489 -  Clipping Kroto 8 Tributary to Cook_Inlet_75000200010148...\n",
      "----------\n",
      "Site ID: Kroto 8 Upstream OK\n",
      " 130 of 489 -  Clipping Kroto 8 Upstream to Cook_Inlet_75000200008033...\n",
      "----------\n",
      "Site ID: Moose 1 Top of Study OK\n",
      " 131 of 489 -  Clipping Moose 1 Top of Study to Cook_Inlet_75000200013185...\n",
      "----------\n",
      "Site ID: Moose 2 Downstream OK\n",
      " 132 of 489 -  Clipping Moose 2 Downstream to Cook_Inlet_75000200010547...\n",
      "----------\n",
      "Site ID: Moose 2 Tributary OK\n",
      " 133 of 489 -  Clipping Moose 2 Tributary to Cook_Inlet_75000200018235...\n",
      "----------\n",
      "Site ID: Moose 2 Upstream OK\n",
      " 134 of 489 -  Clipping Moose 2 Upstream to Cook_Inlet_75000200013187...\n",
      "----------\n",
      "Site ID: Moose 3 Downstream OK\n",
      " 135 of 489 -  Clipping Moose 3 Downstream to Cook_Inlet_75000200010540...\n",
      "----------\n",
      "Site ID: Moose 3 Tributary OK\n",
      " 136 of 489 -  Clipping Moose 3 Tributary to Cook_Inlet_75000200013179...\n",
      "----------\n",
      "Site ID: Moose 3 Upstream OK\n",
      " 137 of 489 -  Clipping Moose 3 Upstream to Cook_Inlet_75000200018266...\n",
      "----------\n",
      "Site ID: Moose 4 Downstream OK\n",
      " 138 of 489 -  Clipping Moose 4 Downstream to Cook_Inlet_75000200002934...\n",
      "----------\n",
      "Site ID: Moose 4 Tributary OK\n",
      " 139 of 489 -  Clipping Moose 4 Tributary to Cook_Inlet_75000200015657...\n",
      "----------\n",
      "Site ID: Moose 4 Upstream OK\n",
      " 140 of 489 -  Clipping Moose 4 Upstream to Cook_Inlet_75000200010538...\n",
      "----------\n",
      "Site ID: Moose 5 Downstream OK\n",
      " 141 of 489 -  Clipping Moose 5 Downstream to Cook_Inlet_75000200000418...\n",
      "----------\n",
      "Site ID: Moose 5 Tributary OK\n",
      " 142 of 489 -  Clipping Moose 5 Tributary to Cook_Inlet_75000200018259...\n",
      "----------\n",
      "Site ID: Moose 5 Upstream OK\n",
      " 143 of 489 -  Clipping Moose 5 Upstream to Cook_Inlet_75000200005448...\n",
      "----------\n",
      "Site ID: Moose 6 Downstream OK\n",
      " 144 of 489 -  Clipping Moose 6 Downstream to Cook_Inlet_75000200013249...\n",
      "----------\n",
      "Site ID: Moose 6 Tributary OK\n",
      " 145 of 489 -  Clipping Moose 6 Tributary to Cook_Inlet_75000200018317...\n",
      "----------\n",
      "Site ID: Moose 6 Upstream OK\n",
      " 146 of 489 -  Clipping Moose 6 Upstream to Cook_Inlet_75000200008110...\n",
      "----------\n",
      "Site ID: Moose 7 Downstream OK\n",
      " 147 of 489 -  Clipping Moose 7 Downstream to Cook_Inlet_75000200005575...\n",
      "----------\n",
      "Site ID: Moose 7 Tributary OK\n",
      " 148 of 489 -  Clipping Moose 7 Tributary to Cook_Inlet_75000200003070...\n",
      "----------\n",
      "Site ID: Moose 7 Upstream OK\n",
      " 149 of 489 -  Clipping Moose 7 Upstream to Cook_Inlet_75000200005573...\n",
      "----------\n",
      "Site ID: Moose 8 Downstream OK\n",
      " 150 of 489 -  Clipping Moose 8 Downstream to Cook_Inlet_75000200003107...\n",
      "----------\n",
      "Site ID: Moose 8 Tributary OK\n",
      " 151 of 489 -  Clipping Moose 8 Tributary to Cook_Inlet_75000200010712...\n",
      "----------\n",
      "Site ID: Moose 8 Upstream OK\n",
      " 152 of 489 -  Clipping Moose 8 Upstream to Cook_Inlet_75000200015867...\n",
      "----------\n",
      "Site ID: OCC1 OK\n",
      " 153 of 489 -  Clipping OCC1 to Cook_Inlet_75000200010144...\n",
      "----------\n",
      "Site ID: OCC2 OK\n",
      " 154 of 489 -  Clipping OCC2 to Cook_Inlet_75000200013010...\n",
      "----------\n",
      "Site ID: OCCT1 OK\n",
      " 155 of 489 -  Clipping OCCT1 to Cook_Inlet_75000200010359...\n",
      "----------\n",
      "Site ID: OMCT1 OK\n",
      " 156 of 489 -  Clipping OMCT1 to Cook_Inlet_75000200008051...\n",
      "----------\n",
      "Site ID: OMCT2 OK\n",
      " 157 of 489 -  Clipping OMCT2 to Cook_Inlet_75000200002552...\n",
      "----------\n",
      "Site ID: OMCT3 OK\n",
      " 158 of 489 -  Clipping OMCT3 to Cook_Inlet_75000200018203...\n",
      "----------\n",
      "Site ID: OMCT4 OK\n",
      " 159 of 489 -  Clipping OMCT4 to Cook_Inlet_75000200005413...\n",
      "----------\n",
      "Site ID: OMCT5 OK\n",
      " 160 of 489 -  Clipping OMCT5 to Cook_Inlet_75000200005077...\n",
      "----------\n",
      "Site ID: OWL1 OK\n",
      " 161 of 489 -  Clipping OWL1 to Cook_Inlet_75000200008009...\n",
      "----------\n",
      "Site ID: PGC1 OK\n",
      " 162 of 489 -  Clipping PGC1 to Cook_Inlet_75000200015587...\n",
      "----------\n",
      "Site ID: PGC2 OK\n",
      " 163 of 489 -  Clipping PGC2 to Cook_Inlet_75000200015584...\n",
      "----------\n",
      "Site ID: PGCT1 OK\n",
      " 164 of 489 -  Clipping PGCT1 to Cook_Inlet_75000200007958...\n",
      "----------\n",
      "Site ID: PGCT2 OK\n",
      " 165 of 489 -  Clipping PGCT2 to Cook_Inlet_75000200002806...\n",
      "----------\n",
      "Site ID: PKC1 OK\n",
      " 166 of 489 -  Clipping PKC1 to Cook_Inlet_75000200015505...\n",
      "----------\n",
      "Site ID: PKCT1 OK\n",
      " 167 of 489 -  Clipping PKCT1 to Cook_Inlet_75000200007870...\n",
      "----------\n",
      "Site ID: PKCT2 OK\n",
      " 168 of 489 -  Clipping PKCT2 to Cook_Inlet_75000200000011...\n",
      "----------\n",
      "Site ID: PMC1 OK\n",
      " 169 of 489 -  Clipping PMC1 to Cook_Inlet_75000200013189...\n",
      "----------\n",
      "Site ID: PMC2 OK\n",
      " 170 of 489 -  Clipping PMC2 to Cook_Inlet_75000200013185...\n",
      "----------\n",
      "Site ID: PMCT1 OK\n",
      " 171 of 489 -  Clipping PMCT1 to Cook_Inlet_75000200018235...\n",
      "----------\n",
      "Site ID: PNC1 OK\n",
      " 172 of 489 -  Clipping PNC1 to Cook_Inlet_75000200007646...\n",
      "----------\n",
      "Site ID: PNCT1 OK\n",
      " 173 of 489 -  Clipping PNCT1 to Cook_Inlet_75000200005606...\n",
      "----------\n",
      "Site ID: PNCT2 OK\n",
      " 174 of 489 -  Clipping PNCT2 to Cook_Inlet_75000200002554...\n",
      "----------\n",
      "Site ID: PNCT4 OK\n",
      " 175 of 489 -  Clipping PNCT4 to Cook_Inlet_75000200013258...\n",
      "----------\n",
      "Site ID: PSM1 OK\n",
      " 176 of 489 -  Clipping PSM1 to Cook_Inlet_75000200005075...\n",
      "----------\n",
      "Site ID: PSM2 OK\n",
      " 177 of 489 -  Clipping PSM2 to Cook_Inlet_75000200010391...\n",
      "----------\n",
      "Site ID: PSMT1 OK\n",
      " 178 of 489 -  Clipping PSMT1 to Cook_Inlet_75000200013033...\n",
      "----------\n",
      "Site ID: PTC1 OK\n",
      " 179 of 489 -  Clipping PTC1 to Cook_Inlet_75000200000010...\n",
      "----------\n",
      "Site ID: PWMC1 OK\n",
      " 180 of 489 -  Clipping PWMC1 to Cook_Inlet_75000200015695...\n",
      "----------\n",
      "Site ID: BM1 OK\n",
      " 181 of 489 -  Clipping BM1 to Cook_Inlet_75004400008917...\n",
      "----------\n",
      "Site ID: BM10 OK\n",
      " 182 of 489 -  Clipping BM10 to Cook_Inlet_75004400009260...\n",
      "----------\n",
      "Site ID: BM11 OK\n",
      " 183 of 489 -  Clipping BM11 to Cook_Inlet_75004400004829...\n",
      "----------\n",
      "Site ID: BM12 OK\n",
      " 184 of 489 -  Clipping BM12 to Cook_Inlet_75004400001872...\n",
      "----------\n",
      "Site ID: BM13 OK\n",
      " 185 of 489 -  Clipping BM13 to Cook_Inlet_75004400009308...\n",
      "----------\n",
      "Site ID: BM14 OK\n",
      " 186 of 489 -  Clipping BM14 to Cook_Inlet_75004400010810...\n",
      "----------\n",
      "Site ID: BM2 OK\n",
      " 187 of 489 -  Clipping BM2 to Cook_Inlet_75004400008917...\n",
      "----------\n",
      "Site ID: BM3 OK\n",
      " 188 of 489 -  Clipping BM3 to Cook_Inlet_75004400001510...\n",
      "----------\n",
      "Site ID: BM4 OK\n",
      " 189 of 489 -  Clipping BM4 to Cook_Inlet_75004400010402...\n",
      "----------\n",
      "Site ID: BM5 OK\n",
      " 190 of 489 -  Clipping BM5 to Cook_Inlet_75004400007388...\n",
      "----------\n",
      "Site ID: BM6 OK\n",
      " 191 of 489 -  Clipping BM6 to Cook_Inlet_75004400008856...\n",
      "----------\n",
      "Site ID: BM7 OK\n",
      " 192 of 489 -  Clipping BM7 to Cook_Inlet_75004400008856...\n",
      "----------\n",
      "Site ID: BM8 OK\n",
      " 193 of 489 -  Clipping BM8 to Cook_Inlet_75004400006846...\n",
      "----------\n",
      "Site ID: BM9 OK\n",
      " 194 of 489 -  Clipping BM9 to Cook_Inlet_75004400010754...\n",
      "----------\n",
      "Site ID: KWF1 OK\n",
      " 195 of 489 -  Clipping KWF1 to Cook_Inlet_75004400008917...\n",
      "----------\n",
      "Site ID: KWF2 OK\n",
      " 196 of 489 -  Clipping KWF2 to Cook_Inlet_75004400008856...\n",
      "----------\n",
      "Site ID: KWF3 OK\n",
      " 197 of 489 -  Clipping KWF3 to Cook_Inlet_75004400009261...\n",
      "----------\n",
      "Site ID: lsarc OK\n",
      " 198 of 489 -  Clipping lsarc to Cook_Inlet_75000200017518...\n",
      "----------\n",
      "Site ID: lscoh OK\n",
      " 199 of 489 -  Clipping lscoh to Cook_Inlet_75000200011392...\n",
      "----------\n",
      "Site ID: lslak OK\n",
      " 200 of 489 -  Clipping lslak to Cook_Inlet_75000200013892...\n",
      "----------\n",
      "Site ID: lslil OK\n",
      " 201 of 489 -  Clipping lslil to Cook_Inlet_75000200008676...\n",
      "----------\n",
      "Site ID: lspap OK\n",
      " 202 of 489 -  Clipping lspap to Cook_Inlet_75000200011034...\n",
      "----------\n",
      "Site ID: lsr112.4 OK\n",
      " 203 of 489 -  Clipping lsr112.4 to Cook_Inlet_75000200007305...\n",
      "----------\n",
      "Site ID: lstrb33 OK\n",
      " 204 of 489 -  Clipping lstrb33 to Cook_Inlet_75000200008452...\n",
      "----------\n",
      "Site ID: lscoa OK\n",
      " 205 of 489 -  Clipping lscoa to Cook_Inlet_75000200019263...\n",
      "----------\n",
      "Site ID: lsgov OK\n",
      " 206 of 489 -  Clipping lsgov to Cook_Inlet_75000200012046...\n",
      "----------\n",
      "Site ID: lslak7 OK\n",
      " 207 of 489 -  Clipping lslak7 to Cook_Inlet_75000200015319...\n",
      "----------\n",
      "Site ID: lsmoo1 OK\n",
      " 208 of 489 -  Clipping lsmoo1 to Cook_Inlet_75000200011623...\n",
      "----------\n",
      "Site ID: lsnlt1 OK\n",
      " 209 of 489 -  Clipping lsnlt1 to Cook_Inlet_75000200008734...\n",
      "----------\n",
      "Site ID: lsr100 OK\n",
      " 210 of 489 -  Clipping lsr100 to Cook_Inlet_75000200014508...\n",
      "----------\n",
      "Site ID: lsr103 OK\n",
      " 211 of 489 -  Clipping lsr103 to Cook_Inlet_75000200019765...\n",
      "----------\n",
      "Site ID: lsr112 OK\n",
      " 212 of 489 -  Clipping lsr112 to Cook_Inlet_75000200014914...\n",
      "----------\n",
      "Site ID: lsr112.2 OK\n",
      " 213 of 489 -  Clipping lsr112.2 to Cook_Inlet_75000200002162...\n",
      "----------\n",
      "Site ID: lsr112.5 OK\n",
      " 214 of 489 -  Clipping lsr112.5 to Cook_Inlet_75000200004615...\n",
      "----------\n",
      "Site ID: lsr28 OK\n",
      " 215 of 489 -  Clipping lsr28 to Cook_Inlet_75000200018581...\n",
      "----------\n",
      "Site ID: lsr28.3 OK\n",
      " 216 of 489 -  Clipping lsr28.3 to Cook_Inlet_75000200018581...\n",
      "----------\n",
      "Site ID: lsr33 OK\n",
      " 217 of 489 -  Clipping lsr33 to Cook_Inlet_75000200000021...\n",
      "----------\n",
      "Site ID: lsr33.1 OK\n",
      " 218 of 489 -  Clipping lsr33.1 to Cook_Inlet_75000200016094...\n",
      "----------\n",
      "Site ID: lsr33.8 OK\n",
      " 219 of 489 -  Clipping lsr33.8 to Cook_Inlet_75000200000021...\n",
      "----------\n",
      "Site ID: lsr47 OK\n",
      " 220 of 489 -  Clipping lsr47 to Cook_Inlet_75000200018667...\n",
      "----------\n",
      "Site ID: lsr48.1 OK\n",
      " 221 of 489 -  Clipping lsr48.1 to Cook_Inlet_75000200018667...\n",
      "----------\n",
      "Site ID: lsr48.3 OK\n",
      " 222 of 489 -  Clipping lsr48.3 to Cook_Inlet_75000200008508...\n",
      "----------\n",
      "Site ID: lsr59 OK\n",
      " 223 of 489 -  Clipping lsr59 to Cook_Inlet_75000200018882...\n",
      "----------\n",
      "Site ID: lsr63.1 OK\n",
      " 224 of 489 -  Clipping lsr63.1 to Cook_Inlet_75000200015320...\n",
      "----------\n",
      "Site ID: lsr63.4 OK\n",
      " 225 of 489 -  Clipping lsr63.4 to Cook_Inlet_75000200007660...\n",
      "----------\n",
      "Site ID: lsr67 OK\n",
      " 226 of 489 -  Clipping lsr67 to Cook_Inlet_75000200007660...\n",
      "----------\n",
      "Site ID: lsr73 OK\n",
      " 227 of 489 -  Clipping lsr73 to Cook_Inlet_75000200003732...\n",
      "----------\n",
      "Site ID: lsr73.1 OK\n",
      " 228 of 489 -  Clipping lsr73.1 to Cook_Inlet_75000200013953...\n",
      "----------\n",
      "Site ID: lsr73.2 OK\n",
      " 229 of 489 -  Clipping lsr73.2 to Cook_Inlet_75000200013953...\n",
      "----------\n",
      "Site ID: lsr87 OK\n",
      " 230 of 489 -  Clipping lsr87 to Cook_Inlet_75000200008950...\n",
      "----------\n",
      "Site ID: lsr89 OK\n",
      " 231 of 489 -  Clipping lsr89 to Cook_Inlet_75000200003896...\n",
      "----------\n",
      "Site ID: lsr93lb OK\n",
      " 232 of 489 -  Clipping lsr93lb to Cook_Inlet_75000200014207...\n",
      "----------\n",
      "Site ID: lsr93rb OK\n",
      " 233 of 489 -  Clipping lsr93rb to Cook_Inlet_75000200014207...\n",
      "----------\n",
      "Site ID: lsswi1 OK\n",
      " 234 of 489 -  Clipping lsswi1 to Cook_Inlet_75000200011572...\n",
      "----------\n",
      "Site ID: lstrb36 OK\n",
      " 235 of 489 -  Clipping lstrb36 to Cook_Inlet_75000200016095...\n",
      "----------\n",
      "Site ID: lstrb88 OK\n",
      " 236 of 489 -  Clipping lstrb88 to Cook_Inlet_75000200014057...\n",
      "----------\n",
      "Site ID: lstrb97 OK\n",
      " 237 of 489 -  Clipping lstrb97 to Cook_Inlet_75000200007670...\n",
      "----------\n",
      "Site ID: USFS_Bench Creek OK\n",
      " 238 of 489 -  Clipping USFS_Bench Creek to Cook_Inlet_75004400009919...\n",
      "----------\n",
      "Site ID: USFS_Center Creek OK\n",
      " 239 of 489 -  Clipping USFS_Center Creek to Cook_Inlet_75004400011322...\n",
      "----------\n",
      "Site ID: USFS_Chickaloon Headwaters OK\n",
      " 240 of 489 -  Clipping USFS_Chickaloon Headwaters to Cook_Inlet_75004400003452...\n",
      "----------\n",
      "Site ID: USFS_Crescent Creek OK\n",
      " 241 of 489 -  Clipping USFS_Crescent Creek to Cook_Inlet_75004400002041...\n",
      "----------\n",
      "Site ID: USFS_Daves Creek OK\n",
      " 242 of 489 -  Clipping USFS_Daves Creek to Cook_Inlet_75004400002951...\n",
      "----------\n",
      "Site ID: USFS_Juneau Creek OK\n",
      " 243 of 489 -  Clipping USFS_Juneau Creek to Cook_Inlet_75004400002950...\n",
      "----------\n",
      "Site ID: USFS_Quartz Creek OK\n",
      " 244 of 489 -  Clipping USFS_Quartz Creek to Cook_Inlet_75004400007948...\n",
      "----------\n",
      "Site ID: USFS_Resurrection Creek OK\n",
      " 245 of 489 -  Clipping USFS_Resurrection Creek to Cook_Inlet_75004400000627...\n",
      "----------\n",
      "Site ID: 15290000 OK\n",
      " 246 of 489 -  Clipping 15290000 to Cook_Inlet_75000200004615...\n",
      "----------\n",
      "Site ID: 15292780 OK\n",
      " 247 of 489 -  Clipping 15292780 to Cook_Inlet_75000200013536...\n",
      "----------\n",
      "Site ID: 15292800 OK\n",
      " 248 of 489 -  Clipping 15292800 to Cook_Inlet_75000200000949...\n",
      "----------\n",
      "Site ID: 15293200 OK\n",
      " 249 of 489 -  Clipping 15293200 to Cook_Inlet_75000200018806...\n",
      "----------\n",
      "Site ID: 15293700 OK\n",
      " 250 of 489 -  Clipping 15293700 to Cook_Inlet_75000200008551...\n",
      "----------\n",
      "Site ID: 15294005 OK\n",
      " 251 of 489 -  Clipping 15294005 to Cook_Inlet_75000200011336...\n",
      "----------\n",
      "Site ID: 15294080 OK\n",
      " 252 of 489 -  Clipping 15294080 to Cook_Inlet_75000200000278...\n",
      "----------\n",
      "Site ID: 15294350 OK\n",
      " 253 of 489 -  Clipping 15294350 to Cook_Inlet_75000200007927...\n",
      "----------\n",
      "Site ID: 15274000 OK\n",
      " 254 of 489 -  Clipping 15274000 to Cook_Inlet_75000100001919...\n",
      "----------\n",
      "Site ID: 15274600 OK\n",
      " 255 of 489 -  Clipping 15274600 to Cook_Inlet_75000100000004...\n",
      "----------\n",
      "Site ID: 15276000 OK\n",
      " 256 of 489 -  Clipping 15276000 to Cook_Inlet_75000100003094...\n",
      "----------\n",
      "Site ID: 15285000 OK\n",
      " 257 of 489 -  Clipping 15285000 to Cook_Inlet_75000100004200...\n",
      "----------\n",
      "Site ID: 15258000 OK\n",
      " 258 of 489 -  Clipping 15258000 to Cook_Inlet_75004400001952...\n",
      "----------\n",
      "Site ID: 15260001 OK\n",
      " 259 of 489 -  Clipping 15260001 to Cook_Inlet_75004400006357...\n",
      "----------\n",
      "Site ID: 15261000 OK\n",
      " 260 of 489 -  Clipping 15261000 to Cook_Inlet_75004400009331...\n",
      "----------\n",
      "Site ID: 15266110 OK\n",
      " 261 of 489 -  Clipping 15266110 to Cook_Inlet_75004400003154...\n",
      "----------\n",
      "Site ID: 15266300 OK\n",
      " 262 of 489 -  Clipping 15266300 to Cook_Inlet_75004400001498...\n",
      "----------\n",
      "Site ID: 15272380 OK\n",
      " 263 of 489 -  Clipping 15272380 to Cook_Inlet_75004400011711...\n",
      "----------\n",
      "Site ID: 15280999 OK\n",
      " 264 of 489 -  Clipping 15280999 to Cook_Inlet_75000400014405...\n",
      "----------\n",
      "Site ID: 15283700 OK\n",
      " 265 of 489 -  Clipping 15283700 to Cook_Inlet_75000400014403...\n",
      "----------\n",
      "Site ID: 15284000 OK\n",
      " 266 of 489 -  Clipping 15284000 to Cook_Inlet_75000400009620...\n",
      "----------\n",
      "Site ID: 15292700 OK\n",
      " 267 of 489 -  Clipping 15292700 to Cook_Inlet_75000300025361...\n",
      "----------\n",
      "Site ID: 15294345 OK\n",
      " 268 of 489 -  Clipping 15294345 to Cook_Inlet_75000600010189...\n",
      "----------\n",
      "Site ID: 15292400 OK\n",
      " 269 of 489 -  Clipping 15292400 to Cook_Inlet_75000500010609...\n",
      "----------\n",
      "Site ID: 15291000 OK\n",
      " 270 of 489 -  Clipping 15291000 to Cook_Inlet_75000700032122...\n",
      "----------\n",
      "Site ID: 15291700 OK\n",
      " 271 of 489 -  Clipping 15291700 to Cook_Inlet_75000700030756...\n",
      "----------\n",
      "Site ID: 15292100 OK\n",
      " 272 of 489 -  Clipping 15292100 to Cook_Inlet_75000700036166...\n",
      "----------\n",
      "Site ID: 15238984 OK\n",
      " 273 of 489 -  Clipping 15238984 to Cook_Inlet_75004300004983...\n",
      "----------\n",
      "Site ID: 15238986 OK\n",
      " 274 of 489 -  Clipping 15238986 to Cook_Inlet_75004300008012...\n",
      "----------\n",
      "Site ID: 15239070 OK\n",
      " 275 of 489 -  Clipping 15239070 to Cook_Inlet_75004300006071...\n",
      "----------\n",
      "Site ID: 15241600 OK\n",
      " 276 of 489 -  Clipping 15241600 to Cook_Inlet_75004300004332...\n",
      "----------\n",
      "Site ID: fws_Long Lake Creek OK\n",
      " 277 of 489 -  Clipping fws_Long Lake Creek to Copper_River_75019700003889...\n",
      "----------\n",
      "Site ID: fws_Tanada Creek OK\n",
      " 278 of 489 -  Clipping fws_Tanada Creek to Copper_River_75019800010313...\n",
      "----------\n",
      "Site ID: Caribou Creek OK\n",
      " 279 of 489 -  Clipping Caribou Creek to Copper_River_75019800014348...\n",
      "----------\n",
      "Site ID: Crystal Creek OK\n",
      " 280 of 489 -  Clipping Crystal Creek to Copper_River_75019700004084...\n",
      "----------\n",
      "Site ID: Gilahina River OK\n",
      " 281 of 489 -  Clipping Gilahina River to Copper_River_75019700001794...\n",
      "----------\n",
      "Site ID: Lakina River OK\n",
      " 282 of 489 -  Clipping Lakina River to Copper_River_75019700004190...\n",
      "----------\n",
      "Site ID: Long Lake Creek OK\n",
      " 283 of 489 -  Clipping Long Lake Creek to Copper_River_75019700003889...\n",
      "----------\n",
      "Site ID: Rock Creek WRST OK\n",
      " 284 of 489 -  Clipping Rock Creek WRST to Copper_River_75019800001957...\n",
      "----------\n",
      "Site ID: Rufus Creek OK\n",
      " 285 of 489 -  Clipping Rufus Creek to Copper_River_75019800000406...\n",
      "----------\n",
      "Site ID: USFS_18 Mile OK\n",
      " 286 of 489 -  Clipping USFS_18 Mile to Copper_River_75003900044738...\n",
      "----------\n",
      "Site ID: USFS_25 Mile OK\n",
      " 287 of 489 -  Clipping USFS_25 Mile to Copper_River_75003900055694...\n",
      "----------\n",
      "Site ID: USFS_Blackhole Creek OK\n",
      " 288 of 489 -  Clipping USFS_Blackhole Creek to Copper_River_75003900027771...\n",
      "----------\n",
      "Site ID: USFS_Cabin Lake Outlet OK\n",
      " 289 of 489 -  Clipping USFS_Cabin Lake Outlet to Copper_River_75003900028507...\n",
      "----------\n",
      "Site ID: USFS_24.9 Mile Creek OK\n",
      " 290 of 489 -  Clipping USFS_24.9 Mile Creek to Copper_River_75003900023674...\n",
      "----------\n",
      "Site ID: USFS_Ibeck Creek-Low OK\n",
      " 291 of 489 -  Clipping USFS_Ibeck Creek-Low to Copper_River_75003900054316...\n",
      "----------\n",
      "Site ID: USFS_18 Mile Middle Fork OK\n",
      " 292 of 489 -  Clipping USFS_18 Mile Middle Fork to Copper_River_75003900044936...\n",
      "----------\n",
      "Site ID: USFS_18 Mile West Fork OK\n",
      " 293 of 489 -  Clipping USFS_18 Mile West Fork to Copper_River_75003900023855...\n",
      "----------\n",
      "Site ID: USFS_Middle Arm Eyak OK\n",
      " 294 of 489 -  Clipping USFS_Middle Arm Eyak to Copper_River_75003900055039...\n",
      "----------\n",
      "Site ID: USFS_Hook Point OK\n",
      " 295 of 489 -  Clipping USFS_Hook Point to Copper_River_75003900039073...\n",
      "----------\n",
      "Site ID: USFS_Little Martin River OK\n",
      " 296 of 489 -  Clipping USFS_Little Martin River to Copper_River_75003900062264...\n",
      "----------\n",
      "Site ID: USFS_Martin Lake- Inlet OK\n",
      " 297 of 489 -  Clipping USFS_Martin Lake- Inlet to Copper_River_75003900055316...\n",
      "----------\n",
      "Site ID: USFS_Power Creek OK\n",
      " 298 of 489 -  Clipping USFS_Power Creek to Copper_River_75003900033524...\n",
      "----------\n",
      "Site ID: USFS_Salmon Creek OK\n",
      " 299 of 489 -  Clipping USFS_Salmon Creek to Copper_River_75003900027489...\n",
      "----------\n",
      "Site ID: USFS_East Fork 18 Mile OK\n",
      " 300 of 489 -  Clipping USFS_East Fork 18 Mile to Copper_River_75003900044738...\n",
      "----------\n",
      "Site ID: USFS_Eyak Lake Tributary OK\n",
      " 301 of 489 -  Clipping USFS_Eyak Lake Tributary to Copper_River_75003900023942...\n",
      "----------\n",
      "Site ID: USFS_Ibeck Creek-Lower Side Channel OK\n",
      " 302 of 489 -  Clipping USFS_Ibeck Creek-Lower Side Channel to Copper_River_75003900054316...\n",
      "----------\n",
      "Site ID: 15209700 OK\n",
      " 303 of 489 -  Clipping 15209700 to Copper_River_75019700017692...\n",
      "----------\n",
      "Site ID: 15200280 OK\n",
      " 304 of 489 -  Clipping 15200280 to Copper_River_75019600118138...\n",
      "----------\n",
      "Site ID: 15200000 OK\n",
      " 305 of 489 -  Clipping 15200000 to Copper_River_75019800019692...\n",
      "----------\n",
      "Site ID: 15212000 OK\n",
      " 306 of 489 -  Clipping 15212000 to Copper_River_75003900062338...\n",
      "----------\n",
      "Site ID: 15215900 OK\n",
      " 307 of 489 -  Clipping 15215900 to Copper_River_75003900058380...\n",
      "----------\n",
      "Site ID: 15298040 OK\n",
      " 308 of 489 -  Clipping 15298040 to Bristol_Bay_2085962...\n",
      "----------\n",
      "Site ID: 15300100 OK\n",
      " 309 of 489 -  Clipping 15300100 to Bristol_Bay_2065914...\n",
      "----------\n",
      "Site ID: 15300250 OK\n",
      " 310 of 489 -  Clipping 15300250 to Bristol_Bay_2074424...\n",
      "----------\n",
      "Site ID: 15300270 OK\n",
      " 311 of 489 -  Clipping 15300270 to Bristol_Bay_2071934...\n",
      "----------\n",
      "Site ID: 15300300 OK\n",
      " 312 of 489 -  Clipping 15300300 to Bristol_Bay_2073464...\n",
      "----------\n",
      "Site ID: 15300320 OK\n",
      " 313 of 489 -  Clipping 15300320 to Bristol_Bay_2066924...\n",
      "----------\n",
      "Site ID: 15301500 OK\n",
      " 314 of 489 -  Clipping 15301500 to Bristol_Bay_4115672...\n",
      "----------\n",
      "Site ID: 15302000 OK\n",
      " 315 of 489 -  Clipping 15302000 to Bristol_Bay_4101123...\n",
      "----------\n",
      "Site ID: 15302200 OK\n",
      " 316 of 489 -  Clipping 15302200 to Bristol_Bay_4098704...\n",
      "----------\n",
      "Site ID: 15302250 OK\n",
      " 317 of 489 -  Clipping 15302250 to Bristol_Bay_4105844...\n",
      "----------\n",
      "Site ID: 15302300 OK\n",
      " 318 of 489 -  Clipping 15302300 to Bristol_Bay_4107464...\n",
      "----------\n",
      "Site ID: 15302320 OK\n",
      " 319 of 489 -  Clipping 15302320 to Bristol_Bay_4105204...\n",
      "----------\n",
      "Site ID: 15302812 OK\n",
      " 320 of 489 -  Clipping 15302812 to Bristol_Bay_4086815...\n",
      "----------\n",
      "Site ID: 580223156504200 OK\n",
      " 321 of 489 -  Clipping 580223156504200 to Bristol_Bay_1023044...\n",
      "----------\n",
      "Site ID: AKBB-011 OK\n",
      " 322 of 489 -  Clipping AKBB-011 to Bristol_Bay_4054120...\n",
      "----------\n",
      "Site ID: AKBB-020 OK\n",
      " 323 of 489 -  Clipping AKBB-020 to Bristol_Bay_4084351...\n",
      "----------\n",
      "Site ID: AKBB-028 OK\n",
      " 324 of 489 -  Clipping AKBB-028 to Bristol_Bay_2070402...\n",
      "----------\n",
      "Site ID: AKBB-029 OK\n",
      " 325 of 489 -  Clipping AKBB-029 to Bristol_Bay_2068584...\n",
      "----------\n",
      "Site ID: AKBB-040 OK\n",
      " 326 of 489 -  Clipping AKBB-040 to Bristol_Bay_4095301...\n",
      "----------\n",
      "Site ID: CIK_Ben Courtney Creek OK\n",
      " 327 of 489 -  Clipping CIK_Ben Courtney Creek to Bristol_Bay_2088586...\n",
      "----------\n",
      "Site ID: CIK_Big Creek OK\n",
      " 328 of 489 -  Clipping CIK_Big Creek to Bristol_Bay_2072993...\n",
      "----------\n",
      "Site ID: CIK_Copper River OK\n",
      " 329 of 489 -  Clipping CIK_Copper River to Bristol_Bay_2065755...\n",
      "----------\n",
      "Site ID: CIK_Gibraltar River OK\n",
      " 330 of 489 -  Clipping CIK_Gibraltar River to Bristol_Bay_2066955...\n",
      "----------\n",
      "Site ID: CIK_Napotoli Creek OK\n",
      " 331 of 489 -  Clipping CIK_Napotoli Creek to Bristol_Bay_4099594...\n",
      "----------\n",
      "Site ID: CIK_Neilson Creek OK\n",
      " 332 of 489 -  Clipping CIK_Neilson Creek to Bristol_Bay_4051056...\n",
      "----------\n",
      "Site ID: CIK_Panaruqak Creek OK\n",
      " 333 of 489 -  Clipping CIK_Panaruqak Creek to Bristol_Bay_4076575...\n",
      "----------\n",
      "Site ID: CIK_Roadhouse Creek OK\n",
      " 334 of 489 -  Clipping CIK_Roadhouse Creek to Bristol_Bay_2067494...\n",
      "----------\n",
      "Site ID: CIK_Silver Salmon Creek OK\n",
      " 335 of 489 -  Clipping CIK_Silver Salmon Creek to Bristol_Bay_4059736...\n",
      "----------\n",
      "Site ID: CIK_Sivanguq Creek OK\n",
      " 336 of 489 -  Clipping CIK_Sivanguq Creek to Bristol_Bay_4106904...\n",
      "----------\n",
      "Site ID: CIK_Squaw Creek OK\n",
      " 337 of 489 -  Clipping CIK_Squaw Creek to Bristol_Bay_4055337...\n",
      "----------\n",
      "Site ID: CIK_Tunravik Creek OK\n",
      " 338 of 489 -  Clipping CIK_Tunravik Creek to Bristol_Bay_4080875...\n",
      "----------\n",
      "Site ID: CIK_Yellow Creek OK\n",
      " 339 of 489 -  Clipping CIK_Yellow Creek to Bristol_Bay_2088326...\n",
      "----------\n",
      "Site ID: GELO OK\n",
      " 340 of 489 -  Clipping GELO to Bristol_Bay_5030363...\n",
      "----------\n",
      "Site ID: ilbig01 OK\n",
      " 341 of 489 -  Clipping ilbig01 to Bristol_Bay_2072993...\n",
      "----------\n",
      "Site ID: iltaz02 OK\n",
      " 342 of 489 -  Clipping iltaz02 to Bristol_Bay_2082393...\n",
      "----------\n",
      "Site ID: iltnr19 OK\n",
      " 343 of 489 -  Clipping iltnr19 to Bristol_Bay_2084713...\n",
      "----------\n",
      "Site ID: KATM_idavc_stream_water OK\n",
      " 344 of 489 -  Clipping KATM_idavc_stream_water to Bristol_Bay_3023044...\n",
      "----------\n",
      "Site ID: KATM_lbrooo_lvl OK\n",
      " 345 of 489 -  Clipping KATM_lbrooo_lvl to Bristol_Bay_3030955...\n",
      "----------\n",
      "Site ID: KATM_lbrooo_temp OK\n",
      " 346 of 489 -  Clipping KATM_lbrooo_temp to Bristol_Bay_3030955...\n",
      "----------\n",
      "Site ID: KATM_margc_stream_water OK\n",
      " 347 of 489 -  Clipping KATM_margc_stream_water to Bristol_Bay_3033956...\n",
      "----------\n",
      "Site ID: KATM_naknlo_continuous_wq OK\n",
      " 348 of 489 -  Clipping KATM_naknlo_continuous_wq to Bristol_Bay_3024343...\n",
      "----------\n",
      "Site ID: KATM_naknlo_lvl OK\n",
      " 349 of 489 -  Clipping KATM_naknlo_lvl to Bristol_Bay_3024343...\n",
      "----------\n",
      "Site ID: KATM_naknlo_temp OK\n",
      " 350 of 489 -  Clipping KATM_naknlo_temp to Bristol_Bay_3024343...\n",
      "----------\n",
      "Site ID: KATM_savor_stream_water OK\n",
      " 351 of 489 -  Clipping KATM_savor_stream_water to Bristol_Bay_3034126...\n",
      "----------\n",
      "Site ID: KATM_upatc_stream_water OK\n",
      " 352 of 489 -  Clipping KATM_upatc_stream_water to Bristol_Bay_3033666...\n",
      "----------\n",
      "Site ID: KULR OK\n",
      " 353 of 489 -  Clipping KULR to Bristol_Bay_5038375...\n",
      "----------\n",
      "Site ID: LACL_kijilo_lvl OK\n",
      " 354 of 489 -  Clipping LACL_kijilo_lvl to Bristol_Bay_2078282...\n",
      "----------\n",
      "Site ID: LACL_kijilo_temp OK\n",
      " 355 of 489 -  Clipping LACL_kijilo_temp to Bristol_Bay_2078282...\n",
      "----------\n",
      "Site ID: LACL_lclaro_continuous_wq OK\n",
      " 356 of 489 -  Clipping LACL_lclaro_continuous_wq to Bristol_Bay_2087913...\n",
      "----------\n",
      "Site ID: LACL_lclaro_lvl OK\n",
      " 357 of 489 -  Clipping LACL_lclaro_lvl to Bristol_Bay_2087913...\n",
      "----------\n",
      "Site ID: LACL_lclaro_temp OK\n",
      " 358 of 489 -  Clipping LACL_lclaro_temp to Bristol_Bay_2087913...\n",
      "----------\n",
      "Site ID: LACL_lkijr_stream_water OK\n",
      " 359 of 489 -  Clipping LACL_lkijr_stream_water to Bristol_Bay_2078282...\n",
      "----------\n",
      "Site ID: LACL_tazir_stream_water OK\n",
      " 360 of 489 -  Clipping LACL_tazir_stream_water to Bristol_Bay_2082373...\n",
      "----------\n",
      "Site ID: LACL_tlikr_stream_water OK\n",
      " 361 of 489 -  Clipping LACL_tlikr_stream_water to Bristol_Bay_2041471...\n",
      "----------\n",
      "Site ID: MALR OK\n",
      " 362 of 489 -  Clipping MALR to Bristol_Bay_5020796...\n",
      "----------\n",
      "Site ID: mubon10 OK\n",
      " 363 of 489 -  Clipping mubon10 to Bristol_Bay_4054200...\n",
      "----------\n",
      "Site ID: muekm23 OK\n",
      " 364 of 489 -  Clipping muekm23 to Bristol_Bay_4092244...\n",
      "----------\n",
      "Site ID: musfk01 OK\n",
      " 365 of 489 -  Clipping musfk01 to Bristol_Bay_4099694...\n",
      "----------\n",
      "Site ID: mussm15 OK\n",
      " 366 of 489 -  Clipping mussm15 to Bristol_Bay_4091424...\n",
      "----------\n",
      "Site ID: mustu17 OK\n",
      " 367 of 489 -  Clipping mustu17 to Bristol_Bay_4104574...\n",
      "----------\n",
      "Site ID: mutsk02 OK\n",
      " 368 of 489 -  Clipping mutsk02 to Bristol_Bay_4089074...\n",
      "----------\n",
      "Site ID: mutsk09 OK\n",
      " 369 of 489 -  Clipping mutsk09 to Bristol_Bay_4088904...\n",
      "----------\n",
      "Site ID: NCLO OK\n",
      " 370 of 489 -  Clipping NCLO to Bristol_Bay_5030704...\n",
      "----------\n",
      "Site ID: Newhalen River OK\n",
      " 371 of 489 -  Clipping Newhalen River to Bristol_Bay_2088253...\n",
      "----------\n",
      "Site ID: NPS_Chulitna_SiteB OK\n",
      " 372 of 489 -  Clipping NPS_Chulitna_SiteB to Bristol_Bay_2085642...\n",
      "----------\n",
      "Site ID: NPS_Hardenburg_Bay OK\n",
      " 373 of 489 -  Clipping NPS_Hardenburg_Bay to Bristol_Bay_2068072...\n",
      "----------\n",
      "Site ID: NPS_Little_Kijik_River_Dan OK\n",
      " 374 of 489 -  Clipping NPS_Little_Kijik_River_Dan to Bristol_Bay_2078232...\n",
      "----------\n",
      "Site ID: NPS_Newhalen_River OK\n",
      " 375 of 489 -  Clipping NPS_Newhalen_River to Bristol_Bay_2088253...\n",
      "----------\n",
      "Site ID: NPS_Six_Mile_Outlet OK\n",
      " 376 of 489 -  Clipping NPS_Six_Mile_Outlet to Bristol_Bay_2088163...\n",
      "----------\n",
      "Site ID: OSLR OK\n",
      " 377 of 489 -  Clipping OSLR to Bristol_Bay_5021476...\n",
      "----------\n",
      "Site ID: OSLR2 OK\n",
      " 378 of 489 -  Clipping OSLR2 to Bristol_Bay_5021476...\n",
      "----------\n",
      "Site ID: PULO OK\n",
      " 379 of 489 -  Clipping PULO to Bristol_Bay_5032474...\n",
      "----------\n",
      "Site ID: PULR OK\n",
      " 380 of 489 -  Clipping PULR to Bristol_Bay_5033094...\n",
      "----------\n",
      "Site ID: SLLR OK\n",
      " 381 of 489 -  Clipping SLLR to Bristol_Bay_5008707...\n",
      "----------\n",
      "Site ID: TOLO OK\n",
      " 382 of 489 -  Clipping TOLO to Bristol_Bay_5034893...\n",
      "----------\n",
      "Site ID: TOLR OK\n",
      " 383 of 489 -  Clipping TOLR to Bristol_Bay_4071036...\n",
      "----------\n",
      "Site ID: UW_Agulowak River OK\n",
      " 384 of 489 -  Clipping UW_Agulowak River to Bristol_Bay_4088675...\n",
      "----------\n",
      "Site ID: UW_Agulukpak River OK\n",
      " 385 of 489 -  Clipping UW_Agulukpak River to Bristol_Bay_4087015...\n",
      "----------\n",
      "Site ID: UW_Aleknagik Bear Creek OK\n",
      " 386 of 489 -  Clipping UW_Aleknagik Bear Creek to Bristol_Bay_4063606...\n",
      "----------\n",
      "Site ID: UW_Aleknagik Big Whitefish Creek OK\n",
      " 387 of 489 -  Clipping UW_Aleknagik Big Whitefish Creek to Bristol_Bay_4059016...\n",
      "----------\n",
      "Site ID: UW_Aleknagik Eagle Creek OK\n",
      " 388 of 489 -  Clipping UW_Aleknagik Eagle Creek to Bristol_Bay_4052076...\n",
      "----------\n",
      "Site ID: UW_Aleknagik Hansen Creek OK\n",
      " 389 of 489 -  Clipping UW_Aleknagik Hansen Creek to Bristol_Bay_4048046...\n",
      "----------\n",
      "Site ID: UW_Aleknagik Happy Creek OK\n",
      " 390 of 489 -  Clipping UW_Aleknagik Happy Creek to Bristol_Bay_4069586...\n",
      "----------\n",
      "Site ID: UW_Aleknagik Ice Creek OK\n",
      " 391 of 489 -  Clipping UW_Aleknagik Ice Creek to Bristol_Bay_4074726...\n",
      "----------\n",
      "Site ID: UW_Aleknagik Mission Creek OK\n",
      " 392 of 489 -  Clipping UW_Aleknagik Mission Creek to Bristol_Bay_4051616...\n",
      "----------\n",
      "Site ID: UW_Aleknagik Pfifer Creek OK\n",
      " 393 of 489 -  Clipping UW_Aleknagik Pfifer Creek to Bristol_Bay_4060036...\n",
      "----------\n",
      "Site ID: UW_Aleknagik Silver Salmon Creek OK\n",
      " 394 of 489 -  Clipping UW_Aleknagik Silver Salmon Creek to Bristol_Bay_4059736...\n",
      "----------\n",
      "Site ID: UW_Aleknagik Squaw Creek OK\n",
      " 395 of 489 -  Clipping UW_Aleknagik Squaw Creek to Bristol_Bay_4046617...\n",
      "----------\n",
      "Site ID: UW_Aleknagik Sunshine Creek OK\n",
      " 396 of 489 -  Clipping UW_Aleknagik Sunshine Creek to Bristol_Bay_4084145...\n",
      "----------\n",
      "Site ID: UW_Aleknagik Yako Creek OK\n",
      " 397 of 489 -  Clipping UW_Aleknagik Yako Creek to Bristol_Bay_4061136...\n",
      "----------\n",
      "Site ID: UW_Aleknagik Youth Creek OK\n",
      " 398 of 489 -  Clipping UW_Aleknagik Youth Creek to Bristol_Bay_4080045...\n",
      "----------\n",
      "Site ID: UW_Beverley Hope Creek OK\n",
      " 399 of 489 -  Clipping UW_Beverley Hope Creek to Bristol_Bay_4095374...\n",
      "----------\n",
      "Site ID: UW_Beverley Moose Creek OK\n",
      " 400 of 489 -  Clipping UW_Beverley Moose Creek to Bristol_Bay_4098114...\n",
      "----------\n",
      "Site ID: UW_Beverley Silverhorn Creek OK\n",
      " 401 of 489 -  Clipping UW_Beverley Silverhorn Creek to Bristol_Bay_4091164...\n",
      "----------\n",
      "Site ID: UW_Beverley Uno Creek OK\n",
      " 402 of 489 -  Clipping UW_Beverley Uno Creek to Bristol_Bay_4089574...\n",
      "----------\n",
      "Site ID: UW_Kulik Grant River OK\n",
      " 403 of 489 -  Clipping UW_Kulik Grant River to Bristol_Bay_4102124...\n",
      "----------\n",
      "Site ID: UW_Kulik K-3 Creek OK\n",
      " 404 of 489 -  Clipping UW_Kulik K-3 Creek to Bristol_Bay_4101274...\n",
      "----------\n",
      "Site ID: UW_Kulik Kulik Creek OK\n",
      " 405 of 489 -  Clipping UW_Kulik Kulik Creek to Bristol_Bay_4105594...\n",
      "----------\n",
      "Site ID: UW_Little Togiak C Creek OK\n",
      " 406 of 489 -  Clipping UW_Little Togiak C Creek to Bristol_Bay_4068584...\n",
      "----------\n",
      "Site ID: UW_Little Togiak Creek OK\n",
      " 407 of 489 -  Clipping UW_Little Togiak Creek to Bristol_Bay_4093084...\n",
      "----------\n",
      "Site ID: UW_Nerka Allah Creek OK\n",
      " 408 of 489 -  Clipping UW_Nerka Allah Creek to Bristol_Bay_4069455...\n",
      "----------\n",
      "Site ID: UW_Nerka Bear Creek OK\n",
      " 409 of 489 -  Clipping UW_Nerka Bear Creek to Bristol_Bay_4069495...\n",
      "----------\n",
      "Site ID: UW_Nerka Beaver Creek OK\n",
      " 410 of 489 -  Clipping UW_Nerka Beaver Creek to Bristol_Bay_4075715...\n",
      "----------\n",
      "Site ID: UW_Nerka Berm Creek OK\n",
      " 411 of 489 -  Clipping UW_Nerka Berm Creek to Bristol_Bay_4074184...\n",
      "----------\n",
      "Site ID: UW_Nerka Bug Creek OK\n",
      " 412 of 489 -  Clipping UW_Nerka Bug Creek to Bristol_Bay_4063775...\n",
      "----------\n",
      "Site ID: UW_Nerka Cabin Creek OK\n",
      " 413 of 489 -  Clipping UW_Nerka Cabin Creek to Bristol_Bay_4087224...\n",
      "----------\n",
      "Site ID: UW_Nerka Chamee Creek OK\n",
      " 414 of 489 -  Clipping UW_Nerka Chamee Creek to Bristol_Bay_4051055...\n",
      "----------\n",
      "Site ID: UW_Nerka Cottonwood Creek OK\n",
      " 415 of 489 -  Clipping UW_Nerka Cottonwood Creek to Bristol_Bay_4075474...\n",
      "----------\n",
      "Site ID: UW_Nerka Elva Creek OK\n",
      " 416 of 489 -  Clipping UW_Nerka Elva Creek to Bristol_Bay_4096064...\n",
      "----------\n",
      "Site ID: UW_Nerka Fenno Creek OK\n",
      " 417 of 489 -  Clipping UW_Nerka Fenno Creek to Bristol_Bay_4076505...\n",
      "----------\n",
      "Site ID: UW_Nerka Hidden Lake Creek OK\n",
      " 418 of 489 -  Clipping UW_Nerka Hidden Lake Creek to Bristol_Bay_4064845...\n",
      "----------\n",
      "Site ID: UW_Nerka Joe Creek OK\n",
      " 419 of 489 -  Clipping UW_Nerka Joe Creek to Bristol_Bay_4089394...\n",
      "----------\n",
      "Site ID: UW_Nerka Kema Creek OK\n",
      " 420 of 489 -  Clipping UW_Nerka Kema Creek to Bristol_Bay_4076675...\n",
      "----------\n",
      "Site ID: UW_Nerka Little Togiak River OK\n",
      " 421 of 489 -  Clipping UW_Nerka Little Togiak River to Bristol_Bay_4084915...\n",
      "----------\n",
      "Site ID: UW_Nerka Lynx Creek Cold Tributary OK\n",
      " 422 of 489 -  Clipping UW_Nerka Lynx Creek Cold Tributary to Bristol_Bay_4073375...\n",
      "----------\n",
      "Site ID: UW_Nerka Lynx Creek OK\n",
      " 423 of 489 -  Clipping UW_Nerka Lynx Creek to Bristol_Bay_4075225...\n",
      "----------\n",
      "Site ID: UW_Nerka Lynx Lake Tributary OK\n",
      " 424 of 489 -  Clipping UW_Nerka Lynx Lake Tributary to Bristol_Bay_4073375...\n",
      "----------\n",
      "Site ID: UW_Nerka N4 Creek OK\n",
      " 425 of 489 -  Clipping UW_Nerka N4 Creek to Bristol_Bay_4064055...\n",
      "----------\n",
      "Site ID: UW_Nerka Pick Creek OK\n",
      " 426 of 489 -  Clipping UW_Nerka Pick Creek to Bristol_Bay_4074505...\n",
      "----------\n",
      "Site ID: UW_Nerka Rainbow Creek OK\n",
      " 427 of 489 -  Clipping UW_Nerka Rainbow Creek to Bristol_Bay_4096454...\n",
      "----------\n",
      "Site ID: UW_Nerka Sam Creek OK\n",
      " 428 of 489 -  Clipping UW_Nerka Sam Creek to Bristol_Bay_4089384...\n",
      "----------\n",
      "Site ID: UW_Nerka Seventh Creek OK\n",
      " 429 of 489 -  Clipping UW_Nerka Seventh Creek to Bristol_Bay_4079234...\n",
      "----------\n",
      "Site ID: UW_Nerka Sixth Creek OK\n",
      " 430 of 489 -  Clipping UW_Nerka Sixth Creek to Bristol_Bay_4082225...\n",
      "----------\n",
      "Site ID: UW_Nerka Stovall Creek OK\n",
      " 431 of 489 -  Clipping UW_Nerka Stovall Creek to Bristol_Bay_4078235...\n",
      "----------\n",
      "Site ID: UW_Nerka Teal Creek OK\n",
      " 432 of 489 -  Clipping UW_Nerka Teal Creek to Bristol_Bay_4071625...\n",
      "----------\n",
      "Site ID: WELR OK\n",
      " 433 of 489 -  Clipping WELR to Bristol_Bay_4071256...\n",
      "----------\n",
      "Site ID: WELR2 OK\n",
      " 434 of 489 -  Clipping WELR2 to Bristol_Bay_4071256...\n",
      "----------\n",
      "Site ID: kdk_busrv01 OK\n",
      " 435 of 489 -  Clipping kdk_busrv01 to Kodiak_76954...\n",
      "----------\n",
      "Site ID: kdk_doscr01 OK\n",
      " 436 of 489 -  Clipping kdk_doscr01 to Kodiak_49617...\n",
      "----------\n",
      "Site ID: kdk_karrv01 OK\n",
      " 437 of 489 -  Clipping kdk_karrv01 to Kodiak_130735...\n",
      "----------\n",
      "Site ID: kdk_doscr02 OK\n",
      " 438 of 489 -  Clipping kdk_doscr02 to Kodiak_106676...\n",
      "----------\n",
      "Site ID: kdk_olgcr01a OK\n",
      " 439 of 489 -  Clipping kdk_olgcr01a to Kodiak_48267...\n",
      "----------\n",
      "Site ID: kdk_olgcr01b OK\n",
      " 440 of 489 -  Clipping kdk_olgcr01b to Kodiak_48267...\n",
      "----------\n",
      "Site ID: kdk_ayarv01 OK\n",
      " 441 of 489 -  Clipping kdk_ayarv01 to Kodiak_108356...\n",
      "----------\n",
      "Site ID: kdk_akacr01 OK\n",
      " 442 of 489 -  Clipping kdk_akacr01 to Kodiak_50197...\n",
      "----------\n",
      "Site ID: kdk_ayarv03 OK\n",
      " 443 of 489 -  Clipping kdk_ayarv03 to Kodiak_107796...\n",
      "----------\n",
      "Site ID: kdk_cancr01 OK\n",
      " 444 of 489 -  Clipping kdk_cancr01 to Kodiak_101556...\n",
      "----------\n",
      "Site ID: kdk_concr01 OK\n",
      " 445 of 489 -  Clipping kdk_concr01 to Kodiak_97276...\n",
      "----------\n",
      "Site ID: kdk_pincr01 OK\n",
      " 446 of 489 -  Clipping kdk_pincr01 to Kodiak_103296...\n",
      "----------\n",
      "Site ID: kdk_relrv01 OK\n",
      " 447 of 489 -  Clipping kdk_relrv01 to Kodiak_103196...\n",
      "----------\n",
      "Site ID: kdk_cascr01 OK\n",
      " 448 of 489 -  Clipping kdk_cascr01 to Kodiak_94216...\n",
      "----------\n",
      "Site ID: kdk_eftrv01 OK\n",
      " 449 of 489 -  Clipping kdk_eftrv01 to Kodiak_103096...\n",
      "----------\n",
      "Site ID: kdk_falcr01 OK\n",
      " 450 of 489 -  Clipping kdk_falcr01 to Kodiak_99516...\n",
      "----------\n",
      "Site ID: kdk_meacr01 OK\n",
      " 451 of 489 -  Clipping kdk_meacr01 to Kodiak_93176...\n",
      "----------\n",
      "Site ID: kdk_omarv01 OK\n",
      " 452 of 489 -  Clipping kdk_omarv01 to Kodiak_100826...\n",
      "----------\n",
      "Site ID: kdk_soucr01 OK\n",
      " 453 of 489 -  Clipping kdk_soucr01 to Kodiak_90346...\n",
      "----------\n",
      "Site ID: kdk_akacr02 OK\n",
      " 454 of 489 -  Clipping kdk_akacr02 to Kodiak_50197...\n",
      "----------\n",
      "Site ID: kdk_cancr02 OK\n",
      " 455 of 489 -  Clipping kdk_cancr02 to Kodiak_101556...\n",
      "----------\n",
      "Site ID: kdk_falcr02 OK\n",
      " 456 of 489 -  Clipping kdk_falcr02 to Kodiak_99516...\n",
      "----------\n",
      "Site ID: kdk_pincr02 OK\n",
      " 457 of 489 -  Clipping kdk_pincr02 to Kodiak_103456...\n",
      "----------\n",
      "Site ID: fws_kdk_aforv01 OK\n",
      " 458 of 489 -  Clipping fws_kdk_aforv01 to Kodiak_64593...\n",
      "----------\n",
      "Site ID: fws_kdk_busrv01 OK\n",
      " 459 of 489 -  Clipping fws_kdk_busrv01 to Kodiak_77794...\n",
      "----------\n",
      "Site ID: 571005154134600 OK\n",
      " 460 of 489 -  Clipping 571005154134600 to Kodiak_50197...\n",
      "----------\n",
      "Site ID: 571221154040300 OK\n",
      " 461 of 489 -  Clipping 571221154040300 to Kodiak_106626...\n",
      "----------\n",
      "Site ID: 571343154244900 OK\n",
      " 462 of 489 -  Clipping 571343154244900 to Kodiak_107816...\n",
      "----------\n",
      "Site ID: 572656154082400 OK\n",
      " 463 of 489 -  Clipping 572656154082400 to Kodiak_129955...\n",
      "----------\n",
      "Site ID: kdk_bigcr01 OK\n",
      " 464 of 489 -  Clipping kdk_bigcr01 to Kodiak_103496...\n",
      "----------\n",
      "Site ID: kdk_karrv02 OK\n",
      " 465 of 489 -  Clipping kdk_karrv02 to Kodiak_130295...\n",
      "----------\n",
      "Site ID: 15295700 OK\n",
      " 466 of 489 -  Clipping 15295700 to Kodiak_128685...\n",
      "----------\n",
      "Site ID: 15297475 OK\n",
      " 467 of 489 -  Clipping 15297475 to Kodiak_72144...\n",
      "----------\n",
      "Site ID: nv_Eyak_Hartney Creek OK\n",
      " 468 of 489 -  Clipping nv_Eyak_Hartney Creek to Prince_William_Sound_29854...\n",
      "----------\n",
      "Site ID: nv_Eyak_Heney Creek OK\n",
      " 469 of 489 -  Clipping nv_Eyak_Heney Creek to Prince_William_Sound_26464...\n",
      "----------\n",
      "Site ID: PWSCC_Erb OK\n",
      " 470 of 489 -  Clipping PWSCC_Erb to Prince_William_Sound_36645...\n",
      "----------\n",
      "Site ID: PWSCC_Gilmour OK\n",
      " 471 of 489 -  Clipping PWSCC_Gilmour to Prince_William_Sound_31865...\n",
      "----------\n",
      "Site ID: PWSCC_Hogan OK\n",
      " 472 of 489 -  Clipping PWSCC_Hogan to Prince_William_Sound_28086...\n",
      "----------\n",
      "Site ID: PWSCC_Stockdale OK\n",
      " 473 of 489 -  Clipping PWSCC_Stockdale to Prince_William_Sound_41515...\n",
      "----------\n",
      "Site ID: USFS_Eagle Creek OK\n",
      " 474 of 489 -  Clipping USFS_Eagle Creek to Prince_William_Sound_30884...\n",
      "----------\n",
      "Apostrophe found in USFS_Hell's Hole Trib, replacing with USFS_Hell''s Hole Trib\n",
      " 475 of 489 -  Clipping USFS_Hell's Hole Trib to Prince_William_Sound_38993...\n",
      "----------\n",
      "Site ID: USFS_Jackpot River OK\n",
      " 476 of 489 -  Clipping USFS_Jackpot River to Prince_William_Sound_43055...\n",
      "----------\n",
      "Site ID: USFS_Koppen Creek OK\n",
      " 477 of 489 -  Clipping USFS_Koppen Creek to Prince_William_Sound_43973...\n",
      "----------\n",
      "Site ID: USFS_Olsen Creek OK\n",
      " 478 of 489 -  Clipping USFS_Olsen Creek to Prince_William_Sound_43383...\n",
      "----------\n",
      "Site ID: USFS_Pigot Bay Spawn Channel OK\n",
      " 479 of 489 -  Clipping USFS_Pigot Bay Spawn Channel to Prince_William_Sound_44553...\n",
      "----------\n",
      "Site ID: USFS_Rude River SC OK\n",
      " 480 of 489 -  Clipping USFS_Rude River SC to Prince_William_Sound_46513...\n",
      "----------\n",
      "Site ID: USFS_Sheep River OK\n",
      " 481 of 489 -  Clipping USFS_Sheep River to Prince_William_Sound_43933...\n",
      "----------\n",
      "Site ID: USFS_Shelter Bay Trib OK\n",
      " 482 of 489 -  Clipping USFS_Shelter Bay Trib to Prince_William_Sound_46055...\n",
      "----------\n",
      "Site ID: USFS_Solf Lake Fish Pass OK\n",
      " 483 of 489 -  Clipping USFS_Solf Lake Fish Pass to Prince_William_Sound_37815...\n",
      "----------\n",
      "Site ID: USFS_Stump Lake Outlet OK\n",
      " 484 of 489 -  Clipping USFS_Stump Lake Outlet to Prince_William_Sound_18457...\n",
      "----------\n",
      "Site ID: USFS_ERB Creek OK\n",
      " 485 of 489 -  Clipping USFS_ERB Creek to Prince_William_Sound_36645...\n",
      "----------\n",
      "Site ID: USFS_Solf Lake Outlet Creek OK\n",
      " 486 of 489 -  Clipping USFS_Solf Lake Outlet Creek to Prince_William_Sound_37815...\n",
      "----------\n",
      "Site ID: 15219000 OK\n",
      " 487 of 489 -  Clipping 15219000 to Prince_William_Sound_42563...\n",
      "----------\n",
      "Site ID: 15236900 OK\n",
      " 488 of 489 -  Clipping 15236900 to Prince_William_Sound_43185...\n",
      "----------\n",
      "Site ID: 15237030 OK\n",
      " 489 of 489 -  Clipping 15237030 to Prince_William_Sound_40285...\n",
      "----------\n",
      "Process completed at 2021-12-03 11:06 (Elapsed time: 0:07:58)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "import os\n",
    "from arcpy.sa import *\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Setting outgdb to location created in Covariate notebook but any temp gdb will work\n",
    "outgdb = r\"D:\\\\GIS\\\\AKSSF_land_met\\\\AKSSF_land_met.gdb\"\n",
    "# Set data dir = to folder with regional subfolders and gdbs\n",
    "data_dir = r\"D:\\GIS\\AKSSF\"\n",
    "arcpy.env.workspace = data_dir\n",
    "arcpy.env.overwriteOutput = True\n",
    "sr = arcpy.SpatialReference(3338)  #'NAD_1983_Alaska_Albers'\n",
    "arcpy.env.outputCoordinateSystem = sr\n",
    "regions = arcpy.ListWorkspaces(workspace_type=\"Folder\")\n",
    "#buffer value of 30 meters\n",
    "buffval = 30\n",
    "bufpath = os.path.join(outgdb, \"sites_buffer\")\n",
    "buffer = arcpy.Buffer_analysis(sitesmerge, bufpath, \"30 meters\")\n",
    "# this makes sure the buffer does not extend outside of the catchment - cannot use memory/ object as input for zonal stats\n",
    "# must write to gdb\n",
    "clips = []\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "buflyr = arcpy.MakeFeatureLayer_management(bufpath, \"buflyr\")\n",
    "catlayer = arcpy.MakeFeatureLayer_management(catsmerge, 'catlayer')\n",
    "fieldlist = []\n",
    "fields = arcpy.ListFields(bufpath)\n",
    "for field in fields:\n",
    "    fieldlist.append(field.name)\n",
    "row_count = len(list(i for i in arcpy.da.SearchCursor(bufpath, fieldlist)))\n",
    "print(row_count)\n",
    "\n",
    "c = 1\n",
    "with arcpy.da.SearchCursor(bufpath, ['SiteID', 'cat_ID_con', 'OBJECTID']) as cur:\n",
    "    for row in cur:\n",
    "        fieldValue = str(row[0])\n",
    "        if fieldValue.find(\"'\") != -1:\n",
    "            newVal = fieldValue.replace(\"'\", \"''\")\n",
    "            print(f'Apostrophe found in {fieldValue}, replacing with {newVal}')\n",
    "        else:\n",
    "            print(f'Site ID: {fieldValue} OK')\n",
    "            newVal = fieldValue\n",
    "\n",
    "        clause = \"\"\" \"cat_ID_con\" = '%s'\"\"\" % row[1]\n",
    "        clause1 = \"\"\" \"SiteID\" = '%s'\"\"\" % newVal\n",
    "        print(f' {c} of {row_count} -  Clipping {row[0]} to {row[1]}...')\n",
    "        print('----------')\n",
    "        bufselect = arcpy.SelectLayerByAttribute_management(buflyr, 'NEW_SELECTION', where_clause=clause1)\n",
    "        catselect = arcpy.SelectLayerByAttribute_management(catlayer, 'NEW_SELECTION', where_clause=clause)\n",
    "        clipname = 'clip_' + str(c)\n",
    "        clipout = os.path.join(outgdb, clipname)\n",
    "        clip = arcpy.Clip_analysis(bufselect, catselect, clipout)\n",
    "        clips.append(clipout)\n",
    "        c += 1\n",
    "    del (row)\n",
    "del (cur)\n",
    "\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "\n",
    "# Report success\n",
    "print(f'Process completed at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "      f'(Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print('----------')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete...\n",
      "----------\n",
      "Process completed at 2021-12-03 11:09 (Elapsed time: 0:03:15)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "import arcpy, datetime, time\n",
    "\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "\n",
    "# Merge Clips and delete individual clipped buffers\n",
    "clip_path = os.path.join(outgdb, 'all_buffsites_clip')\n",
    "clip_outfile = arcpy.Merge_management(clips, clip_path)\n",
    "\n",
    "delete = clips\n",
    "for d in delete:\n",
    "    arcpy.DeleteFeatures_management(d)\n",
    "print('Complete...')\n",
    "print('----------')\n",
    "\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "\n",
    "# Report success\n",
    "print(f'Process completed at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "      f'(Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print('----------')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cook_Inlet in ['Cook_Inlet', 'Copper_River'] AKSSF list, using cat_fields ['cat_ID_txt', 'NHDPlusID', 'cat_ID_con'] and spatial join fields ['cat_ID_txt', 'cat_ID', 'cat_ID_con']\n",
      "----------\n",
      "Cook_Inlet using data from D:\\GIS\\AKSSF\\Cook_Inlet folder\n",
      "--------\n",
      "Flow accumulation grid D:\\GIS\\AKSSF\\Cook_Inlet\\fac.tif selected for Cook_Inlet\n",
      "Calculating Cook_Inlet catchment Max flow accumulation stats...\n",
      "Max Flow zonal stats for Cook_Inlet Elapsed time: (0:04:49)\n",
      "----------\n",
      "Copper_River in ['Cook_Inlet', 'Copper_River'] AKSSF list, using cat_fields ['cat_ID_txt', 'NHDPlusID', 'cat_ID_con'] and spatial join fields ['cat_ID_txt', 'cat_ID', 'cat_ID_con']\n",
      "----------\n",
      "Copper_River using data from D:\\GIS\\AKSSF\\Copper_River folder\n",
      "--------\n",
      "Flow accumulation grid D:\\GIS\\AKSSF\\Copper_River\\fac.tif selected for Copper_River\n",
      "Calculating Copper_River catchment Max flow accumulation stats...\n",
      "Max Flow zonal stats for Copper_River Elapsed time: (0:01:22)\n",
      "----------\n",
      "Bristol_Bay in ['Bristol_Bay', 'Kodiak', 'Prince_William_Sound'] TauDEM list, using cat_fields ['cat_ID_txt', 'catID', 'cat_ID_con'] and spatial join fields ['cat_ID_txt', 'cat_ID', 'cat_ID_con']\n",
      "----------\n",
      "Bristol_Bay using data from D:\\GIS\\AKSSF\\Bristol_Bay folder\n",
      "--------\n",
      "Flow accumulation grid D:\\GIS\\AKSSF\\Bristol_Bay\\fac.tif selected for Bristol_Bay\n",
      "Calculating Bristol_Bay catchment Max flow accumulation stats...\n",
      "Max Flow zonal stats for Bristol_Bay Elapsed time: (0:00:39)\n",
      "----------\n",
      "Kodiak in ['Bristol_Bay', 'Kodiak', 'Prince_William_Sound'] TauDEM list, using cat_fields ['cat_ID_txt', 'gridcode', 'cat_ID_con'] and spatial join fields ['cat_ID_txt', 'cat_ID', 'cat_ID_con']\n",
      "----------\n",
      "Kodiak using data from D:\\GIS\\AKSSF\\Kodiak folder\n",
      "--------\n",
      "Flow accumulation grid D:\\GIS\\AKSSF\\Kodiak\\fac.tif selected for Kodiak\n",
      "Calculating Kodiak catchment Max flow accumulation stats...\n",
      "Max Flow zonal stats for Kodiak Elapsed time: (0:00:10)\n",
      "----------\n",
      "Prince_William_Sound in ['Bristol_Bay', 'Kodiak', 'Prince_William_Sound'] TauDEM list, using cat_fields ['cat_ID_txt', 'gridcode', 'cat_ID_con'] and spatial join fields ['cat_ID_txt', 'cat_ID', 'cat_ID_con']\n",
      "----------\n",
      "Prince_William_Sound using data from D:\\GIS\\AKSSF\\Prince_William_Sound folder\n",
      "--------\n",
      "Flow accumulation grid D:\\GIS\\AKSSF\\Prince_William_Sound\\fac.tif selected for Prince_William_Sound\n",
      "Calculating Prince_William_Sound catchment Max flow accumulation stats...\n",
      "Max Flow zonal stats for Prince_William_Sound Elapsed time: (0:00:11)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#zonal stats on buffer intersection with flow accumulation grids (need to loop through regions for this)\n",
    "# to get maximum flow accumulation bc some points may not exactly fall on stream grid\n",
    "tbl_lst = []\n",
    "# Seperate data by\n",
    "nhdplus_dat = ['Cook_Inlet', 'Copper_River']\n",
    "tauDem_dat = ['Bristol_Bay', 'Kodiak', 'Prince_William_Sound']\n",
    "\n",
    "# Loop through all processing areas\n",
    "rois = nhdplus_dat + tauDem_dat\n",
    "\n",
    "for roi in rois:\n",
    "    # Loop through regional folders\n",
    "    # Grab stream order from VAA/Streams and join to sites_sj\n",
    "    for region in regions:\n",
    "        arcpy.env.workspace = region\n",
    "        raslist = arcpy.ListRasters()\n",
    "        if roi in str(region):\n",
    "            if roi in nhdplus_dat:\n",
    "                cat_cur_fields = ['cat_ID_txt', 'NHDPlusID', \"cat_ID_con\"]\n",
    "                cf = 25\n",
    "                # grab stream order from vaa - upstream and downstream lengths - and stream gradient\n",
    "                vaa = 'vaa_merge'\n",
    "                print(f'{roi} in {nhdplus_dat} AKSSF list, using cat_fields {cat_cur_fields} and spatial join fields '\n",
    "                      f'{sj_cur_fields}')\n",
    "                print('----------')\n",
    "            # Set data and variables unique to regions with TauDEM Data\n",
    "            elif roi in tauDem_dat:\n",
    "                # grab stream order from tauDEM - upstream and downstream lengths - and stream gradient\n",
    "                streams = \"streams_merge\"\n",
    "                # Fields for update cursor\n",
    "                if roi == 'Bristol_Bay':\n",
    "                    # Fields for update cursor\n",
    "                    cat_cur_fields = ['cat_ID_txt', 'catID', \"cat_ID_con\"]\n",
    "                else:\n",
    "                    cat_cur_fields = ['cat_ID_txt', 'gridcode', \"cat_ID_con\"]\n",
    "                cf = 100\n",
    "                print(f'{roi} in {tauDem_dat} TauDEM list, using cat_fields {cat_cur_fields} and spatial join fields '\n",
    "                      f'{sj_cur_fields}')\n",
    "                print('----------')\n",
    "            print(f'{roi} using data from {region} folder')\n",
    "            print('--------')\n",
    "            fac = os.path.join(region, 'fac.tif')\n",
    "            if arcpy.Exists(fac):\n",
    "                print(f'Flow accumulation grid {fac} selected for {roi}')\n",
    "            else:\n",
    "                print(f'No flow accumulation raster for {region}')\n",
    "            outtable = os.path.join(outgdb, (roi + \"_maxfac\"))\n",
    "            print(f'Calculating {roi} catchment Max flow accumulation stats...')\n",
    "            arcpy.env.snapRaster = fac\n",
    "            arcpy.env.cellSize = fac\n",
    "            try:\n",
    "                field = 'cat_ID_con'\n",
    "                operator = 'LIKE'\n",
    "                value = roi\n",
    "                sba = \"\"\"\"{}\" {} '{}%'\"\"\".format(field, operator, value)\n",
    "                clip_select = arcpy.SelectLayerByAttribute_management(clip_outfile, 'NEW_SELECTION', sba)\n",
    "                zon_start = time.time()\n",
    "                cat_facMax_table = ZonalStatisticsAsTable(in_zone_data=clip_select,\n",
    "                                                          zone_field=cat_cur_fields[2],\n",
    "                                                          in_value_raster=fac,\n",
    "                                                          out_table=outtable,\n",
    "                                                          statistics_type='MAXIMUM'\n",
    "                                                          )\n",
    "                # Add region identifier field for catchment table\n",
    "                arcpy.AddField_management(cat_facMax_table, 'region', field_type='TEXT')\n",
    "                # Add cat_ID_Con field\n",
    "                arcpy.AddField_management(cat_facMax_table, 'cat_ID_txt', field_type='TEXT')\n",
    "                # Update fields\n",
    "                # Add upstream area as calculated from Max flow acc zonal stats for catchment table\n",
    "                arcpy.AddField_management(cat_facMax_table, 'site_acc_sqKm', field_type='DOUBLE')\n",
    "\n",
    "                with arcpy.da.UpdateCursor(cat_facMax_table,\n",
    "                                           ['region', 'cat_ID_txt', 'cat_ID_con', 'MAX', 'site_acc_sqKm']) as cur:\n",
    "                    for row in cur:\n",
    "                        strval = str(row[1])\n",
    "                        row[0] = roi\n",
    "                        row[1] = strval.replace('.0', '')\n",
    "                        row[4] = (cf * row[3]) / 1000000\n",
    "                        # Update\n",
    "                        cur.updateRow(row)\n",
    "                    del (row)\n",
    "                del (cur)\n",
    "                # rename MAX field\n",
    "                arcpy.AlterField_management(cat_facMax_table, \"MAX\", 'site_max_acc', 'site_max_acc')\n",
    "                zon_stop = time.time()\n",
    "                zon_time = int(zon_stop - zon_start)\n",
    "                print(f'Max Flow zonal stats for {roi} Elapsed time: ({datetime.timedelta(seconds=zon_time)})')\n",
    "                print('----------')\n",
    "\n",
    "                tbl_lst.append(outtable)\n",
    "            except:\n",
    "                e = sys.exc_info()[1]\n",
    "                print(e.args[0])\n",
    "                arcpy.AddError(e.args[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge all maxfac tables completed\n",
      "Cook_Inlet_wtds_merge\n",
      "Copper_River_wtds_merge\n",
      "Bristol_Bay_wtds_merge\n",
      "Kodiak_wtds_merge\n",
      "Prince_William_Sound_wtds_merge\n",
      "all_wtds_merge\n"
     ]
    }
   ],
   "source": [
    "# Merge flow accumulation outtables\n",
    "out_table_merge = os.path.join(outgdb, \"AKSSF_site_sj_maxfac\")\n",
    "flowmerge = arcpy.Merge_management(tbl_lst, out_table_merge, \"\", \"ADD_SOURCE_INFO\")\n",
    "print(\"Merge all maxfac tables completed\")\n",
    "# Recalculate area_km2 to join back to sites sj - Not all sites had these fields joined\n",
    "arcpy.env.workspace = outgdb\n",
    "for fc in arcpy.ListFeatureClasses('*wtds_merge'):\n",
    "    print(fc)\n",
    "    arcpy.CalculateField_management(fc, \"Area_km2\", expression=\"!SHAPE.area@SQUAREKILOMETERS!\")\n",
    "    fieldlist = arcpy.ListFields(fc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add stream metrics from VAA table and streams merge\n",
    "### VAA ATTRIBUTES\n",
    "* ARBOLATESU takes advantage of the LengthKM field in NHDFlowline, which measures the length of the flowline in kilometers. ARBOLATESU is determined by accumulating the length of all the upstream flowlines from the bottom of the current flowline and so provides the total length of the upstream drainage network from the bottom of the current flowline.\n",
    "* ARBOLATESU is the total length of the upstream drainage network from the bottom of the current flowline\n",
    "\n",
    "* The PATHLENGTH is the distance from the bottom of a flowline to the bottom of the terminal flowline along the main path as identified in the TERMINALPA field. There may be many pathways between a flowline and the terminal flowline because of divergences in the network so PATHLENGTH is computed by following the main path at each divergence.\n",
    "   * PATHLENGTH is the distance from the bottom of a flowline to the end of the network and is calculated on the main network path in km\n",
    "   * PATHLENGTH at the terminal Flowline (Isolated, Sinks, Oceans) is equal to zero.\n",
    "\n",
    "* This is what you need to know about STARTFLAG AND TERMINALFL:\n",
    "  * STARTFLAG identifies headwater flowlines\n",
    "  * TERMINALFL identifies network end flowlines\n",
    "  * Values of 0 indicate the feature is not headwater (STARTFLAG) or network end (TERMINALFL)\n",
    "  * values of 1 indicate the feature is a headwater (STARTFLAG) or network end (TERMINALFL)\n",
    "\n",
    "* TotalDrainageAreaSqKm\n",
    "  * Total cumulative area, in square kilometers\n",
    "* AreaSqKm - Catchment area, in square kilometers\n",
    "* Slope - Slope of the flowline from smoothed elevation (unitless)\n",
    "### tauDEM Attributes\n",
    "* DSContArea - Drainage area at the downstream end of the link. Generally this is one grid cell upstream of the downstream end because the drainage area at the downstream end grid cell includes the area of the stream being joined.\n",
    "* USContArea - Drainage area at the upstream end of the link\n",
    "* Slope - Average slope of the link (computed as drop/length)\n",
    "* DOUT_END - Distance to the outlet from the downstream end of the link in meters\n",
    "* DOUT_START - Distance to the outlet from the upstream end of the link in meters\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outgdb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-8935deaa10fb>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mmath\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mwtds_merge\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutgdb\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'all_wtds_merge'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[1;31m#Join fields from flow acc zonal stats and wtds merge to compare watershed area\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m delete_fields = ['StreamOrde', 'strmOrder', 'Slope', 'Slope_1', 'HUC8_ID', 'HUC8', 'Join_Count', 'TARGET_FID',\n",
      "\u001B[1;31mNameError\u001B[0m: name 'outgdb' is not defined"
     ]
    }
   ],
   "source": [
    "import os,arcpy\n",
    "from math import *\n",
    "\n",
    "wtds_merge = os.path.join(outgdb,'all_wtds_merge')\n",
    "#Join fields from flow acc zonal stats and wtds merge to compare watershed area\n",
    "delete_fields = ['StreamOrde', 'strmOrder', 'Slope', 'Slope_1', 'HUC8_ID', 'HUC8', 'Join_Count', 'TARGET_FID',\n",
    "                 'proc_reg']\n",
    "sj_cur_fields = ['cat_ID_txt', 'cat_ID', \"cat_ID_con\"]\n",
    "str_cur_fields = ['cat_ID_txt', 'catID', \"cat_ID_con\"]\n",
    "flow_join_fields = ['site_max_acc', 'site_acc_sqKm']\n",
    "wtds_join_fields = ['Area_km2']\n",
    "vaa_join_fields = ['StreamOrde', 'Slope', 'AreaSqKm', 'ArbolateSu', 'PathLength', 'StartFlag', 'TerminalPa',\n",
    "                   'TotalDrainageAreaSqKm']\n",
    "streams_join_fields = ['strmOrder', 'Slope', 'USContArea', 'DSContArea', 'LINKNO', 'DOUTEND', 'DOUTSTART']\n",
    "#join flow acc\n",
    "arcpy.JoinField_management(sitesmerge, sj_cur_fields[2], out_table_merge, sj_cur_fields[2], flow_join_fields)\n",
    "#join wtds merge\n",
    "arcpy.JoinField_management(sitesmerge, sj_cur_fields[2], wtds_merge, sj_cur_fields[2], wtds_join_fields)\n",
    "#join NHDPlus vaa table data\n",
    "arcpy.JoinField_management(sitesmerge, sj_cur_fields[2], vaasmerge, str_cur_fields[2], vaa_join_fields)\n",
    "# join TauDEM streams merge data\n",
    "arcpy.JoinField_management(sitesmerge, sj_cur_fields[2], streamsmerge, str_cur_fields[2], streams_join_fields)\n",
    "# Add fields as necessary\n",
    "arcpy.AddField_management(sitesmerge, \"area_diff\", field_type=\"DOUBLE\")\n",
    "arcpy.AddField_management(sitesmerge, \"str_slope\", field_type=\"DOUBLE\")\n",
    "arcpy.AddField_management(sitesmerge, \"str_ord\", field_type=\"SHORT\")\n",
    "arcpy.AddField_management(sitesmerge, \"ds_dist_outlet\", field_type=\"DOUBLE\")\n",
    "arcpy.AddField_management(sitesmerge, \"str_slope_dg\", field_type=\"DOUBLE\")\n",
    "\n",
    "# Make list of fields to keep\n",
    "str_fields = []\n",
    "for field in arcpy.ListFields(sitesmerge):\n",
    "    str_fields.append(field.name)\n",
    "keep_fields = [item for item in str_fields if item not in delete_fields]\n",
    "\n",
    "with arcpy.da.UpdateCursor(sitesmerge,\n",
    "                           [\"area_diff\", 'Area_km2', 'site_acc_sqKm', 'str_slope', 'Slope', 'Slope_1', 'str_ord',\n",
    "                            'StreamOrde', 'strmOrder','ds_dist_outlet','PathLength','DOUTEND','str_slope_dg']) as cur:\n",
    "    for row in cur:\n",
    "        # Set conditions for na values in vaa/tau slope\n",
    "        if row[4] != None:\n",
    "            slope = row[4]\n",
    "        else:\n",
    "            slope = row[5]\n",
    "        # Set conditions for na values in vaa/tau slope_dg\n",
    "        if row[4] != None:\n",
    "            slope_dg = degrees(atan(row[4]))\n",
    "        else:\n",
    "            slope_dg = degrees(atan(row[5]))\n",
    "\n",
    "        # Set conditions for na values in vaa/tau strOrder\n",
    "        if row[7] != None:\n",
    "            ord = row[7]\n",
    "        else:\n",
    "            ord = row[8]\n",
    "        # Set conditions for na values in vaa/tau ds distance to outlet\n",
    "        if row[10] != None:\n",
    "            ds_dist = row[10]\n",
    "        else:\n",
    "            ds_dist = row[11] * 0.001 # convert to km\n",
    "        row[3] = slope\n",
    "        row[6] = ord\n",
    "        # Calculate difference in area as watershed polygon area in sqKm minus area calculated from max flow accumulation in sqKm\n",
    "        row[0] = row[1] - row[2]\n",
    "        row[9] = ds_dist\n",
    "        row[10] =slope_dg\n",
    "        cur.updateRow(row)\n",
    "    del (row)\n",
    "del (cur)\n",
    "print('Join Fields Complete')\n",
    "print('----------')\n",
    "# Calculate lat/lon in Nad83\n",
    "arcpy.management.CalculateGeometryAttributes(\"all_sites_sj_merge\", \"lat POINT_Y;lon POINT_X\", '', '','GEOGCS[\"GCS_North_American_1983\",DATUM[\"D_North_American_1983\",SPHEROID[\"GRS_1980\",6378137.0,298.257222101]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]]', \"DD\")\n",
    "arcpy.DeleteField_management(\"all_sites_sj_merge\",delete_fields)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "<Result 'D:\\\\\\\\GIS\\\\\\\\AKSSF_land_met\\\\\\\\AKSSF_land_met.gdb\\\\all_sites_sj_merge'>",
      "text/html": "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, December 3, 2021 11:35:56\",\"Succeeded at Friday, December 3, 2021 11:35:56 (Elapsed Time: 0.14 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import arcpy,os\n",
    "sitesmerge = os.path.join(outgdb,'all_sites_sj_merge')\n",
    "#Get distance to coastline\n",
    "coast = r'D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\NHD_H_Alaska_Coastline_alb'\n",
    "arcpy.analysis.Near(sitesmerge, coast, None, \"NO_LOCATION\", \"NO_ANGLE\", \"GEODESIC\", \"NEAR_DIST NEAR_DIST\")\n",
    "arcpy.AlterField_management(sitesmerge,'NEAR_DIST','dist_coast_km','dist_coast_km' )\n",
    "#convert distance in meters to km\n",
    "arcpy.CalculateField_management(sitesmerge,'dist_coast_km','!dist_coast_km! * .001')\n",
    "arcpy.DeleteField_management(sitesmerge,'NEAR_FID')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "                          SiteID                  cat_ID_con  area_diff  \\\n0                           APU1   Cook_Inlet_75004300004192   0.368275   \n1                          APU10   Cook_Inlet_75004300004192   0.368275   \n2                          APU11   Cook_Inlet_75004300004304   0.549225   \n3                          APU12   Cook_Inlet_75004300005245   0.039050   \n4                           APU2   Cook_Inlet_75004300003171   0.028375   \n..                           ...                         ...        ...   \n484               USFS_ERB Creek  Prince_William_Sound_36645   0.000000   \n485  USFS_Solf Lake Outlet Creek  Prince_William_Sound_37815   0.010300   \n486                     15219000  Prince_William_Sound_42563   0.001900   \n487                     15236900  Prince_William_Sound_43185   0.188400   \n488                     15237030  Prince_William_Sound_40285   0.060700   \n\n           lat         lon  site_max_acc  site_acc_sqKm    Area_km2  \\\n0    59.772331 -151.836189      23256415     581.410375  581.778650   \n1    59.772246 -151.836298      23256415     581.410375  581.778650   \n2    59.711509 -151.687566      12849755     321.243875  321.793100   \n3    59.778585 -151.818469       7080923     177.023075  177.062125   \n4    59.863859 -151.657504        355448       8.886200    8.914575   \n..         ...         ...           ...            ...         ...   \n484  60.376606 -148.151917         35947       3.594700    3.594700   \n485  60.430692 -147.730911         52568       5.256800    5.267100   \n486  60.761069 -146.174397        122609      12.260900   12.262800   \n487  60.369804 -148.899220        237645      23.764500   23.952900   \n488  60.447986 -148.117277        123168      12.316800   12.377500   \n\n     str_slope  str_ord  dist_coast_km  ds_dist_outlet  \n0     0.002231        6       1.431231        1.750130  \n1     0.002231        6       1.429151        1.750130  \n2     0.005771        6       4.265209       16.928474  \n3     0.003202        5       2.232399        3.621428  \n4     0.003056        1       7.659494       35.164017  \n..         ...      ...            ...             ...  \n484   0.012774        3       0.035917      181.400000  \n485   0.009342        3       0.052664        0.000000  \n486   0.021710        3       0.322026      277.300000  \n487   0.058702        4      11.920299    21657.300000  \n488   0.000000        3       1.094722     5163.200000  \n\n[489 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SiteID</th>\n      <th>cat_ID_con</th>\n      <th>area_diff</th>\n      <th>lat</th>\n      <th>lon</th>\n      <th>site_max_acc</th>\n      <th>site_acc_sqKm</th>\n      <th>Area_km2</th>\n      <th>str_slope</th>\n      <th>str_ord</th>\n      <th>dist_coast_km</th>\n      <th>ds_dist_outlet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>APU1</td>\n      <td>Cook_Inlet_75004300004192</td>\n      <td>0.368275</td>\n      <td>59.772331</td>\n      <td>-151.836189</td>\n      <td>23256415</td>\n      <td>581.410375</td>\n      <td>581.778650</td>\n      <td>0.002231</td>\n      <td>6</td>\n      <td>1.431231</td>\n      <td>1.750130</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>APU10</td>\n      <td>Cook_Inlet_75004300004192</td>\n      <td>0.368275</td>\n      <td>59.772246</td>\n      <td>-151.836298</td>\n      <td>23256415</td>\n      <td>581.410375</td>\n      <td>581.778650</td>\n      <td>0.002231</td>\n      <td>6</td>\n      <td>1.429151</td>\n      <td>1.750130</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>APU11</td>\n      <td>Cook_Inlet_75004300004304</td>\n      <td>0.549225</td>\n      <td>59.711509</td>\n      <td>-151.687566</td>\n      <td>12849755</td>\n      <td>321.243875</td>\n      <td>321.793100</td>\n      <td>0.005771</td>\n      <td>6</td>\n      <td>4.265209</td>\n      <td>16.928474</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>APU12</td>\n      <td>Cook_Inlet_75004300005245</td>\n      <td>0.039050</td>\n      <td>59.778585</td>\n      <td>-151.818469</td>\n      <td>7080923</td>\n      <td>177.023075</td>\n      <td>177.062125</td>\n      <td>0.003202</td>\n      <td>5</td>\n      <td>2.232399</td>\n      <td>3.621428</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>APU2</td>\n      <td>Cook_Inlet_75004300003171</td>\n      <td>0.028375</td>\n      <td>59.863859</td>\n      <td>-151.657504</td>\n      <td>355448</td>\n      <td>8.886200</td>\n      <td>8.914575</td>\n      <td>0.003056</td>\n      <td>1</td>\n      <td>7.659494</td>\n      <td>35.164017</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>484</th>\n      <td>USFS_ERB Creek</td>\n      <td>Prince_William_Sound_36645</td>\n      <td>0.000000</td>\n      <td>60.376606</td>\n      <td>-148.151917</td>\n      <td>35947</td>\n      <td>3.594700</td>\n      <td>3.594700</td>\n      <td>0.012774</td>\n      <td>3</td>\n      <td>0.035917</td>\n      <td>181.400000</td>\n    </tr>\n    <tr>\n      <th>485</th>\n      <td>USFS_Solf Lake Outlet Creek</td>\n      <td>Prince_William_Sound_37815</td>\n      <td>0.010300</td>\n      <td>60.430692</td>\n      <td>-147.730911</td>\n      <td>52568</td>\n      <td>5.256800</td>\n      <td>5.267100</td>\n      <td>0.009342</td>\n      <td>3</td>\n      <td>0.052664</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>486</th>\n      <td>15219000</td>\n      <td>Prince_William_Sound_42563</td>\n      <td>0.001900</td>\n      <td>60.761069</td>\n      <td>-146.174397</td>\n      <td>122609</td>\n      <td>12.260900</td>\n      <td>12.262800</td>\n      <td>0.021710</td>\n      <td>3</td>\n      <td>0.322026</td>\n      <td>277.300000</td>\n    </tr>\n    <tr>\n      <th>487</th>\n      <td>15236900</td>\n      <td>Prince_William_Sound_43185</td>\n      <td>0.188400</td>\n      <td>60.369804</td>\n      <td>-148.899220</td>\n      <td>237645</td>\n      <td>23.764500</td>\n      <td>23.952900</td>\n      <td>0.058702</td>\n      <td>4</td>\n      <td>11.920299</td>\n      <td>21657.300000</td>\n    </tr>\n    <tr>\n      <th>488</th>\n      <td>15237030</td>\n      <td>Prince_William_Sound_40285</td>\n      <td>0.060700</td>\n      <td>60.447986</td>\n      <td>-148.117277</td>\n      <td>123168</td>\n      <td>12.316800</td>\n      <td>12.377500</td>\n      <td>0.000000</td>\n      <td>3</td>\n      <td>1.094722</td>\n      <td>5163.200000</td>\n    </tr>\n  </tbody>\n</table>\n<p>489 rows  12 columns</p>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import arcpy\n",
    "import pandas as pd\n",
    "sitemerge_df = pd.DataFrame()\n",
    "fields = ['SiteID', 'cat_ID_con', 'area_diff', 'lat', 'lon', 'site_max_acc', 'site_acc_sqKm', 'Area_km2', 'str_slope','str_slope_dg',\n",
    "          'str_ord','dist_coast_km', 'ds_dist_outlet']\n",
    "sitesmerge_arr = arcpy.da.TableToNumPyArray(sitesmerge, fields)\n",
    "sitemerge_df = pd.DataFrame(sitesmerge_arr)\n",
    "#sitemerge_df = sitemerge_df.set_index('cat_ID_con')\n",
    "\n",
    "sitemerge_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV export complete\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#Export CSV to read into R\n",
    "outdir = r\"C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\"\n",
    "sj_outname = 'AKSSF_sites_sj_maxfac.csv'\n",
    "arcpy.da.NumPyArrayToTable(sitesmerge_arr,os.path.join(outdir,sj_outname))\n",
    "print('CSV export complete')\n",
    "print('----------')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8caab41e",
   "language": "python",
   "display_name": "PyCharm (AKSSF)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}