{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Create watersheds and catchments\n",
    "\n",
    "AKSSF project has ~ 500 sites that have been shifted to the flow networks.\n",
    "We need to create watersheds for each. This will make extracting spatial\n",
    "and climatic covariates for modeling go much faster.\n",
    "\n",
    "Dustin pointed out that there are fromnodes and tonodes in the NHDPlus that can be used to navigate\n",
    "upstream, save all the NHPPlusIDs, select and merge the catchments to create watersheds for each site.\n",
    "This works in R so just need to transfer to python. Premise is to use a while loop to keep selecting\n",
    "new stream segments that have their tonode match the fromnode of the last segment(s).\n",
    "Logic for stopping while loop:\n",
    "Stop when summing the ids is not greater than 0. I'm not sure why this works, but it does\n",
    "for some watersheds, although I think it may be running infinitely on other watersheds.\n",
    "Alternatively, if sum(StartFlag) == count(rec) then all NHDPlusIDs are headwater streams.\n",
    "\n",
    "Create a loop and process watersheds for all the points. Start with Cook Inlet first.\n",
    "Note that folders, geodbs, and merged catchments are created in the merge_grids script.\n",
    "1. select catchments that intersect points to get NHDPlusID\n",
    "2. create list of IDs\n",
    "3. use loop to create watersheds\n",
    "4. first get list of all upstream NHDPlusIDs\n",
    "5. create temporary layer of catchments\n",
    "6. select catchments that match the upstream IDs\n",
    "7. dissolved on those catchments and save to Cook Inlet gdb and watersheds feature dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# COOK INLET\n",
    "# steps 1 and 2\n",
    "# intersect points with catchments and create list of NHDPlusIDs\n",
    "import arcpy\n",
    "arcpy.env.workspace = r\"W:\\GIS\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb\"\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "points = r\"T:\\Aquatic\\AKSSF\\AKSSF_Hydrography.gdb\\sites_outside_bb_verified_DM\"\n",
    "cats = r\"W:\\GIS\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb\\cats_merge\"\n",
    "idList = []\n",
    "outcats = \"cats_intersect\"\n",
    "\n",
    "arcpy.MakeFeatureLayer_management(cats, \"tempLayer\")\n",
    "arcpy.management.SelectLayerByLocation(\"tempLayer\", \"INTERSECT\", points)\n",
    "arcpy.CopyFeatures_management(\"tempLayer\", outcats)\n",
    "\n",
    "fields = arcpy.ListFields(\"tempLayer\")\n",
    "for field in fields:\n",
    "    print(\"{0}\".format(field.name))\n",
    "with arcpy.da.SearchCursor(\"tempLayer\", [\"NHDPlusID\"]) as cursor:\n",
    "    for row in cursor:\n",
    "        idList.append(row[0])\n",
    "\n",
    "print(len(idList))\n",
    "\n",
    "#check if duplicate catchments in the idList\n",
    "idset = set(idList)\n",
    "print(idset)\n",
    "print(len(idset))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#only 114 watersheds created for cook inlet, but 241 unique catchments\n",
    "# see which ones are missing.\n",
    "import arcpy\n",
    "\n",
    "# Got through 95 watersheds and all other programs froze, restarted and finding which watersheds remain.\n",
    "arcpy.env.workspace = r\"W:\\GIS\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb\\Watersheds\"\n",
    "wtds = arcpy.ListFeatureClasses()\n",
    "#just get numeric part\n",
    "wtds = [x[4:20] for x in wtds]\n",
    "#convert to numeric\n",
    "wtds = [int(i) for i in wtds]\n",
    "print(wtds)\n",
    "print(len(wtds))\n",
    "print(len(idList))\n",
    "#\n",
    "idFilter = [x for x in idList if x not in wtds]\n",
    "print(idFilter)\n",
    "print(\"Original list of sites in Cook Inlet: \" + str(len(idList)))\n",
    "print(\"Watersheds completed: \" + str(len(wtds)))\n",
    "print(\"Watersheds remaining: \" + str(len(idFilter)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(idList)\n",
    "idListord = sorted(idList)\n",
    "print(idListord)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# COOK INLET\n",
    "# steps 4-7\n",
    "\n",
    "import arcpy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# steps 4-9 for loop to create watersheds\n",
    "arcpy.env.workspace = r\"W:/GIS/AKSSF/Cook_Inlet/Cook_Inlet.gdb\"\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.qualifiedFieldNames = False\n",
    "\n",
    "vaa = \"vaa_merge\"\n",
    "cats = \"cats_merge\"\n",
    "output_SR = arcpy.Describe(cats).spatialReference\n",
    "arcpy.env.outputCoordinateSystem = output_SR\n",
    "\n",
    "#watersheds feature dataset for storing fcs\n",
    "# arcpy.management.CreateFeatureDataset(r\"W:\\GIS\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb\", \"Watersheds\", output_SR)\n",
    "\n",
    "field_names = [f.name for f in arcpy.ListFields(vaa)]\n",
    "print(field_names)\n",
    "vaa_flds = arcpy.ListFields(vaa)\n",
    "print(vaa_flds)\n",
    "vaa_df = pd.DataFrame(arcpy.da.TableToNumPyArray(vaa, (\"NHDPlusID\", \"FromNode\", \"ToNode\", \"StartFlag\")))\n",
    "\n",
    "#NHDPlusID for mainstem Susitna below Talkeetna, which doesn't seem to run.\n",
    "#idFilter = [75000200013536]\n",
    "\n",
    "for id in idFilter:\n",
    "    print(\"Starting watershed for: \" + str(id))\n",
    "    rec = [id]\n",
    "    up_ids = []\n",
    "    up_ids.append(rec)\n",
    "    rec_len = len(rec)\n",
    "    hws_sum = 0\n",
    "\n",
    "    while rec_len != hws_sum:\n",
    "        fromnode = vaa_df.loc[vaa_df[\"NHDPlusID\"].isin(rec), \"FromNode\"]\n",
    "        rec = vaa_df.loc[vaa_df[\"ToNode\"].isin(fromnode), \"NHDPlusID\"]\n",
    "        rec_len = len(rec)\n",
    "        rec_hws = vaa_df.loc[vaa_df[\"ToNode\"].isin(fromnode), \"StartFlag\"]\n",
    "        hws_sum = sum(rec_hws)\n",
    "        print(rec)\n",
    "        print(rec_len)\n",
    "        print(hws_sum)\n",
    "        up_ids.append(rec)\n",
    "\n",
    "    #up_ids is a list with more than numbers, use extend to only keep numeric nhdplusids\n",
    "    newup_ids = []\n",
    "    for x in up_ids:\n",
    "        newup_ids.extend(x)\n",
    "\n",
    "    print(type(newup_ids))\n",
    "    tempLayer = \"catsLyr\"\n",
    "    #expression = 'NHDPlusID IN {0}'.format(tuple(newup_ids))\n",
    "    #trying expression to deal with one catchment (i.e. hws)\n",
    "    expression = '\"NHDPlusID\" IN ({0})'.format(', '.join(map(str, newup_ids)) or 'NULL')\n",
    "    arcpy.MakeFeatureLayer_management(cats, tempLayer)\n",
    "    arcpy.management.SelectLayerByAttribute(tempLayer, \"NEW_SELECTION\", expression, None)\n",
    "\n",
    "    outwtd = \"Watersheds\\\\wtd_\" + str(round(id))\n",
    "    print(outwtd)\n",
    "    arcpy.management.Dissolve(tempLayer, outwtd)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# COPPER RIVER\n",
    "# steps 1 and 2\n",
    "# intersect points with catchments and create list of NHDPlusIDs\n",
    "import arcpy\n",
    "arcpy.env.workspace = r\"W:\\GIS\\AKSSF\\Copper_River\\Copper_River.gdb\"\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "points = r\"T:\\Aquatic\\AKSSF\\AKSSF_Hydrography.gdb\\sites_outside_bb_verified_DM\"\n",
    "cats = r\"W:\\GIS\\AKSSF\\Copper_River\\Copper_River.gdb\\cats_merge\"\n",
    "idList = []\n",
    "outcats = \"cats_intersect\"\n",
    "\n",
    "arcpy.MakeFeatureLayer_management(cats, \"tempLayer\")\n",
    "arcpy.management.SelectLayerByLocation(\"tempLayer\", \"INTERSECT\", points)\n",
    "arcpy.CopyFeatures_management(\"tempLayer\", outcats)\n",
    "\n",
    "fields = arcpy.ListFields(\"tempLayer\")\n",
    "for field in fields:\n",
    "    print(\"{0}\".format(field.name))\n",
    "with arcpy.da.SearchCursor(\"tempLayer\", [\"NHDPlusID\"]) as cursor:\n",
    "    for row in cursor:\n",
    "        idList.append(row[0])\n",
    "\n",
    "print(len(idList))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# COPPER RIVER\n",
    "# steps 4-7\n",
    "\n",
    "import arcpy\n",
    "import pandas as pd\n",
    "\n",
    "#idList = [75004300004324]\n",
    "\n",
    "# steps 4-9 for loop to create watersheds\n",
    "arcpy.env.workspace = r\"W:/GIS/AKSSF/Copper_River/Copper_River.gdb\"\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.qualifiedFieldNames = False\n",
    "\n",
    "vaa = \"vaa_merge\"\n",
    "cats = \"cats_merge\"\n",
    "output_SR = arcpy.Describe(cats).spatialReference\n",
    "arcpy.env.outputCoordinateSystem = output_SR\n",
    "\n",
    "#watersheds feature dataset for storing fcs\n",
    "arcpy.management.CreateFeatureDataset(r\"W:\\GIS\\AKSSF\\Copper_River\\Copper_River.gdb\", \"Watersheds\", output_SR)\n",
    "\n",
    "vaa_df = pd.DataFrame(arcpy.da.FeatureClassToNumPyArray(vaa, (\"NHDPlusID\", \"FromNode\", \"ToNode\")))\n",
    "\n",
    "for id in idList:\n",
    "    print(\"Starting watershed for: \" + str(id))\n",
    "    rec = [id]\n",
    "    print(type(rec))\n",
    "    up_ids = []\n",
    "\n",
    "    while sum(rec) > 0:\n",
    "        up_ids.append(rec)\n",
    "        fromnode = vaa_df.loc[vaa_df[\"NHDPlusID\"].isin(rec), \"FromNode\"]\n",
    "        rec = vaa_df.loc[vaa_df[\"ToNode\"].isin(fromnode), \"NHDPlusID\"]\n",
    "\n",
    "    #up_ids is a list with more than numbers, use extend to only keep numeric nhdplusids\n",
    "    newup_ids = []\n",
    "    for x in up_ids:\n",
    "        newup_ids.extend(x)\n",
    "\n",
    "    print(type(newup_ids))\n",
    "    tempLayer = \"catsLyr\"\n",
    "    #expression = 'NHDPlusID IN {0}'.format(tuple(newup_ids))\n",
    "    #trying expression to deal with one catchment (i.e. hws)\n",
    "    expression = '\"NHDPlusID\" IN ({0})'.format(', '.join(map(str, newup_ids)) or 'NULL')\n",
    "    arcpy.MakeFeatureLayer_management(cats, tempLayer)\n",
    "    arcpy.management.SelectLayerByAttribute(tempLayer, \"NEW_SELECTION\", expression, None)\n",
    "\n",
    "    outwtd = \"Watersheds\\\\wtd_\" + str(round(id))\n",
    "    print(outwtd)\n",
    "    arcpy.management.Dissolve(tempLayer, outwtd)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# BRISTOL BAY WATERSHEDS\n",
    "\n",
    "import arcpy\n",
    "import pandas as pd\n",
    "\n",
    "arcpy.env.workspace = r\"W:\\GIS\\AKSSF\\Bristol_Bay\\Bristol_Bay.gdb\"\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "points = r\"W:\\GIS\\AKSSF\\AKSSF_Hydrography.gdb\\bb_MD_verified_DM\"\n",
    "cats = r\"W:\\GIS\\AKSSF\\Bristol_Bay\\Bristol_Bay.gdb\\cats_merge\"\n",
    "idList = []\n",
    "outcats = \"cats_intersect\"\n",
    "\n",
    "arcpy.MakeFeatureLayer_management(cats, \"tempLayer\")\n",
    "arcpy.management.SelectLayerByLocation(\"tempLayer\", \"INTERSECT\", points)\n",
    "arcpy.CopyFeatures_management(\"tempLayer\", outcats)\n",
    "\n",
    "fields = arcpy.ListFields(\"tempLayer\")\n",
    "for field in fields:\n",
    "    print(\"{0}\".format(field.name))\n",
    "with arcpy.da.SearchCursor(\"tempLayer\", [\"catID\"]) as cursor:\n",
    "    for row in cursor:\n",
    "        idList.append(row[0])\n",
    "\n",
    "print(len(idList))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# BRISTOL BAY\n",
    "# steps 4-7\n",
    "\n",
    "import arcpy\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "# idList = [492244] #for testing\n",
    "\n",
    "# steps 4-9 for loop to create watersheds\n",
    "arcpy.env.workspace = r\"W:\\GIS\\AKSSF\\Bristol_Bay\\Bristol_Bay.gdb\"\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.qualifiedFieldNames = False\n",
    "\n",
    "streams = \"streams_merge\"\n",
    "cats = \"cats_merge\"\n",
    "output_SR = arcpy.Describe(cats).spatialReference\n",
    "arcpy.env.outputCoordinateSystem = output_SR\n",
    "\n",
    "#watersheds feature dataset for storing fcs\n",
    "# arcpy.management.CreateFeatureDataset(r\"W:\\GIS\\AKSSF\\Bristol_Bay\\Bristol_Bay.gdb\", \"Watersheds\", output_SR)\n",
    "\n",
    "str_df = pd.DataFrame(arcpy.da.FeatureClassToNumPyArray(streams, (\"catID\", \"upCatID1\", \"upCatID2\")))\n",
    "hws_codes = [999999, 1999999, 2999999, 3999999, 4999999]\n",
    "\n",
    "#idList if doing ALL watersheds.\n",
    "for id in idList:\n",
    "    print(\"Starting watershed for: \" + str(id))\n",
    "    rec = [id]\n",
    "    up_ids = []\n",
    "    sum_rec = sum(rec)\n",
    "    timeout = time.time() + 60*15 # 15 minutes from this point\n",
    "\n",
    "    while(sum_rec > 0):\n",
    "        if time.time() > timeout:\n",
    "            break\n",
    "        up_ids.append(rec)\n",
    "        rec = str_df.loc[str_df[\"catID\"].isin(rec), (\"upCatID1\", \"upCatID2\")]\n",
    "        rec = rec.replace(hws_codes, 0)\n",
    "        rec = pd.concat([rec['upCatID1'], rec['upCatID2']])\n",
    "        # print(rec)\n",
    "        sum_rec = sum(rec)\n",
    "    # print(up_ids)\n",
    "\n",
    "\n",
    "    #up_ids is a list with more than numbers, use extend to only keep numeric nhdplusids\n",
    "    newup_ids = []\n",
    "    for x in up_ids:\n",
    "        newup_ids.extend(x)\n",
    "\n",
    "    # print(type(newup_ids))\n",
    "    # print(newup_ids)\n",
    "    tempLayer = \"catsLyr\"\n",
    "    #expression = 'NHDPlusID IN {0}'.format(tuple(newup_ids))\n",
    "    #trying expression to deal with one catchment (i.e. hws)\n",
    "    expression = '\"catID\" IN ({0})'.format(', '.join(map(str, newup_ids)) or 'NULL')\n",
    "    arcpy.MakeFeatureLayer_management(cats, tempLayer)\n",
    "    arcpy.management.SelectLayerByAttribute(tempLayer, \"NEW_SELECTION\", expression, None)\n",
    "\n",
    "    outwtd = \"Watersheds\\\\wtd_\" + str(round(id))\n",
    "    arcpy.management.Dissolve(tempLayer, outwtd)\n",
    "    print(\"Watershed created at:\" + outwtd)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# code when trouble-shooting bb above.\n",
    "import arcpy\n",
    "\n",
    "# Got through 95 watersheds and all other programs froze, restarted and finding which watersheds remain.\n",
    "arcpy.env.workspace = r\"W:\\GIS\\AKSSF\\Bristol_Bay\\Bristol_Bay.gdb\\Watersheds\"\n",
    "wtds = arcpy.ListFeatureClasses()\n",
    "#just get numeric part\n",
    "wtds = [x[4:10] for x in wtds]\n",
    "#convert to numeric\n",
    "wtds = [int(i) for i in wtds]\n",
    "print(wtds)\n",
    "print(len(wtds))\n",
    "print(len(idList))\n",
    "#\n",
    "# idFilter = [x for x in idList if x not in wtds]\n",
    "# print(idFilter)\n",
    "# print(\"Original list of sites in BB: \" + str(len(idList)))\n",
    "# print(\"Watersheds completed: \" + str(len(wtds)))\n",
    "# print(\"Watersheds remaining: \" + str(len(idFilter)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# PRINCE WILLIAM SOUND WATERSHEDS\n",
    "\n",
    "import arcpy\n",
    "import pandas as pd\n",
    "\n",
    "gdb = r\"W:\\GIS\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\"\n",
    "arcpy.env.workspace = gdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "points = r\"W:\\GIS\\AKSSF\\AKSSF_Hydrography.gdb\\sites_outside_bb_verified_DM\"\n",
    "cats = r\"W:\\GIS\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\\cats_merge\"\n",
    "idList = []\n",
    "outcats = gdb + \"\\\\cats_intersect\"\n",
    "\n",
    "arcpy.MakeFeatureLayer_management(cats, \"tempLayer\")\n",
    "arcpy.management.SelectLayerByLocation(\"templayer\", \"INTERSECT\", points)\n",
    "arcpy.CopyFeatures_management(\"templayer\", outcats)\n",
    "\n",
    "fields = arcpy.ListFields(\"tempLayer\")\n",
    "for field in fields:\n",
    "    print(\"{0}\".format(field.name))\n",
    "with arcpy.da.SearchCursor(\"tempLayer\", [\"gridcode\"]) as cursor:\n",
    "    for row in cursor:\n",
    "        idList.append(row[0])\n",
    "\n",
    "print(len(idList))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Prince_William_Sound\n",
    "# steps 4-7\n",
    "\n",
    "import arcpy\n",
    "import pandas as pd\n",
    "import numpy\n",
    "\n",
    "arcpy.env.workspace = r\"W:\\GIS\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\"\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.qualifiedFieldNames = False\n",
    "\n",
    "streams = \"streams_merge\"\n",
    "cats = \"cats_merge\"\n",
    "output_SR = arcpy.Describe(cats).spatialReference\n",
    "arcpy.env.outputCoordinateSystem = output_SR\n",
    "\n",
    "#watersheds feature dataset for storing fcs\n",
    "arcpy.management.CreateFeatureDataset(r\"W:\\GIS\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\", \"Watersheds\", output_SR)\n",
    "\n",
    "fields = arcpy.ListFields(streams)\n",
    "for field in fields:\n",
    "    print(\"{0}\".format(field.name))\n",
    "\n",
    "str_df = pd.DataFrame(arcpy.da.FeatureClassToNumPyArray(streams, (\"LINKNO\", \"USLINKNO1\", \"USLINKNO2\")))\n",
    "hws_codes = [-1]\n",
    "\n",
    "#idList if doing ALL watersheds.\n",
    "for id in idList:\n",
    "    print(\"Starting watershed for: \" + str(id))\n",
    "    rec = [id]\n",
    "    up_ids = []\n",
    "    sum_rec = sum(rec)\n",
    "\n",
    "    while(sum_rec > 0):\n",
    "        up_ids.append(rec)\n",
    "        rec = str_df.loc[str_df[\"LINKNO\"].isin(rec), (\"USLINKNO1\", \"USLINKNO2\")]\n",
    "        rec = rec.replace(hws_codes, 0)\n",
    "        rec = pd.concat([rec['USLINKNO1'], rec['USLINKNO2']])\n",
    "        # print(rec)\n",
    "        sum_rec = sum(rec)\n",
    "    # print(up_ids)\n",
    "\n",
    "\n",
    "    #up_ids is a list with more than numbers, use extend to only keep numeric nhdplusids\n",
    "    newup_ids = []\n",
    "    for x in up_ids:\n",
    "        newup_ids.extend(x)\n",
    "\n",
    "    # print(type(newup_ids))\n",
    "    # print(newup_ids)\n",
    "    tempLayer = \"catsLyr\"\n",
    "    #expression = 'NHDPlusID IN {0}'.format(tuple(newup_ids))\n",
    "    #trying expression to deal with one catchment (i.e. hws)\n",
    "    expression = '\"gridcode\" IN ({0})'.format(', '.join(map(str, newup_ids)) or 'NULL')\n",
    "    arcpy.MakeFeatureLayer_management(cats, tempLayer)\n",
    "    arcpy.management.SelectLayerByAttribute(tempLayer, \"NEW_SELECTION\", expression, None)\n",
    "\n",
    "    outwtd = \"Watersheds\\\\wtd_\" + str(round(id))\n",
    "    print(outwtd)\n",
    "    arcpy.management.Dissolve(tempLayer, outwtd)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# KODIAK WATERSHEDS\n",
    "\n",
    "import arcpy\n",
    "import pandas as pd\n",
    "\n",
    "arcpy.env.workspace = r\"W:\\GIS\\AKSSF\\Kodiak\\Kodiak.gdb\"\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "points = r\"W:\\GIS\\AKSSF\\AKSSF_Hydrography.gdb\\sites_outside_bb_verified_DM\"\n",
    "cats = r\"W:\\GIS\\AKSSF\\Kodiak\\Kodiak.gdb\\cats_merge\"\n",
    "idList = []\n",
    "outcats = \"cats_intersect\"\n",
    "\n",
    "arcpy.MakeFeatureLayer_management(cats, \"tempLayer\")\n",
    "arcpy.management.SelectLayerByLocation(\"tempLayer\", \"INTERSECT\", points)\n",
    "arcpy.CopyFeatures_management(\"tempLayer\", outcats)\n",
    "\n",
    "fields = arcpy.ListFields(\"tempLayer\")\n",
    "for field in fields:\n",
    "    print(\"{0}\".format(field.name))\n",
    "with arcpy.da.SearchCursor(\"tempLayer\", [\"gridcode\"]) as cursor:\n",
    "    for row in cursor:\n",
    "        idList.append(row[0])\n",
    "\n",
    "print(len(idList))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Kodiak\n",
    "# steps 4-7\n",
    "\n",
    "import arcpy\n",
    "import pandas as pd\n",
    "import numpy\n",
    "\n",
    "arcpy.env.workspace = r\"W:\\GIS\\AKSSF\\Kodiak\\Kodiak.gdb\"\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.qualifiedFieldNames = False\n",
    "\n",
    "streams = \"streams_merge\"\n",
    "cats = \"cats_merge\"\n",
    "output_SR = arcpy.Describe(cats).spatialReference\n",
    "arcpy.env.outputCoordinateSystem = output_SR\n",
    "\n",
    "#watersheds feature dataset for storing fcs\n",
    "arcpy.management.CreateFeatureDataset(r\"W:\\GIS\\AKSSF\\Kodiak\\Kodiak.gdb\", \"Watersheds\", output_SR)\n",
    "\n",
    "fields = arcpy.ListFields(streams)\n",
    "for field in fields:\n",
    "    print(\"{0}\".format(field.name))\n",
    "\n",
    "str_df = pd.DataFrame(arcpy.da.FeatureClassToNumPyArray(streams, (\"LINKNO\", \"USLINKNO1\", \"USLINKNO2\")))\n",
    "hws_codes = [-1]\n",
    "\n",
    "#idList if doing ALL watersheds.\n",
    "for id in idList:\n",
    "    print(\"Starting watershed for: \" + str(id))\n",
    "    rec = [id]\n",
    "    up_ids = []\n",
    "    sum_rec = sum(rec)\n",
    "\n",
    "    while(sum_rec > 0):\n",
    "        up_ids.append(rec)\n",
    "        rec = str_df.loc[str_df[\"LINKNO\"].isin(rec), (\"USLINKNO1\", \"USLINKNO2\")]\n",
    "        rec = rec.replace(hws_codes, 0)\n",
    "        rec = pd.concat([rec['USLINKNO1'], rec['USLINKNO2']])\n",
    "        # print(rec)\n",
    "        sum_rec = sum(rec)\n",
    "    # print(up_ids)\n",
    "\n",
    "\n",
    "    #up_ids is a list with more than numbers, use extend to only keep numeric nhdplusids\n",
    "    newup_ids = []\n",
    "    for x in up_ids:\n",
    "        newup_ids.extend(x)\n",
    "\n",
    "    # print(type(newup_ids))\n",
    "    # print(newup_ids)\n",
    "    tempLayer = \"catsLyr\"\n",
    "    #expression = 'NHDPlusID IN {0}'.format(tuple(newup_ids))\n",
    "    #trying expression to deal with one catchment (i.e. hws)\n",
    "    expression = '\"gridcode\" IN ({0})'.format(', '.join(map(str, newup_ids)) or 'NULL')\n",
    "    arcpy.MakeFeatureLayer_management(cats, tempLayer)\n",
    "    arcpy.management.SelectLayerByAttribute(tempLayer, \"NEW_SELECTION\", expression, None)\n",
    "\n",
    "    outwtd = \"Watersheds\\\\wtd_\" + str(round(id))\n",
    "    print(outwtd)\n",
    "    arcpy.management.Dissolve(tempLayer, outwtd)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Watershed Summaries\n",
    "\n",
    "1. read in all watersheds feature classes\n",
    "2. create a table with the NHDPlusID/catID of the watershed name, region, and watershed area\n",
    "3. do a spatial join or IDENTITY on catchments and sites to get a many to one between SiteIDs and catchments\n",
    "4. create a table with a row for each SiteID, NHDPlusID/catID, and watershed area"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "regions = [\"Copper_River\"]\n",
    "\n",
    "for region in regions:\n",
    "    arcpy.env.workspace = \"W:\\\\GIS\\\\AKSSF\\\\\" + region + \"\\\\\" + region + \".gdb\\\\Watersheds\"\n",
    "    wtds = arcpy.ListFeatureClasses()\n",
    "    print(wtds)\n",
    "    print(len(wtds))\n",
    "    wtdList = []\n",
    "\n",
    "    for wtd in wtds:\n",
    "        wtdName = wtd[4:20]\n",
    "        print(\"Starting wtd: \" + wtdName)\n",
    "        wtdPath = os.path.join(arcpy.env.workspace, wtd)\n",
    "        # arcpy.AddField_management(wtdPath, \"Area_km2\", \"DOUBLE\")\n",
    "        # expression1 = \"{0}\".format(\"!SHAPE.area@SQUAREKILOMETERS!\")\n",
    "        # arcpy.CalculateField_management(wtdPath, \"Area_km2\", expression1, \"PYTHON\", )\n",
    "        # wtdArea = [i for i in arcpy.da.SearchCursor(wtdPath, ['Area_km2'])][0]\n",
    "        wtdArea = [row[0] for row in arcpy.da.SearchCursor(wtdPath, ['Area_km2'])]\n",
    "        print(\"wtdName: \" + str(wtdArea))\n",
    "        wtdList.append({'Region': region, 'Name': wtdName, 'Area_km2': wtdArea})\n",
    "\n",
    "wtdDf = pd.DataFrame(wtdList)\n",
    "print(wtdDf)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import os\n",
    "import numpy\n",
    "import pandas as pd\n",
    "\n",
    "region = \"Copper_River\"\n",
    "arcpy.env.workspace = \"W:\\\\GIS\\\\AKSSF\\\\\" + region + \"\\\\\" + region + \".gdb\"\n",
    "\n",
    "cats = os.path.join(arcpy.env.workspace, \"cats_merge\")\n",
    "print(cats)\n",
    "points = r\"T:\\Aquatic\\AKSSF\\AKSSF_Hydrography.gdb\\sites_outside_bb_verified_DM\"\n",
    "\n",
    "#note spatial join not working, the cats fields are empty!\n",
    "arcpy.SpatialJoin_analysis(points, cats, \"sites_sj\")\n",
    "sites_sj = os.path.join(arcpy.env.workspace, \"sites_sj\")\n",
    "\n",
    "sitesDf = pd.DataFrame(arcpy.da.FeatureClassToNumPyArray(sites_sj, (\"SiteID\", \"NHDPlusID\")))\n",
    "\n",
    "print(sitesDf)\n",
    "print(wtdDf)\n",
    "\n",
    "#merge two data frames to get area linked to nhdplusid and siteid.\n",
    "\n",
    "# sitesList = []\n",
    "# with arcpy.da.SearchCursor(sites_sj, [\"SiteID\", \"NHDPlusID\"]) as cursor:\n",
    "#     for row in cursor:\n",
    "#         sitesList.append({site = row[0], ID = row[1]})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "\n",
     "\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}