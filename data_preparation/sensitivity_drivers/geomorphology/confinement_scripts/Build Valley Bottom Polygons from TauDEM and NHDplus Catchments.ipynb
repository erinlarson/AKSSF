{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# 4 - IP Build RCAs from Pre-Processed NetMap Reaches and DEM\n",
    "\n",
    "Use this tool to build reach contributing area (RCAs) from a TauDEM and NHDPlus stream reaches and a digital elevation model (DEM). This tool is designed to replace the STARS \"Generate Cost RCAs\" tool which was built using Python 2 and designed for use in ArcMap.\n",
    "\n",
    "## Required Software:\n",
    "\n",
    "- This code is formatted as a Jupyter notebook markdown document and can be modified to be run in ARCGIS Pro or any python gui\n",
    "- If any of the geoprocessing steps require an advanced license or any specific extensions, the script will check for these conditions before running.\n",
    "\n",
    "## Required Inputs:\n",
    "\n",
    "- DEMs used to create the synthetic stream networks and NHDPlus data.   \n",
    "\n",
    "- Stream reaches and NHDPlus flowlines\n",
    "\n",
    "- A unique attribute field catchment id or nhdplus id\n",
    "\n",
    "- A feature class name for the RCA polygon output.\n",
    "\n",
    "- A system directory to use as a temporary file location. It is recommended that this be a short file path on an internal hard drive (eg, \"C:/data\").\n",
    "\n",
    "\n",
    "## Geoprocessing Output:\n",
    "\n",
    "- An RCA polygon feature class written to the default project geodatabase.\n",
    "\n",
    "## Processing Steps:\n",
    "\n",
    "1. Convert the pre-processed reaches to a raster, using the same cell size and extent as the input DEM (May already have this raster ).\n",
    "2. Create a raster object from the rasterized streamlines.\n",
    "3. Run a series of Raster Calculator expressions. (These calculations essentially create a cost surface where ridgeline landscape positions become very expensive compared to valley and hillslope positions. This will constrain the RCA polygons and prevent them from crossing ridgetops into adjacent drainages.)\n",
    "4. Run the Cost Allocation using the rasterized stream reaches and the final cost surface.\n",
    "5. Build a raster attribute table for the cost allocation output.\n",
    "6. Convert the cost allocation output to polygon, and dissolve any multi-part polygons.\n",
    "7. Add a field for the RCA ID, then calculate the RCA ID to equal the \"gridcode\" attribute from the original rasterized reaches.\n",
    "8. Delete all intermediary rasters."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa5c98c5e47a947d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Code starts here:\n",
    "\n",
    "#### Setup\n",
    "\n",
    "Import modules and reset environments to default. This should set the ArcPro project geodatabase as the workspace/scratch environment, just in case it was set otherwise. Additionally, prevent the addition of intermediary outputs to the ArcPro project map. Some tools may not run if their target is open in the map display."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69cee3526911be3c"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2023-12-17 21:40:43.034257\n",
      "imports complete\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sys paths ['C:\\\\Program Files\\\\JetBrains\\\\PyCharm 2020.2.3\\\\plugins\\\\python\\\\helpers-pro\\\\jupyter_debug', 'C:\\\\Program Files\\\\JetBrains\\\\PyCharm 2020.2.3\\\\plugins\\\\python\\\\helpers\\\\pydev', 'C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\AKSSF\\\\data_preparation\\\\sensitivity_drivers\\\\geomorphology\\\\confinement_scripts', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\Resources\\\\ArcPy', 'C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\AKSSF', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\python39.zip', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\DLLs', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3', '', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\site-packages', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\Resources\\\\ArcToolbox\\\\Scripts', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\Babel-2.11.0-py3.9.egg', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\future-0.18.2-py3.9.egg', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\pytz-2022.6-py3.9.egg', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\pywin32security', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\sympy-1.9-py3.9.egg', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\dwmerrigan\\\\.ipython']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Python Environment set to - C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "2023-12-17 21:40:43.034257\n",
      "Output directory set to D:\\\\GIS\\\\AKSSF_ValBot_2023\n",
      "Output gdb set to D:\\\\GIS\\\\AKSSF_ValBot_2023\\AKSSF_ValBot.gdb\n"
     ]
    }
   ],
   "source": [
    "import os, arcpy, sys,datetime, traceback\n",
    "\n",
    "import arcpy.management\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "sr = arcpy.SpatialReference(3338)  #'NAD_1983_Alaska_Albers'\n",
    "arcpy.env.outputCoordinateSystem = sr\n",
    "print(f'Date: {datetime.datetime.now()}')\n",
    "print('imports complete')\n",
    "print(f'{(\"-\"*100)}')\n",
    "print(f'sys paths {sys.path}')\n",
    "print(f'{(\"-\"*100)}')\n",
    "print(f'Python Environment set to - {sys.base_exec_prefix}')\n",
    "print(f'{(\"-\"*100)}')\n",
    "print (datetime.datetime.now())\n",
    "outdir = r\"D:\\\\GIS\\\\AKSSF_ValBot_2023\"\n",
    "outgdb = os.path.join(outdir,'AKSSF_ValBot.gdb')\n",
    "#outdir = r\"D:\\\\GIS\\\\AKSSF_ValBot_2023\\TestFol\"\n",
    "#outgdb = os.path.join(outdir,'TestVB.gdb')\n",
    "print(f'Output directory set to {outdir}')\n",
    "print(f'Output gdb set to {outgdb}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T06:40:43.267796300Z",
     "start_time": "2023-12-18T06:40:43.037249800Z"
    }
   },
   "id": "9394216aa9b5551f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The Spatial Analyst extension is required for this script to work. Check for extension, and if its available check it out for use. If it is unavailable or cannot be checked out, throw a license error and provide an error message."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43ac043395c28eb0"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial Analyst license is required.\n",
      "Start Time: Sunday, December 17, 2023 21:23:36\n",
      "Intersecting with layer D:\\GIS\\AKSSF_ValBot_2023\\AKSSF_ValBot.gdb\\vbClipTest...\n",
      "ERROR 160385: Workspace or data source is read only.\n",
      "Failed to execute (PairwiseIntersect).\n",
      "Failed at Sunday, December 17, 2023 21:27:05 (Elapsed Time: 3 minutes 28 seconds)\n",
      "Good news...Spatial Analyst license is available!\n",
      "Start Time: Sunday, December 17, 2023 21:23:36\n",
      "Intersecting with layer D:\\GIS\\AKSSF_ValBot_2023\\AKSSF_ValBot.gdb\\vbClipTest...\n",
      "ERROR 160385: Workspace or data source is read only.\n",
      "Failed to execute (PairwiseIntersect).\n",
      "Failed at Sunday, December 17, 2023 21:27:05 (Elapsed Time: 3 minutes 28 seconds)\n"
     ]
    }
   ],
   "source": [
    "print(\"Spatial Analyst license is required.\")\n",
    "arcpy.AddMessage(\"Spatial Analyst license is required.\")\n",
    "print(arcpy.GetMessages())\n",
    "\n",
    "class LicenseError(Exception):\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    if arcpy.CheckExtension(\"Spatial\") == \"Available\":\n",
    "        arcpy.CheckOutExtension(\"Spatial\")\n",
    "        print(\"Good news...Spatial Analyst license is available!\")\n",
    "        arcpy.AddMessage(\"Good news...Spatial Analyst license is available!\")\n",
    "        print(arcpy.GetMessages())\n",
    "    else:\n",
    "        # raise a custom exception\n",
    "        raise LicenseError\n",
    "\n",
    "except LicenseError:\n",
    "    print(\"Bad news...Spatial Analyst license is unavailable.\")\n",
    "    arcpy.AddMessage(\"Bad news...Spatial Analyst license is unavailable.\")\n",
    "    print(arcpy.GetMessages())\n",
    "except arcpy.ExecuteError:\n",
    "    print(arcpy.GetMessages())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T06:40:43.333129600Z",
     "start_time": "2023-12-18T06:40:43.056198500Z"
    }
   },
   "id": "3cbbc45a33ad7f35"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Function to add key, value pairs to dictionary\n",
    "def append_value(dict_obj, key, value):\n",
    "    # Check if key exist in dict or not\n",
    "    if key in dict_obj:\n",
    "        # Key exist in dict.\n",
    "        # Check if type of value of key is list or not\n",
    "        if not isinstance(dict_obj[key], list):\n",
    "            # If type is not list then make it list\n",
    "            dict_obj[key] = [dict_obj[key]]\n",
    "        # Append the value in list\n",
    "        dict_obj[key].append(value)\n",
    "    else:\n",
    "        # As key is not in dict,\n",
    "        # so, add key-value pair\n",
    "        dict_obj[key] = value\n",
    "# Function to remove parenthesis from user inputs\n",
    "def replace_all(userinput, dic):\n",
    "    for i, j in dic.items():\n",
    "        userinput = userinput.replace(i, j)\n",
    "    return userinput\n",
    "\n",
    "# Getnull rows from numpy array\n",
    "def getnull(cat_ID_con):\n",
    "    nullRows = []\n",
    "    nullRows.append(cat_ID_con)\n",
    "    return True\n",
    "\n",
    "#Generate unique column names\n",
    "def uniquify(df_final):\n",
    "    seen = set()\n",
    "    for item in df_final:\n",
    "        fudge = 1\n",
    "        newitem = item\n",
    "        while newitem in seen:\n",
    "            fudge += 1\n",
    "            newitem = \"{}_{}\".format(item, fudge)\n",
    "        yield newitem\n",
    "        seen.add(newitem)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T06:40:43.336121100Z",
     "start_time": "2023-12-18T06:40:43.081690100Z"
    }
   },
   "id": "d19ae0f49e542746"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set input Data\n",
    "Set input datasets and data dictionaries\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "879e1a717717dab"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin 2023-12-17 21:40:43.107559\n",
      "Bristol_Bay\n",
      "GDB ['D:\\\\GIS\\\\AKSSF\\\\Bristol_Bay\\\\Bristol_Bay.gdb']\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\bbelev.tif already created\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\bbfac.tif already created\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\bbfdr.tif already created\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\bbslope.tif already created\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\AKSSF_ValBot.gdb\\bb_cats_merge already copied\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\AKSSF_ValBot.gdb\\bb_streams_merge already created\n",
      "****************************************************************************************************\n",
      "Process completed at 2023-12-17 21:40 (Elapsed time: 0:00:00)\n",
      "****************************************************************************************************\n",
      "{'Bristol_Bay': ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\AKSSF_ValBot.gdb\\\\bb_streams_merge', 'catID']}\n",
      "****************************************************************************************************\n",
      "{'Bristol_Bay': ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\bbelev.tif', ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\bbfac.tif'], ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\bbfdr.tif'], ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\bbslope.tif']]}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import arcpy\n",
    "\n",
    "prefDict = {'Bristol_Bay':'bb', 'Kodiak':'kod', 'Prince_William_Sound':'pws','Cook_Inlet':'ci','Copper_River':'cr'}\n",
    "\n",
    "# Separate data by source type\n",
    "nhdplus_dat = ['Cook_Inlet', 'Copper_River']\n",
    "tauDem_dat = ['Bristol_Bay', 'Kodiak', 'Prince_William_Sound']\n",
    "\n",
    "# Set input regional folders\n",
    "#regions = [f'D:\\\\GIS\\\\AKSSF\\\\{source}' for source in nhdplus_dat + tauDem_dat]\n",
    "\n",
    "regions = [f'D:\\\\GIS\\\\AKSSF\\\\Bristol_Bay']\n",
    "\n",
    "strDict = {}\n",
    "roiRasDict = {}\n",
    "catsDict = {}\n",
    "\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "print(f'Begin {datetime.datetime.now()}')\n",
    "\n",
    "for region in regions:\n",
    "    roi = os.path.basename(region)\n",
    "    print(roi)\n",
    "\n",
    "    arcpy.env.workspace = region\n",
    "    gdb = arcpy.ListWorkspaces(workspace_type='FileGDB')\n",
    "    print(f'GDB {gdb}')\n",
    "\n",
    "    walk = arcpy.da.Walk(region, datatype=['FeatureClass', 'RasterDataset'])\n",
    "    for dirpath, dirnames, filenames in walk:\n",
    "        for filename in filenames:\n",
    "            if filename == 'NHDFlowline_merge' and roi in nhdplus_dat:\n",
    "                streamname = f'{prefDict[roi]}_{filename}'\n",
    "                streams = os.path.join(outgdb, streamname)\n",
    "                if not arcpy.Exists(streams):\n",
    "                    print(f'Copying {os.path.join(dirpath, filename)} to {outgdb}')\n",
    "                    startTime = time.time()  # Start timer\n",
    "                    # Select only streams/rivers and artificial paths\n",
    "                    arcpy.FeatureClassToFeatureClass_conversion(\n",
    "                        in_features=os.path.join(dirpath, filename),\n",
    "                        out_path=outgdb,\n",
    "                        out_name=streamname,\n",
    "                        where_clause=\"FType = 460 Or FType = 558\"\n",
    "                    )\n",
    "                    endTime = time.time()  # End timer\n",
    "                    elapsedTime = endTime - startTime  # Calculate elapsed time\n",
    "                    print(f'Copy completed in {elapsedTime} seconds')\n",
    "                else:\n",
    "                    print(f'{streams} already copied')\n",
    "                append_value(strDict, roi, [streams, 'NHDPlusID'])\n",
    "                \n",
    "            elif filename == 'streams_merge' and roi in tauDem_dat:\n",
    "                if roi == 'Bristol_Bay':\n",
    "                    id = 'catID'\n",
    "                else:\n",
    "                    id = 'LINKNO'\n",
    "\n",
    "                streamname = f'{prefDict[roi]}_{filename}'\n",
    "                streams = os.path.join(outgdb, streamname)\n",
    "                if not arcpy.Exists(streams):\n",
    "                    print(f'Copying {os.path.join(dirpath, filename)} to {outgdb}')\n",
    "                    startTime = time.time()  # Start timer\n",
    "                    arcpy.FeatureClassToFeatureClass_conversion(\n",
    "                        os.path.join(dirpath, filename),\n",
    "                        outgdb,\n",
    "                        streamname\n",
    "                    )\n",
    "                    endTime = time.time()  # End timer\n",
    "                    elapsedTime = endTime - startTime  # Calculate elapsed time\n",
    "                    print(f'Copy completed in {elapsedTime} seconds')\n",
    "                else:\n",
    "                    print(f'{streams} already created')\n",
    "                append_value(strDict, roi, [streams, id])\n",
    "            \n",
    "            elif filename == 'cats_merge':\n",
    "                if roi in nhdplus_dat:\n",
    "                    catID = 'NHDPlusID'\n",
    "                else:\n",
    "                    catID = 'catID'\n",
    "                    \n",
    "                catsname = f'{prefDict[roi]}_{filename}'\n",
    "                cats = os.path.join(outgdb, catsname)\n",
    "                if not arcpy.Exists(cats):\n",
    "                    print(f'Copying {os.path.join(dirpath, filename)} to {outgdb}')\n",
    "                    startTime = time.time()  # Start timer\n",
    "                    # Select only streams/rivers and artificial paths\n",
    "                    arcpy.FeatureClassToFeatureClass_conversion(\n",
    "                        in_features=os.path.join(dirpath, filename),\n",
    "                        out_path=outgdb,\n",
    "                        out_name=catsname,\n",
    "                    )\n",
    "                    endTime = time.time()  # End timer\n",
    "                    elapsedTime = endTime - startTime  # Calculate elapsed time\n",
    "                    print(f'Copy completed in {elapsedTime} seconds')\n",
    "                else:\n",
    "                    print(f'{cats} already copied')           \n",
    "                append_value(catsDict, roi, [cats, catID])\n",
    "\n",
    "            elif filename.endswith('.tif'):\n",
    "                if filename == 'elev.tif':\n",
    "                    raster_type = 'elev'\n",
    "                elif filename == 'slope.tif':\n",
    "                    raster_type = 'slope'\n",
    "                elif filename == 'fac.tif':\n",
    "                    raster_type = 'fac'\n",
    "                elif filename == 'fdr.tif':\n",
    "                    raster_type = 'fdr'\n",
    "                else:\n",
    "                    continue  # Skip if not the required raster\n",
    "\n",
    "                raster_name = f'{prefDict[roi]}{raster_type}.tif'\n",
    "                raster_path = os.path.join(outdir, raster_name)\n",
    "                if not arcpy.Exists(raster_path):\n",
    "                    print(f'Copying {os.path.join(dirpath, filename)} to {outdir}')\n",
    "                    startTime = time.time()  # Start timer\n",
    "                    arcpy.CopyRaster_management(os.path.join(dirpath, filename), raster_path)\n",
    "                    endTime = time.time()  # End timer\n",
    "                    elapsedTime = endTime - startTime  # Calculate elapsed time\n",
    "                    print(f'Copy completed in {elapsedTime} seconds')\n",
    "                else:\n",
    "                    print(f'{raster_path} already created')\n",
    "                append_value(roiRasDict, roi, [raster_path])\n",
    "\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "# Report success\n",
    "print(f'{\"*\"*100}')\n",
    "print(f'Process completed at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "      f'(Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print(f'{\"*\"*100}')\n",
    "print(strDict)\n",
    "print(f'{\"*\"*100}')\n",
    "print(roiRasDict)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T06:40:43.928715900Z",
     "start_time": "2023-12-18T06:40:43.093597400Z"
    }
   },
   "id": "4462d70e67bdb3ba"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combine the dictionaries\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c01659e3633e182"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "{'Bristol_Bay': ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\bbelev.tif',\n  ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\bbfac.tif'],\n  ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\bbfdr.tif'],\n  ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\bbslope.tif'],\n  'D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\AKSSF_ValBot.gdb\\\\bb_streams_merge',\n  'catID',\n  'D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\AKSSF_ValBot.gdb\\\\bb_cats_merge',\n  'catID']}"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinedDict = {}\n",
    "\n",
    "# Add key-value pairs from strDict to combinedDict\n",
    "combinedDict = {\n",
    "    x: roiRasDict.get(x, 0) + strDict.get(x, 0) + catsDict.get(x, 0)\n",
    "    for x in set(roiRasDict.keys()).union(strDict.keys(), catsDict.keys())\n",
    "}\n",
    "combinedDict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T06:40:43.965616200Z",
     "start_time": "2023-12-18T06:40:43.924725900Z"
    }
   },
   "id": "ca8f8674ddb72334"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate valley bottom polygons\n",
    "Convert stream polylines to raster and generate valley bottom polygons\n",
    "Some headwater streams have valleys that get broken up into \"raster cell\" chunks with disconnect sections...may need to create a buffer (10 meters?) on 1st order streams and merge with valley bottom polygon to fix.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d98ea502a313d3c"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin 2023-12-17 21:40:43.954645\n",
      "Bristol_Bay ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\bbelev.tif', ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\bbfac.tif'], ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\bbfdr.tif'], ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\bbslope.tif'], 'D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\AKSSF_ValBot.gdb\\\\bb_streams_merge', 'catID', 'D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\AKSSF_ValBot.gdb\\\\bb_cats_merge', 'catID']\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\bbrchRas.tif already created\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\AKSSF_ValBot.gdb\\bbvb600Smooth already generated\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\AKSSF_ValBot.gdb\\bbvb600Clean already created\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\AKSSF_ValBot.gdb\\bbvb600CleanIntSpSelect already created\n",
      "All Processes completed at 2023-12-17 21:40 (Elapsed time: 0:00:00)\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "import time, datetime\n",
    "\n",
    "# set accumulation threshold\n",
    "accThresh = 600\n",
    "\n",
    "def timer(processing_step, *args, **kwargs):\n",
    "    try:\n",
    "        # Start timing function\n",
    "        processStart = time.time()\n",
    "        processStartdt = datetime.datetime.now()\n",
    "        print(f'Begin {processing_step.__name__}: {datetime.datetime.now()}')\n",
    "\n",
    "        # Call the original geoprocessing function\n",
    "        result = processing_step(*args, **kwargs)\n",
    "\n",
    "        # End timing\n",
    "        processEnd = time.time()\n",
    "        processElapsed = int(processEnd - processStart)\n",
    "        processSuccess_time = datetime.datetime.now()\n",
    "\n",
    "        # Report success with the specified processing step name\n",
    "        print(f'{processing_step.__name__} completed at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "              f'(Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "        print(f'{\"*\"*100}')\n",
    "\n",
    "        return result, processElapsed\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle exceptions\n",
    "        processError_time = datetime.datetime.now()\n",
    "        print(f'Error in {processing_step.__name__} at {processError_time.strftime(\"%Y-%m-%d %H:%M\")}: {str(e)}')\n",
    "        print(f'{\"*\"*100}')\n",
    "        return None, None\n",
    "    \n",
    "    \n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "print(f'Begin {datetime.datetime.now()}')\n",
    "\n",
    "for k,v in combinedDict.items():\n",
    "    if k == 'Bristol_Bay':\n",
    "        reachRas = os.path.join(outdir,prefDict[k] + \"rchRas.tif\")\n",
    "        vbPoly = os.path.join(outgdb,prefDict[k] + \"_vbPoly\")\n",
    "        DEM_ras = arcpy.Raster(v[0])\n",
    "        slope_ras = arcpy.Raster(v[3])\n",
    "        size = DEM_ras.meanCellWidth\n",
    "        size = int(size)\n",
    "        reachid = v[5]\n",
    "        streams = v[4]\n",
    "        cats = v[6]\n",
    "        catID = v[7]\n",
    "        arcpy.env.snapRaster = DEM_ras\n",
    "        print(k,v)\n",
    "        #reachRas should already exist...src raster no?\n",
    "        if not arcpy.Exists(reachRas):\n",
    "            print(f'Converting {streams} to raster')\n",
    "            reachRas, elapsed_time = timer(arcpy.conversion.PolylineToRaster,streams,#streams\n",
    "                                              reachid,#reachID\n",
    "                                              reachRas,#reachRaster\n",
    "                                              \"\",\n",
    "                                              \"\",\n",
    "                                              size,\n",
    "                                              \"\"\n",
    "                                           )\n",
    "        else:\n",
    "            print(f'{reachRas} already created')\n",
    "        vbSmoothname = f'{prefDict[k]}vb{accThresh}Smooth'    \n",
    "        vbSmooth = os.path.join(outgdb, vbSmoothname)\n",
    "        if not arcpy.Exists(vbSmooth):\n",
    "            outDistAcc, elapsed_time = timer(arcpy.sa.DistanceAccumulation,reachRas, \"\", \"\", slope_ras, \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", 1.75, \"\", \"\")\n",
    "            DistAcc, elapsed_time = timer(arcpy.sa.Con,outDistAcc, 1, -123, f'VALUE <= {accThresh}')\n",
    "            DistAcc_Nulled = arcpy.sa.SetNull(DistAcc, DistAcc, 'VALUE = -123')\n",
    "            vbPoly, elapsed_time= timer(arcpy.conversion.RasterToPolygon, DistAcc_Nulled, vbPoly, \"SIMPLIFY\", \"\", \"\", \"\")\n",
    "            vbSmooth, elapsed_time = timer(arcpy.cartography.SmoothPolygon,vbPoly, vbSmooth, \"PAEK\", 250) \n",
    "            arcpy.management.Delete(outDistAcc)\n",
    "            arcpy.management.Delete(DistAcc)\n",
    "            arcpy.management.Delete(DistAcc_Nulled)\n",
    "        else:\n",
    "            print(f'{vbSmooth} already generated')\n",
    "        \n",
    "        #Clean smoothed polygon\n",
    "        vbCleanname =  f'{prefDict[k]}vb{accThresh}Clean'\n",
    "        vbClean = os.path.join(outgdb,vbCleanname)\n",
    "        if not arcpy.Exists(vbClean):\n",
    "            print(f'Cleaning {vbSmooth} to remove polygon smoothing artifacts')\n",
    "            pcnt1 = arcpy.GetCount_management(vbSmooth)\n",
    "            vbLayer = arcpy.MakeFeatureLayer_management(vbSmooth)\n",
    "            vbSelect = arcpy.management.SelectLayerByLocation(\n",
    "                in_layer = vbSmooth,\n",
    "                overlap_type=\"INTERSECT\",\n",
    "                select_features=streams,\n",
    "                search_distance=None,\n",
    "                selection_type=\"NEW_SELECTION\",\n",
    "                invert_spatial_relationship=\"NOT_INVERT\"\n",
    "            )\n",
    "            pcnt2 = arcpy.GetCount_management(vbSelect)\n",
    "            print(f'Selected {pcnt2} of {pcnt1} vb polygons')\n",
    "            arcpy.FeatureClassToFeatureClass_conversion(vbSelect,outgdb,vbCleanname)\n",
    "            append_value(combinedDict,k,vbClean)\n",
    "        else:\n",
    "            print(f'{vbClean} already created')\n",
    "        \n",
    "        #Intersect catchments with cleaned valley bottom polygons\n",
    "        vbCleanIntname = prefDict[k] + f\"vb{accThresh}CleanInt\"\n",
    "        vbCleanInt = os.path.join(outgdb, vbCleanIntname)\n",
    "        vbCleanIntSpname = prefDict[k] + f\"vb{accThresh}CleanIntSp\"\n",
    "        vbCleanIntSp = os.path.join(outgdb, vbCleanIntSpname)\n",
    "        vbCleanIntSelectname = prefDict[k] + f\"vb{accThresh}CleanIntSpSelect\"\n",
    "        vbCleanIntSelect = os.path.join(outgdb, vbCleanIntSelectname)\n",
    "        if not arcpy.Exists(vbCleanIntSelect):\n",
    "            print(f'Intersecting {cats} with {vbClean}')\n",
    "            arcpy.analysis.PairwiseIntersect(\n",
    "                in_features=[cats,vbClean],\n",
    "                out_feature_class=vbCleanInt,\n",
    "                join_attributes=\"ALL\",\n",
    "                cluster_tolerance=None,\n",
    "                output_type=\"INPUT\"             \n",
    "            )\n",
    "            #convert multipart to single part to identify any catchments split by the intersect operation\n",
    "            print(f'Converting {vbCleanIntname} to single part feature')\n",
    "            vbCleanIntSp, elapsed_time = timer(arcpy.MultipartToSinglepart_management,vbCleanInt,vbCleanIntSp)  \n",
    "            print(f'Selecting intersected catchments using streams')\n",
    "            vbIntSelect = arcpy.management.SelectLayerByLocation(\n",
    "                in_layer = vbCleanIntSp,\n",
    "                overlap_type=\"INTERSECT\",\n",
    "                select_features=streams,\n",
    "                search_distance=None,\n",
    "                selection_type=\"NEW_SELECTION\",\n",
    "                invert_spatial_relationship=\"NOT_INVERT\"\n",
    "            )\n",
    "            vbCleanIntSelect = arcpy.FeatureClassToFeatureClass_conversion(vbIntSelect,outgdb,vbCleanIntSelectname)\n",
    "            append_value(combinedDict,k,vbCleanIntSelect)\n",
    "        else:\n",
    "            print(f'{vbCleanIntSelect} already created')\n",
    "        \n",
    "        \n",
    "\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "# Report success\n",
    "print(f'All Processes completed at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "      f'(Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print(f'{\"*\"*100}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T06:40:44.087063800Z",
     "start_time": "2023-12-18T06:40:43.953648300Z"
    }
   },
   "id": "6a63f47c881974d3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Identify catchments split during the intersect process\n",
    "Catchments that were split into multiple polygons when intersected with the valley bottom polygon must be reselected and cleaned\n",
    "1. Intersect Streams with new catchment/vb intersect polygon\n",
    "2. Convert Stream Intersect to Center points and Endpoints (shifted slightly downstream)\n",
    "3. Merge two point layers together\n",
    "4. Select from polygon layer all catchments that contain clementi the stream mid and endpoints.\n",
    "5. Export and dissolve back on catchment ID"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "160016afeb0823e8"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin 2023-12-17 21:40:44.094164\n",
      "****************************************************************************************************\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\AKSSF_ValBot.gdb\\bbvb600strIntvbInt already created\n",
      "****************************************************************************************************\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\AKSSF_ValBot.gdb\\bbvb600strIntCtrPts already created\n",
      "****************************************************************************************************\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\AKSSF_ValBot.gdb\\bbvb600strIntEndPts already created\n",
      "****************************************************************************************************\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\AKSSF_ValBot.gdb\\bbvb600strIntEndPts created\n",
      "****************************************************************************************************\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\AKSSF_ValBot.gdb\\bbvb600CleanPtSelect already exists\n",
      "****************************************************************************************************\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\AKSSF_ValBot.gdb\\bbvb600Final already created\n",
      "****************************************************************************************************\n",
      "\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\AKSSF_ValBot.gdb\\bbvb600Final has 190646 features \n",
      "\n",
      "All Processes completed at 2023-12-17 21:40 (Elapsed time: 0:00:00)\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import arcpy\n",
    "\n",
    "for k,v in combinedDict.items():\n",
    "    if k == 'Bristol_Bay':\n",
    "        streams = combinedDict[k][4]\n",
    "        # Start timing function\n",
    "        processStart = time.time()\n",
    "        processStartdt = datetime.datetime.now()\n",
    "        print(f'Begin {datetime.datetime.now()}')\n",
    "        print(f'{\"*\"*100}')\n",
    "        \n",
    "        vbCleanname = f'{prefDict[k]}vb{accThresh}Clean'\n",
    "        vbClean = os.path.join(outgdb, vbCleanname)\n",
    "        vbFinalname = f'{prefDict[k]}vb{accThresh}Final'\n",
    "        vbFinal = os.path.join(outgdb, vbFinalname)\n",
    "        vbCleanPtSelectname = f'{prefDict[k]}vb{accThresh}CleanPtSelect'\n",
    "        vbCleanPtSelect = os.path.join(outgdb, vbCleanPtSelectname)\n",
    "        streamIntname = f'{prefDict[k]}vb{accThresh}strIntvbInt'\n",
    "        streamInt = os.path.join(outgdb, streamIntname)\n",
    "        vbCleanIntSelectname = f'{prefDict[k]}vb{accThresh}CleanIntSpSelect'\n",
    "        vbCleanIntSelect = os.path.join(outgdb, vbCleanIntSelectname)\n",
    "        strIntCtrPtname = f'{prefDict[k]}vb{accThresh}strIntCtrPts'\n",
    "        strIntCtrPts = os.path.join(outgdb, strIntCtrPtname)\n",
    "        strIntEndPtname = f'{prefDict[k]}vb{accThresh}strIntEndPts'\n",
    "        strIntEndPts = os.path.join(outgdb, strIntEndPtname)\n",
    "        strIntAllPtname = f'{prefDict[k]}vb{accThresh}strIntEndPts'\n",
    "        strIntAllPts = os.path.join(outgdb, strIntAllPtname)\n",
    "        \n",
    "        # Intersect Streams with catchments/vb\n",
    "        if not arcpy.Exists(streamInt):\n",
    "            print(f'Intersecting streams with catchment/vb polygons')\n",
    "            print(f'{\"*\"*100}')\n",
    "            \n",
    "            streamInt,elapsed_time = timer(arcpy.PairwiseIntersect_analysis,\n",
    "                                           in_features=[streams,vbCleanIntSelect],\n",
    "                                           out_feature_class=streamInt,\n",
    "                                           join_attributes=\"ALL\",\n",
    "                                           cluster_tolerance=None,\n",
    "                                           output_type=\"LINE\"\n",
    "                                           )\n",
    "        else:\n",
    "            print(f'{streamInt} already created')\n",
    "            print(f'{\"*\"*100}')\n",
    "            \n",
    "        # Create Stream Intersect Polyine center points\n",
    "        if not arcpy.Exists(strIntCtrPts):\n",
    "            print(f'Creating stream center point feature class: {strIntCtrPts}')\n",
    "            print(f'{\"*\"*100}')\n",
    "            \n",
    "            strIntCtrPts, elapsed_time = timer(arcpy.management.FeatureToPoint,\n",
    "                                               in_features=streamInt,\n",
    "                                               out_feature_class=strIntCtrPts,\n",
    "                                               point_location=\"INSIDE\"\n",
    "                                               )\n",
    "        else:\n",
    "            print(f'{strIntCtrPts} already created')\n",
    "            print(f'{\"*\"*100}')\n",
    "            \n",
    "        # Create point layer of stream endpoints shifted down the line by one meter\n",
    "        if not arcpy.Exists(strIntEndPts):\n",
    "            print(f'Creating shifted endpoints feature class')\n",
    "            print(f'{\"*\"*100}')\n",
    "            \n",
    "            strIntEndPts = arcpy.CreateFeatureclass_management(outgdb,strIntEndPtname,'POINT')\n",
    "            \n",
    "            # Record the start time\n",
    "            start_time = time.time()\n",
    "           \n",
    "            # Search cursor to iterate through polyline features\n",
    "            with arcpy.da.SearchCursor(streamInt, [\"SHAPE@\"]) as cursor:\n",
    "                for row in cursor:\n",
    "                    polyline = row[0]\n",
    "            \n",
    "                    # Get the last point of the polyline (endpoint)\n",
    "                    endpoint = polyline.lastPoint\n",
    "            \n",
    "                    # Specify the distance to slide the point (0.1 meters to the left)\n",
    "                    offset_distance = -1.0  # negative for left\n",
    "            \n",
    "                    # Use the positionAlongLine method to slide the point\n",
    "                    point = polyline.positionAlongLine(polyline.length + offset_distance)\n",
    "            \n",
    "                    # Create a point geometry\n",
    "                    new_point = arcpy.Point(point.firstPoint.X, point.firstPoint.Y)\n",
    "            \n",
    "                    # Insert the new point into the output feature class\n",
    "                    with arcpy.da.InsertCursor(strIntEndPts, [\"SHAPE@\"]) as insert_cursor:\n",
    "                        insert_cursor.insertRow([new_point])\n",
    "            \n",
    "            # Record the end time\n",
    "            end_time = time.time()           \n",
    "            # Calculate the elapsed time\n",
    "            elapsed_time = end_time - start_time\n",
    "            print(\"Point generation complete.\")\n",
    "            print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "            print(f'{\"*\"*100}')\n",
    "            \n",
    "        else: \n",
    "            print(f'{strIntEndPts} already created')\n",
    "            print(f'{\"*\"*100}')\n",
    "        \n",
    "        #Merge stream center and offset endpoints together\n",
    "        if not arcpy.Exists(strIntAllPts):\n",
    "            print(f'Merging center and endpoints together')\n",
    "            print(f'{\"*\"*100}')\n",
    "            arcpy.Merge_management([strIntCtrPts,strIntEndPts],strIntAllPts,add_source='NO_SOURCE_INFO')\n",
    "        else:\n",
    "            print (f'{strIntAllPts} created')\n",
    "            print(f'{\"*\"*100}')\n",
    "            \n",
    "        if not arcpy.Exists(vbCleanPtSelect):\n",
    "            print(f'Selecting catchments from {vbCleanIntSelect}')\n",
    "            print(f'{\"*\"*100}')\n",
    "            \n",
    "            vbSelectbyPoints = arcpy.management.SelectLayerByLocation(\n",
    "            in_layer=vbCleanIntSelect,\n",
    "            overlap_type=\"CONTAINS_CLEMENTINI\",\n",
    "            select_features=strIntAllPts,\n",
    "            search_distance=None,\n",
    "            selection_type=\"NEW_SELECTION\",\n",
    "            invert_spatial_relationship=\"NOT_INVERT\"\n",
    "                )\n",
    "                             \n",
    "            # Export Selected features\n",
    "            arcpy.FeatureClassToFeatureClass_conversion(vbSelectbyPoints,\n",
    "                                                        outgdb,\n",
    "                                                        vbCleanPtSelectname                                                        \n",
    "                                                        )\n",
    "        else:\n",
    "            print(f'{vbCleanPtSelect} already exists')\n",
    "            print(f'{\"*\"*100}')\n",
    "        \n",
    "        #Dissolve selection back on catchment ID\n",
    "        if not arcpy.Exists(vbFinal):\n",
    "            arcpy.PairwiseDissolve_analysis(vbCleanPtSelect,vbFinal,combinedDict[k][7])\n",
    "        else:\n",
    "            print(f'{vbFinal} already created')\n",
    "            print(f'{\"*\"*100}')\n",
    "        \n",
    "        # End timing\n",
    "        processEnd = time.time()\n",
    "        processElapsed = int(processEnd - processStart)\n",
    "        processSuccess_time = datetime.datetime.now()\n",
    "    \n",
    "        print(f'\\n{vbFinal} has {arcpy.GetCount_management(vbFinal)} features \\n')\n",
    "        print(f'All Processes completed at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "              f'(Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "        print(f'{\"*\"*100}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T06:40:44.417330500Z",
     "start_time": "2023-12-18T06:40:44.077090300Z"
    }
   },
   "id": "66eb78e773eba7e4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calculate vb mean widths\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ac83db675bd7bb5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  New Method using transects to calculate vb widths\n",
    " \n",
    "Extend transect lines well past valley basin polygon boundaries. \n",
    "Clip to vb basin and intersect\n",
    "Dissolve and select again using original small transects to remove lines that may extend outside of basin and enter again\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d12986de40056a47"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Smooth streamlines and generate transects\n",
    "Smooth streams using PAEK (50 meter) method to try and reduce jaggedness from raster derived streams\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93a04791a08323bd"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smooth_lines started 2023-12-17 21:40:44.416333\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\AKSSF_ValBot.gdb\\bbvb600smoothPAEK50Topo already created\n",
      "smooth_lines completed in 0.07 seconds\n",
      "****************************************************************************************************\n",
      "\n",
      "generate_small_transects started 2023-12-17 21:40:44.484152\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\AKSSF_ValBot.gdb\\bbvb600smallTrans already created\n",
      "generate_small_transects completed in 0.06 seconds\n",
      "****************************************************************************************************\n",
      "\n",
      "generate_transects started 2023-12-17 21:40:44.540730\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\AKSSF_ValBot.gdb\\bbvb600trans5000 already created\n",
      "generate_transects completed in 0.06 seconds\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "# Timer decorator\n",
    "def timer(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        print(f\"{func.__name__} started {datetime.datetime.now()}\")\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"{func.__name__} completed in {elapsed_time:.2f} seconds\")\n",
    "        print(f\"{'*'*100}\\n\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# Decorate functions with the timer decorator\n",
    "@timer\n",
    "def smooth_lines(instreams, barriers, smoothstreamspath):\n",
    "    if not arcpy.Exists(smoothstreamspath):\n",
    "        print (f'Smoothing streams')\n",
    "        arcpy.cartography.SmoothLine(\n",
    "        in_features=instreams,\n",
    "        out_feature_class=smoothstreamspath,\n",
    "        algorithm=\"PAEK\",\n",
    "        tolerance=\"50 Meters\",\n",
    "        endpoint_option=\"FIXED_CLOSED_ENDPOINT\",\n",
    "        error_option=\"RESOLVE_ERRORS\",\n",
    "        in_barriers=barriers\n",
    "            )\n",
    "    else:\n",
    "        print(f'{smoothstreamspath} already created')\n",
    "    return smoothstreamspath\n",
    "\n",
    "@timer\n",
    "def generate_small_transects(smooth_streams, smalltransname):\n",
    "    if not arcpy.Exists(smalltrans):\n",
    "        print (f'Generating selection transects')\n",
    "        arcpy.management.GenerateTransectsAlongLines(\n",
    "            in_features=smooth_streams,\n",
    "            out_feature_class=os.path.join(outgdb, smalltransname),\n",
    "            interval=\"50 Meters\",\n",
    "            transect_length=\"1 Meters\",\n",
    "            include_ends=\"NO_END_POINTS\"\n",
    "            )\n",
    "    else:\n",
    "        print(f'{smalltrans} already created')\n",
    "\n",
    "@timer\n",
    "def generate_transects(smooth_streams, transname, extension_length):\n",
    "    if not arcpy.Exists(transects):\n",
    "        print (f'Generating transects')\n",
    "        arcpy.management.GenerateTransectsAlongLines(\n",
    "            in_features=smooth_streams,\n",
    "            out_feature_class=os.path.join(outgdb, transname),\n",
    "            interval=\"50 Meters\",\n",
    "            transect_length=f\"{str(extension_length)} Meters\",\n",
    "            include_ends=\"NO_END_POINTS\"\n",
    "            )\n",
    "    else:\n",
    "        print(f'{transects} already created')\n",
    "       \n",
    "for k,v in combinedDict.items():\n",
    "    if k == 'Bristol_Bay':\n",
    "        #Input parameters\n",
    "        #outgdb = r'D:\\GIS\\AKSSF_ValBot_2023\\AKSSF_ValBot.gdb'\n",
    "        instreams = combinedDict[k][4]\n",
    "        smoothstreamsname =f'{prefDict[k]}vb{accThresh}smoothPAEK50Topo'\n",
    "        smoothstreamspath = os.path.join(outgdb, smoothstreamsname)\n",
    "        barriers = os.path.join(outgdb, f'{prefDict[k]}vb{accThresh}Final')\n",
    "        #extension_length = float(input(\"Enter the extension length (default is 5000): \") or 5000)\n",
    "        extension_length = 5000\n",
    "        smalltransname = f'{prefDict[k]}vb{accThresh}smallTrans'\n",
    "        smalltrans = os.path.join(outgdb,smalltransname)\n",
    "        transname = f'{prefDict[k]}vb{accThresh}trans{str(extension_length).replace(\".0\",\"\")}'\n",
    "        transects = os.path.join(outgdb, transname)\n",
    "        \n",
    "        # Execute decorated functions with user input\n",
    "        smooth_lines(instreams, barriers, smoothstreamspath)\n",
    "        generate_small_transects(smoothstreamspath, smalltransname)\n",
    "        generate_transects(smoothstreamspath,transname, extension_length)\n",
    "        #arcpy.PairwiseClip_analysis(transects,vbFinal,os.path.join(outgdb,'vbClipTest'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T06:40:44.615153Z",
     "start_time": "2023-12-18T06:40:44.416333700Z"
    }
   },
   "id": "d91e59c53eaca69e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate Transects\n",
    "\n",
    "wow! this used memory workspace and seemed to utilize all cores with some throttling\n",
    "Script started at 2023-12-13 10:54:07\n",
    "pairwise_intersect_features started 2023-12-13 10:54:07.660705\n",
    "pairwise_intersect_features completed in 534.86 seconds\n",
    "****************************************************************************************************\n",
    "\n",
    "Randomly getting ExecuteError: ERROR 160385: Workspace or data source is read only.\n",
    "Failed to execute (PairwiseIntersect).\n",
    "Tried different drives and memory workspace? Will try on another computer.  Maybe need to free up more RAM?\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddc022774ddfe8a"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script started at 2023-12-17 21:41:28\n",
      "pairwise_intersect_features started 2023-12-17 21:41:28.851569\n"
     ]
    },
    {
     "ename": "ExecuteError",
     "evalue": "ERROR 160385: Workspace or data source is read only.\nFailed to execute (PairwiseIntersect).\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mExecuteError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_7848\\319736726.py\u001B[0m in \u001B[0;36m<cell line: 84>\u001B[1;34m()\u001B[0m\n\u001B[0;32m    108\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    109\u001B[0m         \u001B[1;31m# Intersect clipped transects with valley bottom polygons using the pairwise tool\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 110\u001B[1;33m         \u001B[0mtransInt\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpairwise_intersect_features\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutgdb\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'vbClipTest'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvbFinal\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtransIntpath\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    111\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    112\u001B[0m         \u001B[1;31m#Convert multipart intersect to singlepart\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_7848\\319736726.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m      9\u001B[0m         \u001B[0mstart_time\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"{func.__name__} started {datetime.datetime.now()}\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 11\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     12\u001B[0m         \u001B[0mend_time\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m         \u001B[0melapsed_time\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mend_time\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mstart_time\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_7848\\319736726.py\u001B[0m in \u001B[0;36mpairwise_intersect_features\u001B[1;34m(features, output_fc)\u001B[0m\n\u001B[0;32m     61\u001B[0m \u001B[1;33m@\u001B[0m\u001B[0mtimer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mpairwise_intersect_features\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutput_fc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 63\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0marcpy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0manalysis\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mPairwiseIntersect\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0min_features\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout_feature_class\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0moutput_fc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mjoin_attributes\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"ALL\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcluster_tolerance\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutput_type\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"LINE\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     64\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[1;33m@\u001B[0m\u001B[0mtimer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\analysis.py\u001B[0m in \u001B[0;36mPairwiseIntersect\u001B[1;34m(in_features, out_feature_class, join_attributes, cluster_tolerance, output_type)\u001B[0m\n\u001B[0;32m   1194\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mretval\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1195\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1196\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1197\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1198\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\analysis.py\u001B[0m in \u001B[0;36mPairwiseIntersect\u001B[1;34m(in_features, out_feature_class, join_attributes, cluster_tolerance, output_type)\u001B[0m\n\u001B[0;32m   1191\u001B[0m     \u001B[1;32mfrom\u001B[0m \u001B[0marcpy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marcobjects\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marcobjectconversion\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mconvertArcObjectToPythonObject\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1192\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1193\u001B[1;33m         \u001B[0mretval\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconvertArcObjectToPythonObject\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mPairwiseIntersect_analysis\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mgp_fixargs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0min_features\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout_feature_class\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mjoin_attributes\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcluster_tolerance\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutput_type\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1194\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mretval\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1195\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\geoprocessing\\_base.py\u001B[0m in \u001B[0;36m<lambda>\u001B[1;34m(*args)\u001B[0m\n\u001B[0;32m    518\u001B[0m         \u001B[0mval\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_gp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mattr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    519\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcallable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mval\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 520\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[1;32mlambda\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mval\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mgp_fixargs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    521\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    522\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mconvertArcObjectToPythonObject\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mval\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mExecuteError\u001B[0m: ERROR 160385: Workspace or data source is read only.\nFailed to execute (PairwiseIntersect).\n"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "import os\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.parallelProcessingFactor = 100\n",
    "\n",
    "# Timer decorator\n",
    "def timer(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        print(f\"{func.__name__} started {datetime.datetime.now()}\")\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"{func.__name__} completed in {elapsed_time:.2f} seconds\")\n",
    "        print(f\"{'*'*100}\\n\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# Check existing funcs\n",
    "# @timer\n",
    "# def pairwise_intersect_features(features, output_fc):\n",
    "#     if not arcpy.Exists(output_fc):\n",
    "#         print(f\"Creating {output_fc}. {__name__}.{pairwise_intersect_features.__name__} starting at {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "#         arcpy.analysis.PairwiseIntersect(in_features=features, out_feature_class=output_fc, join_attributes=\"ALL\", cluster_tolerance=None, output_type=\"LINE\")\n",
    "#     else:\n",
    "#         print(f\"{output_fc} already exists.\")\n",
    "# \n",
    "# @timer\n",
    "# def mp2sp(input_intersection, out_mp):\n",
    "#     if not arcpy.Exists(out_mp):\n",
    "#         print(f\"Creating {out_mp}. {__name__}.{mp2sp.__name__} starting at {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "#         arcpy.management.MultipartToSinglepart(in_features=input_intersection, out_feature_class=out_mp)\n",
    "#     else:\n",
    "#         print(f\"{out_mp} already exists.\")\n",
    "#     \n",
    "# @timer\n",
    "# def select_by_location(in_layer, overlap_type, select_features, selection_type, invert_spatial_relationship):\n",
    "#     result = arcpy.management.SelectLayerByLocation(\n",
    "#         in_layer=in_layer, overlap_type=overlap_type, select_features=select_features,\n",
    "#         selection_type=selection_type, invert_spatial_relationship=invert_spatial_relationship\n",
    "#     )\n",
    "#     return result\n",
    "# \n",
    "# @timer\n",
    "# def copy_selected_features(input_fc, output_fc):\n",
    "#     if not arcpy.Exists(output_fc):\n",
    "#         print(f\" Creating {output_fc}. {__name__}.{copy_selected_features.__name__} starting at {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "#         arcpy.management.CopyFeatures(input_fc, output_fc)\n",
    "#     else:\n",
    "#         print(f\"{output_fc} already exists.\")\n",
    "# \n",
    "# @timer\n",
    "# def select_and_copy_features(input_fc, output_fc, select_features):\n",
    "#     if not arcpy.Exists(output_fc):\n",
    "#         selected_lines = select_by_location(input_fc, \"SHARE_A_LINE_SEGMENT_WITH\", select_features, \"NEW_SELECTION\", \"NOT_INVERT\")\n",
    "#         copy_selected_features(selected_lines, output_fc)\n",
    "#     else:\n",
    "#         print(f'{output_fc} already exists')\n",
    "\n",
    "\n",
    "@timer\n",
    "def pairwise_intersect_features(features, output_fc):\n",
    "    return arcpy.analysis.PairwiseIntersect(in_features=features, out_feature_class=output_fc, join_attributes=\"ALL\", cluster_tolerance=None, output_type=\"LINE\")\n",
    "\n",
    "@timer\n",
    "def mp2sp(input_intersection, out_mp):\n",
    "    return arcpy.management.MultipartToSinglepart( in_features = input_intersection, out_feature_class=out_mp)\n",
    "\n",
    "@timer\n",
    "def select_by_location(in_layer, overlap_type, select_features, selection_type, invert_spatial_relationship):\n",
    "    return arcpy.management.SelectLayerByLocation(in_layer=in_layer, overlap_type=overlap_type, select_features=select_features, selection_type=selection_type, invert_spatial_relationship=invert_spatial_relationship)\n",
    "\n",
    "@timer\n",
    "def copy_selected_features(input_fc, output_fc):\n",
    "    return arcpy.management.CopyFeatures(input_fc, output_fc)\n",
    "\n",
    "# Combine selection and copy features steps\n",
    "@timer\n",
    "def select_and_copy_features(input_fc, output_fc, select_features):\n",
    "    selected_lines = select_by_location(input_fc, \"SHARE_A_LINE_SEGMENT_WITH\", select_features, \"NEW_SELECTION\", \"NOT_INVERT\")\n",
    "    copy_selected_features(selected_lines, output_fc)\n",
    "\n",
    "\n",
    "for k,v in combinedDict.items():\n",
    "    if k == 'Bristol_Bay':\n",
    "        #outgdb = r'C:\\Users\\dwmerrigan\\Documents\\ArcGIS\\AKSSF_Vb.gdb'\n",
    "        # Input parameters\n",
    "        outgdb = r'D:\\GIS\\AKSSF_ValBot_2023\\AKSSF_ValBot.gdb'\n",
    "        #extension_length = float(input(\"Enter the extension length (default is 5000): \") or 5000)\n",
    "        vbFinalname = f'{prefDict[k]}vb{accThresh}Final'\n",
    "        vbFinal = os.path.join(outgdb, vbFinalname)\n",
    "        smalltransname = f'{prefDict[k]}vb{accThresh}smallTrans'\n",
    "        transname = f'{prefDict[k]}vb{accThresh}trans{str(extension_length).replace(\".0\",\"\")}'\n",
    "        smalltrans = os.path.join(outgdb,smalltransname)\n",
    "        transects = os.path.join(outgdb, transname)\n",
    "        transIntname = f'{prefDict[k]}vb{accThresh}transInt'\n",
    "        transIntpath = os.path.join(r'memory\\\\', transIntname)\n",
    "        transmp2spname = f'{prefDict[k]}vb{accThresh}transIntSp'\n",
    "        transmp2sppath = os.path.join(outgdb, transmp2spname)\n",
    "        finaltransname = f'{prefDict[k]}vb{accThresh}TransectsFinal'\n",
    "        finaltranspath = os.path.join(outgdb,finaltransname)\n",
    "        # Print the start time\n",
    "        print(f\"Script started at {time.strftime('%Y-%m-%d %H:%M:%S')}\")     \n",
    "        \n",
    "        arcpy.env.workspace = outgdb\n",
    "        arcpy.env.overwriteOutput = True\n",
    "        arcpy.env.parallelProcessingFactor = \"100%\"\n",
    "        \n",
    "        # Intersect clipped transects with valley bottom polygons using the pairwise tool\n",
    "        transInt = pairwise_intersect_features([os.path.join(outgdb,'vbClipTest'), vbFinal], transIntpath)\n",
    "        \n",
    "        #Convert multipart intersect to singlepart\n",
    "        mp2spout = mp2sp(transIntpath, transmp2sppath)\n",
    "        \n",
    "        # Select lines that share a line segment with the original input transect feature class\n",
    "        select_and_copy_features(transmp2sppath, finaltranspath, smalltrans)\n",
    "        \n",
    "        # Print the end time\n",
    "        print(f\"Script completed at {time.strftime('%Y-%m-%d %H:%M:%S')}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T06:42:14.326157200Z",
     "start_time": "2023-12-18T06:41:28.844587200Z"
    }
   },
   "id": "be6c23c2d6ea2090"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Summarize valley widths by catchment and watershed?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "675e49974544c619"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
