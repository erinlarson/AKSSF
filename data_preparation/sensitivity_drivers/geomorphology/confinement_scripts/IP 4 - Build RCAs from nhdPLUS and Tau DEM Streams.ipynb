{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 4 - IP Build RCAs from Pre-Processed NetMap Reaches and DEM\n",
    "\n",
    "Use this tool to build reach contributing area (RCAs) from a NetMap stream reaches and a digital elevation model (DEM). This tool is designed to replace the STARS \"Generate Cost RCAs\" tool which was built using Python 2 and designed for use in ArcMap.\n",
    "\n",
    "## Required Software:\n",
    "\n",
    "- The code contained in this notebook is designed to be run within an ESRI ArcPro project. The script output is written to the default project geodatabase and therefore the user must open and run the notebook .IPYNB file within an ArcPro project.\n",
    "- If any of the geoprocessing steps require an advanced license or any specific extensions, the script will check for these conditions before running.\n",
    "- A modified version of this script has been included as a .PY file, and added to the **IP.tbx** ESRI toolbox included with this package. The setup code block in that version of the script has been modified to accept input parameters from the ArcPro GUI instead of notebook code. That alternate setup code block is included in this script for reference, but has been hashed out.\n",
    "\n",
    "## Required Inputs:\n",
    "\n",
    "- A DEM, preferably the same source that was used to create the NetMap reaches. For the Yukon-Kuskokwim IP project, this is the 5m IFSAR Digital Surface Model (DSM) that can be downloaded from various repositories online. See the Data.gov catalog entry for metadata (https://catalog.data.gov/dataset/5-meter-alaska-digital-elevation-models-dems-usgs-national-map-3dep-downloadable-data-collectio) and the USGS National Map online application for a download option (https://apps.nationalmap.gov/downloader/).\n",
    "\n",
    "- NetMap synthetic stream reaches, clipped to HUC8 extent and pruned to keep only those reaches with greater than 5km catchment area. These reaches should be pre-processed using the \"Prune Netmap Reaches to 5km and Clip by HUC8\" script included in this toolbox. (Attempting to process a full size NetMap product with a 5m DEM will likely crash the program.)\n",
    "\n",
    "- A unique attribute field in the pre-processed NetMap synthetic stream reach feature layer. The values in this field will become the unique RCA IDs.\n",
    "\n",
    "- A feature class name for the RCA polygon output.\n",
    "\n",
    "- A system directory to use as a temporary file location. It is recommended that this be a short file path on an internal hard drive (eg, \"C:/data\").\n",
    "\n",
    "\n",
    "## Geoprocessing Output:\n",
    "\n",
    "- An RCA polygon feature class written to the default project geodatabase.\n",
    "\n",
    "## Processing Steps:\n",
    "\n",
    "1. Convert the pre-processed reaches to a raster, using the same cell size and extent as the input DEM.\n",
    "2. Create a raster object from the rasterized streamlines.\n",
    "3. Run a series of Raster Calculator expressions. (These calculations essentially create a cost surface where ridgeline landscape positions become very expensive compared to valley and hillslope positions. This will constrain the RCA polygons and prevent them from crossing ridgetops into adjacent drainages.)\n",
    "4. Run the Cost Allocation using the rasterized stream reaches and the final cost surface.\n",
    "5. Build a raster attribute table for the the cost allocation output.\n",
    "6. Convert the cost allocation output to polygon, and dissolve any multi-part polygons.\n",
    "7. Add a field for the RCA ID, then calculate the RCA ID to equal the \"gridcode\" attribute from the original rasterized reaches.\n",
    "8. Delete all intermediary rasters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Code starts here:\n",
    "\n",
    "#### Setup\n",
    "\n",
    "Import modules and reset environments to default. This should set the ArcPro project geodatabase as the workspace/scratch environment, just in case it was set otherwise. Additionally, prevent the addition of intermediary outputs to the ArcPro project map. Some tools may not run if their target is open in the map display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-11-14T19:07:55.942102700Z",
     "start_time": "2023-11-14T19:07:43.715061400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2023-11-14 10:07:55.919164\n",
      "imports complete\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sys paths ['C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\AKSSF\\\\data_preparation\\\\sensitivity_drivers\\\\geomorphology\\\\confinement_scripts', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\Resources\\\\ArcPy', 'C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\AKSSF', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\python39.zip', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\DLLs', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3', '', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\site-packages', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\Resources\\\\ArcToolbox\\\\Scripts', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\Babel-2.11.0-py3.9.egg', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\future-0.18.2-py3.9.egg', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\jedi-0.18.2-py3.9.egg', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\pytz-2022.6-py3.9.egg', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\pywin32security', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\sympy-1.9-py3.9.egg', 'C:\\\\Program Files\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\dwmerrigan\\\\.ipython']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Python Environment set to - C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "2023-11-14 10:07:55.919164\n",
      "Output directory set to D:\\\\GIS\\\\AKSSF_ValBot_2023\n",
      "Output gdb set to D:\\\\GIS\\\\AKSSF_ValBot_2023\\AKSSF_ValBot.gdb\n"
     ]
    }
   ],
   "source": [
    "import os, arcpy, sys,datetime, traceback\n",
    "\n",
    "import arcpy.management\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "sr = arcpy.SpatialReference(3338)  #'NAD_1983_Alaska_Albers'\n",
    "arcpy.env.outputCoordinateSystem = sr\n",
    "print(f'Date: {datetime.datetime.now()}')\n",
    "print('imports complete')\n",
    "print(f'{(\"-\"*100)}')\n",
    "print(f'sys paths {sys.path}')\n",
    "print(f'{(\"-\"*100)}')\n",
    "print(f'Python Environment set to - {sys.base_exec_prefix}')\n",
    "print(f'{(\"-\"*100)}')\n",
    "print (datetime.datetime.now())\n",
    "outdir = r\"D:\\\\GIS\\\\AKSSF_ValBot_2023\"\n",
    "outgdb = os.path.join(outdir,'AKSSF_ValBot.gdb')\n",
    "print(f'Output directory set to {outdir}')\n",
    "print(f'Output gdb set to {outgdb}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The Spatial Analyst extension is required for this script to work. Check for extension, and if its available check it out for use. If it is unavailable or cannot be checked out, throw a license error and provide an error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-11-14T17:17:57.877799800Z",
     "start_time": "2023-11-14T17:17:57.836657500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial Analyst license is required.\n",
      "\n",
      "Good news...Spatial Analyst license is available!\n"
     ]
    }
   ],
   "source": [
    "print(\"Spatial Analyst license is required.\")\n",
    "arcpy.AddMessage(\"Spatial Analyst license is required.\")\n",
    "print(arcpy.GetMessages())\n",
    "\n",
    "class LicenseError(Exception):\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    if arcpy.CheckExtension(\"Spatial\") == \"Available\":\n",
    "        arcpy.CheckOutExtension(\"Spatial\")\n",
    "        print(\"Good news...Spatial Analyst license is available!\")\n",
    "        arcpy.AddMessage(\"Good news...Spatial Analyst license is available!\")\n",
    "        print(arcpy.GetMessages())\n",
    "    else:\n",
    "        # raise a custom exception\n",
    "        raise LicenseError\n",
    "\n",
    "except LicenseError:\n",
    "    print(\"Bad news...Spatial Analyst license is unavailable.\")\n",
    "    arcpy.AddMessage(\"Bad news...Spatial Analyst license is unavailable.\")\n",
    "    print(arcpy.GetMessages())\n",
    "except arcpy.ExecuteError:\n",
    "    print(arcpy.GetMessages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Function to add key, value pairs to dictionary\n",
    "def append_value(dict_obj, key, value):\n",
    "    # Check if key exist in dict or not\n",
    "    if key in dict_obj:\n",
    "        # Key exist in dict.\n",
    "        # Check if type of value of key is list or not\n",
    "        if not isinstance(dict_obj[key], list):\n",
    "            # If type is not list then make it list\n",
    "            dict_obj[key] = [dict_obj[key]]\n",
    "        # Append the value in list\n",
    "        dict_obj[key].append(value)\n",
    "    else:\n",
    "        # As key is not in dict,\n",
    "        # so, add key-value pair\n",
    "        dict_obj[key] = value\n",
    "# Function to remove parenthesis from user inputs\n",
    "def replace_all(userinput, dic):\n",
    "    for i, j in dic.items():\n",
    "        userinput = userinput.replace(i, j)\n",
    "    return userinput\n",
    "\n",
    "# Getnull rows from numpy array\n",
    "def getnull(cat_ID_con):\n",
    "    nullRows = []\n",
    "    nullRows.append(cat_ID_con)\n",
    "    return True\n",
    "\n",
    "#Generate unique column names\n",
    "def uniquify(df_final):\n",
    "    seen = set()\n",
    "    for item in df_final:\n",
    "        fudge = 1\n",
    "        newitem = item\n",
    "        while newitem in seen:\n",
    "            fudge += 1\n",
    "            newitem = \"{}_{}\".format(item, fudge)\n",
    "        yield newitem\n",
    "        seen.add(newitem)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-11-14T17:18:00.931947400Z",
     "start_time": "2023-11-14T17:18:00.911638200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin 2023-11-14 08:18:47.211317\n",
      "Cook_Inlet\n",
      "GDB ['D:\\\\GIS\\\\AKSSF\\\\Cook_Inlet\\\\Cook_Inlet.gdb']\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\cielev.tif already created\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\cifac.tif already created\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\cifdr.tif already created\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\cislope.tif already created\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\AKSSF_ValBot.gdb\\Cook_Inlet_NHDFlowline_merge already created\n",
      "Copper_River\n",
      "GDB ['D:\\\\GIS\\\\AKSSF\\\\Copper_River\\\\Copper_River.gdb']\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\crelev.tif already created\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\crfac.tif already created\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\crfdr.tif already created\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\crslope.tif already created\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\AKSSF_ValBot.gdb\\Copper_River_NHDFlowline_merge already created\n",
      "Bristol_Bay\n",
      "GDB ['D:\\\\GIS\\\\AKSSF\\\\Bristol_Bay\\\\Bristol_Bay.gdb']\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\bbelev.tif already created\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\bbfac.tif already created\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\bbfdr.tif already created\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\bbslope.tif already created\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\AKSSF_ValBot.gdb\\Bristol_Bay_streams_merge already created\n",
      "Kodiak\n",
      "GDB ['D:\\\\GIS\\\\AKSSF\\\\Kodiak\\\\Kodiak.gdb']\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\kodelev.tif already created\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\kodfac.tif already created\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\kodfdr.tif already created\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\kodslope.tif already created\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\AKSSF_ValBot.gdb\\Kodiak_streams_merge already created\n",
      "Prince_William_Sound\n",
      "GDB ['D:\\\\GIS\\\\AKSSF\\\\Prince_William_Sound\\\\Prince_William_Sound.gdb']\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\pwselev.tif already created\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\pwsfac.tif already created\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\pwsfdr.tif already created\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\pwsslope.tif already created\n",
      "D:\\\\GIS\\\\AKSSF_ValBot_2023\\AKSSF_ValBot.gdb\\Prince_William_Sound_streams_merge already created\n",
      "****************************************************************************************************\n",
      "Process completed at 2023-11-14 08:18 (Elapsed time: 0:00:06)\n",
      "****************************************************************************************************\n",
      "{'Cook_Inlet': ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\AKSSF_ValBot.gdb\\\\Cook_Inlet_NHDFlowline_merge', 'NHDPlusID'], 'Copper_River': ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\AKSSF_ValBot.gdb\\\\Copper_River_NHDFlowline_merge', 'NHDPlusID'], 'Bristol_Bay': ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\AKSSF_ValBot.gdb\\\\Bristol_Bay_streams_merge', 'catID'], 'Kodiak': ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\AKSSF_ValBot.gdb\\\\Kodiak_streams_merge', 'LINKNO'], 'Prince_William_Sound': ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\AKSSF_ValBot.gdb\\\\Prince_William_Sound_streams_merge', 'LINKNO']}\n",
      "****************************************************************************************************\n",
      "{'Cook_Inlet': ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\cielev.tif', ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\cifac.tif'], ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\cifdr.tif'], ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\cislope.tif']], 'Copper_River': ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\crelev.tif', ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\crfac.tif'], ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\crfdr.tif'], ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\crslope.tif']], 'Bristol_Bay': ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\bbelev.tif', ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\bbfac.tif'], ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\bbfdr.tif'], ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\bbslope.tif']], 'Kodiak': ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\kodelev.tif', ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\kodfac.tif'], ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\kodfdr.tif'], ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\kodslope.tif']], 'Prince_William_Sound': ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\pwselev.tif', ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\pwsfac.tif'], ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\pwsfdr.tif'], ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\pwsslope.tif']]}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import arcpy\n",
    "\n",
    "prefDict = {'Bristol_Bay':'bb', 'Kodiak':'kod', 'Prince_William_Sound':'pws','Cook_Inlet':'ci','Copper_River':'cr'}\n",
    "\n",
    "# Separate data by source type\n",
    "nhdplus_dat = ['Cook_Inlet', 'Copper_River']\n",
    "tauDem_dat = ['Bristol_Bay', 'Kodiak', 'Prince_William_Sound']\n",
    "\n",
    "# Set input regional folders\n",
    "regions = [f'D:\\\\GIS\\\\AKSSF\\\\{source}' for source in nhdplus_dat + tauDem_dat]\n",
    "\n",
    "strDict = {}\n",
    "roiRasDict = {}\n",
    "\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "print(f'Begin {datetime.datetime.now()}')\n",
    "\n",
    "for region in regions:\n",
    "    roi = os.path.basename(region)\n",
    "    print(roi)\n",
    "\n",
    "    arcpy.env.workspace = region\n",
    "    gdb = arcpy.ListWorkspaces(workspace_type='FileGDB')\n",
    "    print(f'GDB {gdb}')\n",
    "\n",
    "    walk = arcpy.da.Walk(region, datatype=['FeatureClass', 'RasterDataset'])\n",
    "    for dirpath, dirnames, filenames in walk:\n",
    "        for filename in filenames:\n",
    "            if filename == 'NHDFlowline_merge' and roi in nhdplus_dat:\n",
    "                streamname = f'{roi}_{filename}'\n",
    "                streams = os.path.join(outgdb, streamname)\n",
    "                if not arcpy.Exists(streams):\n",
    "                    print(f'Copying {os.path.join(dirpath, filename)} to {outgdb}')\n",
    "                    startTime = time.time()  # Start timer\n",
    "                    # Select only streams/rivers and artificial paths\n",
    "                    arcpy.FeatureClassToFeatureClass_conversion(\n",
    "                        in_features=os.path.join(dirpath, filename),\n",
    "                        out_path=outgdb,\n",
    "                        out_name=streamname,\n",
    "                        where_clause=\"FType = 460 Or FType = 558\"\n",
    "                    )\n",
    "                    endTime = time.time()  # End timer\n",
    "                    elapsedTime = endTime - startTime  # Calculate elapsed time\n",
    "                    print(f'Copy completed in {elapsedTime} seconds')\n",
    "                else:\n",
    "                    print(f'{streams} already created')\n",
    "                append_value(strDict, roi, [streams, 'NHDPlusID'])\n",
    "\n",
    "            elif filename == 'streams_merge' and roi in tauDem_dat:\n",
    "                if roi == 'Bristol_Bay':\n",
    "                    id = 'catID'\n",
    "                else:\n",
    "                    id = 'LINKNO'\n",
    "\n",
    "                streamname = f'{roi}_{filename}'\n",
    "                streams = os.path.join(outgdb, streamname)\n",
    "                if not arcpy.Exists(streams):\n",
    "                    print(f'Copying {os.path.join(dirpath, filename)} to {outgdb}')\n",
    "                    startTime = time.time()  # Start timer\n",
    "                    arcpy.FeatureClassToFeatureClass_conversion(\n",
    "                        os.path.join(dirpath, filename),\n",
    "                        outgdb,\n",
    "                        streamname\n",
    "                    )\n",
    "                    endTime = time.time()  # End timer\n",
    "                    elapsedTime = endTime - startTime  # Calculate elapsed time\n",
    "                    print(f'Copy completed in {elapsedTime} seconds')\n",
    "                else:\n",
    "                    print(f'{streams} already created')\n",
    "                append_value(strDict, roi, [streams, id])\n",
    "\n",
    "            elif filename.endswith('.tif'):\n",
    "                if filename == 'elev.tif':\n",
    "                    raster_type = 'elev'\n",
    "                elif filename == 'slope.tif':\n",
    "                    raster_type = 'slope'\n",
    "                elif filename == 'fac.tif':\n",
    "                    raster_type = 'fac'\n",
    "                elif filename == 'fdr.tif':\n",
    "                    raster_type = 'fdr'\n",
    "                else:\n",
    "                    continue  # Skip if not the required raster\n",
    "\n",
    "                raster_name = f'{prefDict[roi]}{raster_type}.tif'\n",
    "                raster_path = os.path.join(outdir, raster_name)\n",
    "                if not arcpy.Exists(raster_path):\n",
    "                    print(f'Copying {os.path.join(dirpath, filename)} to {outdir}')\n",
    "                    startTime = time.time()  # Start timer\n",
    "                    arcpy.CopyRaster_management(os.path.join(dirpath, filename), raster_path)\n",
    "                    endTime = time.time()  # End timer\n",
    "                    elapsedTime = endTime - startTime  # Calculate elapsed time\n",
    "                    print(f'Copy completed in {elapsedTime} seconds')\n",
    "                else:\n",
    "                    print(f'{raster_path} already created')\n",
    "                append_value(roiRasDict, roi, [raster_path])\n",
    "\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "# Report success\n",
    "print(f'{\"*\"*100}')\n",
    "print(f'Process completed at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "      f'(Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print(f'{\"*\"*100}')\n",
    "print(strDict)\n",
    "print(f'{\"*\"*100}')\n",
    "print(roiRasDict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-11-14T17:18:53.856082Z",
     "start_time": "2023-11-14T17:18:47.199350300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Set processing regions and paths to stream/flowline and elevation rasters.  Copy to outdir/gdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-11-14T17:19:18.492094900Z",
     "start_time": "2023-11-14T17:19:18.463854400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'Copper_River': ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\crelev.tif',\n  ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\crfac.tif'],\n  ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\crfdr.tif'],\n  ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\crslope.tif'],\n  'D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\AKSSF_ValBot.gdb\\\\Copper_River_NHDFlowline_merge',\n  'NHDPlusID'],\n 'Bristol_Bay': ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\bbelev.tif',\n  ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\bbfac.tif'],\n  ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\bbfdr.tif'],\n  ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\bbslope.tif'],\n  'D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\AKSSF_ValBot.gdb\\\\Bristol_Bay_streams_merge',\n  'catID'],\n 'Kodiak': ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\kodelev.tif',\n  ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\kodfac.tif'],\n  ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\kodfdr.tif'],\n  ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\kodslope.tif'],\n  'D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\AKSSF_ValBot.gdb\\\\Kodiak_streams_merge',\n  'LINKNO'],\n 'Prince_William_Sound': ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\pwselev.tif',\n  ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\pwsfac.tif'],\n  ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\pwsfdr.tif'],\n  ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\pwsslope.tif'],\n  'D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\AKSSF_ValBot.gdb\\\\Prince_William_Sound_streams_merge',\n  'LINKNO'],\n 'Cook_Inlet': ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\cielev.tif',\n  ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\cifac.tif'],\n  ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\cifdr.tif'],\n  ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\cislope.tif'],\n  'D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\AKSSF_ValBot.gdb\\\\Cook_Inlet_NHDFlowline_merge',\n  'NHDPlusID']}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "combinedDict = {}\n",
    "\n",
    "# Add key-value pairs from strDict to combinedDict\n",
    "combinedDict = {x: roiRasDict.get(x, 0) + strDict.get(x, 0)\n",
    "                    for x in set(roiRasDict).union(strDict)}\n",
    "\n",
    "combinedDict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Convert stream reaches to a raster, using the same cell size as the DEM. Also, use the DEM as the snap raster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "'D:\\\\GIS\\\\AKSSF_ValBot_2023\\\\kodelev.tif'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.normpath(combinedDict['Kodiak'][0]) \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T22:56:17.195661400Z",
     "start_time": "2023-11-10T22:56:17.155761500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-11-14T18:29:41.538664500Z",
     "start_time": "2023-11-14T17:22:14.890258300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin 2023-11-14 08:22:14.909206\n",
      "Begin 2023-11-14 08:22:14.910203\n",
      "Bristol_Bay ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\bbelev.tif', ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\bbfac.tif'], ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\bbfdr.tif'], ['D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\bbslope.tif'], 'D:\\\\\\\\GIS\\\\\\\\AKSSF_ValBot_2023\\\\AKSSF_ValBot.gdb\\\\Bristol_Bay_streams_merge', 'catID']\n",
      "Converting D:\\\\GIS\\\\AKSSF_ValBot_2023\\AKSSF_ValBot.gdb\\Bristol_Bay_streams_merge to raster\n",
      "Stream to raster Process completed at 2023-11-14 08:23 (Elapsed time: 0:01:17)\n",
      "****************************************************************************************************\n",
      "Begin 2023-11-14 08:23:32.405811\n",
      "p3. Focal Mean Annulus Process completed at 2023-11-14 08:23 (Elapsed time: 0:00:00)\n",
      "****************************************************************************************************\n",
      "Begin 2023-11-14 08:23:32.529332\n",
      "p4. Focal Mean Annulus Process completed at 2023-11-14 08:23 (Elapsed time: 0:00:00)\n",
      "****************************************************************************************************\n",
      "Begin 2023-11-14 08:23:32.539306\n",
      "p5. Focal Mean Annulus Process completed at 2023-11-14 08:23 (Elapsed time: 0:00:00)\n",
      "****************************************************************************************************\n",
      "Begin 2023-11-14 08:23:32.549279\n",
      "p.6 Focal Mean Annulus Process completed at 2023-11-14 08:23 (Elapsed time: 0:00:00)\n",
      "****************************************************************************************************\n",
      "Begin 2023-11-14 08:23:32.577273\n",
      "p7. Focal Mean Annulus Process completed at 2023-11-14 08:23 (Elapsed time: 0:00:00)\n",
      "****************************************************************************************************\n",
      "Begin 2023-11-14 08:23:32.596222\n",
      "p8. Focal Mean Annulus Process completed at 2023-11-14 09:29 (Elapsed time: 1:06:08)\n",
      "****************************************************************************************************\n",
      "Process completed at 2023-11-14 09:29 (Elapsed time: 1:07:26)\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "print(f'Begin {datetime.datetime.now()}')\n",
    "\n",
    "for k,v in combinedDict.items():\n",
    "    if k == 'Bristol_Bay':\n",
    "        roi = k\n",
    "        reachRas = os.path.join(outdir,prefDict[k] + \"rchRas.tif\")\n",
    "        # Start timing function\n",
    "        processStart2 = time.time()\n",
    "        processStartdt2 = datetime.datetime.now()\n",
    "        print(f'Begin {datetime.datetime.now()}')\n",
    "        print(k,v)\n",
    "        DEM_ras = arcpy.Raster(v[0])\n",
    "        fac_ras = arcpy.Raster(v[1])\n",
    "        fdr_ras = arcpy.Raster(v[2])\n",
    "        slope_ras = arcpy.Raster(v[3])\n",
    "        size = DEM_ras.meanCellWidth\n",
    "        size = int(size)\n",
    "        reachid = v[5]\n",
    "        streams = v[4]\n",
    "        arcpy.env.snapRaster = DEM_ras\n",
    "        if not arcpy.Exists(reachRas):\n",
    "            print(f'Converting {streams} to raster')\n",
    "            arcpy.conversion.PolylineToRaster(streams,#streams\n",
    "                                              reachid,#reachID\n",
    "                                              reachRas,#reachRaster\n",
    "                                              \"\",\n",
    "                                              \"\",\n",
    "                                              size,\n",
    "                                              \"\"\n",
    "                                              )\n",
    "        else:\n",
    "            print(f'{reachRas} already created')\n",
    "        append_value(combinedDict,k,reachRas)\n",
    "        # End timing\n",
    "        processEnd2 = time.time()\n",
    "        processElapsed2 = int(processEnd2 - processStart2)\n",
    "        processSuccess_time2 = datetime.datetime.now()\n",
    "        # Report success\n",
    "        print(f'Stream to raster Process completed at {processSuccess_time2.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "              f'(Elapsed time: {datetime.timedelta(seconds=processElapsed2)})')\n",
    "        print(f'{\"*\"*100}')\n",
    "\n",
    "\n",
    "        # Focal Mean equation using the annulus shape around each raster cell. (Annulus size parameters used here are copied directly from the STARS tool.)\n",
    "        # Start timing function\n",
    "        processStart3 = time.time()\n",
    "        processStartdt3 = datetime.datetime.now()\n",
    "        print(f'Begin {datetime.datetime.now()}')\n",
    "\n",
    "        nbr = arcpy.sa.NbrAnnulus(7, 12, \"CELL\")\n",
    "        Ann_Raw = arcpy.sa.Int((DEM_ras - (arcpy.sa.FocalStatistics(DEM_ras, nbr, \"MEAN\", \"\"))) + 0.5)\n",
    "\n",
    "        # End timing\n",
    "        processEnd3 = time.time()\n",
    "        processElapsed3 = int(processEnd3 - processStart3)\n",
    "        processSuccess_time3 = datetime.datetime.now()\n",
    "        # Report success\n",
    "        print(f'p3. Focal Mean Annulus Process completed at {processSuccess_time3.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "              f'(Elapsed time: {datetime.timedelta(seconds=processElapsed3)})')\n",
    "        print(f'{\"*\"*100}')\n",
    "\n",
    "        #Weight the ridgelines using a conditional statement. If the difference between the DEM elevation and the annulus focal mean was greater than 0, that means the pixel is probably on a convexity (ie, surrounded by lower elevation areas). In the convex condition, increase the elevation exponentionally to provide a heavy cost for traversing that pixel. In non-convex conditions, assign a value of 1.\n",
    "\n",
    "        # Start timing function\n",
    "        processStart4 = time.time()\n",
    "        processStartdt4 = datetime.datetime.now()\n",
    "        print(f'Begin {datetime.datetime.now()}')\n",
    "\n",
    "        Ann_Cost = arcpy.sa.Con(Ann_Raw > 0, arcpy.sa.Power(Ann_Raw, 1.9), 1)\n",
    "\n",
    "        # End timing\n",
    "        processEnd4 = time.time()\n",
    "        processElapsed4 = int(processEnd4 - processStart4)\n",
    "        processSuccess_time4 = datetime.datetime.now()\n",
    "        # Report success\n",
    "        print(f'p4. Focal Mean Annulus Process completed at {processSuccess_time4.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "              f'(Elapsed time: {datetime.timedelta(seconds=processElapsed4)})')\n",
    "        print(f'{\"*\"*100}')\n",
    "\n",
    "        # Start timing function\n",
    "        processStart5 = time.time()\n",
    "        processStartdt5 = datetime.datetime.now()\n",
    "        print(f'Begin {datetime.datetime.now()}')\n",
    "\n",
    "        #Run focal statistics on the flow accumulation layer to determine the maximum flow accumulation in a 6 cell radius.\n",
    "        nbr2 = arcpy.sa.NbrCircle(6, \"CELL\")\n",
    "        flowmax = arcpy.sa.FocalStatistics(fac_ras, nbr2, \"MAXIMUM\", \"\")\n",
    "\n",
    "        # End timing\n",
    "        processEnd5 = time.time()\n",
    "        processElapsed5 = int(processEnd5 - processStart5)\n",
    "        processSuccess_time5 = datetime.datetime.now()\n",
    "        # Report success\n",
    "        print(f'p5. Focal Mean Annulus Process completed at {processSuccess_time5.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "              f'(Elapsed time: {datetime.timedelta(seconds=processElapsed5)})')\n",
    "        print(f'{\"*\"*100}')\n",
    "\n",
    "        # Start timing function\n",
    "        processStart6 = time.time()\n",
    "        processStartdt6 = datetime.datetime.now()\n",
    "        print(f'Begin {datetime.datetime.now()}')\n",
    "\n",
    "        #Apply the hydrologic weights equation copied directly from the STARS tool. In this equation, where the maximum flow accumulation is greater than 1, replace those values with a non-zero topographic wetness index. Where the maximum flow is less than one, or slope is zero, replace those values with 1.\n",
    "        #This step should take all areas with very low flow accumulation (ie ridgelines) and assign their value as 1. All other areas will have a hydrologic weight calculated.\n",
    "        flow_wt = arcpy.sa.Con(flowmax > 1, arcpy.sa.Con(fac_ras > 1, (1.0 / flowmax * arcpy.sa.Tan(fac_ras / 57.2957)), 1), 1)\n",
    "\n",
    "        # End timing\n",
    "        processEnd6 = time.time()\n",
    "        processElapsed6 = int(processEnd6 - processStart6)\n",
    "        processSuccess_time6 = datetime.datetime.now()\n",
    "        # Report success\n",
    "        print(f'p.6 Focal Mean Annulus Process completed at {processSuccess_time6.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "              f'(Elapsed time: {datetime.timedelta(seconds=processElapsed6)})')\n",
    "        print(f'{\"*\"*100}')\n",
    "\n",
    "        # Start timing function\n",
    "        processStart7 = time.time()\n",
    "        processStartdt7 = datetime.datetime.now()\n",
    "        print(f'Begin {datetime.datetime.now()}')\n",
    "\n",
    "        #Calculate a cost surface using the flow weight. In this equation, where the DEM cost surface is less than 100 million (ie, all pixels), multiply the cost surface by the flow weight pixels with value greater than or equal to 1. If the flow weight pixels have value less than or equal to 1, multiply the cost surface by 0.1.\n",
    "        # In areas of high cost identified from the DEM (ie ridgelines), we are multiplying them by the hydrologic weight of 1 (the default hydro weight value for areas of low flow). The high cost on those ridgelines will therefore be unchanged.\n",
    "        # In all other low cost areas identified from the DEM (ie, non-ridgelines), multiplying them by the hydrologic weight should produce somewhat higher values. (The intention of this tool is a scaling step that will make the following cost allocation tool perform correctly.)\n",
    "        cost_surf = arcpy.sa.Con(Ann_Cost < 100000000, Ann_Cost * arcpy.sa.Con(flow_wt >= 1, flow_wt, 0.1), 100000000)\n",
    "\n",
    "        # End timing\n",
    "        processEnd7 = time.time()\n",
    "        processElapsed7 = int(processEnd7 - processStart7)\n",
    "        processSuccess_time7 = datetime.datetime.now()\n",
    "        # Report success\n",
    "        print(f'p7. Focal Mean Annulus Process completed at {processSuccess_time7.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "              f'(Elapsed time: {datetime.timedelta(seconds=processElapsed7)})')\n",
    "        print(f'{\"*\"*100}')\n",
    "\n",
    "        # Start timing function\n",
    "        processStart8 = time.time()\n",
    "        processStartdt8 = datetime.datetime.now()\n",
    "        print(f'Begin {datetime.datetime.now()}')\n",
    "\n",
    "        #Run the Cost Allocation using the rasterized stream reaches and the final cost surface to create the base RCA raster.\n",
    "        OutRCA = os.path.join(outgdb,prefDict[roi]+'RCA')\n",
    "        RCA_ras = arcpy.sa.CostAllocation(reachRas, cost_surf)\n",
    "        #Build a raster attribute table in the RCA raster.\n",
    "        arcpy.management.BuildRasterAttributeTable(RCA_ras, \"Overwrite\")\n",
    "        #Convert the RCA raster to polygon, and dissolve any multipart polygons.\n",
    "        arcpy.conversion.RasterToPolygon(RCA_ras, \"OutRCA_temp\", \"SIMPLIFY\", \"Value\")\n",
    "        arcpy.management.Dissolve(\"OutRCA_temp\", OutRCA, \"GRIDCODE\", \"\", \"MULTI_PART\")\n",
    "        #Add a field for the RCA ID, and calculate that field.\n",
    "        arcpy.management.AddField(OutRCA, \"RCA_ID\", \"LONG\", \"\", \"\", \"\", \"\")\n",
    "        arcpy.management.CalculateField(OutRCA, \"RCA_ID\", \"!GRIDCODE!\")\n",
    "\n",
    "        # End timing\n",
    "        processEnd8 = time.time()\n",
    "        processElapsed8 = int(processEnd8 - processStart8)\n",
    "        processSuccess_time8 = datetime.datetime.now()\n",
    "        # Report success\n",
    "        print(f'p8. Focal Mean Annulus Process completed at {processSuccess_time8.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "              f'(Elapsed time: {datetime.timedelta(seconds=processElapsed8)})')\n",
    "        print(f'{\"*\"*100}')\n",
    "\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "# Report success\n",
    "print(f'Process completed at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "      f'(Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print(f'{\"*\"*100}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
