{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a id='top'></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Watershed lake, Wetland and Glacial cover.\n",
    "\n",
    "## Glacier Cover\n",
    "Calculate percent Glacier cover using Randolph Glacial Inventory data. Calculate percent cover using tabulate area.\n",
    "* **wtd_glacier_per = percent of watershed with glacier cover**\n",
    "\n",
    "## Wetland cover\n",
    "Calculate percent wetland cover using NLCD data converted to binary grid as follows:\n",
    "wetlands = Con(nlcd_ras == 90, 1, Con(nlcd_ras == 95, 1, 0))\n",
    "Calculate percent cover using tabulate area.\n",
    "* **wtd_wet_per = percent of watershed with wetland cover**\n",
    "\n",
    "### Lake Cover\n",
    "Calculate percent lake cover (ftype = lakes/ponds) NHDPlus data for regions with those data and most current NHD data\n",
    " available for regions without. Calculate percent cover using tabulate area.\n",
    "\n",
    "* **wtd_lake_per = percent of watershed with lake cover**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import modules"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14102021\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\landcover\n",
      "C:\\Users\\dwmerrigan\\AppData\\Local\\Programs\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\n"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "arcpy.env.overwriteOutput = True\n",
    "today = datetime.datetime.now()\n",
    "# Make the time stamp.\n",
    "time_stamp = '{:%d%m%Y}'.format(today)\n",
    "print(time_stamp)\n",
    "\n",
    "path = os.getcwd()\n",
    "print (path)\n",
    "print (sys.base_exec_prefix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Collect data and set working output locations\n",
    "Set data_dir to folder containing all AKSSF regional subfolders/geoadatabases\n",
    "* RS data folder: data_dir = r\"W:\\GIS\\AKSSF\"\n",
    "* DM data folder: data_dir = r\"D:\\GIS_Temp\\AKSSF_BeckyCopy\\AKSSF\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\GIS_temp\\\\AKSSF_BeckyCopy\\\\AKSSF\\\\Bristol_Bay', 'D:\\\\GIS_temp\\\\AKSSF_BeckyCopy\\\\AKSSF\\\\Cook_Inlet', 'D:\\\\GIS_temp\\\\AKSSF_BeckyCopy\\\\AKSSF\\\\Copper_River', 'D:\\\\GIS_temp\\\\AKSSF_BeckyCopy\\\\AKSSF\\\\Kodiak', 'D:\\\\GIS_temp\\\\AKSSF_BeckyCopy\\\\AKSSF\\\\Prince_William_Sound']\n",
      "Working Folder already created... D:\\GIS_temp\\AKSSF_land_met\n",
      "Output location already exists D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\n"
     ]
    }
   ],
   "source": [
    "# Set AKSSF Data directory\n",
    "# data_dir = r\"W:\\GIS\\AKSSF\"\n",
    "\n",
    "# dm local\n",
    "data_dir = r\"D:\\GIS_Temp\\AKSSF\\\"\n",
    "\n",
    "arcpy.env.workspace = data_dir\n",
    "regions = arcpy.ListWorkspaces(workspace_type=\"Folder\")\n",
    "rois= []\n",
    "print (regions)\n",
    "\n",
    "# Path to create output folder/gdb\n",
    "temppath = r\"D:\\GIS_temp\" # Output folder\n",
    "dirname = 'AKSSF_land_met'\n",
    "tempgdbname = 'AKSSF_land_met.gdb'\n",
    "temp_dir = os.path.join(temppath, dirname)\n",
    "\n",
    "# Create temporary working gdb\n",
    "if not arcpy.Exists(temp_dir):\n",
    "    os.makedirs(temp_dir)\n",
    "else:\n",
    "    print('Working Folder already created...', temp_dir)\n",
    "\n",
    "outcheck = os.path.join(temp_dir, tempgdbname)\n",
    "\n",
    "if arcpy.Exists(outcheck):\n",
    "    print ('Output location already exists', outcheck)\n",
    "    outgdb = outcheck\n",
    "if not arcpy.Exists(outcheck):\n",
    "    print('Creating output GDB')\n",
    "    tempgdb = arcpy.CreateFileGDB_management(temp_dir,tempgdbname)\n",
    "    print ('Output geodatabase created at', outcheck)\n",
    "    outgdb = tempgdb.getOutput(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "['D:\\\\GIS_temp\\\\AKSSF_BeckyCopy\\\\AKSSF\\\\Bristol_Bay',\n 'D:\\\\GIS_temp\\\\AKSSF_BeckyCopy\\\\AKSSF\\\\Cook_Inlet',\n 'D:\\\\GIS_temp\\\\AKSSF_BeckyCopy\\\\AKSSF\\\\Copper_River',\n 'D:\\\\GIS_temp\\\\AKSSF_BeckyCopy\\\\AKSSF\\\\Kodiak',\n 'D:\\\\GIS_temp\\\\AKSSF_BeckyCopy\\\\AKSSF\\\\Prince_William_Sound']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set regional workspaces from AKSSF data folder and store in list\n",
    "arcpy.env.workspace = data_dir\n",
    "regions  = arcpy.ListWorkspaces(workspace_type=\"Folder\")\n",
    "regions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Begin GIS portion\n",
    "- May be faster and save more space to create aspect rasters here using extract by mask?\n",
    "- May be able to use aspect raster with tabulate intersection to calculate percent North (aspects from 315-45 degrees)\n",
    "\n",
    "### <b>UPDATE - 2021-10-12 Do not run aspect metrics at this time. Only need to run percent North for watersheds</b>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\GIS_temp\\AKSSF_BeckyCopy\\AKSSF\\Bristol_Bay\n",
      "D:\\GIS_temp\\AKSSF_BeckyCopy\\AKSSF\\Cook_Inlet\n",
      "D:\\GIS_temp\\AKSSF_BeckyCopy\\AKSSF\\Copper_River\n",
      "D:\\GIS_temp\\AKSSF_BeckyCopy\\AKSSF\\Copper_River found for Copper_River\n",
      "NHD data: north raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_NHDPlus_north_aspect.tif\n",
      "         aspect raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_NHDPlus_aspect.tif\n",
      "      elevation raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_NHDPlus_elev_cm.tif\n",
      "----------\n",
      "Calculating aspect metrics and percent north for catchments & watersheds of interest in Copper_River region\n",
      "----------\n",
      "Geodatabase: ['D:\\\\GIS_temp\\\\AKSSF_BeckyCopy\\\\AKSSF\\\\Copper_River\\\\Copper_River.gdb']\n",
      "----------\n",
      "Elevation Raster: elev_merge\n",
      "----------\n",
      "28 Watersheds to process\n",
      "----------\n",
      "Catchment intersect memory\\cat_copy selected\n",
      "----------\n",
      "Watershed Merge for Copper_River Elapsed time: (0:00:04)\n",
      "----------\n",
      "Begin zonal statistics min/mean/max std dev for watersheds and catchments in Copper_River region\n",
      "Zonal Stats for Copper_River Elapsed time: (0:03:56)\n",
      "----------\n",
      "Begin tabulate area of north facing cells for watersheds and catchments in Copper_River region\n",
      "Tabulate area for Copper_River Elapsed time: (0:00:54)\n",
      "----------\n",
      "D:\\GIS_temp\\AKSSF_BeckyCopy\\AKSSF\\Kodiak\n",
      "D:\\GIS_temp\\AKSSF_BeckyCopy\\AKSSF\\Prince_William_Sound\n",
      "Region Copper_River not found in D:\\GIS_temp\\AKSSF_BeckyCopy\\AKSSF\\Prince_William_Sound\n",
      "Process completed at 2021-10-14 11:36 (Elapsed time: 0:04:56)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "from arcpy.sa import *\n",
    "import re\n",
    "\n",
    "# Set data_dir equal to folder containing AKSSF regional subfolders containing GDBs and raster datasets\n",
    "arcpy.env.workspace = data_dir\n",
    "arcpy.env.overwriteOutput = True\n",
    "regions  = arcpy.ListWorkspaces(workspace_type=\"Folder\")\n",
    "\n",
    "# Lists to store output tables\n",
    "wtd_wet_tables = []\n",
    "wtd_glacier_tables = []\n",
    "wtd_lake_tables = []\n",
    "\n",
    "# Set path to datasets common to both networks\n",
    "nlcd_ras = r''\n",
    "rgi = r''\n",
    "\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "\n",
    "# Seperate data by\n",
    "nhdplus_dat = ['Cook_Inlet','Copper_River']\n",
    "tauDem_dat = ['Bristol_Bay', 'Kodiak', 'Prince_William_Sound']\n",
    "\n",
    "# Loop through all processing areas\n",
    "rois = nhdplus_dat + tauDem_dat\n",
    "rois = ['Copper_River']\n",
    "for roi in rois:\n",
    "# Loop through regional folders\n",
    "    for region in regions:\n",
    "        print (region)\n",
    "        if roi in str(region):\n",
    "            print(f'{region} found for {roi}')\n",
    "            if roi in nhdplus_dat:\n",
    "                # NHDPLus raster data for DM pc, variables will be overwritten below if they exist in source folder.\n",
    "                wbds = r\"D:\\Basedata\\AKSSF_Basedata\\AKSSF_NHDPlus_north_aspect.tif\"\n",
    "                print(f'NHD data: north raster - {nor_rast}')\n",
    "                print('----------')\n",
    "\n",
    "            elif roi in tauDem_dat:\n",
    "                # TauDEM raster data for DM pc, variables will be overwritten below if they exist in source folder.\n",
    "                nor_rast = r\"D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_north_aspect.tif\"\n",
    "                asp_rast = r\"D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_aspect.tif\"\n",
    "                elev_rast = r\"D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_extract.tif\"\n",
    "                print(f'TauDem data: north raster - {nor_rast}')\n",
    "                print(f'         aspect raster - {asp_rast}')\n",
    "                print(f'      elevation raster - {elev_rast}')\n",
    "                print('----------')\n",
    "\n",
    "            stats_fields = ['MEAN','MAX','MIN','STD']\n",
    "            wtds = []\n",
    "            cats = []\n",
    "            # Start iter timing function\n",
    "            iteration_start = time.time()\n",
    "            # Set workspace to region folder\n",
    "            arcpy.env.workspace = region\n",
    "            gdb = arcpy.ListWorkspaces(workspace_type='FileGDB')\n",
    "            walk = arcpy.da.Walk(region, datatype = ['FeatureClass','RasterDataset'])\n",
    "            for dirpath, dirnames, filenames in walk:\n",
    "                for filename in filenames:\n",
    "                    # Create list of watersheds\n",
    "                    if ((\"wtd\" in filename) and (\"merge\" not in filename)):\n",
    "                        wtds.append(os.path.join(dirpath, filename))\n",
    "\n",
    "                    # Select elevation raster\n",
    "                    elif 'elev_merge' in filename:\n",
    "                        elev_rast = os.path.join(dirpath, filename)\n",
    "\n",
    "                    # # Select aspect raster\n",
    "                    # elif 'aspect' in filename:\n",
    "                    #     asp_rast = os.path.join(dirpath, filename)\n",
    "\n",
    "                    # Select north raster\n",
    "                    elif 'north_asp' in filename:\n",
    "                        nor_rast = os.path.join(dirpath, filename)\n",
    "\n",
    "                    # Select catch_int fc (catchments of interest for region) and make a copy\n",
    "                    elif 'cats_intersect' in filename:\n",
    "                        cats = arcpy.FeatureClassToFeatureClass_conversion(os.path.join(dirpath,filename),\n",
    "                                                                           tempgdb,'cat_copy')\n",
    "                        arcpy.AddField_management(cats,\"NHDPlusID_txt\",field_type='TEXT')\n",
    "                        # Copy NHDPlusID as text field for use in zonal stats\n",
    "                        with arcpy.da.UpdateCursor(cats, ['NHDPlusID','NHDPlusID_txt']) as cur:\n",
    "                            for row in cur:\n",
    "                                row[1] = roi + \"_\" + str(row[0])\n",
    "                                # Update rows\n",
    "                                cur.updateRow(row)\n",
    "                            del(row)\n",
    "                        del(cur)\n",
    "\n",
    "            print (f'Calculating aspect metrics and percent north for catchments & watersheds of interest in {roi}'\n",
    "                   f' region')\n",
    "            print ('----------')\n",
    "            print(f'Geodatabase: {gdb}')\n",
    "            print ('----------')\n",
    "            print (f'Elevation Raster: {elev_rast}')\n",
    "            print ('----------')\n",
    "            print (f'North Aspect Raster: {nor_rast}')\n",
    "            print ('----------')\n",
    "            print (f'{len(wtds)} Watersheds to process')\n",
    "            print ('----------')\n",
    "            print (f'Catchment intersect {cats} selected')\n",
    "            print ('----------')\n",
    "\n",
    "            try:\n",
    "                mergestart = time.time()\n",
    "                # Set output names/paths for watershed and catchment tables\n",
    "                wtd_merge_name = roi + \"_Watersheds_Merge\"\n",
    "                wtd_merge_path = os.path.join(outgdb,wtd_merge_name)\n",
    "\n",
    "                # # Aspect variables\n",
    "                # wtd_merge_asp_table_name = roi + \"_Watersheds_Merge_AspectZstats\"\n",
    "                # wtd_merge_asp_table_path = os.path.join(outgdb, wtd_merge_asp_table_name)\n",
    "                # cat_asp_table_name = roi + \"_Catchments_AspectZstats\"\n",
    "                # cat_asp_table_path = os.path.join(outgdb, cat_asp_table_name)\n",
    "\n",
    "                # Percent North variables\n",
    "                wtd_merge_pernorth_table_name = roi + \"_Watersheds_Merge_PercentNorth\"\n",
    "                wtd_merge_pernorth_table_path = os.path.join(outgdb, wtd_merge_pernorth_table_name)\n",
    "                # cat_pernorth_table_name = roi + \"_Catchments_PercentNorth\"\n",
    "                # cat_pernorth_table_path = os.path.join(outgdb, cat_pernorth_table_name)\n",
    "\n",
    "                # Elevation variables\n",
    "                wtd_merge_elev_table_name = roi + \"_Watersheds_Merge_ElevZstats\"\n",
    "                wtd_merge_elev_table_path = os.path.join(outgdb, wtd_merge_elev_table_name)\n",
    "                cat_elev_table_name = roi + \"_Catchments_ElevZstats\"\n",
    "                cat_elev_table_path = os.path.join(outgdb, cat_elev_table_name)\n",
    "\n",
    "                # Merge watersheds if they are not already created\n",
    "                if not arcpy.Exists(wtd_merge):\n",
    "                    wtd_merge = arcpy.Merge_management( wtds, wtd_merge_path ,add_source='ADD_SOURCE_INFO')\n",
    "                    # Add wtd_id field\n",
    "                    arcpy.AddField_management(wtd_merge,'wtd_id',field_type='TEXT')\n",
    "                    # Add region field\n",
    "                    arcpy.AddField_management(wtd_merge,'region',field_type='TEXT')\n",
    "                    # Populate watershed id and region information using update cursor - faster than field calc\n",
    "                    with arcpy.da.UpdateCursor(wtd_merge,['MERGE_SRC','wtd_id','region']) as cur:\n",
    "                        for row in cur:\n",
    "                            row[1] = re.findall('\\d+', row[0])[0]\n",
    "                            row[2] = roi\n",
    "                            # Update\n",
    "                            cur.updateRow(row)\n",
    "                        del(row)\n",
    "                    del(cur)\n",
    "                    mergestop = time.time()\n",
    "                    mergetime = int (mergestop - mergestart)\n",
    "                    print(f'Watershed Merge for {roi} Elapsed time: ({datetime.timedelta(seconds=mergetime)})')\n",
    "                    print('----------')\n",
    "\n",
    "                # Begin Zonal Stats\n",
    "                zstat_start = time.time()\n",
    "                print(f'Begin zonal statistics min/mean/max std dev for watersheds and catchments in {roi} region')\n",
    "\n",
    "                # Elevation Zonal statistics  for watersheds\n",
    "                wtd_elev_metrics_table = ZonalStatisticsAsTable(in_zone_data = wtd_merge,\n",
    "                                                                zone_field = \"wtd_id\",\n",
    "                                                                in_value_raster = elev_rast,\n",
    "                                                                out_table = wtd_merge_elev_table_path,\n",
    "                                                                statistics_type='ALL'\n",
    "                                                                )\n",
    "                # Add region identifier field for watershed tables                                                )\n",
    "                arcpy.AddField_management(wtd_elev_metrics_table,'region',field_type='TEXT')\n",
    "                # Update region field\n",
    "                with arcpy.da.UpdateCursor(wtd_elev_metrics_table,'region') as cur:\n",
    "                    for row in cur:\n",
    "                        row[0] = roi\n",
    "                        # Update\n",
    "                        cur.updateRow(row)\n",
    "                    del(row)\n",
    "                del(cur)\n",
    "                # Append watershed elev table to list\n",
    "                wtd_elev_ztables.append(wtd_elev_metrics_table)\n",
    "\n",
    "                # Elevation zonal statistics for catchments\n",
    "                cat_elev_metrics_table = ZonalStatisticsAsTable(in_zone_data = cats ,\n",
    "                                                                zone_field = \"NHDPlusID_txt\",\n",
    "                                                                in_value_raster = elev_rast,\n",
    "                                                                out_table = cat_elev_table_path,\n",
    "                                                                statistics_type='ALL'\n",
    "                                                                )\n",
    "                # Add region identifier field for catchment table\n",
    "                arcpy.AddField_management(cat_elev_metrics_table,'region',field_type='TEXT')\n",
    "\n",
    "                # Update region field\n",
    "                with arcpy.da.UpdateCursor(cat_elev_metrics_table,'region') as cur:\n",
    "                    for row in cur:\n",
    "                        row[0] = roi\n",
    "                        # Update\n",
    "                        cur.updateRow(row)\n",
    "                    del(row)\n",
    "                del(cur)\n",
    "                # Append catchment elev table to list\n",
    "                cat_elev_ztables.append(cat_elev_metrics_table)\n",
    "\n",
    "                # # Aspect Zonal statistics  for watersheds\n",
    "                # wtd_asp_metrics_table = ZonalStatisticsAsTable(in_zone_data = wtd_merge, zone_field =\"wtd_id\",\n",
    "                #                                                in_value_raster = asp_rast, out_table = wtd_merge_asp_table_path,\n",
    "                #                                                statistics_type='ALL')\n",
    "                # arcpy.AddField_management(wtd_asp_metrics_table, 'region', field_type='TEXT')\n",
    "                # arcpy.CalculateField_management(wtd_asp_metrics_table, 'region', 'roi')\n",
    "                # wtd_asp_ztables.append(wtd_asp_metrics_table)\n",
    "\n",
    "                # # Aspect Zonal statistics for catchments\n",
    "                # cat_asp_metrics_table = ZonalStatisticsAsTable(in_zone_data = cats, zone_field =\"NHDPlusID_txt\",\n",
    "                #                                                in_value_raster = asp_rast, out_table = cat_asp_table_path,\n",
    "                #                                                statistics_type='ALL')\n",
    "                # cat_asp_ztables.append(cat_asp_metrics_table)\n",
    "\n",
    "                zstat_stop = time.time()\n",
    "                zstat_time = int (zstat_stop - zstat_start)\n",
    "                print(f'Zonal Stats for {roi} Elapsed time: ({datetime.timedelta(seconds=zstat_time)})')\n",
    "                print('----------')\n",
    "\n",
    "                # Tabulate Area with north grid and catchments/watersheds\n",
    "                tabarea_start = time.time()\n",
    "                print(f'Begin tabulate area of north facing cells for watersheds and catchments in {roi} region')\n",
    "                # Percent North Tabulate area for watersheds\n",
    "                wtd_per_north_tabarea = arcpy.sa.TabulateArea(in_zone_data= wtd_merge,\n",
    "                                                              zone_field='wtd_id',\n",
    "                                                              in_class_data=nor_rast,\n",
    "                                                              class_field=\"Value\",\n",
    "                                                              out_table=wtd_merge_pernorth_table_path\n",
    "                                                              )\n",
    "                # Add region and percent north fields\n",
    "                arcpy.AddField_management(wtd_per_north_tabarea, 'region', field_type='TEXT')\n",
    "                arcpy.AddField_management(wtd_per_north_tabarea, 'north_wtd', field_type='Float')\n",
    "\n",
    "                with arcpy.da.UpdateCursor(wtd_per_north_tabarea,['wtd_id','region', 'VALUE_0',\n",
    "                                                                        'VALUE_1', 'north_wtd']) as cur:\n",
    "                    for row in cur:\n",
    "                        row[1] = roi\n",
    "                        row[4] = row[3]/(row[3]+row[2])*100\n",
    "                        # Update\n",
    "                        cur.updateRow(row)\n",
    "                    del(row)\n",
    "                del(cur)\n",
    "                # Append watershed percent north table to list\n",
    "                wtd_pernorth_taba_tables.append(wtd_per_north_tabarea)\n",
    "\n",
    "                # # Percent North Tabulate Area for catchments\n",
    "                # cat_per_north_tabarea = arcpy.sa.TabulateArea(in_zone_data= cats, zone_field='NHDPlusID',\n",
    "                #                                             in_class_data=nor_rast,\"Value\",\n",
    "                #                                             out_table=cat_pernorth_table_path)\n",
    "\n",
    "                # # Add and calculate region identifier field for catchment table\n",
    "                # arcpy.AddField_management(cat_per_north_tabarea, 'wtd_id', field_type='Float')\n",
    "                # arcpy.AddField_management(cat_per_north_tabarea, 'region', field_type='TEXT')\n",
    "                # arcpy.AddField_management(cat_per_north_tabarea, 'north_cat', field_type='Float')\n",
    "                #\n",
    "                # with arcpy.da.UpdateCursor(cat_per_north_tabarea,['NHDPlusID','region', 'VALUE_0',\n",
    "                #                                                         'VALUE_1', 'north_cat']) as cur:\n",
    "                #     for row in cur:\n",
    "                #         row[1] = roi\n",
    "                #         row[4] = row[3]/(row[3]+row[2])*100\n",
    "                #         # Update\n",
    "                #         cur.updateRow(row)\n",
    "                #     del(row)\n",
    "                # del(cur)\n",
    "                # cat_pernorth_taba_tables.append(cat_per_north_tabarea)\n",
    "                tabarea_stop = time.time()\n",
    "                tabarea_time = int (tabarea_stop - tabarea_start)\n",
    "                print(f'Tabulate area for {roi} Elapsed time: ({datetime.timedelta(seconds=tabarea_time)})')\n",
    "                print('----------')\n",
    "\n",
    "            except:\n",
    "                e = sys.exc_info()[1]\n",
    "                print(e.args[0])\n",
    "                arcpy.AddError(e.args[0])\n",
    "\n",
    "    else:\n",
    "        print(f'Region {str(roi)} not found in {region}')\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "\n",
    "# Report success\n",
    "print(f'Process completed at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "      f'(Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print('----------')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Drop unnecessary fields and rename as needed from merged tables.\n",
    "- Create Key value dictionary and use update cursor to rename fields."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Merge tables together\n",
    "        # wtd_per_north = arcpy.Merge_management(wtd_elev_ztables, wtd_per_north_table_out)\n",
    "        # cat_per_north = arcpy.Merge_management(cat_asp_ztables, cat_per_north_table_out)\n",
    "        # Use update cursor to calculate percent North\n",
    "                        # with arcpy.da.UpdateCursor(wtd_per_north,['VALUE_0','VALUE_1','wtd_aspect_mn']) as cur:\n",
    "                        #     for row in cur:\n",
    "                        #         row[2] = row[1]/(row[0] + row[1]) *100\n",
    "                        #         cur.updateRow(row)\n",
    "                        #     del(row)\n",
    "                        # del(cur)\n",
    "\n",
    "# Select tables and rename fields\n",
    "\n",
    "# Export to csv\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8caab41e",
   "language": "python",
   "display_name": "PyCharm (AKSSF)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}