{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a id='top'></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Watershed metrics for all Huc12 subwatersheds that intersect AWC recorded streams\n",
    "Iterate over AKSSF regions and identify all HUC12 sub-watersheds that intersect an AWC recorded stream. Identify the downstream-most/outlet catchment for each Huc12 from this pool and convert the polygon to INSIDE centroid point.  Calculate the distance to coastline as the straight line distance in Km from centroid point to NHD recorded coastline and export this as a feature class/table.  Next use the outlet catchments unique identifier to query the appropriate dataset and build watersheds for each outlet catchment.  Calculate watershed metrics listed in the covariate section and export final merged csv using the catchment unique identifier field \"cat_ID_con\" to link the metric back to the source catchment/HUC12.  Merge watersheds together and use to calculate covariates.\n",
    "## Covariates\n",
    "Covariates needed for prediction on AWC-HUC12 outlets are as follows:\n",
    "### Summer Precipitation\n",
    "To be calculated in R using the outlet catchment centroid point feature class exported during outlet identification process.\n",
    "### Watershed Slope Metrics\n",
    "Regional Slope grids created in AKSSF_merge_grids.ipynb script.\n",
    "Run zonal statistics on slope grid using merged watershed as zone feature.\n",
    "Field names and descriptions:\n",
    "* **awc_huc12s_wtd_slope_mn = mean watershed slope**\n",
    "* **awc_huc12s_wtd_slope_min = min watershed slope**\n",
    "* **awc_huc12s_wtd_slope_max = max watershed slope**\n",
    "* **awc_huc12s_wtd_slope_sd (or cv) = standard deviation of watershed slope**\n",
    "### Watershed Percent North Aspect\n",
    "Regional North grids created in AKSSF_merge_grids.ipynb scripts.\n",
    "North = aspects from 315-45 degrees and calculate the percentage of land area facing north for each watershed. Run tabulate area on north grid using merged watershed as zone feature and calculate percentage from area.\n",
    "Field names and descriptions:\n",
    "* **awc_huc12s_north_wtd = percent watershed with north aspect**\n",
    "### Watershed Percent Lake Cover\n",
    "Lakes feature classes for each network datatype (NHDPlus vs TauDEM) stored in AKSSF hydrography database on the T:\n",
    "Calculate percentage of watershed that is covered by lakes/ponds using tabulate interesection between lake features and watersheds.\n",
    "Field names and descriptions:\n",
    "* **awc_huc12s_wtd_lake_per = percent watershed covered by lakes**\n",
    "### Watershed Percent Glacier Cover\n",
    "Use input glacier fc (from previous covariate calculations) stored in regional gdbs an calculate percent of watershed with glacial coverage using tabulate intersection between lake features and watersheds.\n",
    "Field names and descriptions:\n",
    "* **awc_huc12s_wtd_glac_per = percent watershed covered by glaciers**\n",
    "### Watershed LCLD\n",
    "LCLD rasters created in AKSSF_MODIS_lcld_ipynb.\n",
    "Iterate over LCLD input rasters to produce yearly means for watersheds using zonal statistics.\n",
    "Field names and descriptions:\n",
    "* **awc_huc12s_wtd_lcld_mn_YYYY = mean lcld**\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import modules\n",
    "Set initial environments and import modules\n",
    "Print system paths"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports complete\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sys paths ['C:\\\\Program Files\\\\JetBrains\\\\PyCharm 2020.2.3\\\\plugins\\\\python\\\\helpers-pro\\\\jupyter_debug', 'C:\\\\Program Files\\\\JetBrains\\\\PyCharm 2020.2.3\\\\plugins\\\\python\\\\helpers\\\\pydev', 'C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\AKSSF\\\\data_preparation\\\\sensitivity_drivers\\\\landcover', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\Resources\\\\ArcPy', 'C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\AKSSF', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\python37.zip', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\DLLs', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3', '', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\Resources\\\\ArcToolbox\\\\Scripts', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\Resources\\\\ArcToolBox\\\\Scripts', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\Resources\\\\ArcToolBox\\\\Scripts\\\\archydro', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\Resources\\\\ArcToolBox\\\\Scripts\\\\GRAIP', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\future-0.18.2-py3.7.egg', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\pytz-2020.1-py3.7.egg', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\pywin32_ctypes-0.2.0-py3.7.egg', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\pywin32security', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\sympy-1.5.1-py3.7.egg', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\dwmerrigan\\\\.ipython']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Python Environment set to - C:\\Users\\dwmerrigan\\AppData\\Local\\Programs\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "2022-02-11 15:28:06.280318\n",
      "CSV table output directory set to C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\n"
     ]
    }
   ],
   "source": [
    "import os, arcpy, sys,datetime, traceback\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "sr = arcpy.SpatialReference(3338)  #'NAD_1983_Alaska_Albers'\n",
    "arcpy.env.outputCoordinateSystem = sr\n",
    "\n",
    "print('imports complete')\n",
    "print(f'{(\"-\"*100)}')\n",
    "print(f'sys paths {sys.path}')\n",
    "print(f'{(\"-\"*100)}')\n",
    "print(f'Python Environment set to - {sys.base_exec_prefix}')\n",
    "print(f'{(\"-\"*100)}')\n",
    "print (datetime.datetime.now())\n",
    "outdir = os.path.dirname(os.getcwd())\n",
    "print(f'CSV table output directory set to {outdir}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functions\n",
    "Define any functions that will be used"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Function to add key, value pairs to dictionary\n",
    "def append_value(dict_obj, key, value):\n",
    "    # Check if key exist in dict or not\n",
    "    if key in dict_obj:\n",
    "        # Key exist in dict.\n",
    "        # Check if type of value of key is list or not\n",
    "        if not isinstance(dict_obj[key], list):\n",
    "            # If type is not list then make it list\n",
    "            dict_obj[key] = [dict_obj[key]]\n",
    "        # Append the value in list\n",
    "        dict_obj[key].append(value)\n",
    "    else:\n",
    "        # As key is not in dict,\n",
    "        # so, add key-value pair\n",
    "        dict_obj[key] = value\n",
    "# Function to remove parenthesis from user inputs\n",
    "def replace_all(userinput, dic):\n",
    "    for i, j in dic.items():\n",
    "        userinput = userinput.replace(i, j)\n",
    "    return userinput\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 1\n",
    "### Set input datasets, output locations, and scratch workspaces\n",
    "User to input paths for necessary input data and output locations\n",
    "Scratch workspaces and output workspaces will be automatically created if they do not already exist."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NHDPlus lakes set to D:\\Basedata\\AKSSF_Basedata\\AKSSF_Basedata.gdb\\AKSSF_NHDPlus_LakePond_alb\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "NHD_H_Alaska lakes for TauDEM regions set to D:\\Basedata\\AKSSF_Basedata\\AKSSF_Basedata.gdb\\AKSSF_NHDPlus_LakePond_alb\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "AKSSF parent directory set to D:\\GIS\\AKSSF\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "AWC events feature class set to D:\\Basedata\\AWC\\AWC_2021_SpeciesEvents.gdb\\awcEventArcs\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Output locations will be created at D:\\GIS\\\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "LCLD subfolders located at D:\\Basedata\\LCLD_rasters_archive\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Working Folder already created D:\\GIS\\AKSSF_awcHuc12_cv\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Output location already exists D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\n",
      " ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Get user inputs\n",
    "# Used to format user inputs\n",
    "inputDict = {\"'\":\"\",'\"':\"\"}\n",
    "\n",
    "# Specify path to nhdPlus lakes\n",
    "while True:\n",
    "    try:\n",
    "        userinput7 = replace_all((input('Input path to NHDPlus lakes feature class.\\nHydrography database on T: has copy\\nLeave blank and hit enter to use the default location.\\nDefault = D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\AKSSF_NHDPlus_LakePond_alb') or 'D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\AKSSF_NHDPlus_LakePond_alb'),inputDict)\n",
    "        if not arcpy.Exists(userinput7):\n",
    "            print('Path specified does not exist!\\nPlease re-enter a valid path')\n",
    "            continue\n",
    "        else:\n",
    "            nhd_lakes_fc = userinput7\n",
    "            break\n",
    "    except KeyboardInterrupt:\n",
    "        print('interrupted!')\n",
    "        sys.exit()\n",
    "\n",
    "print(f'NHDPlus lakes set to {nhd_lakes_fc}\\n {\"-\"*100}')\n",
    "\n",
    "# Specify path to nhd lakes for tau regions\n",
    "while True:\n",
    "    try:\n",
    "        userinput8 = replace_all((input('Input path to NHD_H_Alaska_State_GDB lakes feature class.\\nHydrography database on T: has copy\\nLeave blank and hit enter to use the default location.\\nDefault = D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\AKSSF_NHD_LakesPonds_alb') or 'D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\AKSSF_NHD_LakesPonds_alb'),inputDict)\n",
    "        if not arcpy.Exists(userinput8):\n",
    "            print('Path specified does not exist!\\nPlease re-enter a valid path')\n",
    "            continue\n",
    "        else:\n",
    "            tau_lakes_fc = userinput8\n",
    "            break\n",
    "    except KeyboardInterrupt:\n",
    "        print('interrupted!')\n",
    "        sys.exit()\n",
    "print(f'NHD_H_Alaska lakes for TauDEM regions set to {nhd_lakes_fc}\\n {\"-\"*100}')\n",
    "\n",
    "# Specify path to AKSSF parent directory\n",
    "while True:\n",
    "    try:\n",
    "        userinput = replace_all((input('Input AKSSF parent directory containing regional sub-folders.\\nLeave blank and hit enter to use the default location.\\nDefault = D:\\\\GIS\\\\AKSSF\\\\') or 'D:\\\\GIS\\\\AKSSF'),inputDict)\n",
    "        if not arcpy.Exists(userinput):\n",
    "            print('Path specified does not exist!\\nPlease re-enter a valid path')\n",
    "            continue\n",
    "        else:\n",
    "            data_dir = userinput\n",
    "            break\n",
    "    except KeyboardInterrupt:\n",
    "        print('interrupted!')\n",
    "        sys.exit()\n",
    "\n",
    "print(f'AKSSF parent directory set to {data_dir}\\n {\"-\"*100}')\n",
    "\n",
    "# Specify path to AWC events fc\n",
    "while True:\n",
    "    try:\n",
    "        userinput2 = replace_all((input('Input path to awc events feature class or shapefile.\\nLeave blank and hit enter to use the default location.\\nDefault = D:\\\\Basedata\\\\AWC\\\\AWC_2021_SpeciesEvents.gdb\\\\awcEventArcs') or \"D:\\\\Basedata\\\\AWC\\\\AWC_2021_SpeciesEvents.gdb\\\\awcEventArcs\"), inputDict)\n",
    "        if not arcpy.Exists(userinput2):\n",
    "            print('Path specified does not exist!\\nPlease re-enter a valid path')\n",
    "            continue\n",
    "        else:\n",
    "            awc_events = userinput2\n",
    "            break\n",
    "    except KeyboardInterrupt:\n",
    "        print('interrupted!')\n",
    "        sys.exit()\n",
    "print(f'AWC events feature class set to {awc_events}\\n {\"-\"*100}')\n",
    "\n",
    "# Enter output destination  - to create working folders and gdbs\n",
    "while True:\n",
    "    try:\n",
    "        userinput3 = replace_all((input('Input path to create working folders.\\nLeave blank and hit enter to use the default location.\\nDefault = D:\\\\GIS\\\\') or 'D:\\\\GIS\\\\'),inputDict)\n",
    "        if not arcpy.Exists(userinput):\n",
    "            print('Path specified does not exist!\\nPlease re-enter a valid path')\n",
    "            continue\n",
    "        else:\n",
    "            temp_path = userinput3\n",
    "            print(f'Output locations will be created at {temp_path}\\n {\"-\"*100}')\n",
    "            break\n",
    "    except KeyboardInterrupt:\n",
    "        print('interrupted!')\n",
    "        sys.exit()\n",
    "\n",
    "\n",
    "# Path to lcld rasters\n",
    "lcld_folder = r'D:\\\\Basedata\\\\LCLD_rasters_archive'\n",
    "# Enter output destination  - to create working folders and gdbs\n",
    "while True:\n",
    "    try:\n",
    "        userinput4 = replace_all((input('Input path to LCLD raster parent folder.\\nLeave blank and hit enter to use the default location.\\nDefault = D:\\\\Basedata\\\\LCLD_rasters_archive\\\\') or 'D:\\\\Basedata\\\\LCLD_rasters_archive'),inputDict)\n",
    "        if not arcpy.Exists(userinput):\n",
    "            print('Path specified does not exist!\\nPlease re-enter a valid path')\n",
    "            continue\n",
    "        else:\n",
    "            lcld_folder = userinput4\n",
    "            print(f'LCLD subfolders located at {lcld_folder}\\n {\"-\"*100}')\n",
    "            break\n",
    "    except KeyboardInterrupt:\n",
    "        print('interrupted!')\n",
    "        sys.exit()\n",
    "\n",
    "## Create working output location to store intermediate data\n",
    "dirname = 'AKSSF_awcHuc12_cv'\n",
    "tempgdbname = 'AKSSF_awcHuc12_cv.gdb'\n",
    "temp_dir = os.path.join(temp_path, dirname)\n",
    "\n",
    "# Create temporary working gdb\n",
    "if not arcpy.Exists(temp_dir):\n",
    "    os.makedirs(temp_dir)\n",
    "else:\n",
    "    print(f'Working Folder already created {temp_dir}\\n {\"-\"*100}')\n",
    "\n",
    "outcheck = os.path.join(temp_dir, tempgdbname)\n",
    "\n",
    "if arcpy.Exists(outcheck):\n",
    "    print (f'Output location already exists {outcheck}\\n {\"-\"*100}')\n",
    "    outgdb = outcheck\n",
    "if not arcpy.Exists(outcheck):\n",
    "    print(f'Creating output GDB\\n {\"-\"*100}')\n",
    "    tempgdb = arcpy.CreateFileGDB_management(temp_dir,tempgdbname)\n",
    "    print (f'Output geodatabase created at {outcheck}\\n {\"-\"*100}')\n",
    "    outgdb = tempgdb.getOutput(0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 1.1\n",
    "### Set and create local copies of additional input data\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tau Region Hucs D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\\NHD_H_HUC12 located and exists = True\n",
      "NHDPlus Hucs D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\\NHDPlusHUC12 located and exists = True\n"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "arcpy.env.overwriteOutput = True\n",
    "sr = arcpy.SpatialReference(3338)  #'NAD_1983_Alaska_Albers'\n",
    "arcpy.env.outputCoordinateSystem = sr\n",
    "\n",
    "nhdplusfol = []\n",
    "tahuc12=[]\n",
    "\n",
    "# Create and set HUC12 data if it does not already exist\n",
    "nhdplushucs = os.path.join(outgdb, 'NHDPlusHUC12')\n",
    "tauhucs = os.path.join(outgdb, 'NHD_H_HUC12')\n",
    "\n",
    "if not arcpy.Exists(tauhucs):\n",
    "    print(f'Huc12 data for Tau Regions not yet created')\n",
    "    #Enter path to WBDHU12 from NHD_H gdb\n",
    "    while True:\n",
    "        try:\n",
    "            userinput6 = replace_all((input('Input path to source WBDHU12 for state of Alaska.\\nLeave blank and hit enter to use the default location.\\nDefault = D:\\\\Basedata\\\\NHD_H_Alaska_State_GDB.gdb\\\\WBD\\\\WBDHU12') or 'D:\\\\Basedata\\\\NHD_H_Alaska_State_GDB.gdb\\\\WBD\\\\WBDHU12'),inputDict)\n",
    "            if not arcpy.Exists(userinput6):\n",
    "                print('Path specified does not exist!\\nPlease re-enter a valid path')\n",
    "                continue\n",
    "            else:\n",
    "                tauhuc12 = userinput6\n",
    "                arcpy.CopyFeatures_management(tauhuc12,tauhucs)\n",
    "                print(f'WBD Huc12  copied to {tauhucs}\\n {\"-\"*100}')\n",
    "                break\n",
    "        except KeyboardInterrupt:\n",
    "            print('interrupted!')\n",
    "            sys.exit()\n",
    "\n",
    "else:\n",
    "    print(f'Tau Region Hucs {tauhucs} located and exists = {arcpy.Exists(tauhucs)}')\n",
    "\n",
    "if not arcpy.Exists(nhdplushucs):\n",
    "    print(f'Huc12 data for NHDPlus Regions not yet created')\n",
    "    #Enter NHDplus data folder\n",
    "    while True:\n",
    "        try:\n",
    "            userinput5 = replace_all((input('Input path to source NHDPlus parent folder.\\nLeave blank and hit enter to use the default location.\\nDefault = D:\\\\Basedata\\\\NHDPlus') or 'D:\\\\Basedata\\\\NHDPlus'),inputDict)\n",
    "            if not arcpy.Exists(userinput5):\n",
    "                print('Path specified does not exist!\\nPlease re-enter a valid path')\n",
    "                continue\n",
    "            else:\n",
    "                nhdplusfol = userinput5\n",
    "                print(f'NHD HUC12 will be copied to {nhdplushucs}\\n {\"-\"*100}')\n",
    "                hucs = []\n",
    "                walk = arcpy.da.Walk(nhdplusfol, datatype=\"FeatureClass\", type=\"Polygon\")\n",
    "\n",
    "                for dirpath, dirnames, filenames in walk:\n",
    "                    for filename in filenames:\n",
    "                        if filename == 'WBDHU12':\n",
    "                            hucs.append(os.path.join(dirpath, filename))\n",
    "                arcpy.Merge_management(hucs,nhdplushucs,'','ADD_SOURCE_INFO')\n",
    "                break\n",
    "        except KeyboardInterrupt:\n",
    "            print('interrupted!')\n",
    "            sys.exit()\n",
    "else:\n",
    "    print(f'NHDPlus Hucs {nhdplushucs} located and exists = {arcpy.Exists(nhdplushucs)}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 2\n",
    "### By Region\n",
    "Identify downstream-most catchment for each Huc 12\n",
    " * Select by location and select catchment with most us contributing area\n",
    "    * NHDPlus\n",
    "        * Use update cursor to join TotalDrainageAreaSqKm from vaa table to catchment\n",
    "        * Find max value from selection and save as outlet catchment for that HUC12\n",
    "    * TauDEM\n",
    "        * DSContArea - Drainage area at the downstream end of the link. Generally this is one grid cell upstream of the downstream end because the drainage area at the downstream end grid cell includes the area of the stream being joined.\n",
    " * Generate Centroid point and append to centroid dataset\n",
    "    * Retain cat_id and Huc12-id\n",
    " * Append to HUC12 catchment dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prince_William_Sound\n",
      "Prince_William_Sound using data from Prince_William_Sound folder\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Region Prince_William_Sound will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "158 huc12s in Prince_William_Sound\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "112 Huc12s in Prince_William_Sound intersect awc events input\n",
      "****************************************************************************************************\n",
      "Processing HUC 190202011602\n",
      "1. Finding outlet for HUC 190202011602 out of 253 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011604\n",
      "2. Finding outlet for HUC 190202011604 out of 105 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012506\n",
      "3. Finding outlet for HUC 190202012506 out of 132 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011106\n",
      "4. Finding outlet for HUC 190202011106 out of 155 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012304\n",
      "5. Finding outlet for HUC 190202012304 out of 490 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010602\n",
      "6. Finding outlet for HUC 190202010602 out of 123 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012502\n",
      "7. Finding outlet for HUC 190202012502 out of 161 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011307\n",
      "8. Finding outlet for HUC 190202011307 out of 656 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012001\n",
      "9. Finding outlet for HUC 190202012001 out of 88 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010301\n",
      "10. Finding outlet for HUC 190202010301 out of 277 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011603\n",
      "11. Finding outlet for HUC 190202011603 out of 38 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012309\n",
      "12. Finding outlet for HUC 190202012309 out of 261 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011108\n",
      "13. Finding outlet for HUC 190202011108 out of 130 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011503\n",
      "14. Finding outlet for HUC 190202011503 out of 234 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011804\n",
      "15. Finding outlet for HUC 190202011804 out of 481 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012508\n",
      "16. Finding outlet for HUC 190202012508 out of 342 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011601\n",
      "17. Finding outlet for HUC 190202011601 out of 82 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012101\n",
      "18. Finding outlet for HUC 190202012101 out of 102 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010703\n",
      "19. Finding outlet for HUC 190202010703 out of 128 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011107\n",
      "20. Finding outlet for HUC 190202011107 out of 192 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010105\n",
      "21. Finding outlet for HUC 190202010105 out of 281 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012103\n",
      "22. Finding outlet for HUC 190202012103 out of 50 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010603\n",
      "23. Finding outlet for HUC 190202010603 out of 59 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011403\n",
      "24. Finding outlet for HUC 190202011403 out of 145 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010907\n",
      "25. Finding outlet for HUC 190202010907 out of 272 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010701\n",
      "26. Finding outlet for HUC 190202010701 out of 244 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011105\n",
      "27. Finding outlet for HUC 190202011105 out of 395 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012204\n",
      "28. Finding outlet for HUC 190202012204 out of 288 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012307\n",
      "29. Finding outlet for HUC 190202012307 out of 97 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010905\n",
      "30. Finding outlet for HUC 190202010905 out of 289 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011308\n",
      "31. Finding outlet for HUC 190202011308 out of 137 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012102\n",
      "32. Finding outlet for HUC 190202012102 out of 185 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011504\n",
      "33. Finding outlet for HUC 190202011504 out of 186 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011805\n",
      "34. Finding outlet for HUC 190202011805 out of 460 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011505\n",
      "35. Finding outlet for HUC 190202011505 out of 525 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010704\n",
      "36. Finding outlet for HUC 190202010704 out of 90 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011906\n",
      "37. Finding outlet for HUC 190202011906 out of 321 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010601\n",
      "38. Finding outlet for HUC 190202010601 out of 113 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010804\n",
      "39. Finding outlet for HUC 190202010804 out of 149 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011102\n",
      "40. Finding outlet for HUC 190202011102 out of 286 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011401\n",
      "41. Finding outlet for HUC 190202011401 out of 253 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012507\n",
      "42. Finding outlet for HUC 190202012507 out of 148 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012505\n",
      "43. Finding outlet for HUC 190202012505 out of 91 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010702\n",
      "44. Finding outlet for HUC 190202010702 out of 166 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011103\n",
      "45. Finding outlet for HUC 190202011103 out of 154 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011402\n",
      "46. Finding outlet for HUC 190202011402 out of 159 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012501\n",
      "47. Finding outlet for HUC 190202012501 out of 123 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010102\n",
      "48. Finding outlet for HUC 190202010102 out of 337 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010401\n",
      "49. Finding outlet for HUC 190202010401 out of 85 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012301\n",
      "50. Finding outlet for HUC 190202012301 out of 390 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010302\n",
      "51. Finding outlet for HUC 190202010302 out of 149 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010908\n",
      "52. Finding outlet for HUC 190202010908 out of 603 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011109\n",
      "53. Finding outlet for HUC 190202011109 out of 146 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011110\n",
      "54. Finding outlet for HUC 190202011110 out of 74 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012104\n",
      "55. Finding outlet for HUC 190202012104 out of 332 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011104\n",
      "56. Finding outlet for HUC 190202011104 out of 508 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012002\n",
      "57. Finding outlet for HUC 190202012002 out of 328 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011606\n",
      "58. Finding outlet for HUC 190202011606 out of 85 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010604\n",
      "59. Finding outlet for HUC 190202010604 out of 325 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010402\n",
      "60. Finding outlet for HUC 190202010402 out of 212 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011101\n",
      "61. Finding outlet for HUC 190202011101 out of 131 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011202\n",
      "62. Finding outlet for HUC 190202011202 out of 219 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010200\n",
      "63. Finding outlet for HUC 190202010200 out of 402 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012504\n",
      "64. Finding outlet for HUC 190202012504 out of 217 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012510\n",
      "65. Finding outlet for HUC 190202012510 out of 185 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012310\n",
      "66. Finding outlet for HUC 190202012310 out of 281 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011404\n",
      "67. Finding outlet for HUC 190202011404 out of 128 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012105\n",
      "68. Finding outlet for HUC 190202012105 out of 350 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011201\n",
      "69. Finding outlet for HUC 190202011201 out of 134 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012509\n",
      "70. Finding outlet for HUC 190202012509 out of 156 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010705\n",
      "71. Finding outlet for HUC 190202010705 out of 461 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012003\n",
      "72. Finding outlet for HUC 190202012003 out of 400 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012511\n",
      "73. Finding outlet for HUC 190202012511 out of 67 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012306\n",
      "74. Finding outlet for HUC 190202012306 out of 97 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012308\n",
      "75. Finding outlet for HUC 190202012308 out of 105 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010503\n",
      "76. Finding outlet for HUC 190202010503 out of 502 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010303\n",
      "77. Finding outlet for HUC 190202010303 out of 48 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010906\n",
      "78. Finding outlet for HUC 190202010906 out of 231 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011605\n",
      "79. Finding outlet for HUC 190202011605 out of 209 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030105\n",
      "80. Finding outlet for HUC 190202030105 out of 302 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030208\n",
      "81. Finding outlet for HUC 190202030208 out of 85 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030302\n",
      "82. Finding outlet for HUC 190202030302 out of 46 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030204\n",
      "83. Finding outlet for HUC 190202030204 out of 65 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030205\n",
      "84. Finding outlet for HUC 190202030205 out of 144 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030304\n",
      "85. Finding outlet for HUC 190202030304 out of 232 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030202\n",
      "86. Finding outlet for HUC 190202030202 out of 135 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030207\n",
      "87. Finding outlet for HUC 190202030207 out of 93 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030701\n",
      "88. Finding outlet for HUC 190202030701 out of 278 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030104\n",
      "89. Finding outlet for HUC 190202030104 out of 108 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030502\n",
      "90. Finding outlet for HUC 190202030502 out of 99 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030503\n",
      "91. Finding outlet for HUC 190202030503 out of 377 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030206\n",
      "92. Finding outlet for HUC 190202030206 out of 48 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030201\n",
      "93. Finding outlet for HUC 190202030201 out of 103 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030409\n",
      "94. Finding outlet for HUC 190202030409 out of 218 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030403\n",
      "95. Finding outlet for HUC 190202030403 out of 159 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030101\n",
      "96. Finding outlet for HUC 190202030101 out of 476 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030203\n",
      "97. Finding outlet for HUC 190202030203 out of 122 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030406\n",
      "98. Finding outlet for HUC 190202030406 out of 445 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030305\n",
      "99. Finding outlet for HUC 190202030305 out of 47 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030102\n",
      "100. Finding outlet for HUC 190202030102 out of 284 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030306\n",
      "101. Finding outlet for HUC 190202030306 out of 67 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030702\n",
      "102. Finding outlet for HUC 190202030702 out of 1016 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030209\n",
      "103. Finding outlet for HUC 190202030209 out of 147 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030303\n",
      "104. Finding outlet for HUC 190202030303 out of 157 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030103\n",
      "105. Finding outlet for HUC 190202030103 out of 233 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030408\n",
      "106. Finding outlet for HUC 190202030408 out of 188 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030402\n",
      "107. Finding outlet for HUC 190202030402 out of 240 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030405\n",
      "108. Finding outlet for HUC 190202030405 out of 207 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030401\n",
      "109. Finding outlet for HUC 190202030401 out of 106 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030404\n",
      "110. Finding outlet for HUC 190202030404 out of 62 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030301\n",
      "111. Finding outlet for HUC 190202030301 out of 88 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030407\n",
      "112. Finding outlet for HUC 190202030407 out of 136 catchments.\n",
      "************************************************************\n",
      "Creating copy of 112 outlet catchments for Region Prince_William_Sound at D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\\Prince_William_Sound_TauAwcH12_cats_outlets\n",
      "****************************************************************************************************\n",
      "Prince_William_Sound Elapsed time: (0:00:30)\n",
      "************************************************************\n",
      "Process complete\n",
      "Process completed at 2022-02-09 18:12 (Elapsed time: 0:00:30)\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "import arcpy, time, os, datetime, operator\n",
    "\n",
    "arcpy.env.workspace = data_dir\n",
    "regions = arcpy.ListWorkspaces()\n",
    "\n",
    "# Dictionaries and lists\n",
    "nhdplusoutlets = []\n",
    "tauoutlets = []\n",
    "nhdplusawccatouts = []\n",
    "tauawccatouts = []\n",
    "vaaDict = {}\n",
    "strDict = {}\n",
    "catsDict = {}\n",
    "huc12Dict = {}\n",
    "nhdidDict = {}\n",
    "tauidDict = {}\n",
    "tauhuc12Dict = {}\n",
    "\n",
    "# Separate data by source type\n",
    "nhdplus_dat = ['Cook_Inlet','Copper_River']\n",
    "tauDem_dat = ['Bristol_Bay', 'Kodiak', 'Prince_William_Sound']\n",
    "\n",
    "# Loop through all processing areas\n",
    "# rois = nhdplus_dat + tauDem_dat\n",
    "\n",
    "# Or comment above and specify below specific subset\n",
    "#regions = ['D:\\\\GIS\\\\AKSSF\\\\Cook_Inlet', 'D:\\\\GIS\\\\AKSSF\\\\Copper_River' ]\n",
    "regions = ['Prince_William_Sound']\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "\n",
    "for region in regions:\n",
    "    roi = os.path.basename(region)\n",
    "    print(roi)\n",
    "    if roi in nhdplus_dat:\n",
    "        # Start roi time\n",
    "        roi_start = time.time()\n",
    "        hucs = nhdplushucs\n",
    "        catsList = []\n",
    "        outletList = []\n",
    "        print(f'{roi} using data from {region} folder')\n",
    "        # Set workspace to region folder\n",
    "        arcpy.env.workspace = region\n",
    "        gdb = arcpy.ListWorkspaces(workspace_type='FileGDB')\n",
    "        sourcegdb = gdb[0]\n",
    "        walk = arcpy.da.Walk(sourcegdb, datatype = ['FeatureClass','Table'])\n",
    "        for dirpath, dirnames, filenames in walk:\n",
    "            for filename in filenames:\n",
    "                if filename == 'cats_merge':\n",
    "                    cats  = os.path.join(dirpath, filename)\n",
    "                    append_value(catsDict,roi,cats)\n",
    "                elif filename == 'vaa_merge':\n",
    "                    vaas = os.path.join(dirpath, filename)\n",
    "                    append_value(vaaDict, roi, vaas)\n",
    "        #Output names and paths\n",
    "        outletcatsname = roi + '_NhdAwcH12_cats_outlets'\n",
    "        outcatspath = os.path.join(outgdb,outletcatsname)\n",
    "        outcatspath2 = os.path.join(sourcegdb,'awc_huc12_catchment_outlets')\n",
    "        outletcatptsname = roi + '_NhdAwcH12_cats_outlets_pts'\n",
    "        outcatptspath = os.path.join(outgdb,outletcatptsname)\n",
    "        outcatptspath2 = os.path.join(sourcegdb,'awc_huc12_catchment_outlets_pts')\n",
    "\n",
    "        if not arcpy.Exists(outcatspath):\n",
    "            # Build Value dictionary to relate NHDPlus id to contributing area\n",
    "            fields = ['NHDPlusID','TotDASqKm']\n",
    "            fields2 = fields + ['cat_ID_con']\n",
    "            valueDict = {int(r[0]):(r[1]) for r in arcpy.da.SearchCursor(vaas, fields)}\n",
    "            where_clause=f'\"MERGE_SRC\" LIKE \\'%{roi}%\\''\n",
    "            print(f'where_clause = {where_clause}')\n",
    "            huclayer = arcpy.MakeFeatureLayer_management(hucs,'huclayer',where_clause = where_clause)\n",
    "            print(f'{arcpy.GetCount_management(huclayer)} huc12s in {roi}')\n",
    "            print(('*'*100))\n",
    "            hucselect = arcpy.SelectLayerByLocation_management(huclayer,'INTERSECT',awc_events,'','SUBSET_SELECTION')\n",
    "            print(('*'*100))\n",
    "            print(f'{arcpy.GetCount_management(hucselect)} Huc12s in {roi} intersect awc events input')\n",
    "            print(('*'*100))\n",
    "            hucFields = [f for f in arcpy.ListFields(hucselect)]\n",
    "            vcount =1\n",
    "            with arcpy.da.SearchCursor(hucselect,['HUC12','SHAPE@']) as cur:\n",
    "                for row in cur:\n",
    "                    print(f'Processing HUC {row[0]}')\n",
    "                    inhuc = row[1]\n",
    "                    cat_layer = arcpy.MakeFeatureLayer_management(cats,'cat_layer')\n",
    "                    # Select by location using awc and huc 12\n",
    "                    arcpy.SelectLayerByLocation_management(cat_layer,'HAVE_THEIR_CENTER_IN',inhuc,'','NEW_SELECTION')\n",
    "                    print(f'{vcount}. Finding outlet for HUC {row[0]} out of {arcpy.GetCount_management(cat_layer)} catchments.\\n{(\"*\" * 60)}')\n",
    "                    catList = [r[0] for r in arcpy.da.SearchCursor(cat_layer, 'NHDPlusID')]\n",
    "                    intersect = list(set(catList).intersection(valueDict))\n",
    "                    catDict = {int(i):(valueDict[i]) for i in intersect}\n",
    "                    # Find Catchment with max drainage area\n",
    "                    outcatch = max(catDict.items(), key = operator.itemgetter(1))[0]\n",
    "                    append_value(huc12Dict, row[0], [int(outcatch),roi,valueDict[int(outcatch)]])\n",
    "                    append_value(nhdidDict,int(outcatch),[roi,row[0], valueDict[int(outcatch)]])\n",
    "                    outletList.append(int(outcatch))\n",
    "                    vcount+=1\n",
    "                del(row)\n",
    "            del(cur)\n",
    "\n",
    "            outlet_cats = arcpy.MakeFeatureLayer_management(cats,'outlet_cats')\n",
    "            out_expression ='\"NHDPlusID\" IN ' + str(tuple(outletList))\n",
    "            #print(out_expression)\n",
    "            outlet_cats_select = arcpy.SelectLayerByAttribute_management(outlet_cats,'NEW_SELECTION', out_expression)\n",
    "            print(f'Creating copy of {arcpy.GetCount_management(outlet_cats)} outlet catchments for Region {roi} at {outcatspath}')\n",
    "            print(('*'*100))\n",
    "\n",
    "            # Copy outputs\n",
    "            arcpy.FeatureClassToFeatureClass_conversion(outlet_cats_select,outgdb,outletcatsname)\n",
    "            arcpy.FeatureToPoint_management(outcatspath, outcatptspath, 'INSIDE')\n",
    "            # Create Copies to akssf data_dir regional gdbs also\n",
    "            arcpy.FeatureClassToFeatureClass_conversion(outlet_cats_select,sourcegdb,'awc_huc12_catchment_outlets')\n",
    "            arcpy.FeatureToPoint_management(outcatspath2, outcatptspath2, 'INSIDE')\n",
    "            nhdplusoutlets.append(outcatptspath)\n",
    "            nhdplusawccatouts.append(outcatspath)\n",
    "            # Add total drainage km from value dict to feature classes and cat_ID_con from regDict\n",
    "            upfcs = [outcatspath, outcatptspath,outcatptspath2,outcatptspath2]\n",
    "            for upfc in upfcs:\n",
    "                arcpy.AddField_management(upfc,fields[1],'TEXT')\n",
    "                arcpy.AddField_management(upfc,fields2[2],'TEXT')\n",
    "                with arcpy.da.UpdateCursor(upfc,fields2) as cur:\n",
    "                    for row in cur:\n",
    "                        row[1] = valueDict[row[0]]\n",
    "                        row[2] = roi + '_' + str(int(row[0]))\n",
    "                        cur.updateRow(row)\n",
    "                    del(row)\n",
    "                del(cur)\n",
    "\n",
    "            # End roi time\n",
    "            roi_stop = time.time()\n",
    "            roi_time = int (roi_stop - roi_start)\n",
    "            print(f'{roi} Elapsed time: ({datetime.timedelta(seconds=roi_time)})')\n",
    "            print(f'{\"*\"*60}')\n",
    "        else:\n",
    "            print(f'Catchments for {roi} already created at {outcatspath2}')\n",
    "\n",
    "    elif roi in tauDem_dat:\n",
    "        # Start roi time\n",
    "        roi_start = time.time()\n",
    "        hucs = tauhucs\n",
    "        catsList = []\n",
    "        outletList = []\n",
    "        print(f'{roi} using data from {region} folder')\n",
    "        # Set workspace to region folder\n",
    "        arcpy.env.workspace = region\n",
    "        gdb = arcpy.ListWorkspaces(workspace_type='FileGDB')\n",
    "        sourcegdb = gdb[0]\n",
    "        walk = arcpy.da.Walk(sourcegdb, datatype = ['FeatureClass','Table'])\n",
    "        for dirpath, dirnames, filenames in walk:\n",
    "            for filename in filenames:\n",
    "                if filename == 'cats_merge':\n",
    "                    cats  = os.path.join(dirpath, filename)\n",
    "                    append_value(catsDict,roi,cats)\n",
    "                elif filename == 'streams_merge':\n",
    "                    streams = os.path.join(dirpath, filename)\n",
    "                    append_value(strDict, roi, streams)\n",
    "\n",
    "        #Output names and paths\n",
    "        outletcatsname = roi + '_TauAwcH12_cats_outlets'\n",
    "        outcatspath = os.path.join(outgdb,outletcatsname)\n",
    "        outcatspath2 = os.path.join(sourcegdb,'awc_huc12_catchment_outlets')\n",
    "        outletcatptsname = roi + '_TauAwcH12_cats_outlets_pts'\n",
    "        outcatptspath = os.path.join(outgdb,outletcatptsname)\n",
    "        outcatptspath2 = os.path.join(sourcegdb,'awc_huc12_catchment_outlets_pts')\n",
    "        print(('-'*100),'\\n')\n",
    "        if not arcpy.Exists(outcatspath):\n",
    "            # Build Value dictionary to relate NHDPlus id to contributing area\n",
    "            fields = ['LINKNO','DSContArea']\n",
    "            fields2 = fields + ['cat_ID_con']\n",
    "            fields3 = ['gridcode','DSContArea','cat_ID_con']\n",
    "            valueDict = {int(r[0]):(r[1]) for r in arcpy.da.SearchCursor(streams, fields)}\n",
    "            huclayer = arcpy.MakeFeatureLayer_management(hucs,'huclayer')\n",
    "            hucselect_reg = arcpy.SelectLayerByLocation_management(huclayer,'INTERSECT',streams,'','NEW_SELECTION')\n",
    "            print(f'{arcpy.GetCount_management(huclayer)} huc12s in {roi}')\n",
    "            print(('*'*100))\n",
    "            hucselect = arcpy.SelectLayerByLocation_management(hucselect_reg,'INTERSECT',awc_events,'','SUBSET_SELECTION')\n",
    "            print(('*'*100))\n",
    "            print(f'{arcpy.GetCount_management(hucselect)} Huc12s in {roi} intersect awc events input')\n",
    "            print(('*'*100))\n",
    "            hucFields = [f for f in arcpy.ListFields(hucselect)]\n",
    "            vcount =1\n",
    "            with arcpy.da.SearchCursor(hucselect,['HUC12','SHAPE@']) as cur:\n",
    "                for row in cur:\n",
    "                    print(f'Processing HUC {row[0]}')\n",
    "                    inhuc = row[1]\n",
    "                    cat_layer = arcpy.MakeFeatureLayer_management(cats,'cat_layer')\n",
    "                    # Select by location using awc and huc 12\n",
    "                    arcpy.SelectLayerByLocation_management(cat_layer,'HAVE_THEIR_CENTER_IN',inhuc,'','NEW_SELECTION')\n",
    "                    print(f'{vcount}. Finding outlet for HUC {row[0]} out of {arcpy.GetCount_management(cat_layer)} catchments.\\n{(\"*\" * 60)}')\n",
    "                    catList = [r[0] for r in arcpy.da.SearchCursor(cat_layer, 'gridcode')]\n",
    "                    intersect = list(set(catList).intersection(valueDict))\n",
    "                    catDict = {int(i):(valueDict[i]) for i in intersect}\n",
    "                    # Find Catchment with max drainage area\n",
    "                    outcatch = max(catDict.items(), key = operator.itemgetter(1))[0]\n",
    "                    append_value(tauhuc12Dict, row[0], [int(outcatch),roi,valueDict[int(outcatch)]])\n",
    "                    append_value(tauidDict,int(outcatch),[roi,row[0], valueDict[int(outcatch)]])\n",
    "                    outletList.append(int(outcatch))\n",
    "                    vcount+=1\n",
    "                del(row)\n",
    "            del(cur)\n",
    "            outlet_cats = arcpy.MakeFeatureLayer_management(cats,'outlet_cats')\n",
    "            out_expression ='\"gridcode\" IN ' + str(tuple(outletList))\n",
    "            #print(out_expression)\n",
    "            outlet_cats_select = arcpy.SelectLayerByAttribute_management(outlet_cats,'NEW_SELECTION', out_expression)\n",
    "            print(f'Creating copy of {arcpy.GetCount_management(outlet_cats)} outlet catchments for Region {roi} at {outcatspath}')\n",
    "            print(('*'*100))\n",
    "\n",
    "            # Copy outputs\n",
    "            arcpy.FeatureClassToFeatureClass_conversion(outlet_cats_select,outgdb,outletcatsname)\n",
    "            arcpy.FeatureToPoint_management(outcatspath, outcatptspath, 'INSIDE')\n",
    "            # Create Copies to akssf data_dir regional gdbs also\n",
    "            arcpy.FeatureClassToFeatureClass_conversion(outlet_cats_select,sourcegdb,'awc_huc12_catchment_outlets')\n",
    "            arcpy.FeatureToPoint_management(outcatspath2, outcatptspath2, 'INSIDE')\n",
    "            tauoutlets.append(outcatptspath)\n",
    "            tauawccatouts.append(outcatspath)\n",
    "            # Add total drainage km from value dict to feature classes and cat_ID_con from regDict\n",
    "            upfcs = [outcatspath, outcatptspath,outcatptspath2,outcatptspath2]\n",
    "            for upfc in upfcs:\n",
    "                arcpy.AddField_management(upfc,fields[1],'TEXT')\n",
    "                arcpy.AddField_management(upfc,fields2[2],'TEXT')\n",
    "                with arcpy.da.UpdateCursor(upfc,fields3) as cur:\n",
    "                    for row in cur:\n",
    "                        row[1] = valueDict[row[0]]\n",
    "                        row[2] = roi + '_' + str(int(row[0]))\n",
    "                        cur.updateRow(row)\n",
    "                    del(row)\n",
    "                del(cur)\n",
    "\n",
    "            # End roi time\n",
    "            roi_stop = time.time()\n",
    "            roi_time = int (roi_stop - roi_start)\n",
    "            print(f'{roi} Elapsed time: ({datetime.timedelta(seconds=roi_time)})')\n",
    "            print(f'{\"*\"*60}')\n",
    "\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "print(f'Process complete')\n",
    "\n",
    "# Report success\n",
    "print(f'Process completed at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "      f'(Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print(f'{\"*\"*100}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 2.1\n",
    "### Merge all outlet points together and calculate distance to coastline\n",
    "Calculate Distance to Coast from outlet catchment point to the nearest coastline as a straight line distance\n",
    " * Generate near table and export as seperate csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "NHDPlus Section\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlet points already created at D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\\AKSSF_NHDPlus_awcHuc12_outlet_cats_points\n"
     ]
    }
   ],
   "source": [
    "import arcpy, datetime\n",
    "import numpy as pd\n",
    "\n",
    "# Input path to coastline\n",
    "coast = r\"D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\NHD_H_Alaska_Coastline_alb\"\n",
    "\n",
    "# Merge all catchment outlet centroids together\n",
    "nhdoutletsname = 'AKSSF_NHDPlus_awcHuc12_outlet_cats_points'\n",
    "nhdoutletspath = os.path.join(outgdb, nhdoutletsname)\n",
    "\n",
    "if not arcpy.Exists(nhdoutletspath):\n",
    "    all_nhd_outlet_pts = arcpy.Merge_management(nhdplusoutlets,nhdoutletspath)\n",
    "    # Start timing function\n",
    "    start = datetime.datetime.now()\n",
    "    print(f'Getting distance to coast {datetime.datetime.now()}...')\n",
    "    arcpy.analysis.Near(all_nhd_outlet_pts, coast, None, \"NO_LOCATION\", \"NO_ANGLE\", \"GEODESIC\", \"NEAR_DIST NEAR_DIST\")\n",
    "    arcpy.AlterField_management(all_nhd_outlet_pts,'NEAR_DIST','dist_catch_coast_km','dist_catch_coast_km' )\n",
    "    arcpy.AddField_management(all_nhd_outlet_pts,'HUC12','TEXT')\n",
    "\n",
    "    # Convert distance in meters to km\n",
    "    with arcpy.da.UpdateCursor(all_nhd_outlet_pts,['dist_catch_coast_km','NHDPlusID','HUC12']) as cur:\n",
    "        for row in cur:\n",
    "            row[0] = row[0] * 0.001\n",
    "            row[2] = nhdidDict[row[1]][1]\n",
    "            cur.updateRow(row)\n",
    "        del(row)\n",
    "    del(cur)\n",
    "    print(f'Process complete')\n",
    "else:\n",
    "    print(f'Outlet points already created at {nhdoutletspath}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TauDEM Section\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting distance to coast 2022-02-09 18:22:59.855894...\n",
      "Process complete\n"
     ]
    }
   ],
   "source": [
    "import arcpy, datetime\n",
    "import numpy as pd\n",
    "\n",
    "# Input path to coastline\n",
    "coast = r\"D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\NHD_H_Alaska_Coastline_alb\"\n",
    "\n",
    "# Merge all catchment outlet centroids together\n",
    "tauoutname = 'AKSSF_TauDEM_awcHuc12_outlet_cats_points'\n",
    "tauoutpath = os.path.join(outgdb, tauoutname)\n",
    "\n",
    "if not arcpy.Exists(tauoutpath):\n",
    "    all_tau_outpts = arcpy.Merge_management(tauoutlets,tauoutpath)\n",
    "    # Start timing function\n",
    "    start = datetime.datetime.now()\n",
    "    print(f'Getting distance to coast {datetime.datetime.now()}...')\n",
    "    arcpy.analysis.Near(all_tau_outpts, coast, None, \"NO_LOCATION\", \"NO_ANGLE\", \"GEODESIC\", \"NEAR_DIST NEAR_DIST\")\n",
    "    arcpy.AlterField_management(all_tau_outpts,'NEAR_DIST','dist_catch_coast_km','dist_catch_coast_km' )\n",
    "    arcpy.AddField_management(all_tau_outpts,'HUC12','TEXT')\n",
    "    arcpy.AddField_management(all_tau_outpts,'DSContAreaSqKM','DOUBLE')\n",
    "\n",
    "    # Convert distance in meters to km\n",
    "    with arcpy.da.UpdateCursor(all_tau_outpts,['dist_catch_coast_km','gridcode','HUC12','DSContArea','DSContAreaSqKM']) as cur:\n",
    "        for row in cur:\n",
    "            row[0] = row[0] * 0.001\n",
    "            row[2] = tauidDict[row[1]][1]\n",
    "            row[4] = int(row[3])/1000000 #convert sq meters to sq km\n",
    "            cur.updateRow(row)\n",
    "        del(row)\n",
    "    del(cur)\n",
    "    print(f'Process complete')\n",
    "else:\n",
    "    print(f'Outlet points already created at {tauoutpath}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Merge NHD and Tau points together and export as CSV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging all available catchment outlet points\n"
     ]
    }
   ],
   "source": [
    "# NHDPoints\n",
    "nhdoutletsname = 'AKSSF_NHDPlus_awcHuc12_outlet_cats_points'\n",
    "nhdoutletspath = os.path.join(outgdb, nhdoutletsname)\n",
    "\n",
    "# Taupoints\n",
    "tauoutname = 'AKSSF_TauDEM_awcHuc12_outlet_cats_points'\n",
    "tauoutpath = os.path.join(outgdb, tauoutname)\n",
    "\n",
    "# All points\n",
    "catpointsname = 'AKSSF_awcHuc12_outlet_cats_points'\n",
    "catpointspath = os.path.join(outgdb, catpointsname)\n",
    "\n",
    "# Create FieldMappings object to manage merge output fields\n",
    "out_fms = arcpy.FieldMappings()\n",
    "\n",
    "# Add all fields from both point fcs\n",
    "out_fms.addTable(nhdoutletspath)\n",
    "out_fms.addTable(tauoutpath)\n",
    "\n",
    "# Add input fields\n",
    "out_fm_dsdrain = arcpy.FieldMap()\n",
    "out_fm_dsdrain.addInputField(nhdoutletspath,'TotDASqKm')\n",
    "out_fm_dsdrain.addInputField(tauoutpath,'DSContAreaSqKM')\n",
    "\n",
    "# Set name of new output field \"Street_Name\"\n",
    "dsdrain = out_fm_dsdrain.outputField\n",
    "dsdrain.name = \"DsContAreaSqKm\"\n",
    "out_fm_dsdrain.outputField = dsdrain\n",
    "\n",
    "# add to field mappings\n",
    "out_fms.addFieldMap(out_fm_dsdrain)\n",
    "\n",
    "for field in out_fms.fields:\n",
    "    if field.name not in ['cat_ID_con', 'DsContAreaSqKm','dist_catch_coast_km', 'HUC12']:\n",
    "        out_fms.removeFieldMap(out_fms.findFieldMapIndex(field.name))\n",
    "\n",
    "#if not arcpy.Exists(catpointspath):\n",
    "addSourceInfo = \"ADD_SOURCE_INFO\"\n",
    "cats_outlets = arcpy.Merge_management([nhdoutletspath,tauoutpath],\n",
    "                                      catpointspath,\n",
    "                                      out_fms,\n",
    "                                      addSourceInfo)\n",
    "print(f'Merging all available catchment outlet points')\n",
    "#else:\n",
    "#    print(f'AKSSF AWC Catchment outlets already identified and exported to {catpointspath}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Convert to df and examine"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJECTID\n",
      "Shape\n",
      "cat_ID_con\n",
      "dist_catch_coast_km\n",
      "HUC12\n",
      "DsContAreaSqKm\n",
      "MERGE_SRC\n"
     ]
    },
    {
     "data": {
      "text/plain": "                            dist_catch_coast_km DsContAreaSqKm         HUC12\ncat_ID_con                                                                  \nCook_Inlet_75004200000901             21.633384    36.96257508  190202020501\nCook_Inlet_75004200001724             17.599013   170.81217492  190202020503\nCook_Inlet_75004200001726              0.128861    570.1149751  190202020508\nCook_Inlet_75004200001493              0.147499         9.6406  190202020303\nCook_Inlet_75004200004105              0.137137    14.02302496  190202020102\n...                                         ...            ...           ...\nPrince_William_Sound_91741            17.543384      572.85728  190202010906\nPrince_William_Sound_91751            17.338805     574.793792  190202010905\nPrince_William_Sound_91921            12.177571     739.347904  190202010907\nPrince_William_Sound_92151             0.047172     920.540288  190202010908\nPrince_William_Sound_93261             0.020080       117.1584  190202011102\n\n[1018 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dist_catch_coast_km</th>\n      <th>DsContAreaSqKm</th>\n      <th>HUC12</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Cook_Inlet_75004200000901</th>\n      <td>21.633384</td>\n      <td>36.96257508</td>\n      <td>190202020501</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004200001724</th>\n      <td>17.599013</td>\n      <td>170.81217492</td>\n      <td>190202020503</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004200001726</th>\n      <td>0.128861</td>\n      <td>570.1149751</td>\n      <td>190202020508</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004200001493</th>\n      <td>0.147499</td>\n      <td>9.6406</td>\n      <td>190202020303</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004200004105</th>\n      <td>0.137137</td>\n      <td>14.02302496</td>\n      <td>190202020102</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_91741</th>\n      <td>17.543384</td>\n      <td>572.85728</td>\n      <td>190202010906</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_91751</th>\n      <td>17.338805</td>\n      <td>574.793792</td>\n      <td>190202010905</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_91921</th>\n      <td>12.177571</td>\n      <td>739.347904</td>\n      <td>190202010907</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_92151</th>\n      <td>0.047172</td>\n      <td>920.540288</td>\n      <td>190202010908</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_93261</th>\n      <td>0.020080</td>\n      <td>117.1584</td>\n      <td>190202011102</td>\n    </tr>\n  </tbody>\n</table>\n<p>1018 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "\n",
    "# Make catchment points df\n",
    "cat_df = pd.DataFrame()\n",
    "cat_field_list = []\n",
    "\n",
    "for field in arcpy.ListFields(catpointspath):\n",
    "    print(field.name)\n",
    "    cat_field_list.append(field.name)\n",
    "cat_arr = arcpy.da.TableToNumPyArray(catpointspath, ['cat_ID_con','dist_catch_coast_km','DsContAreaSqKm','HUC12'])\n",
    "cat_df = pd.DataFrame(cat_arr)\n",
    "cat_df = cat_df.set_index('cat_ID_con')\n",
    "cat_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Export csv of outlet points for NHDPlus regions\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV export complete\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#Export CSV to read into R\n",
    "catpts_outname = 'AKSSF_awcHuc12_dist_catch_coast_km.csv'\n",
    "outlets_csv = os.path.join(outdir,catpts_outname)\n",
    "if not arcpy.Exists(outlets_csv):\n",
    "    arcpy.da.NumPyArrayToTable(cat_arr,outlets_csv)\n",
    "    print('CSV export complete')\n",
    "else:\n",
    "    print(f'Csv of catchment outlet points already exported to {outlets_csv}')\n",
    "print('----------')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 3\n",
    "### Watersheds\n",
    "Generate Watersheds\n",
    "* If watersheds have already been created there is no need to run this section again in order for subsequent process to run."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prince_William_Sound\n",
      "D:\\GIS\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\\cats_merge Indexed\n",
      "OBJECTID\n",
      "Shape\n",
      "LINKNO\n",
      "DSLINKNO\n",
      "USLINKNO1\n",
      "USLINKNO2\n",
      "DSNODEID\n",
      "strmOrder\n",
      "Length\n",
      "Magnitude\n",
      "DSContArea\n",
      "strmDrop\n",
      "Slope\n",
      "StraightL\n",
      "USContArea\n",
      "WSNO\n",
      "DOUTEND\n",
      "DOUTSTART\n",
      "DOUTMID\n",
      "Shape_Length\n",
      "1. Starting watershed for HUC 3038 (111 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "2. Starting watershed for HUC 13227 (110 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "3. Starting watershed for HUC 17027 (109 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "4. Starting watershed for HUC 17697 (108 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "5. Starting watershed for HUC 18357 (107 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "6. Starting watershed for HUC 18547 (106 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "7. Starting watershed for HUC 18737 (105 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "8. Starting watershed for HUC 18747 (104 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "9. Starting watershed for HUC 22134 (103 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "10. Starting watershed for HUC 23854 (102 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "11. Starting watershed for HUC 25516 (101 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "12. Starting watershed for HUC 26246 (100 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "13. Starting watershed for HUC 26334 (99 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "14. Starting watershed for HUC 27856 (98 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "15. Starting watershed for HUC 28576 (97 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "16. Starting watershed for HUC 29954 (96 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "17. Starting watershed for HUC 30084 (95 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "18. Starting watershed for HUC 30114 (94 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "19. Starting watershed for HUC 30596 (93 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "20. Starting watershed for HUC 30774 (92 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "21. Starting watershed for HUC 30886 (91 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "22. Starting watershed for HUC 30934 (90 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "23. Starting watershed for HUC 31226 (89 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "24. Starting watershed for HUC 31916 (88 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "25. Starting watershed for HUC 32766 (87 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "26. Starting watershed for HUC 33106 (86 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "27. Starting watershed for HUC 33396 (85 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "28. Starting watershed for HUC 33616 (84 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "29. Starting watershed for HUC 34003 (83 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "30. Starting watershed for HUC 34455 (82 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "31. Starting watershed for HUC 37373 (81 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "32. Starting watershed for HUC 37815 (80 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "33. Starting watershed for HUC 38615 (79 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "34. Starting watershed for HUC 39065 (78 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "35. Starting watershed for HUC 39565 (77 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "36. Starting watershed for HUC 40615 (76 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "37. Starting watershed for HUC 40743 (75 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "38. Starting watershed for HUC 41123 (74 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "39. Starting watershed for HUC 41143 (73 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "40. Starting watershed for HUC 41515 (72 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "41. Starting watershed for HUC 41525 (71 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "42. Starting watershed for HUC 41963 (70 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "43. Starting watershed for HUC 41995 (69 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "44. Starting watershed for HUC 42005 (68 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "45. Starting watershed for HUC 42455 (67 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "46. Starting watershed for HUC 42595 (66 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "47. Starting watershed for HUC 43085 (65 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "48. Starting watershed for HUC 43125 (64 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "49. Starting watershed for HUC 43195 (63 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "50. Starting watershed for HUC 43255 (62 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "51. Starting watershed for HUC 43473 (61 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "52. Starting watershed for HUC 43513 (60 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "53. Starting watershed for HUC 43535 (59 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "54. Starting watershed for HUC 43705 (58 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "55. Starting watershed for HUC 43793 (57 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "56. Starting watershed for HUC 43933 (56 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "57. Starting watershed for HUC 44113 (55 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "58. Starting watershed for HUC 44273 (54 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "59. Starting watershed for HUC 44503 (53 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "60. Starting watershed for HUC 44545 (52 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "61. Starting watershed for HUC 44595 (51 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "62. Starting watershed for HUC 44605 (50 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "63. Starting watershed for HUC 44633 (49 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "64. Starting watershed for HUC 44663 (48 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "65. Starting watershed for HUC 45473 (47 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "66. Starting watershed for HUC 45835 (46 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "67. Starting watershed for HUC 45863 (45 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "68. Starting watershed for HUC 45915 (44 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "69. Starting watershed for HUC 45925 (43 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "70. Starting watershed for HUC 46065 (42 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "71. Starting watershed for HUC 46103 (41 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "72. Starting watershed for HUC 46293 (40 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "73. Starting watershed for HUC 46483 (39 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "74. Starting watershed for HUC 46513 (38 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "75. Starting watershed for HUC 46613 (37 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "76. Starting watershed for HUC 46623 (36 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "77. Starting watershed for HUC 62232 (35 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "78. Starting watershed for HUC 64192 (34 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "79. Starting watershed for HUC 66912 (33 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "80. Starting watershed for HUC 67552 (32 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "81. Starting watershed for HUC 70762 (31 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "82. Starting watershed for HUC 71952 (30 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "83. Starting watershed for HUC 72402 (29 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "84. Starting watershed for HUC 72972 (28 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "85. Starting watershed for HUC 74042 (27 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "86. Starting watershed for HUC 74542 (26 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "87. Starting watershed for HUC 74602 (25 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "88. Starting watershed for HUC 75002 (24 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "89. Starting watershed for HUC 75422 (23 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "90. Starting watershed for HUC 75432 (22 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "91. Starting watershed for HUC 76622 (21 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "92. Starting watershed for HUC 76652 (20 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "93. Starting watershed for HUC 76692 (19 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "94. Starting watershed for HUC 76812 (18 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "95. Starting watershed for HUC 77292 (17 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "96. Starting watershed for HUC 77992 (16 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "97. Starting watershed for HUC 78522 (15 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "98. Starting watershed for HUC 79531 (14 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "99. Starting watershed for HUC 79792 (13 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "100. Starting watershed for HUC 79972 (12 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "101. Starting watershed for HUC 80112 (11 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:05)\n",
      "************************************************************\n",
      "102. Starting watershed for HUC 80272 (10 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "103. Starting watershed for HUC 82471 (9 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "104. Starting watershed for HUC 84641 (8 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "105. Starting watershed for HUC 86871 (7 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "106. Starting watershed for HUC 87851 (6 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "107. Starting watershed for HUC 89681 (5 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "108. Starting watershed for HUC 91741 (4 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:04)\n",
      "************************************************************\n",
      "109. Starting watershed for HUC 91751 (3 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:04)\n",
      "************************************************************\n",
      "110. Starting watershed for HUC 91921 (2 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:04)\n",
      "************************************************************\n",
      "111. Starting watershed for HUC 92151 (1 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:04)\n",
      "************************************************************\n",
      "112. Starting watershed for HUC 93261 (0 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "A column was specified that does not exist.\n",
      "Process completed at 2022-02-09 21:08 (Elapsed time: 0:04:26)\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# NHDPLUS Watersheds\n",
    "\n",
    "import arcpy, time, datetime, os\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import arcpy, time, os, datetime, operator\n",
    "\n",
    "arcpy.env.workspace = data_dir\n",
    "regions = arcpy.ListWorkspaces()\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.qualifiedFieldNames = False\n",
    "sr = arcpy.SpatialReference(3338)  #'NAD_1983_Alaska_Albers'\n",
    "arcpy.env.outputCoordinateSystem = sr\n",
    "\n",
    "wtdDict = {}\n",
    "\n",
    "# Separate data by source type\n",
    "nhdplus_dat = ['Cook_Inlet','Copper_River']\n",
    "# Limit to Cook inlet for testing\n",
    "# regions = ['D:\\\\GIS\\\\AKSSF\\\\Copper_River','D:\\\\GIS\\\\AKSSF\\\\Cook_Inlet']\n",
    "regions = ['D:\\\\GIS\\\\AKSSF\\\\Prince_William_Sound']\n",
    "\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "\n",
    "for region in regions:\n",
    "    reg_start = time.time()\n",
    "    roi = os.path.basename(region)\n",
    "    print(roi)\n",
    "    if roi in nhdplus_dat:\n",
    "        try:\n",
    "            wtdList = []\n",
    "            arcpy.env.workspace = region\n",
    "            gdb = arcpy.ListWorkspaces(workspace_type='FileGDB')\n",
    "            ingdb = gdb[0]\n",
    "            # set inputs\n",
    "            vaa = os.path.join(ingdb, \"vaa_merge\")\n",
    "            cats = os.path.join(ingdb, \"cats_merge\")\n",
    "            streams = os.path.join(ingdb, \"NHDFlowline_merge\")\n",
    "            outcats = os.path.join(ingdb, \"awc_huc12_catchment_outlets\")\n",
    "            # Create list of nhdplus ids for outlet catchments\n",
    "            idList = [int(row[0]) for row in arcpy.da.SearchCursor(outcats,'NHDPlusID')]\n",
    "            #Make test list of few small catchments\n",
    "            #idList = [75004400004166,75004400004344, 75004400010328]\n",
    "            # Get list of index names for cats merge and add index if not already created\n",
    "            index_names = [i.name for i in arcpy.ListIndexes(cats)]\n",
    "            print(index_names)\n",
    "            if 'NHDPlusID_index' not in index_names:\n",
    "                print (f'Creating index for {cats}')\n",
    "                arcpy.AddIndex_management(cats,'NHDPlusID','NHDPlusID_index')\n",
    "            else:\n",
    "                print(f'{cats} Indexed')\n",
    "\n",
    "            #watersheds feature dataset for storing fcs\n",
    "            fdatname = roi + '_Watersheds'\n",
    "            fdat = os.path.join(outgdb,fdatname)\n",
    "            if not arcpy.Exists(fdat):\n",
    "                arcpy.management.CreateFeatureDataset(outgdb, fdatname, sr)\n",
    "            else:\n",
    "                print(f'{fdat} exists for {roi}')\n",
    "\n",
    "            vaa_df1 = pd.DataFrame(arcpy.da.TableToNumPyArray(vaa, (\"NHDPlusID\", \"FromNode\", \"ToNode\", \"StartFlag\")))\n",
    "            stream_df = pd.DataFrame(arcpy.da.TableToNumPyArray(streams, (\"NHDPlusID\", \"FType\")))\n",
    "            dfs = [vaa_df1, stream_df]\n",
    "            vaa_df = reduce(lambda left,right: pd.merge(left,right,on='NHDPlusID',how=\"outer\"), dfs)\n",
    "            # remove pipelines\n",
    "            vaa_df = vaa_df[(vaa_df['FType'] != 428 )]\n",
    "            vaa_df\n",
    "\n",
    "            c=1\n",
    "            for id in idList:\n",
    "                iteration_start = time.time()\n",
    "                print(f'{c}. Starting watershed for HUC {str(id)} ({(len(idList) - c)} remaining)')\n",
    "                rec = [id]\n",
    "                up_ids = []\n",
    "                up_ids.append(rec)\n",
    "                rec_len = len(rec)\n",
    "                hws_sum = 0\n",
    "\n",
    "                while rec_len != hws_sum:\n",
    "                    fromnode = vaa_df.loc[vaa_df[\"NHDPlusID\"].isin(rec), \"FromNode\"]\n",
    "                    rec = vaa_df.loc[vaa_df[\"ToNode\"].isin(fromnode), \"NHDPlusID\"]\n",
    "                    rec_len = len(rec)\n",
    "                    rec_hws = vaa_df.loc[vaa_df[\"ToNode\"].isin(fromnode), \"StartFlag\"]\n",
    "                    hws_sum = sum(rec_hws)\n",
    "                    up_ids.append(rec)\n",
    "                #up_ids is a list with more than numbers, use extend to only keep numeric nhdplusids\n",
    "                newup_ids = []\n",
    "                for x in up_ids:\n",
    "                    newup_ids.extend(x)\n",
    "\n",
    "                tempLayer = \"catsLyr\"\n",
    "                expression = '\"NHDPlusID\" IN ({0})'.format(', '.join(map(str, newup_ids)) or 'NULL')\n",
    "                arcpy.MakeFeatureLayer_management(cats, tempLayer, where_clause=expression)\n",
    "                outdis = \"memory/wtd_\" + str(round(id))\n",
    "                outwtd = os.path.join(fdat,f'{roi}_wtd_{str(int(id))}')\n",
    "                dis = arcpy.Dissolve_management(tempLayer, outdis)\n",
    "                watershed = arcpy.EliminatePolygonPart_management(dis, outwtd,\"PERCENT\", \"0 SquareKilometers\", 90, \"CONTAINED_ONLY\")\n",
    "                wtdList.append(outwtd)\n",
    "                append_value(wtdDict,roi,outwtd)\n",
    "\n",
    "                # Stop iteration timer\n",
    "                iteration_stop = time.time()\n",
    "                iter_time = int (iteration_stop - iteration_start)\n",
    "                print(f'Elapsed time: ({datetime.timedelta(seconds=iter_time)})')\n",
    "                print(f'{\"*\"*60}')\n",
    "                c+=1\n",
    "\n",
    "            wtd_merge = arcpy.Merge_management(wtdList, os.path.join(ingdb,'awc_huc12_wtds_merge'),'','ADD_SOURCE_INFO')\n",
    "            arcpy.AddField_management(wtd_merge,'cat_ID_con','TEXT')\n",
    "            arcpy.AddField_management(wtd_merge,'cat_ID','DOUBLE')\n",
    "            arcpy.AddField_management(wtd_merge,'cat_ID_txt','TEXT')\n",
    "            arcpy.AddField_management(wtd_merge,'NHDPlusID','DOUBLE')\n",
    "            with arcpy.da.UpdateCursor(wtd_merge,['MERGE_SRC','NHDPlusID','cat_ID_con','cat_ID','cat_ID_txt']) as cur:\n",
    "                for row in cur:\n",
    "                    # Pull nhdplus id from merge source and calculate fields\n",
    "                    nhdplusid= int(row[0].split('_')[-1])\n",
    "                    row[1] = nhdplusid\n",
    "                    row[2] = roi + '_' + str(nhdplusid)\n",
    "                    row[3] = nhdplusid\n",
    "                    row[4] = str(nhdplusid)\n",
    "                    cur.updateRow(row)\n",
    "                del(row)\n",
    "            del(cur)\n",
    "            arcpy.CopyFeatures_management(wtd_merge,os.path.join(outgdb,f'{roi}_NhdAwcH12_wtds_merge' ))\n",
    "\n",
    "            # Stop iteration timer\n",
    "            reg_stop = time.time()\n",
    "            reg_time = int (reg_stop - reg_start)\n",
    "            print(f'{roi} Elapsed time: ({datetime.timedelta(seconds=reg_time)})')\n",
    "            print(f'{\"*\"*100}')\n",
    "\n",
    "        except:\n",
    "            e = sys.exc_info()[1]\n",
    "            print(e.args[0])\n",
    "            arcpy.AddError(e.args[0])\n",
    "\n",
    "    elif roi in tauDem_dat:\n",
    "        try:\n",
    "            reg_start = time.time()\n",
    "            wtdList = []\n",
    "            arcpy.env.workspace = region\n",
    "            gdb = arcpy.ListWorkspaces(workspace_type='FileGDB')\n",
    "            ingdb = gdb[0]\n",
    "            # set inputs\n",
    "            cats = os.path.join(ingdb, \"cats_merge\")\n",
    "            streams = os.path.join(ingdb, \"streams_merge\")\n",
    "            outcats = os.path.join(ingdb, \"awc_huc12_catchment_outlets\")\n",
    "            # Create list of nhdplus ids for outlet catchments\n",
    "            idList = [int(row[0]) for row in arcpy.da.SearchCursor(outcats,'gridcode')]\n",
    "            index_names = [i.name for i in arcpy.ListIndexes(cats)]\n",
    "            if 'catid_index' not in index_names:\n",
    "                print (f'Creating index for {cats}')\n",
    "                arcpy.AddIndex_management(cats, \"catID\", \"catid_index\")\n",
    "            else:\n",
    "                print(f'{cats} Indexed')\n",
    "            #watersheds feature dataset for storing fcs\n",
    "            fdatname = roi + '_Watersheds'\n",
    "            fdat = os.path.join(outgdb,fdatname)\n",
    "            if not arcpy.Exists(fdat):\n",
    "                arcpy.management.CreateFeatureDataset(outgdb, fdatname, sr)\n",
    "            else:\n",
    "                print(f'{fdat} exists for {roi}')\n",
    "            fields = arcpy.ListFields(streams)\n",
    "            str_df = pd.DataFrame(arcpy.da.FeatureClassToNumPyArray(streams, (\"LINKNO\", \"USLINKNO1\", \"USLINKNO2\")))\n",
    "            hws_codes = [-1]\n",
    "\n",
    "            # Generate watersheds\n",
    "            c=1\n",
    "            for id in idList:\n",
    "                iteration_start = time.time()\n",
    "                print(f'{c}. Starting watershed for HUC {str(id)} ({(len(idList) - c)} remaining)')\n",
    "                rec = [id]\n",
    "                up_ids = []\n",
    "                sum_rec = sum(rec)\n",
    "                while(sum_rec > 0):\n",
    "                    up_ids.append(rec)\n",
    "                    rec = str_df.loc[str_df[\"LINKNO\"].isin(rec), (\"USLINKNO1\", \"USLINKNO2\")]\n",
    "                    rec = pd.concat([rec['USLINKNO1'], rec['USLINKNO2']])\n",
    "                    sum_rec = sum(rec)\n",
    "                # up_ids is a list with more than numbers, use extend to only keep numeric nhdplusids\n",
    "                newup_ids = []\n",
    "                for x in up_ids:\n",
    "                    newup_ids.extend(x)\n",
    "\n",
    "                tempLayer = \"catsLyr\"\n",
    "                expression = '\"gridcode\" IN ({0})'.format(', '.join(map(str, newup_ids)) or 'NULL')\n",
    "                arcpy.MakeFeatureLayer_management(cats, tempLayer)\n",
    "                arcpy.management.SelectLayerByAttribute(tempLayer, \"NEW_SELECTION\", expression, None)\n",
    "                print(\"Starting dissolve\")\n",
    "                outdis = \"memory/wtd_\" + str(round(id))\n",
    "                outwtd = os.path.join(fdat,f'{roi}_wtd_{str(int(id))}')\n",
    "                dis = arcpy.Dissolve_management(tempLayer, outdis)\n",
    "                watershed = arcpy.EliminatePolygonPart_management(dis, outwtd,\"PERCENT\", \"0 SquareKilometers\", 90, \"CONTAINED_ONLY\")\n",
    "                wtdList.append(watershed)\n",
    "                append_value(wtdDict,roi,outwtd)\n",
    "\n",
    "                # Stop iteration timer\n",
    "                iteration_stop = time.time()\n",
    "                iter_time = int (iteration_stop - iteration_start)\n",
    "                print(f'Elapsed time: ({datetime.timedelta(seconds=iter_time)})')\n",
    "                print(f'{\"*\"*60}')\n",
    "                c+=1\n",
    "\n",
    "            wtd_merge = arcpy.Merge_management(wtdList, os.path.join(ingdb,'awc_huc12_wtds_merge'),'','ADD_SOURCE_INFO')\n",
    "            arcpy.AddField_management(wtd_merge,'cat_ID_con','TEXT')\n",
    "            arcpy.AddField_management(wtd_merge,'cat_ID','DOUBLE')\n",
    "            arcpy.AddField_management(wtd_merge,'cat_ID_txt','TEXT')\n",
    "            with arcpy.da.UpdateCursor(wtd_merge,['MERGE_SRC','cat_ID_con','cat_ID','cat_ID_txt']) as cur:\n",
    "                for row in cur:\n",
    "                    gridcode= int(row[0].split('_')[-1])\n",
    "                    row[1] = roi + '_' + str(gridcode)\n",
    "                    row[2] = int(gridcode)\n",
    "                    row[3] = str(gridcode)\n",
    "                    cur.updateRow(row)\n",
    "                del(row)\n",
    "            del(cur)\n",
    "            arcpy.CopyFeatures_management(wtd_merge,os.path.join(outgdb, f'{roi}_NhdAwcH12_wtds_merge' ))\n",
    "\n",
    "            # Stop iteration timer\n",
    "            reg_stop = time.time()\n",
    "            reg_time = int (reg_stop - reg_start)\n",
    "            print(f'{roi} Elapsed time: ({datetime.timedelta(seconds=reg_time)})')\n",
    "            print(f'{\"*\"*100}')\n",
    "\n",
    "        except:\n",
    "            e = sys.exc_info()[1]\n",
    "            print(e.args[0])\n",
    "            arcpy.AddError(e.args[0])\n",
    "    else:\n",
    "        print(f'{roi} not found - check inputs')\n",
    "        sys.exit(f'{roi} not found - check inputs')\n",
    "\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "\n",
    "# Report success\n",
    "print(f'Process completed at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "      f'(Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print(f'{\"*\"*100}')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TROUBLESHOOTING BLOCK\n",
    "### Zonal statistics as table is failing with unknown error when run on watershed_merge and slope/elev rasters if using 'ALL' statistics.\n",
    "Try alternative methods.  Below is test chunk for iterating over a list of stats individually and join results back to a copy of the merged watershed table.\n",
    "* Cannot Run ZonalStatistics because tool does not process overlapping polygons as individual features whereas ZonalStatistics as table will\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "### TEST CHUNK###\n",
    "\n",
    "import os, arcpy,time, datetime\n",
    "from arcpy.sa import *\n",
    "arcpy.env.overwriteOutput = True\n",
    "#\n",
    "# testoutgdb = r\"C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\ArcGIS_Default\\\\ArcGIS_Default.gdb\"\n",
    "# wtd_merge = r\"D:\\\\GIS\\\\AKSSF_awcHuc12_cv\\\\AKSSF_awcHuc12_cv.gdb\\\\Cook_Inlet_NhdAwcH12_wtds_merge\"\n",
    "# wtd_cur_fields = ['cat_ID_txt', 'cat_ID',\"cat_ID_con\"]\n",
    "# elev_rast = r\"D:\\\\GIS\\\\AKSSF\\\\Cook_Inlet\\\\elev.tif\"\n",
    "# zstats = ['MIN_MAX_MEAN','STD']\n",
    "# roi = 'Cook_Inlet'\n",
    "#\n",
    "# # Elevation variables\n",
    "# wtd_merge_elev_table_name = roi + \"_Watersheds_Merge_ElevZstats\"\n",
    "# wtd_merge_elev_table_path = os.path.join(testoutgdb, wtd_merge_elev_table_name)\n",
    "#\n",
    "# # list to store zonal stat tables\n",
    "# wtdelevstats =[]\n",
    "#\n",
    "# # Create field mappings\n",
    "# elev_fm = arcpy.FieldMap()\n",
    "# elev_fms = arcpy.FieldMappings()\n",
    "# for field in arcpy.ListFields(wtd_merge)[6:]:\n",
    "#     elev_fm = arcpy.FieldMap()\n",
    "#     elev_fm.addInputField(wtd_merge,field.name)\n",
    "#     elev_fm.mergeRule = 'First'\n",
    "#     # Set properties of the output name.\n",
    "#     f_name = elev_fm.outputField\n",
    "#     f_name.name = field.name\n",
    "#     f_name.aliasName = field.name\n",
    "#     elev_fm.outputField = f_name\n",
    "#     elev_fms.addFieldMap(elev_fm)\n",
    "#\n",
    "# # Make copy of watershed merge input as table to join stats fields\n",
    "# wtd_elev_metrics_table = arcpy.TableToTable_conversion(wtd_merge,\n",
    "#                                                        testoutgdb,\n",
    "#                                                        wtd_merge_elev_table_name,\n",
    "#                                                        '',\n",
    "#                                                        elev_fms,\n",
    "#                                                        )\n",
    "# # Add region identifier field for watershed tables                                                )\n",
    "# arcpy.AddField_management(wtd_elev_metrics_table,'region',field_type='TEXT')\n",
    "# # expression to calculate region field with roi name\n",
    "# exp =  '\"'+roi+'\"'\n",
    "# arcpy.CalculateField_management(wtd_elev_metrics_table,'region',exp)\n",
    "#\n",
    "# zstat_start = time.time()\n",
    "# for stat in zstats:\n",
    "#     outstattable = os.path.join(testoutgdb,f'{roi}_wtdElev{stat}')\n",
    "#     zstat_start1 = time.time()\n",
    "#     try:\n",
    "#         print (f'running {stat}')\n",
    "#         stat_table = ZonalStatisticsAsTable(in_zone_data = wtdmerge,\n",
    "#                                             zone_field = wtd_cur_fields[0],\n",
    "#                                             in_value_raster = elev_rast,\n",
    "#                                             out_table = outstattable,\n",
    "#                                             statistics_type=stat\n",
    "#                                             )\n",
    "#\n",
    "#         stat_fields = [f.name for f in arcpy.ListFields(stat_table)]\n",
    "#         arcpy.JoinField_management(wtd_elev_metrics_table,\n",
    "#                                wtd_cur_fields[0],\n",
    "#                                stat_table,\n",
    "#                                wtd_cur_fields[0],\n",
    "#                                stat_fields[5:]\n",
    "#                                )\n",
    "#\n",
    "#         # Report time\n",
    "#         zstat_stop1 = time.time()\n",
    "#         zstat_time1 = int (zstat_stop1 - zstat_start1)\n",
    "#         print(f'Watershed elev Zonal Stats for {stat} Elapsed time: ({datetime.timedelta(seconds=zstat_time1)})')\n",
    "#         print(f'{\"*\"*100}')\n",
    "#     except:\n",
    "#         e = sys.exc_info()[1]\n",
    "#         print(e.args[0])\n",
    "#         arcpy.AddError(e.args[0])\n",
    "# # Report time\n",
    "# zstat_stop = time.time()\n",
    "# zstat_time = int (zstat_stop - zstat_start)\n",
    "# print(f'Watershed elev Zonal Stats for {roi} Elapsed time: ({datetime.timedelta(seconds=zstat_time)})')\n",
    "# print(f'{\"*\"*100}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 4\n",
    "Calculate Covariates\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prince_William_Sound in ['Bristol_Bay', 'Kodiak', 'Prince_William_Sound'] TauDEM list, using cat_fields ['cat_ID_txt', 'gridcode', 'cat_ID_con'] and watershed fields ['cat_ID_txt', 'cat_ID', 'cat_ID_con']\n",
      "****************************************************************************************************\n",
      "cat_ID_txt field already in dataset D:\\GIS\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\\awc_huc12_catchment_outlets\n",
      "****************************************************************************************************\n",
      "cat_ID_con field already in dataset D:\\GIS\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\\awc_huc12_catchment_outlets\n",
      "****************************************************************************************************\n",
      "Merged watershed dataset awc_huc12_wtds_merge found\n",
      "****************************************************************************************************\n",
      "cat_ID_txt field already in dataset\n",
      "****************************************************************************************************\n",
      "cat_ID_con field already in dataset D:\\GIS\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\\awc_huc12_wtds_merge\n",
      "****************************************************************************************************\n",
      "Calculating topographic metrics for catchments & watersheds of interest in Prince_William_Sound region\n",
      "----------\n",
      "Geodatabase: D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\n",
      "----------\n",
      "Watershed Merge: D:\\GIS\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\\awc_huc12_wtds_merge\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "HUC12 Catchment Outlets: D:\\GIS\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\\awc_huc12_catchment_outlets\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Elevation Raster: D:\\GIS\\AKSSF\\Prince_William_Sound\\elev.tif\n",
      "  Projection: NAD_1983_Alaska_Albers\n",
      "----------\n",
      "North Aspect Raster: D:\\GIS\\AKSSF\\Prince_William_Sound\\north.tif\n",
      "  Projection: NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Wetlands Raster: D:\\GIS\\AKSSF\\Prince_William_Sound\\wetlands.tif\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Slope Raster: D:\\GIS\\AKSSF\\Prince_William_Sound\\slope.tif\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Lakes Ponds fc: D:\\Basedata\\AKSSF_Basedata\\AKSSF_Basedata.gdb\\AKSSF_NHD_LakesPonds_alb\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Glaciers fc: D:\\GIS\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\\glaciers \n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "112 Watersheds to process\n",
      "----------\n",
      "Catchment intersect D:\\GIS\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\\awc_huc12_catchment_outlets selected\n",
      "----------\n",
      "Begin Slope zonal statistics min/mean/max std dev for watersheds and catchments in Prince_William_Sound region\n",
      "Calculating Prince_William_Sound watershed slope zonal stats...\n",
      "running MIN_MAX_MEAN\n",
      "Watershed Slope Zonal MIN_MAX_MEAN for Prince_William_Sound complete.\n",
      "Elapsed time: (0:00:10)\n",
      "****************************************************************************************************\n",
      "running STD\n",
      "Watershed Slope Zonal STD for Prince_William_Sound complete.\n",
      "Elapsed time: (0:00:10)\n",
      "****************************************************************************************************\n",
      "Begin Elevation zonal statistics min/mean/max std dev for watersheds and catchments in Prince_William_Sound region\n",
      "running MIN_MAX_MEAN\n",
      "Watershed Elevation Zonal MIN_MAX_MEAN for Prince_William_Sound complete.\n",
      "Elapsed time: (0:00:12)\n",
      "****************************************************************************************************\n",
      "running STD\n",
      "Watershed Elevation Zonal STD for Prince_William_Sound complete.\n",
      "Elapsed time: (0:00:24)\n",
      "****************************************************************************************************\n",
      "Calculating Prince_William_Sound catchment elevation zonal stats...\n",
      "Elevation Zonal Stats for Prince_William_Sound catchments complete.\n",
      "Elapsed time: (0:00:05)\n",
      "****************************************************************************************************\n",
      "Calculating Prince_William_Sound catchment slope zonal stats...\n",
      "Slope Zonal Stats for Prince_William_Sound catchments complete.\n",
      "Elapsed time: (0:00:05)\n",
      "****************************************************************************************************\n",
      "All Zonal Stats for Prince_William_Sound Elapsed time: (0:00:58)\n",
      "****************************************************************************************************\n",
      "Begin tabulate area of north facing cells for watersheds and catchments in Prince_William_Sound region\n",
      "****************************************************************************************************\n",
      "Watershed percent north Tabulate area/intersections for Prince_William_Sound complete.\n",
      "Elapsed time: (0:00:15)\n",
      "****************************************************************************************************\n",
      "Begin watershed percent lakes ponds for Prince_William_Sound\n",
      "Percent Lakes Tabulate area/intersections for Prince_William_Sound complete.\n",
      "Elapsed time: (0:00:03)\n",
      "****************************************************************************************************\n",
      "Begin tabulate intersection between D:\\GIS\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\\glaciers and watersheds in Prince_William_Sound region\n",
      "****************************************************************************************************\n",
      "Percent Glacier Tabulate area/intersections for Prince_William_Sound complete.\n",
      "Elapsed time: (0:00:05)\n",
      "****************************************************************************************************\n",
      "Begin tabulate intersection between D:\\GIS\\AKSSF\\Prince_William_Sound\\wetlands.tif and watersheds in Prince_William_Sound region\n",
      "****************************************************************************************************\n",
      "Percent Wetlands Tabulate area/intersections for Prince_William_Sound complete.\n",
      "Elapsed time: (0:00:14)\n",
      "****************************************************************************************************\n",
      "Tabulate area/intersections for Prince_William_Sound complete\n",
      "Elapsed time: (0:00:38)\n",
      "****************************************************************************************************\n",
      "Year: 2001 - raster path D:\\Basedata\\LCLD_rasters_archive\\2001_lcld_32.tif\n",
      "Calculating 2001_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2001_lcld_32.tif\n",
      "Zonal Stats for 2001_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2002 - raster path D:\\Basedata\\LCLD_rasters_archive\\2002_lcld_32.tif\n",
      "Calculating 2002_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2002_lcld_32.tif\n",
      "Zonal Stats for 2002_lcld_32.tif - Elapsed time: (0:00:09)\n",
      "Year: 2003 - raster path D:\\Basedata\\LCLD_rasters_archive\\2003_lcld_32.tif\n",
      "Calculating 2003_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2003_lcld_32.tif\n",
      "Zonal Stats for 2003_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2004 - raster path D:\\Basedata\\LCLD_rasters_archive\\2004_lcld_32.tif\n",
      "Calculating 2004_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2004_lcld_32.tif\n",
      "Zonal Stats for 2004_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2005 - raster path D:\\Basedata\\LCLD_rasters_archive\\2005_lcld_32.tif\n",
      "Calculating 2005_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2005_lcld_32.tif\n",
      "Zonal Stats for 2005_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2006 - raster path D:\\Basedata\\LCLD_rasters_archive\\2006_lcld_32.tif\n",
      "Calculating 2006_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2006_lcld_32.tif\n",
      "Zonal Stats for 2006_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2007 - raster path D:\\Basedata\\LCLD_rasters_archive\\2007_lcld_32.tif\n",
      "Calculating 2007_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2007_lcld_32.tif\n",
      "Zonal Stats for 2007_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2008 - raster path D:\\Basedata\\LCLD_rasters_archive\\2008_lcld_32.tif\n",
      "Calculating 2008_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2008_lcld_32.tif\n",
      "Zonal Stats for 2008_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2009 - raster path D:\\Basedata\\LCLD_rasters_archive\\2009_lcld_32.tif\n",
      "Calculating 2009_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2009_lcld_32.tif\n",
      "Zonal Stats for 2009_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2010 - raster path D:\\Basedata\\LCLD_rasters_archive\\2010_lcld_32.tif\n",
      "Calculating 2010_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2010_lcld_32.tif\n",
      "Zonal Stats for 2010_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2011 - raster path D:\\Basedata\\LCLD_rasters_archive\\2011_lcld_32.tif\n",
      "Calculating 2011_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2011_lcld_32.tif\n",
      "Zonal Stats for 2011_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2012 - raster path D:\\Basedata\\LCLD_rasters_archive\\2012_lcld_32.tif\n",
      "Calculating 2012_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2012_lcld_32.tif\n",
      "Zonal Stats for 2012_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2013 - raster path D:\\Basedata\\LCLD_rasters_archive\\2013_lcld_32.tif\n",
      "Calculating 2013_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2013_lcld_32.tif\n",
      "Zonal Stats for 2013_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2014 - raster path D:\\Basedata\\LCLD_rasters_archive\\2014_lcld_32.tif\n",
      "Calculating 2014_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2014_lcld_32.tif\n",
      "Zonal Stats for 2014_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2015 - raster path D:\\Basedata\\LCLD_rasters_archive\\2015_lcld_32.tif\n",
      "Calculating 2015_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2015_lcld_32.tif\n",
      "Zonal Stats for 2015_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2016 - raster path D:\\Basedata\\LCLD_rasters_archive\\2016_lcld_32.tif\n",
      "Calculating 2016_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2016_lcld_32.tif\n",
      "Zonal Stats for 2016_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2017 - raster path D:\\Basedata\\LCLD_rasters_archive\\2017_lcld_32.tif\n",
      "Calculating 2017_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2017_lcld_32.tif\n",
      "Zonal Stats for 2017_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2018 - raster path D:\\Basedata\\LCLD_rasters_archive\\2018_lcld_32.tif\n",
      "Calculating 2018_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2018_lcld_32.tif\n",
      "Zonal Stats for 2018_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2019 - raster path D:\\Basedata\\LCLD_rasters_archive\\2019_lcld_32.tif\n",
      "Calculating 2019_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2019_lcld_32.tif\n",
      "Zonal Stats for 2019_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "All Covariates for Prince_William_Sound completed.\n",
      "Elapsed time: (0:04:16)\n",
      "****************************************************************************************************\n",
      "Cook_Inlet in ['Cook_Inlet', 'Copper_River'] AKSSF list, using cat_fields ['cat_ID_txt', 'NHDPlusID', 'cat_ID_con'] and watershed fields ['cat_ID_txt', 'cat_ID', 'cat_ID_con']\n",
      "****************************************************************************************************\n",
      "cat_ID_txt field already in dataset D:\\GIS\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb\\awc_huc12_catchment_outlets\n",
      "****************************************************************************************************\n",
      "cat_ID_con field already in dataset D:\\GIS\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb\\awc_huc12_catchment_outlets\n",
      "****************************************************************************************************\n",
      "Merged watershed dataset awc_huc12_wtds_merge found\n",
      "****************************************************************************************************\n",
      "cat_ID_txt field already in dataset\n",
      "****************************************************************************************************\n",
      "cat_ID_con field already in dataset D:\\GIS\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb\\awc_huc12_wtds_merge\n",
      "****************************************************************************************************\n",
      "Calculating topographic metrics for catchments & watersheds of interest in Cook_Inlet region\n",
      "----------\n",
      "Geodatabase: D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\n",
      "----------\n",
      "Watershed Merge: D:\\GIS\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb\\awc_huc12_wtds_merge\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "HUC12 Catchment Outlets: D:\\GIS\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb\\awc_huc12_catchment_outlets\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Elevation Raster: D:\\GIS\\AKSSF\\Cook_Inlet\\elev.tif\n",
      "  Projection: NAD_1983_Alaska_Albers\n",
      "----------\n",
      "North Aspect Raster: D:\\GIS\\AKSSF\\Cook_Inlet\\north.tif\n",
      "  Projection: NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Wetlands Raster: D:\\GIS\\AKSSF\\Cook_Inlet\\wetlands.tif\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Slope Raster: D:\\GIS\\AKSSF\\Cook_Inlet\\slope.tif\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Lakes Ponds fc: D:\\Basedata\\AKSSF_Basedata\\AKSSF_Basedata.gdb\\AKSSF_NHDPlus_LakePond_alb\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Glaciers fc: D:\\GIS\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb\\glaciers \n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "661 Watersheds to process\n",
      "----------\n",
      "Catchment intersect D:\\GIS\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb\\awc_huc12_catchment_outlets selected\n",
      "----------\n",
      "Begin Slope zonal statistics min/mean/max std dev for watersheds and catchments in Cook_Inlet region\n",
      "Calculating Cook_Inlet watershed slope zonal stats...\n",
      "running MIN_MAX_MEAN\n",
      "Watershed Slope Zonal MIN_MAX_MEAN for Cook_Inlet complete.\n",
      "Elapsed time: (0:03:08)\n",
      "****************************************************************************************************\n",
      "running STD\n",
      "Watershed Slope Zonal STD for Cook_Inlet complete.\n",
      "Elapsed time: (0:02:14)\n",
      "****************************************************************************************************\n",
      "Begin Elevation zonal statistics min/mean/max std dev for watersheds and catchments in Cook_Inlet region\n",
      "running MIN_MAX_MEAN\n",
      "Watershed Elevation Zonal MIN_MAX_MEAN for Cook_Inlet complete.\n",
      "Elapsed time: (0:02:51)\n",
      "****************************************************************************************************\n",
      "running STD\n",
      "Watershed Elevation Zonal STD for Cook_Inlet complete.\n",
      "Elapsed time: (0:05:21)\n",
      "****************************************************************************************************\n",
      "Calculating Cook_Inlet catchment elevation zonal stats...\n",
      "Elevation Zonal Stats for Cook_Inlet catchments complete.\n",
      "Elapsed time: (0:00:36)\n",
      "****************************************************************************************************\n",
      "Calculating Cook_Inlet catchment slope zonal stats...\n",
      "Slope Zonal Stats for Cook_Inlet catchments complete.\n",
      "Elapsed time: (0:00:23)\n",
      "****************************************************************************************************\n",
      "All Zonal Stats for Cook_Inlet Elapsed time: (0:11:48)\n",
      "****************************************************************************************************\n",
      "Begin tabulate area of north facing cells for watersheds and catchments in Cook_Inlet region\n",
      "****************************************************************************************************\n",
      "Watershed percent north Tabulate area/intersections for Cook_Inlet complete.\n",
      "Elapsed time: (0:02:39)\n",
      "****************************************************************************************************\n",
      "Begin watershed percent lakes ponds for Cook_Inlet\n",
      "Percent Lakes Tabulate area/intersections for Cook_Inlet complete.\n",
      "Elapsed time: (0:02:02)\n",
      "****************************************************************************************************\n",
      "Begin tabulate intersection between D:\\GIS\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb\\glaciers and watersheds in Cook_Inlet region\n",
      "****************************************************************************************************\n",
      "Percent Glacier Tabulate area/intersections for Cook_Inlet complete.\n",
      "Elapsed time: (0:00:50)\n",
      "****************************************************************************************************\n",
      "Begin tabulate intersection between D:\\GIS\\AKSSF\\Cook_Inlet\\wetlands.tif and watersheds in Cook_Inlet region\n",
      "****************************************************************************************************\n",
      "Percent Wetlands Tabulate area/intersections for Cook_Inlet complete.\n",
      "Elapsed time: (0:02:35)\n",
      "****************************************************************************************************\n",
      "Tabulate area/intersections for Cook_Inlet complete\n",
      "Elapsed time: (0:08:07)\n",
      "****************************************************************************************************\n",
      "Year: 2001 - raster path D:\\Basedata\\LCLD_rasters_archive\\2001_lcld_32.tif\n",
      "Calculating 2001_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2001_lcld_32.tif\n",
      "Zonal Stats for 2001_lcld_32.tif - Elapsed time: (0:01:59)\n",
      "Year: 2002 - raster path D:\\Basedata\\LCLD_rasters_archive\\2002_lcld_32.tif\n",
      "Calculating 2002_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2002_lcld_32.tif\n",
      "Zonal Stats for 2002_lcld_32.tif - Elapsed time: (0:02:00)\n",
      "Year: 2003 - raster path D:\\Basedata\\LCLD_rasters_archive\\2003_lcld_32.tif\n",
      "Calculating 2003_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2003_lcld_32.tif\n",
      "Zonal Stats for 2003_lcld_32.tif - Elapsed time: (0:02:01)\n",
      "Year: 2004 - raster path D:\\Basedata\\LCLD_rasters_archive\\2004_lcld_32.tif\n",
      "Calculating 2004_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2004_lcld_32.tif\n",
      "Zonal Stats for 2004_lcld_32.tif - Elapsed time: (0:02:01)\n",
      "Year: 2005 - raster path D:\\Basedata\\LCLD_rasters_archive\\2005_lcld_32.tif\n",
      "Calculating 2005_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2005_lcld_32.tif\n",
      "Zonal Stats for 2005_lcld_32.tif - Elapsed time: (0:02:02)\n",
      "Year: 2006 - raster path D:\\Basedata\\LCLD_rasters_archive\\2006_lcld_32.tif\n",
      "Calculating 2006_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2006_lcld_32.tif\n",
      "Zonal Stats for 2006_lcld_32.tif - Elapsed time: (0:02:01)\n",
      "Year: 2007 - raster path D:\\Basedata\\LCLD_rasters_archive\\2007_lcld_32.tif\n",
      "Calculating 2007_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2007_lcld_32.tif\n",
      "Zonal Stats for 2007_lcld_32.tif - Elapsed time: (0:02:02)\n",
      "Year: 2008 - raster path D:\\Basedata\\LCLD_rasters_archive\\2008_lcld_32.tif\n",
      "Calculating 2008_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2008_lcld_32.tif\n",
      "Zonal Stats for 2008_lcld_32.tif - Elapsed time: (0:02:01)\n",
      "Year: 2009 - raster path D:\\Basedata\\LCLD_rasters_archive\\2009_lcld_32.tif\n",
      "Calculating 2009_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2009_lcld_32.tif\n",
      "Zonal Stats for 2009_lcld_32.tif - Elapsed time: (0:02:01)\n",
      "Year: 2010 - raster path D:\\Basedata\\LCLD_rasters_archive\\2010_lcld_32.tif\n",
      "Calculating 2010_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2010_lcld_32.tif\n",
      "Zonal Stats for 2010_lcld_32.tif - Elapsed time: (0:02:02)\n",
      "Year: 2011 - raster path D:\\Basedata\\LCLD_rasters_archive\\2011_lcld_32.tif\n",
      "Calculating 2011_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2011_lcld_32.tif\n",
      "Zonal Stats for 2011_lcld_32.tif - Elapsed time: (0:02:02)\n",
      "Year: 2012 - raster path D:\\Basedata\\LCLD_rasters_archive\\2012_lcld_32.tif\n",
      "Calculating 2012_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2012_lcld_32.tif\n",
      "Zonal Stats for 2012_lcld_32.tif - Elapsed time: (0:02:01)\n",
      "Year: 2013 - raster path D:\\Basedata\\LCLD_rasters_archive\\2013_lcld_32.tif\n",
      "Calculating 2013_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2013_lcld_32.tif\n",
      "Zonal Stats for 2013_lcld_32.tif - Elapsed time: (0:02:02)\n",
      "Year: 2014 - raster path D:\\Basedata\\LCLD_rasters_archive\\2014_lcld_32.tif\n",
      "Calculating 2014_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2014_lcld_32.tif\n",
      "Zonal Stats for 2014_lcld_32.tif - Elapsed time: (0:01:59)\n",
      "Year: 2015 - raster path D:\\Basedata\\LCLD_rasters_archive\\2015_lcld_32.tif\n",
      "Calculating 2015_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2015_lcld_32.tif\n",
      "Zonal Stats for 2015_lcld_32.tif - Elapsed time: (0:02:01)\n",
      "Year: 2016 - raster path D:\\Basedata\\LCLD_rasters_archive\\2016_lcld_32.tif\n",
      "Calculating 2016_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2016_lcld_32.tif\n",
      "Zonal Stats for 2016_lcld_32.tif - Elapsed time: (0:02:00)\n",
      "Year: 2017 - raster path D:\\Basedata\\LCLD_rasters_archive\\2017_lcld_32.tif\n",
      "Calculating 2017_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2017_lcld_32.tif\n",
      "Zonal Stats for 2017_lcld_32.tif - Elapsed time: (0:02:00)\n",
      "Year: 2018 - raster path D:\\Basedata\\LCLD_rasters_archive\\2018_lcld_32.tif\n",
      "Calculating 2018_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2018_lcld_32.tif\n",
      "Zonal Stats for 2018_lcld_32.tif - Elapsed time: (0:02:00)\n",
      "Year: 2019 - raster path D:\\Basedata\\LCLD_rasters_archive\\2019_lcld_32.tif\n",
      "Calculating 2019_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2019_lcld_32.tif\n",
      "Zonal Stats for 2019_lcld_32.tif - Elapsed time: (0:02:00)\n",
      "All Covariates for Cook_Inlet completed.\n",
      "Elapsed time: (0:58:24)\n",
      "****************************************************************************************************\n",
      "Copper_River in ['Cook_Inlet', 'Copper_River'] AKSSF list, using cat_fields ['cat_ID_txt', 'NHDPlusID', 'cat_ID_con'] and watershed fields ['cat_ID_txt', 'cat_ID', 'cat_ID_con']\n",
      "****************************************************************************************************\n",
      "cat_ID_txt field already in dataset D:\\GIS\\AKSSF\\Copper_River\\Copper_River.gdb\\awc_huc12_catchment_outlets\n",
      "****************************************************************************************************\n",
      "cat_ID_con field already in dataset D:\\GIS\\AKSSF\\Copper_River\\Copper_River.gdb\\awc_huc12_catchment_outlets\n",
      "****************************************************************************************************\n",
      "Merged watershed dataset awc_huc12_wtds_merge found\n",
      "****************************************************************************************************\n",
      "cat_ID_txt field already in dataset\n",
      "****************************************************************************************************\n",
      "cat_ID_con field already in dataset D:\\GIS\\AKSSF\\Copper_River\\Copper_River.gdb\\awc_huc12_wtds_merge\n",
      "****************************************************************************************************\n",
      "Calculating topographic metrics for catchments & watersheds of interest in Copper_River region\n",
      "----------\n",
      "Geodatabase: D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\n",
      "----------\n",
      "Watershed Merge: D:\\GIS\\AKSSF\\Copper_River\\Copper_River.gdb\\awc_huc12_wtds_merge\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "HUC12 Catchment Outlets: D:\\GIS\\AKSSF\\Copper_River\\Copper_River.gdb\\awc_huc12_catchment_outlets\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Elevation Raster: D:\\GIS\\AKSSF\\Copper_River\\elev.tif\n",
      "  Projection: NAD_1983_Alaska_Albers\n",
      "----------\n",
      "North Aspect Raster: D:\\GIS\\AKSSF\\Copper_River\\north.tif\n",
      "  Projection: NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Wetlands Raster: D:\\GIS\\AKSSF\\Copper_River\\wetlands.tif\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Slope Raster: D:\\GIS\\AKSSF\\Copper_River\\slope.tif\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Lakes Ponds fc: D:\\Basedata\\AKSSF_Basedata\\AKSSF_Basedata.gdb\\AKSSF_NHDPlus_LakePond_alb\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Glaciers fc: D:\\GIS\\AKSSF\\Copper_River\\Copper_River.gdb\\glaciers \n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "245 Watersheds to process\n",
      "----------\n",
      "Catchment intersect D:\\GIS\\AKSSF\\Copper_River\\Copper_River.gdb\\awc_huc12_catchment_outlets selected\n",
      "----------\n",
      "Begin Slope zonal statistics min/mean/max std dev for watersheds and catchments in Copper_River region\n",
      "Calculating Copper_River watershed slope zonal stats...\n",
      "running MIN_MAX_MEAN\n",
      "Watershed Slope Zonal MIN_MAX_MEAN for Copper_River complete.\n",
      "Elapsed time: (0:03:33)\n",
      "****************************************************************************************************\n",
      "running STD\n",
      "Watershed Slope Zonal STD for Copper_River complete.\n",
      "Elapsed time: (0:02:59)\n",
      "****************************************************************************************************\n",
      "Begin Elevation zonal statistics min/mean/max std dev for watersheds and catchments in Copper_River region\n",
      "running MIN_MAX_MEAN\n",
      "Watershed Elevation Zonal MIN_MAX_MEAN for Copper_River complete.\n",
      "Elapsed time: (0:03:17)\n",
      "****************************************************************************************************\n",
      "running STD\n",
      "Watershed Elevation Zonal STD for Copper_River complete.\n",
      "Elapsed time: (0:06:24)\n",
      "****************************************************************************************************\n",
      "Calculating Copper_River catchment elevation zonal stats...\n",
      "Elevation Zonal Stats for Copper_River catchments complete.\n",
      "Elapsed time: (0:00:17)\n",
      "****************************************************************************************************\n",
      "Calculating Copper_River catchment slope zonal stats...\n",
      "Slope Zonal Stats for Copper_River catchments complete.\n",
      "Elapsed time: (0:00:11)\n",
      "****************************************************************************************************\n",
      "All Zonal Stats for Copper_River Elapsed time: (0:13:28)\n",
      "****************************************************************************************************\n",
      "Begin tabulate area of north facing cells for watersheds and catchments in Copper_River region\n",
      "****************************************************************************************************\n",
      "Watershed percent north Tabulate area/intersections for Copper_River complete.\n",
      "Elapsed time: (0:03:12)\n",
      "****************************************************************************************************\n",
      "Begin watershed percent lakes ponds for Copper_River\n",
      "Percent Lakes Tabulate area/intersections for Copper_River complete.\n",
      "Elapsed time: (0:00:36)\n",
      "****************************************************************************************************\n",
      "Begin tabulate intersection between D:\\GIS\\AKSSF\\Copper_River\\Copper_River.gdb\\glaciers and watersheds in Copper_River region\n",
      "****************************************************************************************************\n",
      "Percent Glacier Tabulate area/intersections for Copper_River complete.\n",
      "Elapsed time: (0:00:27)\n",
      "****************************************************************************************************\n",
      "Begin tabulate intersection between D:\\GIS\\AKSSF\\Copper_River\\wetlands.tif and watersheds in Copper_River region\n",
      "****************************************************************************************************\n",
      "Percent Wetlands Tabulate area/intersections for Copper_River complete.\n",
      "Elapsed time: (0:03:09)\n",
      "****************************************************************************************************\n",
      "Tabulate area/intersections for Copper_River complete\n",
      "Elapsed time: (0:07:26)\n",
      "****************************************************************************************************\n",
      "Year: 2001 - raster path D:\\Basedata\\LCLD_rasters_archive\\2001_lcld_32.tif\n",
      "Calculating 2001_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2001_lcld_32.tif\n",
      "Zonal Stats for 2001_lcld_32.tif - Elapsed time: (0:02:51)\n",
      "Year: 2002 - raster path D:\\Basedata\\LCLD_rasters_archive\\2002_lcld_32.tif\n",
      "Calculating 2002_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2002_lcld_32.tif\n",
      "Zonal Stats for 2002_lcld_32.tif - Elapsed time: (0:02:51)\n",
      "Year: 2003 - raster path D:\\Basedata\\LCLD_rasters_archive\\2003_lcld_32.tif\n",
      "Calculating 2003_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2003_lcld_32.tif\n",
      "Zonal Stats for 2003_lcld_32.tif - Elapsed time: (0:02:52)\n",
      "Year: 2004 - raster path D:\\Basedata\\LCLD_rasters_archive\\2004_lcld_32.tif\n",
      "Calculating 2004_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2004_lcld_32.tif\n",
      "Zonal Stats for 2004_lcld_32.tif - Elapsed time: (0:02:51)\n",
      "Year: 2005 - raster path D:\\Basedata\\LCLD_rasters_archive\\2005_lcld_32.tif\n",
      "Calculating 2005_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2005_lcld_32.tif\n",
      "Zonal Stats for 2005_lcld_32.tif - Elapsed time: (0:02:51)\n",
      "Year: 2006 - raster path D:\\Basedata\\LCLD_rasters_archive\\2006_lcld_32.tif\n",
      "Calculating 2006_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2006_lcld_32.tif\n",
      "Zonal Stats for 2006_lcld_32.tif - Elapsed time: (0:02:51)\n",
      "Year: 2007 - raster path D:\\Basedata\\LCLD_rasters_archive\\2007_lcld_32.tif\n",
      "Calculating 2007_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2007_lcld_32.tif\n",
      "Zonal Stats for 2007_lcld_32.tif - Elapsed time: (0:02:51)\n",
      "Year: 2008 - raster path D:\\Basedata\\LCLD_rasters_archive\\2008_lcld_32.tif\n",
      "Calculating 2008_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2008_lcld_32.tif\n",
      "Zonal Stats for 2008_lcld_32.tif - Elapsed time: (0:02:51)\n",
      "Year: 2009 - raster path D:\\Basedata\\LCLD_rasters_archive\\2009_lcld_32.tif\n",
      "Calculating 2009_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2009_lcld_32.tif\n",
      "Zonal Stats for 2009_lcld_32.tif - Elapsed time: (0:02:50)\n",
      "Year: 2010 - raster path D:\\Basedata\\LCLD_rasters_archive\\2010_lcld_32.tif\n",
      "Calculating 2010_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2010_lcld_32.tif\n",
      "Zonal Stats for 2010_lcld_32.tif - Elapsed time: (0:02:51)\n",
      "Year: 2011 - raster path D:\\Basedata\\LCLD_rasters_archive\\2011_lcld_32.tif\n",
      "Calculating 2011_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2011_lcld_32.tif\n",
      "Zonal Stats for 2011_lcld_32.tif - Elapsed time: (0:02:51)\n",
      "Year: 2012 - raster path D:\\Basedata\\LCLD_rasters_archive\\2012_lcld_32.tif\n",
      "Calculating 2012_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2012_lcld_32.tif\n",
      "Zonal Stats for 2012_lcld_32.tif - Elapsed time: (0:02:51)\n",
      "Year: 2013 - raster path D:\\Basedata\\LCLD_rasters_archive\\2013_lcld_32.tif\n",
      "Calculating 2013_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2013_lcld_32.tif\n",
      "Zonal Stats for 2013_lcld_32.tif - Elapsed time: (0:02:50)\n",
      "Year: 2014 - raster path D:\\Basedata\\LCLD_rasters_archive\\2014_lcld_32.tif\n",
      "Calculating 2014_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2014_lcld_32.tif\n",
      "Zonal Stats for 2014_lcld_32.tif - Elapsed time: (0:02:50)\n",
      "Year: 2015 - raster path D:\\Basedata\\LCLD_rasters_archive\\2015_lcld_32.tif\n",
      "Calculating 2015_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2015_lcld_32.tif\n",
      "Zonal Stats for 2015_lcld_32.tif - Elapsed time: (0:02:51)\n",
      "Year: 2016 - raster path D:\\Basedata\\LCLD_rasters_archive\\2016_lcld_32.tif\n",
      "Calculating 2016_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2016_lcld_32.tif\n",
      "Zonal Stats for 2016_lcld_32.tif - Elapsed time: (0:02:51)\n",
      "Year: 2017 - raster path D:\\Basedata\\LCLD_rasters_archive\\2017_lcld_32.tif\n",
      "Calculating 2017_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2017_lcld_32.tif\n",
      "Zonal Stats for 2017_lcld_32.tif - Elapsed time: (0:02:53)\n",
      "Year: 2018 - raster path D:\\Basedata\\LCLD_rasters_archive\\2018_lcld_32.tif\n",
      "Calculating 2018_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2018_lcld_32.tif\n",
      "Zonal Stats for 2018_lcld_32.tif - Elapsed time: (0:02:51)\n",
      "Year: 2019 - raster path D:\\Basedata\\LCLD_rasters_archive\\2019_lcld_32.tif\n",
      "Calculating 2019_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2019_lcld_32.tif\n",
      "Zonal Stats for 2019_lcld_32.tif - Elapsed time: (0:02:51)\n",
      "All Covariates for Copper_River completed.\n",
      "Elapsed time: (1:15:13)\n",
      "****************************************************************************************************\n",
      "Process completed at 2022-02-10 00:09 (Elapsed time: 2:17:54)\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "from arcpy.sa import *\n",
    "arcpy.env.workspace = data_dir\n",
    "arcpy.env.overwriteOutput = True\n",
    "sr = arcpy.SpatialReference(3338) #'NAD_1983_Alaska_Albers'\n",
    "arcpy.env.outputCoordinateSystem = sr\n",
    "regions  = arcpy.ListWorkspaces(workspace_type=\"Folder\")\n",
    "\n",
    "# Lists for variables not needed at present time\n",
    "#cat_asp_ztables = []\n",
    "#wtd_asp_ztables = []\n",
    "#cat_pernorth_taba_tables=[]\n",
    "\n",
    "# Lists to store output tables\n",
    "wtd_pernorth_taba_tables=[]\n",
    "wtd_lp_tabint_tables = []\n",
    "wtd_glac_tabint_tables = []\n",
    "wtd_wet_taba_tables = []\n",
    "cat_elev_ztables = []\n",
    "wtd_elev_ztables = []\n",
    "cat_slope_ztables = []\n",
    "wtd_slope_ztables = []\n",
    "lcld_Ztables = []\n",
    "\n",
    "# Clear lists\n",
    "cat_cur_fields = []\n",
    "wtd_cur_fields = []\n",
    "\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "\n",
    "# Split data by type\n",
    "nhdplus_dat = ['Cook_Inlet','Copper_River']\n",
    "tauDem_dat = ['Bristol_Bay', 'Kodiak', 'Prince_William_Sound']\n",
    "\n",
    "#Limit to ci for testing\n",
    "#regions = ['D:\\\\GIS\\\\AKSSF\\\\Cook_Inlet','D:\\\\GIS\\\\AKSSF\\\\Copper_River']\n",
    "#Try with both data types\n",
    "regions = ['D:\\\\GIS\\\\AKSSF\\\\Prince_William_Sound','D:\\\\GIS\\\\AKSSF\\\\Cook_Inlet','D:\\\\GIS\\\\AKSSF\\\\Copper_River']\n",
    "\n",
    "for region in regions:\n",
    "    roi = os.path.basename(region)\n",
    "    # expression to calculate region field with roi name\n",
    "    exp =  '\"'+roi+'\"'\n",
    "    if roi in nhdplus_dat:\n",
    "        lakes_fc = nhd_lakes_fc\n",
    "        # Fields for update cursor\n",
    "        cat_cur_fields = ['cat_ID_txt', 'NHDPlusID',\"cat_ID_con\"]\n",
    "        wtd_cur_fields = ['cat_ID_txt', 'cat_ID',\"cat_ID_con\"]\n",
    "        print (f'{roi} in {nhdplus_dat} AKSSF list, using cat_fields {cat_cur_fields} and watershed fields {wtd_cur_fields}')\n",
    "        print(f'{\"*\"*100}')\n",
    "    # Set data and variables unique to regions with TauDEM Data\n",
    "    elif roi in tauDem_dat:\n",
    "        lakes_fc = tau_lakes_fc\n",
    "        # Fields for update cursor\n",
    "        if roi == 'Bristol_Bay':\n",
    "            cat_cur_fields = ['cat_ID_txt', 'catID',\"cat_ID_con\"]\n",
    "            wtd_cur_fields = ['cat_ID_txt', 'cat_ID',\"cat_ID_con\"]\n",
    "        else:\n",
    "            cat_cur_fields = ['cat_ID_txt', 'gridcode',\"cat_ID_con\"]\n",
    "            wtd_cur_fields = ['cat_ID_txt', 'cat_ID',\"cat_ID_con\"]\n",
    "        print (f'{roi} in {tauDem_dat} TauDEM list, using cat_fields {cat_cur_fields} and watershed fields {wtd_cur_fields}')\n",
    "        print(f'{\"*\"*100}')\n",
    "    # Start iter timing function\n",
    "    iteration_start = time.time()\n",
    "    # Set workspace to region folder\n",
    "    arcpy.env.workspace = region\n",
    "    walk = arcpy.da.Walk(region, datatype = ['FeatureClass','RasterDataset'])\n",
    "    for dirpath, dirnames, filenames in walk:\n",
    "        for filename in filenames:\n",
    "            # Set merged watersheds dataset\n",
    "            if 'awc_huc12_wtds_merge'== filename:\n",
    "                wtdpath = os.path.join(dirpath,filename)\n",
    "                wtdname = roi +'_'+ filename\n",
    "                # Make local copy projected in AKAlbers\n",
    "                wtd_merge = os.path.join(dirpath, filename)\n",
    "                print(f'Merged watershed dataset {filename} found')\n",
    "                print(f'{\"*\"*100}')\n",
    "                wtdfieldnames = []\n",
    "                wtdlstFields = arcpy.ListFields(wtd_merge)\n",
    "                for field in wtdlstFields:\n",
    "                    wtdfieldnames.append(field.name)\n",
    "                if str(wtd_cur_fields[0]) in wtdfieldnames:\n",
    "                    print (f'{wtd_cur_fields[0]} field already in dataset')\n",
    "                    print(f'{\"*\"*100}')\n",
    "                else:\n",
    "                    print (f'Adding {wtd_cur_fields[0]} field to watershed dataset {wtd_merge}')\n",
    "                    print(f'{\"*\"*100}')\n",
    "                    # add cat_ID_txt field and concat cat_ID + region\n",
    "                    arcpy.AddField_management(wtd_merge, str(wtd_cur_fields[0]),field_type='TEXT')\n",
    "                    # populate cat_ID_txt\n",
    "                    with arcpy.da.UpdateCursor(wtd_merge, wtd_cur_fields[0:2]) as cur:\n",
    "                        for row in cur:\n",
    "                            strval = str(row[1])\n",
    "                            row[0] = strval.replace('.0',\"\")\n",
    "                            # Update rows\n",
    "                            cur.updateRow(row)\n",
    "                        del(row)\n",
    "                    del(cur)\n",
    "                if str(wtd_cur_fields[2]) in wtdfieldnames:\n",
    "                    print (f'{wtd_cur_fields[2]} field already in dataset {wtd_merge}')\n",
    "                    print(f'{\"*\"*100}')\n",
    "                else:\n",
    "                    print (f'Adding {wtd_cur_fields[2]} field to watershed dataset {wtd_merge}')\n",
    "                    print(f'{\"*\"*100}')\n",
    "                    # add cat_ID_con field and concat cat_ID + region\n",
    "                    arcpy.AddField_management(wtd_merge, str(wtd_cur_fields[2]),field_type='TEXT')\n",
    "                    # populate cat_ID_txt\n",
    "                    with arcpy.da.UpdateCursor(wtd_merge, wtd_cur_fields) as cur:\n",
    "                        for row in cur:\n",
    "                            strval = str(row[1])\n",
    "                            row[2] = str(roi) +'_'+ strval.replace(\".0\",\"\")\n",
    "                            # Update rows\n",
    "                            cur.updateRow(row)\n",
    "                        del(row)\n",
    "                    del(cur)\n",
    "\n",
    "            # Select glaciers fc\n",
    "            elif 'glaciers' == filename:\n",
    "                # Make local copy projected in AKAlbers\n",
    "                glacpath = os.path.join(dirpath, filename)\n",
    "                glacname = roi+'_'+filename\n",
    "                glac_fc = glacpath\n",
    "\n",
    "            # Select elevation raster\n",
    "            elif 'elev.tif' == filename:\n",
    "                elev_rast = os.path.join(dirpath, filename)\n",
    "\n",
    "            # # Select aspect raster\n",
    "            # elif 'aspect' in filename:\n",
    "            #     asp_rast = os.path.join(dirpath, filename)\n",
    "\n",
    "            # Select north raster\n",
    "            elif 'north.tif' == filename:\n",
    "                nor_rast = os.path.join(dirpath, filename)\n",
    "\n",
    "            # Select slope raster\n",
    "            elif 'slope.tif' == filename:\n",
    "                slope_rast = os.path.join(dirpath, filename)\n",
    "\n",
    "            # Select wetland raster\n",
    "            elif 'wetlands.tif' == filename:\n",
    "                wet_rast = os.path.join(dirpath, filename)\n",
    "\n",
    "            # Select catch_int fc (catchments of interest for region) and make a copy\n",
    "            elif 'awc_huc12_catchment_outlets' == filename:\n",
    "                # Make local copy projected in AKAlbers\n",
    "                catspath = os.path.join(dirpath,filename)\n",
    "                catsname = roi +\"_\"+filename\n",
    "                cats = catspath\n",
    "                catlstfields = arcpy.ListFields(cats)\n",
    "                catfieldnames = []\n",
    "                for field in catlstfields:\n",
    "                    catfieldnames.append(field.name)\n",
    "                if str(cat_cur_fields[0]) in catfieldnames:\n",
    "                    print (f'{cat_cur_fields[0]} field already in dataset {cats}')\n",
    "                    print(f'{\"*\"*100}')\n",
    "                else:\n",
    "                    print (f'Adding {cat_cur_fields[0]} field to catchment dataset {cats}')\n",
    "                    print(f'{\"*\"*100}')\n",
    "                    # add cat_ID_txt field\n",
    "                    arcpy.AddField_management(cats, str(cat_cur_fields[0]), field_type='TEXT')\n",
    "                    # populate cat_ID_txt\n",
    "                    with arcpy.da.UpdateCursor(cats, cat_cur_fields[0:2]) as cur:\n",
    "                        for row in cur:\n",
    "                            strval = str(row[1])\n",
    "                            row[0] = strval.replace('.0',\"\")\n",
    "                            # Update rows\n",
    "                            cur.updateRow(row)\n",
    "                        del(row)\n",
    "                    del(cur)\n",
    "                if str(cat_cur_fields[2]) in catfieldnames:\n",
    "                    print (f'{cat_cur_fields[2]} field already in dataset {cats}')\n",
    "                    print(f'{\"*\"*100}')\n",
    "                else:\n",
    "                    print (f'Adding {cat_cur_fields[2]} field to catchment dataset {cats}')\n",
    "                    print(f'{\"*\"*100}')\n",
    "                    # add cat_ID_txt field & cat_ID + region concat field\n",
    "                    arcpy.AddField_management(cats,str(cat_cur_fields[2]),field_type='TEXT')\n",
    "                    # populate cat_ID_con\n",
    "                    with arcpy.da.UpdateCursor(cats, cat_cur_fields) as cur:\n",
    "                        for row in cur:\n",
    "                            strval = str(row[1])\n",
    "                            row[2] = str(roi) +'_'+ strval.replace('.0',\"\")\n",
    "                            # Update rows\n",
    "                            cur.updateRow(row)\n",
    "                        del(row)\n",
    "                    del(cur)\n",
    "\n",
    "    print (f'Calculating topographic metrics for catchments & watersheds of interest in {roi} region')\n",
    "    print ('----------')\n",
    "    print(f'Geodatabase: {outgdb}')\n",
    "    print ('----------')\n",
    "    print (f'Watershed Merge: {wtd_merge}')\n",
    "    print (f'  Projection {arcpy.Describe(wtd_merge).spatialReference.name}')\n",
    "    print ('----------')\n",
    "    print (f'HUC12 Catchment Outlets: {cats}')\n",
    "    print (f'  Projection {arcpy.Describe(cats).spatialReference.name}')\n",
    "    print ('----------')\n",
    "    print (f'Elevation Raster: {elev_rast}')\n",
    "    print (f'  Projection: {arcpy.Describe(elev_rast).spatialReference.name}')\n",
    "    print ('----------')\n",
    "    print (f'North Aspect Raster: {nor_rast}')\n",
    "    print (f'  Projection: {arcpy.Describe(nor_rast).spatialReference.name}')\n",
    "    print ('----------')\n",
    "    print (f'Wetlands Raster: {wet_rast}')\n",
    "    print (f'  Projection {arcpy.Describe(wet_rast).spatialReference.name}')\n",
    "    print ('----------')\n",
    "    print (f'Slope Raster: {slope_rast}')\n",
    "    print (f'  Projection {arcpy.Describe(slope_rast).spatialReference.name}')\n",
    "    print ('----------')\n",
    "    print (f'Lakes Ponds fc: {lakes_fc}')\n",
    "    print (f'  Projection {arcpy.Describe(lakes_fc).spatialReference.name}')\n",
    "    print ('----------')\n",
    "    print (f'Glaciers fc: {glac_fc} ')\n",
    "    print (f'  Projection {arcpy.Describe(glac_fc).spatialReference.name}')\n",
    "    print ('----------')\n",
    "    print (f'{arcpy.GetCount_management(wtd_merge)} Watersheds to process')\n",
    "    print ('----------')\n",
    "    print (f'Catchment intersect {cats} selected')\n",
    "    print ('----------')\n",
    "\n",
    "    # # Aspect variables\n",
    "    # wtd_merge_asp_table_name = roi + \"_NhdAwcH12_wtd_mer_AspectZstats\"\n",
    "    # wtd_merge_asp_table_path = os.path.join(outgdb, wtd_merge_asp_table_name)\n",
    "    # cat_asp_table_name = roi + \"_NhdAwcH12_cats_AspectZstats\"\n",
    "    # cat_asp_table_path = os.path.join(outgdb, cat_asp_table_name)\n",
    "\n",
    "    # Percent North variables\n",
    "    wtd_merge_pernorth_table_name = roi + \"_NhdAwcH12_wtd_mer_PerNorth\"\n",
    "    wtd_merge_pernorth_table_path = os.path.join(outgdb, wtd_merge_pernorth_table_name)\n",
    "    # cat_pernorth_table_name = roi + \"_NhdAwcH12_cats_PercentNorth\"\n",
    "    # cat_pernorth_table_path = os.path.join(outgdb, cat_pernorth_table_name)\n",
    "\n",
    "    # Elevation variables\n",
    "    wtd_merge_elev_table_name = roi + \"_NhdAwcH12_wtd_mer_ElevZstats\"\n",
    "    wtd_merge_elev_table_path = os.path.join(outgdb, wtd_merge_elev_table_name)\n",
    "    cat_elev_table_name = roi + \"_NhdAwcH12_cats_ElevZstats\"\n",
    "    cat_elev_table_path = os.path.join(outgdb, cat_elev_table_name)\n",
    "\n",
    "    # Slope variables\n",
    "    wtd_merge_slope_table_name = roi + \"_NhdAwcH12_wtd_mer_SlopeZstats\"\n",
    "    wtd_merge_slope_table_path = os.path.join(outgdb, wtd_merge_slope_table_name)\n",
    "    cat_slope_table_name = roi + \"_NhdAwcH12_cats_SlopeZstats\"\n",
    "    cat_slope_table_path = os.path.join(outgdb, cat_slope_table_name)\n",
    "\n",
    "    # Lakes Ponds variables\n",
    "    wtd_merge_lp_table_name = roi + \"_NhdAwcH12_wtd_mer_PerLakes\"\n",
    "    wtd_merge_lp_table_path = os.path.join(outgdb, wtd_merge_lp_table_name)\n",
    "    cat_lp_table_name = roi + \"_NhdAwcH12_cats_PerLakes\"\n",
    "    cat_lp_path = os.path.join(outgdb, cat_lp_table_name)\n",
    "\n",
    "    # Wetlands variables\n",
    "    wtd_merge_wetlands_table_name = roi + \"_NhdAwcH12_wtd_mer_PerWet\"\n",
    "    wtd_merge_wetlands_table_path = os.path.join(outgdb, wtd_merge_wetlands_table_name)\n",
    "    cat_wetlands_table_name = roi + \"NhdAwcH12_cats_PerWet\"\n",
    "    cat_wetlands_table_path = os.path.join(outgdb, cat_wetlands_table_name)\n",
    "\n",
    "    # Glaciers\n",
    "    wtd_merge_glac_table_name = roi + \"_NhdAwcH12_wtd_mer_PerGlac\"\n",
    "    wtd_merge_glac_table_path = os.path.join(outgdb, wtd_merge_glac_table_name)\n",
    "    cat_glac_table_name = roi + \"_NhdAwcH12_cats_Glaciers\"\n",
    "    cat_glac_table_path = os.path.join(outgdb, cat_glac_table_name)\n",
    "\n",
    "    try: # Zonal Stats section\n",
    "        print(f'Begin Slope zonal statistics min/mean/max std dev for watersheds and catchments in {roi}'\n",
    "              f' region')\n",
    "        # Statistics to run for watersheds - 'ALL' is not an option at this time as tool will fail with unknown error\n",
    "        zstats = ['MIN_MAX_MEAN','STD']\n",
    "        # Begin Zonal Stats\n",
    "        zstat_start = time.time()\n",
    "        zstat_start1 = time.time()\n",
    "\n",
    "        # Watershed slope Zonal Statistics\n",
    "        print(f'Calculating {roi} watershed slope zonal stats...')\n",
    "        arcpy.env.snapRaster = slope_rast\n",
    "        arcpy.env.cellSize = slope_rast\n",
    "\n",
    "        # Create field mappings\n",
    "        slope_fm = arcpy.FieldMap()\n",
    "        slope_fms = arcpy.FieldMappings()\n",
    "        for field in arcpy.ListFields(wtd_merge)[6:]:\n",
    "            slope_fm = arcpy.FieldMap()\n",
    "            slope_fm.addInputField(wtd_merge,field.name)\n",
    "            slope_fm.mergeRule = 'First'\n",
    "            # Set properties of the output name.\n",
    "            f_name = slope_fm.outputField\n",
    "            f_name.name = field.name\n",
    "            f_name.aliasName = field.name\n",
    "            slope_fm.outputField = f_name\n",
    "            slope_fms.addFieldMap(slope_fm)\n",
    "\n",
    "        # Make copy of watershed merge input as table to join stats fields\n",
    "        wtd_slope_metrics_table = arcpy.TableToTable_conversion(wtd_merge,\n",
    "                                                               outgdb,\n",
    "                                                               wtd_merge_slope_table_name,\n",
    "                                                               '',\n",
    "                                                               slope_fms,\n",
    "                                                               )\n",
    "        # Add region identifier field for watershed tables                                                )\n",
    "        arcpy.AddField_management(wtd_slope_metrics_table,'region',field_type='TEXT')\n",
    "        arcpy.CalculateField_management(wtd_slope_metrics_table,'region',exp)\n",
    "\n",
    "        for stat in zstats:\n",
    "            outstattable = os.path.join(outgdb,f'{roi}_wtdSlope_{stat}')\n",
    "            zstat_start1 = time.time()\n",
    "            print (f'running {stat}')\n",
    "            stat_table = ZonalStatisticsAsTable(in_zone_data = wtd_merge,\n",
    "                                                zone_field = wtd_cur_fields[0],\n",
    "                                                in_value_raster = slope_rast,\n",
    "                                                out_table = outstattable,\n",
    "                                                statistics_type=stat\n",
    "                                                )\n",
    "\n",
    "            stat_fields = [f.name for f in arcpy.ListFields(stat_table)]\n",
    "            arcpy.JoinField_management(wtd_slope_metrics_table,\n",
    "                                   wtd_cur_fields[0],\n",
    "                                   stat_table,\n",
    "                                   wtd_cur_fields[0],\n",
    "                                   stat_fields[5:] # Keep only stat field/s\n",
    "                                   )\n",
    "\n",
    "            # Report time\n",
    "            zstat_stop1 = time.time()\n",
    "            zstat_time1 = int (zstat_stop1 - zstat_start1)\n",
    "            print(f'Watershed Slope Zonal {stat} for {roi} complete.\\nElapsed time: ({datetime.timedelta(seconds=zstat_time1)})')\n",
    "            print(f'{\"*\"*100}')\n",
    "\n",
    "        # Append watershed slope table to list\n",
    "        wtd_slope_ztables.append(wtd_slope_metrics_table)\n",
    "\n",
    "\n",
    "        # Elevation Zonal statistics  for watersheds\n",
    "        print(f'Begin Elevation zonal statistics min/mean/max std dev for watersheds and catchments in {roi}'\n",
    "              f' region')\n",
    "        zstat_start2 = time.time()\n",
    "        arcpy.env.snapRaster = elev_rast\n",
    "        arcpy.env.cellSize = elev_rast\n",
    "\n",
    "        # Create field mappings\n",
    "        elev_fm = arcpy.FieldMap()\n",
    "        elev_fms = arcpy.FieldMappings()\n",
    "        for field in arcpy.ListFields(wtd_merge)[6:]:\n",
    "            elev_fm = arcpy.FieldMap()\n",
    "            elev_fm.addInputField(wtd_merge,field.name)\n",
    "            elev_fm.mergeRule = 'First'\n",
    "            # Set properties of the output name.\n",
    "            f_name = elev_fm.outputField\n",
    "            f_name.name = field.name\n",
    "            f_name.aliasName = field.name\n",
    "            elev_fm.outputField = f_name\n",
    "            elev_fms.addFieldMap(elev_fm)\n",
    "\n",
    "        # Make copy of watershed merge input as table to join stats fields\n",
    "        wtd_elev_metrics_table = arcpy.TableToTable_conversion(wtd_merge,\n",
    "                                                               outgdb,\n",
    "                                                               wtd_merge_elev_table_name,\n",
    "                                                               '',\n",
    "                                                               elev_fms,\n",
    "                                                               )\n",
    "        # Add region identifier field for watershed tables                                                )\n",
    "        arcpy.AddField_management(wtd_elev_metrics_table,'region',field_type='TEXT')\n",
    "        arcpy.CalculateField_management(wtd_elev_metrics_table,'region',exp)\n",
    "\n",
    "        for stat in zstats:\n",
    "            outstattable = os.path.join(outgdb,f'{roi}_wtdElev_{stat}')\n",
    "            zstat_start1 = time.time()\n",
    "            print (f'running {stat}')\n",
    "            stat_table = ZonalStatisticsAsTable(in_zone_data = wtd_merge,\n",
    "                                                zone_field = wtd_cur_fields[0],\n",
    "                                                in_value_raster = elev_rast,\n",
    "                                                out_table = outstattable,\n",
    "                                                statistics_type=stat\n",
    "                                                )\n",
    "\n",
    "            stat_fields = [f.name for f in arcpy.ListFields(stat_table)]\n",
    "            arcpy.JoinField_management(wtd_elev_metrics_table,\n",
    "                                   wtd_cur_fields[0],\n",
    "                                   stat_table,\n",
    "                                   wtd_cur_fields[0],\n",
    "                                   stat_fields[5:] # Keep only stat field/s\n",
    "                                   )\n",
    "\n",
    "            # Report time\n",
    "            zstat_stop2 = time.time()\n",
    "            zstat_time2 = int (zstat_stop2 - zstat_start2)\n",
    "            print(f'Watershed Elevation Zonal {stat} for {roi} complete.\\nElapsed time: ({datetime.timedelta(seconds=zstat_time2)})')\n",
    "            print(f'{\"*\"*100}')\n",
    "        # Append watershed elev table to list\n",
    "        wtd_elev_ztables.append(wtd_elev_metrics_table)\n",
    "\n",
    "\n",
    "        # Elevation zonal statistics for catchments\n",
    "        print(f'Calculating {roi} catchment elevation zonal stats...')\n",
    "        zstat_start3 = time.time()\n",
    "        arcpy.env.snapRaster = elev_rast\n",
    "        arcpy.env.cellSize = elev_rast\n",
    "        cat_elev_metrics_table = ZonalStatisticsAsTable(in_zone_data = cats ,\n",
    "                                                        zone_field = cat_cur_fields[0],\n",
    "                                                        in_value_raster = elev_rast,\n",
    "                                                        out_table = cat_elev_table_path,\n",
    "                                                        statistics_type='ALL'\n",
    "                                                        )\n",
    "        # Add region identifier field for catchment table\n",
    "        arcpy.AddField_management(cat_elev_metrics_table,'region',field_type='TEXT')\n",
    "        # Add cat_ID_Con field\n",
    "        arcpy.AddField_management(cat_elev_metrics_table,'cat_ID_con',field_type='TEXT')\n",
    "\n",
    "        # Update fields\n",
    "        with arcpy.da.UpdateCursor(cat_elev_metrics_table,['region','cat_ID_txt','cat_ID_con']) as cur:\n",
    "            for row in cur:\n",
    "                row[0] = roi\n",
    "                strval = str(row[1])\n",
    "                row[2] = roi+\"_\"+strval.replace(\".0\",\"\")\n",
    "                # Update\n",
    "                cur.updateRow(row)\n",
    "            del(row)\n",
    "        del(cur)\n",
    "        # Append catchment elev table to list\n",
    "        cat_elev_ztables.append(cat_elev_metrics_table)\n",
    "        # Report time\n",
    "        zstat_stop3 = time.time()\n",
    "        zstat_time3 = int (zstat_stop3 - zstat_start3)\n",
    "        print(f'Elevation Zonal Stats for {roi} catchments complete.\\nElapsed time: ({datetime.timedelta(seconds=zstat_time3)})')\n",
    "        print(f'{\"*\"*100}')\n",
    "\n",
    "        # Slope zonal statistics for catchments\n",
    "        zstat_start4 = time.time()\n",
    "        print(f'Calculating {roi} catchment slope zonal stats...')\n",
    "        arcpy.env.snapRaster = slope_rast\n",
    "        arcpy.env.cellSize = slope_rast\n",
    "        cat_slope_metrics_table = ZonalStatisticsAsTable(in_zone_data = cats ,\n",
    "                                                        zone_field = cat_cur_fields[0],\n",
    "                                                        in_value_raster = slope_rast,\n",
    "                                                        out_table = cat_slope_table_path,\n",
    "                                                        statistics_type='ALL'\n",
    "                                                        )\n",
    "        # Add region identifier field for catchment table\n",
    "        arcpy.AddField_management(cat_slope_metrics_table,'region',field_type='TEXT')\n",
    "        # Add cat_ID_Con field\n",
    "        arcpy.AddField_management(cat_slope_metrics_table,'cat_ID_con',field_type='TEXT')\n",
    "\n",
    "        # Update region field\n",
    "        with arcpy.da.UpdateCursor(cat_slope_metrics_table,['region','cat_ID_txt','cat_ID_con']) as cur:\n",
    "            for row in cur:\n",
    "                row[0] = roi\n",
    "                strval =str(row[1])\n",
    "                row[2] = roi+\"_\"+strval.replace(\".0\",\"\")\n",
    "                # Update\n",
    "                cur.updateRow(row)\n",
    "            del(row)\n",
    "        del(cur)\n",
    "        # Append catchment slope table to list\n",
    "        cat_slope_ztables.append(cat_slope_metrics_table)\n",
    "        # Report time\n",
    "        zstat_stop4 = time.time()\n",
    "        zstat_time4 = int (zstat_stop4 - zstat_start4)\n",
    "        print(f'Slope Zonal Stats for {roi} catchments complete.\\nElapsed time: ({datetime.timedelta(seconds=zstat_time4)})')\n",
    "        print(f'{\"*\"*100}')\n",
    "\n",
    "\n",
    "        # # Aspect Zonal statistics  for watersheds\n",
    "        # print(f'Calculating {roi} watershed aspect zonal stats...')\n",
    "        # wtd_asp_metrics_table = ZonalStatisticsAsTable(in_zone_data = wtd_merge, zone_field =\"cat_ID_txt\",\n",
    "        #                                                in_value_raster = asp_rast, out_table = wtd_merge_asp_table_path,\n",
    "        #                                                statistics_type='ALL')\n",
    "        # arcpy.AddField_management(wtd_asp_metrics_table, 'region', field_type='TEXT')\n",
    "        # Add cat_ID_Con field\n",
    "        # arcpy.AddField_management(wtd_asp_metrics_table,'cat_ID_con',field_type='TEXT')\n",
    "        # arcpy.CalculateField_management(wtd_asp_metrics_table, 'region', 'roi')\n",
    "        # Update region field\n",
    "        # with arcpy.da.UpdateCursor(wtd_asp_metrics_table,['region','cat_ID_txt','cat_ID_con']) as cur:\n",
    "        #     for row in cur:\n",
    "        #         row[0] = roi\n",
    "        #         strval = str(row[1])\n",
    "        #         row[2] = roi+\"_\"+strval.replace(\".0\",\"\")\n",
    "        #         # Update\n",
    "        #         cur.updateRow(row)\n",
    "        #     del(row)\n",
    "        # del(cur)\n",
    "        # wtd_asp_ztables.append(wtd_asp_metrics_table)\n",
    "\n",
    "        # # Aspect Zonal statistics for catchments\n",
    "        # print(f'Calculating {roi} catchment aspect zonal stats...')\n",
    "        # cat_asp_metrics_table = ZonalStatisticsAsTable(in_zone_data = cats, zone_field =\"cat_ID_txt\",\n",
    "        #                                                in_value_raster = asp_rast, out_table = cat_asp_table_path,\n",
    "        #                                                statistics_type='ALL')\n",
    "        # arcpy.AddField_management(cat_asp_metrics_table, 'region', field_type='TEXT')\n",
    "        # Add cat_ID_Con field\n",
    "        # arcpy.AddField_management(cat_asp_metrics_table,'cat_ID_con',field_type='TEXT')\n",
    "        # arcpy.CalculateField_management(cat_asp_metrics_table, 'region', 'roi')\n",
    "        # Update region field\n",
    "        # with arcpy.da.UpdateCursor(cat_asp_metrics_table,['region','cat_ID_txt','cat_ID_con']) as cur:\n",
    "        #     for row in cur:\n",
    "        #         strval = str(row[1])\n",
    "        #         row[2] = roi+\"_\"+strval.replace(\".0\",\"\")\n",
    "        #         # Update\n",
    "        #         cur.updateRow(row)\n",
    "        #     del(row)\n",
    "        # del(cur)\n",
    "        # cat_asp_ztables.append(cat_asp_metrics_table)\n",
    "\n",
    "        zstat_stop = time.time()\n",
    "        zstat_time = int (zstat_stop - zstat_start)\n",
    "        print(f'All Zonal Stats for {roi} Elapsed time: ({datetime.timedelta(seconds=zstat_time)})')\n",
    "        print(f'{\"*\"*100}')\n",
    "\n",
    "        # Tabulate Area with north grid and watersheds\n",
    "        tabarea_start = time.time()\n",
    "        tabarea_start1 = time.time()\n",
    "        print(f'Begin tabulate area of north facing cells for watersheds and catchments in {roi} region')\n",
    "        print(f'{\"*\"*100}')\n",
    "        # Percent North Tabulate area for watersheds\n",
    "        wtd_per_north_tabarea = arcpy.sa.TabulateArea(in_zone_data= wtd_merge,\n",
    "                                                      zone_field= wtd_cur_fields[0],\n",
    "                                                      in_class_data=nor_rast,\n",
    "                                                      class_field=\"Value\",\n",
    "                                                      out_table = wtd_merge_pernorth_table_path\n",
    "                                                      )\n",
    "        # Add region and percent north fields\n",
    "        arcpy.AlterField_management(wtd_per_north_tabarea,'CAT_ID_TXT','CAT_ID_TXT_DEL','CAT_ID_TXT_DEL')\n",
    "        arcpy.AddField_management(wtd_per_north_tabarea, 'region', field_type='TEXT')\n",
    "        arcpy.AddField_management(wtd_per_north_tabarea, 'NhdAwcH12_wtd_north_per', field_type='Float')\n",
    "        arcpy.AddField_management(wtd_per_north_tabarea, wtd_cur_fields[0], field_type='TEXT')\n",
    "        arcpy.AddField_management(wtd_per_north_tabarea, wtd_cur_fields[2], field_type='TEXT')\n",
    "        wtdnorfields = [f.name for f in arcpy.ListFields(wtd_per_north_tabarea)]\n",
    "        #print (wtdnorfields)\n",
    "        with arcpy.da.UpdateCursor(wtd_per_north_tabarea, wtdnorfields) as cur:\n",
    "            for row in cur:\n",
    "                strval = str(row[1])\n",
    "                row[4] = roi\n",
    "                row[5] = row[3]/(row[3]+row[2])*100\n",
    "                row[6] = strval.replace('.0','')\n",
    "                row[7] = roi +'_'+ strval.replace(\".0\",\"\")\n",
    "                # Update\n",
    "                cur.updateRow(row)\n",
    "            del(row)\n",
    "        del(cur)\n",
    "        # Drop UPPERCASE field form tab area\n",
    "        arcpy.DeleteField_management(wtd_per_north_tabarea,'CAT_ID_TXT_DEL')\n",
    "        # Append watershed percent north table to list\n",
    "        wtd_pernorth_taba_tables.append(wtd_per_north_tabarea)\n",
    "        # Report tab area times\n",
    "        tabarea_stop1 = time.time()\n",
    "        tabarea_time1 = int (tabarea_stop1 - tabarea_start1)\n",
    "        print(f'Watershed percent north Tabulate area/intersections for {roi} complete.\\nElapsed time: ({datetime.timedelta(seconds=tabarea_time1)})')\n",
    "        print(f'{\"*\"*100}')\n",
    "\n",
    "        # Percent Lakes Ponds using Tabulate Intersection for watersheds\n",
    "        print(f'Begin watershed percent lakes ponds for {roi}')\n",
    "        tabarea_start2 = time.time()\n",
    "        wtd_lp_tabint = arcpy.TabulateIntersection_analysis(wtd_merge,\n",
    "                                                            zone_fields=wtd_cur_fields[0],\n",
    "                                                            in_class_features=lakes_fc,\n",
    "                                                            out_table=wtd_merge_lp_table_path,\n",
    "                                                            class_fields='Ftype',\n",
    "                                                            out_units=\"SQUARE_METERS\"\n",
    "                                                            )\n",
    "        # Add region and cat id fields\n",
    "        arcpy.AlterField_management(wtd_lp_tabint,'PERCENTAGE','NhdAwcH12_wtd_lake_per','NhdAwcH12_wtd_lake_per')\n",
    "        arcpy.AlterField_management(wtd_lp_tabint,'AREA','NhdAwcH12_wtd_lake_area_sqm','NhdAwcH12_wtd_lake_area_sqm')\n",
    "        arcpy.AddField_management(wtd_lp_tabint, 'region', field_type='TEXT')\n",
    "        arcpy.AddField_management(wtd_lp_tabint, wtd_cur_fields[1], field_type='TEXT')\n",
    "        arcpy.AddField_management(wtd_lp_tabint, wtd_cur_fields[2], field_type='TEXT')\n",
    "        wtdlpfields = [f.name for f in arcpy.ListFields(wtd_lp_tabint)]\n",
    "        #print (wtdlpfields)\n",
    "        with arcpy.da.UpdateCursor(wtd_lp_tabint, wtdlpfields) as cur:\n",
    "            for row in cur:\n",
    "                strval = str(row[1])\n",
    "                row[5] = roi\n",
    "                row[6] = strval.replace('.0','')\n",
    "                row[7] = roi +'_'+ strval.replace(\".0\",\"\")\n",
    "                # Update\n",
    "                cur.updateRow(row)\n",
    "            del(row)\n",
    "        del(cur)\n",
    "\n",
    "        # Append watershed lakes ponds table to list\n",
    "        wtd_lp_tabint_tables.append(wtd_lp_tabint)\n",
    "        # Report tab area times\n",
    "        tabarea_stop2 = time.time()\n",
    "        tabarea_time2 = int (tabarea_stop2 - tabarea_start2)\n",
    "        print(f'Percent Lakes Tabulate area/intersections for {roi} complete.\\nElapsed time: ({datetime.timedelta(seconds=tabarea_time2)})')\n",
    "        print(f'{\"*\"*100}')\n",
    "\n",
    "        # Percent glaciers using Tabulate Intersection for watersheds\n",
    "        tabarea_start3 = time.time()\n",
    "        print(f'Begin tabulate intersection between {glac_fc} and watersheds in {roi} region')\n",
    "        print(f'{\"*\"*100}')\n",
    "        wtd_glac_tabint = arcpy.TabulateIntersection_analysis(wtd_merge,\n",
    "                                                            zone_fields=wtd_cur_fields[0],\n",
    "                                                            in_class_features=glac_fc,\n",
    "                                                            out_table=wtd_merge_glac_table_path,\n",
    "                                                            class_fields='O1Region',\n",
    "                                                            out_units=\"SQUARE_METERS\"\n",
    "                                                            )\n",
    "        # Add region and cat id fields\n",
    "        arcpy.AlterField_management(wtd_glac_tabint,'PERCENTAGE','NhdAwcH12_wtd_glacier_per','NhdAwcH12_wtd_glacier_per')\n",
    "        arcpy.AlterField_management(wtd_glac_tabint,'AREA','NhdAwcH12_wtd_glacier_area_sqm','NhdAwcH12_wtd_glacier_area_sqm')\n",
    "        arcpy.AddField_management(wtd_glac_tabint, 'region', field_type='TEXT')\n",
    "        arcpy.AddField_management(wtd_glac_tabint, wtd_cur_fields[1], field_type='TEXT')\n",
    "        arcpy.AddField_management(wtd_glac_tabint, wtd_cur_fields[2], field_type='TEXT')\n",
    "        wtdglacfields = [f.name for f in arcpy.ListFields(wtd_glac_tabint)]\n",
    "        #print (wtdglacfields)\n",
    "        with arcpy.da.UpdateCursor(wtd_glac_tabint, wtdglacfields) as cur:\n",
    "            for row in cur:\n",
    "                strval = str(row[1])\n",
    "                row[5] = roi\n",
    "                row[6] = strval.replace('.0','')\n",
    "                row[7] = roi +'_'+ strval.replace(\".0\",\"\")\n",
    "                # Update\n",
    "                cur.updateRow(row)\n",
    "            del(row)\n",
    "        del(cur)\n",
    "        # Append watershed percent glacier table to list\n",
    "        wtd_glac_tabint_tables.append(wtd_glac_tabint)\n",
    "        # Report tab area times\n",
    "        tabarea_stop3 = time.time()\n",
    "        tabarea_time3 = int (tabarea_stop3 - tabarea_start3)\n",
    "        print(f'Percent Glacier Tabulate area/intersections for {roi} complete.\\nElapsed time: ({datetime.timedelta(seconds=tabarea_time3)})')\n",
    "        print(f'{\"*\"*100}')\n",
    "\n",
    "        # Tabulate Area with wetlands grid and watersheds\n",
    "        tabarea_start4 = time.time()\n",
    "        print(f'Begin tabulate intersection between {wet_rast} and watersheds in {roi} region')\n",
    "        print(f'{\"*\"*100}')\n",
    "        # Wetlands tabulate area for watersheds\n",
    "        wtd_per_wet_tabarea = arcpy.sa.TabulateArea(in_zone_data= wtd_merge,\n",
    "                                                      zone_field= wtd_cur_fields[0],\n",
    "                                                      in_class_data=wet_rast,\n",
    "                                                      class_field=\"Value\",\n",
    "                                                      out_table=wtd_merge_wetlands_table_path\n",
    "                                                      )\n",
    "        # Add region and percent wet fields\n",
    "        arcpy.AlterField_management(wtd_per_wet_tabarea,'CAT_ID_TXT','CAT_ID_TXT_DEL','CAT_ID_TXT_DEL')\n",
    "        arcpy.AddField_management(wtd_per_wet_tabarea, 'region', field_type='TEXT')\n",
    "        arcpy.AddField_management(wtd_per_wet_tabarea, 'NhdAwcH12_wtd_wet_per', field_type='Float')\n",
    "        arcpy.AddField_management(wtd_per_wet_tabarea, wtd_cur_fields[0], field_type='TEXT')\n",
    "        arcpy.AddField_management(wtd_per_wet_tabarea, wtd_cur_fields[2], field_type='TEXT')\n",
    "        wtdwetfields = [f.name for f in arcpy.ListFields(wtd_per_wet_tabarea)]\n",
    "        #print (wtdwetfields)\n",
    "        with arcpy.da.UpdateCursor(wtd_per_wet_tabarea, wtdwetfields) as cur:\n",
    "            for row in cur:\n",
    "                strval = str(row[1])\n",
    "                row[4] = roi\n",
    "                row[5] = row[3]/(row[3]+row[2])*100\n",
    "                row[6] = strval.replace('.0','')\n",
    "                row[7] = roi +'_'+ strval.replace(\".0\",\"\")\n",
    "                # Update\n",
    "                cur.updateRow(row)\n",
    "            del(row)\n",
    "        del(cur)\n",
    "        # Drop UPPERCASE field form tab area\n",
    "        arcpy.DeleteField_management(wtd_per_wet_tabarea,'CAT_ID_TXT_DEL')\n",
    "        # Append watershed percent wetlands table to list\n",
    "        wtd_wet_taba_tables.append(wtd_per_wet_tabarea)\n",
    "        # Report tab area times\n",
    "        tabarea_stop4 = time.time()\n",
    "        tabarea_time4 = int (tabarea_stop4 - tabarea_start4)\n",
    "        print(f'Percent Wetlands Tabulate area/intersections for {roi} complete.\\nElapsed time: ({datetime.timedelta(seconds=tabarea_time4)})')\n",
    "        print(f'{\"*\"*100}')\n",
    "\n",
    "        # # Percent North Tabulate Area for catchments\n",
    "        # cat_per_north_tabarea = arcpy.sa.TabulateArea(in_zone_data= cats, zone_field='cat_ID_con',\n",
    "        #                                             in_class_data=nor_rast,\"Value\",\n",
    "        #                                             out_table=cat_pernorth_table_path)\n",
    "\n",
    "        # # Add and calculate region identifier field for catchment table\n",
    "        # arcpy.AlterField_management(cat_per_north_tabarea,'CAT_ID_TXT','CAT_ID_TXT_DEL','CAT_ID_TXT_DEL')\n",
    "        # arcpy.AddField_management(cat_per_north_tabarea, 'region', field_type='TEXT')\n",
    "        # arcpy.AddField_management(cat_per_north_tabarea, 'cat_north_per', field_type='Float')\n",
    "        # arcpy.AddField_management(cat_per_north_tabarea, cat_cur_fields[0], field_type='TEXT')\n",
    "        # arcpy.AddField_management(cat_per_north_tabarea, cat_cur_fields[2], field_type='TEXT')\n",
    "        # catnorfields = [f.name for f in arcpy.ListFields(cat_per_north_tabarea)]\n",
    "        # print (catnorfields)\n",
    "        # with arcpy.da.UpdateCursor(cat_per_north_tabarea,catnorfields) as cur:\n",
    "        #     for row in cur:\n",
    "        #         strval = str(row[1])\n",
    "        #         row[4] = roi\n",
    "        #         row[5] = row[3]/(row[3]+row[2])*100\n",
    "        #         row[6] = strval.replace('.0','')\n",
    "        #         row[7] = roi +'_'+ strval.replace(\".0\",\"\")\n",
    "        #         # Update\n",
    "        #         cur.updateRow(row)\n",
    "        #     del(row)\n",
    "        # del(cur)\n",
    "        # Drop UPPERCASE field form tab area\n",
    "        # arcpy.DeleteField_management(cat_per_north_tabarea,'CAT_ID_TXT_DEL')\n",
    "        # # Append catchment percent north table to list\n",
    "        # cat_pernorth_taba_tables.append(cat_per_north_tabarea)\n",
    "        # Report tab area times\n",
    "        tabarea_stop = time.time()\n",
    "        tabarea_time = int (tabarea_stop - tabarea_start)\n",
    "        print(f'Tabulate area/intersections for {roi} complete\\nElapsed time: ({datetime.timedelta(seconds=tabarea_time)})')\n",
    "        print(f'{\"*\"*100}')\n",
    "\n",
    "        # Begin LCLD calculations\n",
    "        walk = arcpy.da.Walk(lcld_folder, datatype='RasterDataset')\n",
    "        for dirpath, dirnames, filenames in walk:\n",
    "            for filename in filenames:\n",
    "                raspath = os.path.join(dirpath, filename)\n",
    "                year = filename[0:4]\n",
    "                lcld_outname = roi+'_NhdAwcH12_lcld_'+str(year)+'_zStats'\n",
    "                lcld_outpath = os.path.join(outgdb, lcld_outname)\n",
    "                print(f'Year: {year} - raster path {raspath}')\n",
    "                colname = 'NhdAwcH12_wtd_lcld_mn_' + str(year)\n",
    "                # lcld zonal statistics as table for all akssf watersheds\n",
    "                print(f'Calculating {filename} zonal stats for all {roi} watersheds...')\n",
    "                #arcpy.env.snapRaster = raspath\n",
    "                #arcpy.env.cellSize = raspath\n",
    "\n",
    "                # Begin Zonal Stats\n",
    "                lcldzstat_start = time.time()\n",
    "                print(f'Begin zonal stats for {filename}')\n",
    "                lcld_table = ZonalStatisticsAsTable(in_zone_data = wtd_merge,\n",
    "                                                                zone_field = 'cat_ID_con',\n",
    "                                                                in_value_raster = raspath,\n",
    "                                                                out_table = lcld_outpath,\n",
    "                                                                statistics_type='MEAN'\n",
    "                                                                )\n",
    "                # Append zTable to table list\n",
    "                lcld_Ztables.append(lcld_outpath)\n",
    "                arcpy.AlterField_management(lcld_table,'MEAN', colname,colname)\n",
    "                proc_list = [row[0] for row in arcpy.da.SearchCursor(lcld_table,'cat_ID_con')]\n",
    "                lcldzstat_stop = time.time()\n",
    "                lcldzstat_time = int (lcldzstat_stop - lcldzstat_start)\n",
    "                print(f'Zonal Stats for {filename} - Elapsed time: ({datetime.timedelta(seconds=lcldzstat_time)})')\n",
    "\n",
    "\n",
    "    except:\n",
    "        e = sys.exc_info()[1]\n",
    "        print(f'ERRFLAG!!! = {e.args[0]}')\n",
    "        arcpy.AddError(e.args[0])\n",
    "\n",
    "    iter_stop = time.time()\n",
    "    iter_time = int(iter_stop - iteration_start)\n",
    "    print(f'All Covariates for {roi} completed.\\nElapsed time: ({datetime.timedelta(seconds=iter_time)})')\n",
    "    print(f'{\"*\"*100}')\n",
    "\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "\n",
    "# Report success\n",
    "print(f'Process completed at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "      f'(Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print(f'{\"*\"*100}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Examine LCLD tables and merge/export\n",
    "* Discovered one watershed for PWS (Prince_William_Sound_23854) only has 6 years of LCLD data attributed to it.  Modis Coverage along the Coastline and PWS in particular is poor and many of the Islands/Coastlines have limited coverage."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2001']\n",
      "lcld_2001_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2002']\n",
      "lcld_2002_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2003']\n",
      "lcld_2003_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2004']\n",
      "lcld_2004_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2005']\n",
      "lcld_2005_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2006']\n",
      "lcld_2006_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2007']\n",
      "lcld_2007_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2008']\n",
      "lcld_2008_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2009']\n",
      "lcld_2009_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2010']\n",
      "lcld_2010_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2011']\n",
      "lcld_2011_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2012']\n",
      "lcld_2012_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2013']\n",
      "lcld_2013_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2014']\n",
      "lcld_2014_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2015']\n",
      "lcld_2015_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2016']\n",
      "lcld_2016_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2017']\n",
      "lcld_2017_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2018']\n",
      "lcld_2018_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2019']\n",
      "lcld_2019_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2001']\n",
      "lcld_2001_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2002']\n",
      "lcld_2002_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2003']\n",
      "lcld_2003_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2004']\n",
      "lcld_2004_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2005']\n",
      "lcld_2005_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2006']\n",
      "lcld_2006_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2007']\n",
      "lcld_2007_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2008']\n",
      "lcld_2008_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2009']\n",
      "lcld_2009_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2010']\n",
      "lcld_2010_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2011']\n",
      "lcld_2011_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2012']\n",
      "lcld_2012_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2013']\n",
      "lcld_2013_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2014']\n",
      "lcld_2014_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2015']\n",
      "lcld_2015_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2016']\n",
      "lcld_2016_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2017']\n",
      "lcld_2017_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2018']\n",
      "lcld_2018_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2019']\n",
      "lcld_2019_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2001']\n",
      "lcld_2001_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2002']\n",
      "lcld_2002_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2003']\n",
      "lcld_2003_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2004']\n",
      "lcld_2004_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2005']\n",
      "lcld_2005_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2006']\n",
      "lcld_2006_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2007']\n",
      "lcld_2007_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2008']\n",
      "lcld_2008_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2009']\n",
      "lcld_2009_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2010']\n",
      "lcld_2010_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2011']\n",
      "lcld_2011_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2012']\n",
      "lcld_2012_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2013']\n",
      "lcld_2013_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2014']\n",
      "lcld_2014_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2015']\n",
      "lcld_2015_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2016']\n",
      "lcld_2016_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2017']\n",
      "lcld_2017_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2018']\n",
      "lcld_2018_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2019']\n",
      "lcld_2019_zStats\n",
      "['cat_ID_con', 'NhdAwcH12_wtd_lcld_mn_2001', 'NhdAwcH12_wtd_lcld_mn_2002', 'NhdAwcH12_wtd_lcld_mn_2003', 'NhdAwcH12_wtd_lcld_mn_2004', 'NhdAwcH12_wtd_lcld_mn_2005', 'NhdAwcH12_wtd_lcld_mn_2006', 'NhdAwcH12_wtd_lcld_mn_2007', 'NhdAwcH12_wtd_lcld_mn_2008', 'NhdAwcH12_wtd_lcld_mn_2009', 'NhdAwcH12_wtd_lcld_mn_2010', 'NhdAwcH12_wtd_lcld_mn_2011', 'NhdAwcH12_wtd_lcld_mn_2012', 'NhdAwcH12_wtd_lcld_mn_2013', 'NhdAwcH12_wtd_lcld_mn_2014', 'NhdAwcH12_wtd_lcld_mn_2015', 'NhdAwcH12_wtd_lcld_mn_2016', 'NhdAwcH12_wtd_lcld_mn_2017', 'NhdAwcH12_wtd_lcld_mn_2018', 'NhdAwcH12_wtd_lcld_mn_2019']\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = outgdb\n",
    "lcld_Ztables = [t for t in arcpy.ListTables('*_lcld_*')]\n",
    "from collections import OrderedDict\n",
    "lcld_Dict = {}\n",
    "dfs = []\n",
    "lcld_cols = []\n",
    "drop_cols = ['OBJECTID','ZONE_CODE', 'AREA', 'COUNT']\n",
    "for table in lcld_Ztables:\n",
    "    cols = [f.name for f in arcpy.ListFields(table)]\n",
    "    search_cols = [x for x in cols if x not in drop_cols]\n",
    "    #cols.remove(drop_cols)\n",
    "    print(search_cols)\n",
    "    lcld_cols.append(search_cols)\n",
    "    tblname = table[-16:]\n",
    "    print(tblname)\n",
    "    with arcpy.da.SearchCursor(table, search_cols) as cur:\n",
    "        for row in cur:\n",
    "\n",
    "            append_value(lcld_Dict,row[0],row[1])\n",
    "\n",
    "lcld_cols = [item for sublist in lcld_cols for item in sublist]\n",
    "lcld_cols = list(OrderedDict.fromkeys(lcld_cols))\n",
    "print(lcld_cols)\n",
    "\n",
    "#Create list of tuples containing unique id followed by mean lcld for years 2001-2019\n",
    "row_values = [(k,)+tuple(v) for k,v in lcld_Dict.items()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create an empty table to append yearly data\n",
    " * Attempting to convert to df and numpy arrays has been unsuccessful"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "'cat_ID_con'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unids = [r[0] for r in row_values]\n",
    "len(unids)\n",
    "lcld_cols[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018\n"
     ]
    }
   ],
   "source": [
    "print(len(row_values))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LCDL table has 1018 records of 1018 input rows\n"
     ]
    }
   ],
   "source": [
    "lcld_table = arcpy.CreateTable_management(outgdb,'AKSSF_ALL_LCLD_mn')\n",
    "arcpy.AddField_management(lcld_table.getOutput(0),lcld_cols[0],'TEXT')\n",
    "cur = arcpy.da.InsertCursor(lcld_table.getOutput(0),lcld_cols[0])\n",
    "# Populate table with cat_ID_con values stored in list of lcld tuples\n",
    "try:\n",
    "    for row in row_values:\n",
    "        cur.insertRow([row[0]])\n",
    "        del(row)\n",
    "    del(cur)\n",
    "except:\n",
    "    e = sys.exc_info()[1]\n",
    "    print(f'ERRFLAG!!! = {e.args[0]}\\n')\n",
    "    # Get the traceback object\n",
    "    tb = sys.exc_info()[2]\n",
    "    tbinfo = traceback.format_tb(tb)[0]\n",
    "    # Concatenate information together concerning the error into a message string\n",
    "    pymsg = \"PYTHON ERRORS:\\nTraceback info:\\n\" + tbinfo + \"\\nError Info:\\n\" + str(sys.exc_info()[1])\n",
    "    msgs = \"ArcPy ERRORS:\\n\" + arcpy.GetMessages(2) + \"\\n\"\n",
    "    # Return Python error messages for use in script tool or Python window\n",
    "    arcpy.AddError(pymsg)\n",
    "    arcpy.AddError(msgs)\n",
    "    # Print Python error messages for use in Python / Python window\n",
    "    print(pymsg)\n",
    "    print(msgs)\n",
    "    arcpy.AddError(e.args[0])\n",
    "print(f'LCDL table has {arcpy.GetCount_management(lcld_table)} records of {len(row_values)} input rows')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001 using tables ['Prince_William_SoundNhdAwcH12_lcld_2001_zStats', 'Cook_InletNhdAwcH12_lcld_2001_zStats', 'Copper_RiverNhdAwcH12_lcld_2001_zStats'] with val ['Prince_William_SoundNhdAwcH12_lcld_2001_zStats', 'Cook_InletNhdAwcH12_lcld_2001_zStats', 'Copper_RiverNhdAwcH12_lcld_2001_zStats']\n",
      "\n",
      "Joining field NhdAwcH12_wtd_lcld_mn_2001 from memory\\tempTable to D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\\AKSSF_ALL_LCLD_mn\n",
      "\n",
      "****************************************************************************************************\n",
      "2002 using tables ['Prince_William_SoundNhdAwcH12_lcld_2002_zStats', 'Cook_InletNhdAwcH12_lcld_2002_zStats', 'Copper_RiverNhdAwcH12_lcld_2002_zStats'] with val ['Prince_William_SoundNhdAwcH12_lcld_2002_zStats', 'Cook_InletNhdAwcH12_lcld_2002_zStats', 'Copper_RiverNhdAwcH12_lcld_2002_zStats']\n",
      "\n",
      "Joining field NhdAwcH12_wtd_lcld_mn_2002 from memory\\tempTable to D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\\AKSSF_ALL_LCLD_mn\n",
      "\n",
      "****************************************************************************************************\n",
      "2003 using tables ['Prince_William_SoundNhdAwcH12_lcld_2003_zStats', 'Cook_InletNhdAwcH12_lcld_2003_zStats', 'Copper_RiverNhdAwcH12_lcld_2003_zStats'] with val ['Prince_William_SoundNhdAwcH12_lcld_2003_zStats', 'Cook_InletNhdAwcH12_lcld_2003_zStats', 'Copper_RiverNhdAwcH12_lcld_2003_zStats']\n",
      "\n",
      "Joining field NhdAwcH12_wtd_lcld_mn_2003 from memory\\tempTable to D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\\AKSSF_ALL_LCLD_mn\n",
      "\n",
      "****************************************************************************************************\n",
      "2004 using tables ['Prince_William_SoundNhdAwcH12_lcld_2004_zStats', 'Cook_InletNhdAwcH12_lcld_2004_zStats', 'Copper_RiverNhdAwcH12_lcld_2004_zStats'] with val ['Prince_William_SoundNhdAwcH12_lcld_2004_zStats', 'Cook_InletNhdAwcH12_lcld_2004_zStats', 'Copper_RiverNhdAwcH12_lcld_2004_zStats']\n",
      "\n",
      "Joining field NhdAwcH12_wtd_lcld_mn_2004 from memory\\tempTable to D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\\AKSSF_ALL_LCLD_mn\n",
      "\n",
      "****************************************************************************************************\n",
      "2005 using tables ['Prince_William_SoundNhdAwcH12_lcld_2005_zStats', 'Cook_InletNhdAwcH12_lcld_2005_zStats', 'Copper_RiverNhdAwcH12_lcld_2005_zStats'] with val ['Prince_William_SoundNhdAwcH12_lcld_2005_zStats', 'Cook_InletNhdAwcH12_lcld_2005_zStats', 'Copper_RiverNhdAwcH12_lcld_2005_zStats']\n",
      "\n",
      "Joining field NhdAwcH12_wtd_lcld_mn_2005 from memory\\tempTable to D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\\AKSSF_ALL_LCLD_mn\n",
      "\n",
      "****************************************************************************************************\n",
      "2006 using tables ['Prince_William_SoundNhdAwcH12_lcld_2006_zStats', 'Cook_InletNhdAwcH12_lcld_2006_zStats', 'Copper_RiverNhdAwcH12_lcld_2006_zStats'] with val ['Prince_William_SoundNhdAwcH12_lcld_2006_zStats', 'Cook_InletNhdAwcH12_lcld_2006_zStats', 'Copper_RiverNhdAwcH12_lcld_2006_zStats']\n",
      "\n",
      "Joining field NhdAwcH12_wtd_lcld_mn_2006 from memory\\tempTable to D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\\AKSSF_ALL_LCLD_mn\n",
      "\n",
      "****************************************************************************************************\n",
      "2007 using tables ['Prince_William_SoundNhdAwcH12_lcld_2007_zStats', 'Cook_InletNhdAwcH12_lcld_2007_zStats', 'Copper_RiverNhdAwcH12_lcld_2007_zStats'] with val ['Prince_William_SoundNhdAwcH12_lcld_2007_zStats', 'Cook_InletNhdAwcH12_lcld_2007_zStats', 'Copper_RiverNhdAwcH12_lcld_2007_zStats']\n",
      "\n",
      "Joining field NhdAwcH12_wtd_lcld_mn_2007 from memory\\tempTable to D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\\AKSSF_ALL_LCLD_mn\n",
      "\n",
      "****************************************************************************************************\n",
      "2008 using tables ['Prince_William_SoundNhdAwcH12_lcld_2008_zStats', 'Cook_InletNhdAwcH12_lcld_2008_zStats', 'Copper_RiverNhdAwcH12_lcld_2008_zStats'] with val ['Prince_William_SoundNhdAwcH12_lcld_2008_zStats', 'Cook_InletNhdAwcH12_lcld_2008_zStats', 'Copper_RiverNhdAwcH12_lcld_2008_zStats']\n",
      "\n",
      "Joining field NhdAwcH12_wtd_lcld_mn_2008 from memory\\tempTable to D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\\AKSSF_ALL_LCLD_mn\n",
      "\n",
      "****************************************************************************************************\n",
      "2009 using tables ['Prince_William_SoundNhdAwcH12_lcld_2009_zStats', 'Cook_InletNhdAwcH12_lcld_2009_zStats', 'Copper_RiverNhdAwcH12_lcld_2009_zStats'] with val ['Prince_William_SoundNhdAwcH12_lcld_2009_zStats', 'Cook_InletNhdAwcH12_lcld_2009_zStats', 'Copper_RiverNhdAwcH12_lcld_2009_zStats']\n",
      "\n",
      "Joining field NhdAwcH12_wtd_lcld_mn_2009 from memory\\tempTable to D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\\AKSSF_ALL_LCLD_mn\n",
      "\n",
      "****************************************************************************************************\n",
      "2010 using tables ['Prince_William_SoundNhdAwcH12_lcld_2010_zStats', 'Cook_InletNhdAwcH12_lcld_2010_zStats', 'Copper_RiverNhdAwcH12_lcld_2010_zStats'] with val ['Prince_William_SoundNhdAwcH12_lcld_2010_zStats', 'Cook_InletNhdAwcH12_lcld_2010_zStats', 'Copper_RiverNhdAwcH12_lcld_2010_zStats']\n",
      "\n",
      "Joining field NhdAwcH12_wtd_lcld_mn_2010 from memory\\tempTable to D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\\AKSSF_ALL_LCLD_mn\n",
      "\n",
      "****************************************************************************************************\n",
      "2011 using tables ['Prince_William_SoundNhdAwcH12_lcld_2011_zStats', 'Cook_InletNhdAwcH12_lcld_2011_zStats', 'Copper_RiverNhdAwcH12_lcld_2011_zStats'] with val ['Prince_William_SoundNhdAwcH12_lcld_2011_zStats', 'Cook_InletNhdAwcH12_lcld_2011_zStats', 'Copper_RiverNhdAwcH12_lcld_2011_zStats']\n",
      "\n",
      "Joining field NhdAwcH12_wtd_lcld_mn_2011 from memory\\tempTable to D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\\AKSSF_ALL_LCLD_mn\n",
      "\n",
      "****************************************************************************************************\n",
      "2012 using tables ['Prince_William_SoundNhdAwcH12_lcld_2012_zStats', 'Cook_InletNhdAwcH12_lcld_2012_zStats', 'Copper_RiverNhdAwcH12_lcld_2012_zStats'] with val ['Prince_William_SoundNhdAwcH12_lcld_2012_zStats', 'Cook_InletNhdAwcH12_lcld_2012_zStats', 'Copper_RiverNhdAwcH12_lcld_2012_zStats']\n",
      "\n",
      "Joining field NhdAwcH12_wtd_lcld_mn_2012 from memory\\tempTable to D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\\AKSSF_ALL_LCLD_mn\n",
      "\n",
      "****************************************************************************************************\n",
      "2013 using tables ['Prince_William_SoundNhdAwcH12_lcld_2013_zStats', 'Cook_InletNhdAwcH12_lcld_2013_zStats', 'Copper_RiverNhdAwcH12_lcld_2013_zStats'] with val ['Prince_William_SoundNhdAwcH12_lcld_2013_zStats', 'Cook_InletNhdAwcH12_lcld_2013_zStats', 'Copper_RiverNhdAwcH12_lcld_2013_zStats']\n",
      "\n",
      "Joining field NhdAwcH12_wtd_lcld_mn_2013 from memory\\tempTable to D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\\AKSSF_ALL_LCLD_mn\n",
      "\n",
      "****************************************************************************************************\n",
      "2014 using tables ['Prince_William_SoundNhdAwcH12_lcld_2014_zStats', 'Cook_InletNhdAwcH12_lcld_2014_zStats', 'Copper_RiverNhdAwcH12_lcld_2014_zStats'] with val ['Prince_William_SoundNhdAwcH12_lcld_2014_zStats', 'Cook_InletNhdAwcH12_lcld_2014_zStats', 'Copper_RiverNhdAwcH12_lcld_2014_zStats']\n",
      "\n",
      "Joining field NhdAwcH12_wtd_lcld_mn_2014 from memory\\tempTable to D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\\AKSSF_ALL_LCLD_mn\n",
      "\n",
      "****************************************************************************************************\n",
      "2015 using tables ['Prince_William_SoundNhdAwcH12_lcld_2015_zStats', 'Cook_InletNhdAwcH12_lcld_2015_zStats', 'Copper_RiverNhdAwcH12_lcld_2015_zStats'] with val ['Prince_William_SoundNhdAwcH12_lcld_2015_zStats', 'Cook_InletNhdAwcH12_lcld_2015_zStats', 'Copper_RiverNhdAwcH12_lcld_2015_zStats']\n",
      "\n",
      "Joining field NhdAwcH12_wtd_lcld_mn_2015 from memory\\tempTable to D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\\AKSSF_ALL_LCLD_mn\n",
      "\n",
      "****************************************************************************************************\n",
      "2016 using tables ['Prince_William_SoundNhdAwcH12_lcld_2016_zStats', 'Cook_InletNhdAwcH12_lcld_2016_zStats', 'Copper_RiverNhdAwcH12_lcld_2016_zStats'] with val ['Prince_William_SoundNhdAwcH12_lcld_2016_zStats', 'Cook_InletNhdAwcH12_lcld_2016_zStats', 'Copper_RiverNhdAwcH12_lcld_2016_zStats']\n",
      "\n",
      "Joining field NhdAwcH12_wtd_lcld_mn_2016 from memory\\tempTable to D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\\AKSSF_ALL_LCLD_mn\n",
      "\n",
      "****************************************************************************************************\n",
      "2017 using tables ['Prince_William_SoundNhdAwcH12_lcld_2017_zStats', 'Cook_InletNhdAwcH12_lcld_2017_zStats', 'Copper_RiverNhdAwcH12_lcld_2017_zStats'] with val ['Prince_William_SoundNhdAwcH12_lcld_2017_zStats', 'Cook_InletNhdAwcH12_lcld_2017_zStats', 'Copper_RiverNhdAwcH12_lcld_2017_zStats']\n",
      "\n",
      "Joining field NhdAwcH12_wtd_lcld_mn_2017 from memory\\tempTable to D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\\AKSSF_ALL_LCLD_mn\n",
      "\n",
      "****************************************************************************************************\n",
      "2018 using tables ['Prince_William_SoundNhdAwcH12_lcld_2018_zStats', 'Cook_InletNhdAwcH12_lcld_2018_zStats', 'Copper_RiverNhdAwcH12_lcld_2018_zStats'] with val ['Prince_William_SoundNhdAwcH12_lcld_2018_zStats', 'Cook_InletNhdAwcH12_lcld_2018_zStats', 'Copper_RiverNhdAwcH12_lcld_2018_zStats']\n",
      "\n",
      "Joining field NhdAwcH12_wtd_lcld_mn_2018 from memory\\tempTable to D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\\AKSSF_ALL_LCLD_mn\n",
      "\n",
      "****************************************************************************************************\n",
      "2019 using tables ['Prince_William_SoundNhdAwcH12_lcld_2019_zStats', 'Cook_InletNhdAwcH12_lcld_2019_zStats', 'Copper_RiverNhdAwcH12_lcld_2019_zStats'] with val ['Prince_William_SoundNhdAwcH12_lcld_2019_zStats', 'Cook_InletNhdAwcH12_lcld_2019_zStats', 'Copper_RiverNhdAwcH12_lcld_2019_zStats']\n",
      "\n",
      "Joining field NhdAwcH12_wtd_lcld_mn_2019 from memory\\tempTable to D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\\AKSSF_ALL_LCLD_mn\n",
      "\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "years = [x for x in range(2001,2020)]\n",
    "lcldyr_Dict = {}\n",
    "for y in years:\n",
    "    for table in lcld_Ztables:\n",
    "        if str(y) in table:\n",
    "            append_value(lcldyr_Dict,str(y),table)\n",
    "#print(lcldyr_Dict)\n",
    "\n",
    "for k, v in lcldyr_Dict.items():\n",
    "    year = k\n",
    "    intables = v\n",
    "    print (f'{year} using tables {intables} with val {v}\\n')\n",
    "    tempTable = arcpy.Merge_management(v,f'memory\\\\tempTable')\n",
    "    infields = [f.name for f in arcpy.ListFields(tempTable)]\n",
    "    print(f'Joining field {infields[5]} from {tempTable} to {lcld_table}')\n",
    "    print(f'{'*'*100}\\n')\n",
    "    arcpy.JoinField_management(lcld_table,lcld_cols[0],tempTable,lcld_cols[0],infields[5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "                             OBJECTID  NhdAwcH12_wtd_lcld_mn_2001  \\\ncat_ID_con                                                          \nPrince_William_Sound_3038           1                  508.555029   \nPrince_William_Sound_13227          2                  514.252371   \nPrince_William_Sound_17027          3                  515.999191   \nPrince_William_Sound_17697          4                  522.877156   \nPrince_William_Sound_18357          5                  518.928843   \n...                               ...                         ...   \nCopper_River_75003900029086      1014                  428.084574   \nCopper_River_75003900044552      1015                  506.135406   \nCopper_River_75003900054944      1016                  471.212499   \nCopper_River_75003900029096      1017                  516.471106   \nCopper_River_75003900047600      1018                  537.854095   \n\n                             NhdAwcH12_wtd_lcld_mn_2002  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                    508.128684   \nPrince_William_Sound_13227                   505.159319   \nPrince_William_Sound_17027                   517.335258   \nPrince_William_Sound_17697                   531.425302   \nPrince_William_Sound_18357                   519.123082   \n...                                                 ...   \nCopper_River_75003900029086                  486.099145   \nCopper_River_75003900044552                  501.755675   \nCopper_River_75003900054944                  494.243152   \nCopper_River_75003900029096                  518.699512   \nCopper_River_75003900047600                  530.406944   \n\n                             NhdAwcH12_wtd_lcld_mn_2003  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                    463.393467   \nPrince_William_Sound_13227                   480.000000   \nPrince_William_Sound_17027                   471.393950   \nPrince_William_Sound_17697                   496.266759   \nPrince_William_Sound_18357                   479.084527   \n...                                                 ...   \nCopper_River_75003900029086                  434.007325   \nCopper_River_75003900044552                  441.515220   \nCopper_River_75003900054944                  422.678038   \nCopper_River_75003900029096                  480.499865   \nCopper_River_75003900047600                  513.481196   \n\n                             NhdAwcH12_wtd_lcld_mn_2004  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                    500.807675   \nPrince_William_Sound_13227                   516.000000   \nPrince_William_Sound_17027                   509.214663   \nPrince_William_Sound_17697                   521.571098   \nPrince_William_Sound_18357                   511.788717   \n...                                                 ...   \nCopper_River_75003900029086                  470.238494   \nCopper_River_75003900044552                  487.940728   \nCopper_River_75003900054944                  464.086918   \nCopper_River_75003900029096                  512.699893   \nCopper_River_75003900047600                  517.581046   \n\n                             NhdAwcH12_wtd_lcld_mn_2005  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                    476.085032   \nPrince_William_Sound_13227                   487.000000   \nPrince_William_Sound_17027                   492.210631   \nPrince_William_Sound_17697                   501.987227   \nPrince_William_Sound_18357                   493.635879   \n...                                                 ...   \nCopper_River_75003900029086                  426.929563   \nCopper_River_75003900044552                  475.953439   \nCopper_River_75003900054944                  439.834718   \nCopper_River_75003900029096                  497.851787   \nCopper_River_75003900047600                  518.363138   \n\n                             NhdAwcH12_wtd_lcld_mn_2006  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                    508.915857   \nPrince_William_Sound_13227                   511.800851   \nPrince_William_Sound_17027                   511.377111   \nPrince_William_Sound_17697                   520.330224   \nPrince_William_Sound_18357                   521.300112   \n...                                                 ...   \nCopper_River_75003900029086                  461.685259   \nCopper_River_75003900044552                  497.688529   \nCopper_River_75003900054944                  477.171759   \nCopper_River_75003900029096                  510.147052   \nCopper_River_75003900047600                  530.390511   \n\n                             NhdAwcH12_wtd_lcld_mn_2007  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                    508.936782   \nPrince_William_Sound_13227                   511.383761   \nPrince_William_Sound_17027                   519.209941   \nPrince_William_Sound_17697                   533.479922   \nPrince_William_Sound_18357                   529.690076   \n...                                                 ...   \nCopper_River_75003900029086                  479.305537   \nCopper_River_75003900044552                  502.735879   \nCopper_River_75003900054944                  486.436765   \nCopper_River_75003900029096                  511.157301   \nCopper_River_75003900047600                  521.928085   \n\n                             NhdAwcH12_wtd_lcld_mn_2008  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                    524.235347   \nPrince_William_Sound_13227                   513.995746   \nPrince_William_Sound_17027                   531.016164   \nPrince_William_Sound_17697                   554.323597   \nPrince_William_Sound_18357                   542.799450   \n...                                                 ...   \nCopper_River_75003900029086                  481.603447   \nCopper_River_75003900044552                  514.357314   \nCopper_River_75003900054944                  488.877583   \nCopper_River_75003900029096                  527.377826   \nCopper_River_75003900047600                  540.397409   \n\n                             NhdAwcH12_wtd_lcld_mn_2009  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                    520.363026   \nPrince_William_Sound_13227                   520.000000   \nPrince_William_Sound_17027                   522.439286   \nPrince_William_Sound_17697                   545.339405   \nPrince_William_Sound_18357                   532.419252   \n...                                                 ...   \nCopper_River_75003900029086                  482.134102   \nCopper_River_75003900044552                  500.875332   \nCopper_River_75003900054944                  489.949104   \nCopper_River_75003900029096                  530.031048   \nCopper_River_75003900047600                  521.474405   \n\n                             NhdAwcH12_wtd_lcld_mn_2010  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                    504.248257   \nPrince_William_Sound_13227                   506.243233   \nPrince_William_Sound_17027                   510.353149   \nPrince_William_Sound_17697                   522.740585   \nPrince_William_Sound_18357                   516.344181   \n...                                                 ...   \nCopper_River_75003900029086                  472.782352   \nCopper_River_75003900044552                  505.846055   \nCopper_River_75003900054944                  475.444300   \nCopper_River_75003900029096                  511.948393   \nCopper_River_75003900047600                  526.071806   \n\n                             NhdAwcH12_wtd_lcld_mn_2011  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                    497.990594   \nPrince_William_Sound_13227                   509.960170   \nPrince_William_Sound_17027                   500.020681   \nPrince_William_Sound_17697                   524.488093   \nPrince_William_Sound_18357                   510.726020   \n...                                                 ...   \nCopper_River_75003900029086                  458.794501   \nCopper_River_75003900044552                  494.667803   \nCopper_River_75003900054944                  476.375077   \nCopper_River_75003900029096                  515.507792   \nCopper_River_75003900047600                  530.774082   \n\n                             NhdAwcH12_wtd_lcld_mn_2012  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                    519.367798   \nPrince_William_Sound_13227                   533.761740   \nPrince_William_Sound_17027                   530.855632   \nPrince_William_Sound_17697                   548.313281   \nPrince_William_Sound_18357                   538.696188   \n...                                                 ...   \nCopper_River_75003900029086                  485.641902   \nCopper_River_75003900044552                  529.897337   \nCopper_River_75003900054944                  505.542194   \nCopper_River_75003900029096                  543.378319   \nCopper_River_75003900047600                  561.578317   \n\n                             NhdAwcH12_wtd_lcld_mn_2013  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                    516.442898   \nPrince_William_Sound_13227                   524.000000   \nPrince_William_Sound_17027                   524.138335   \nPrince_William_Sound_17697                   533.971525   \nPrince_William_Sound_18357                   528.862207   \n...                                                 ...   \nCopper_River_75003900029086                  487.820103   \nCopper_River_75003900044552                  514.894985   \nCopper_River_75003900054944                  493.379799   \nCopper_River_75003900029096                  537.522651   \nCopper_River_75003900047600                  541.536563   \n\n                             NhdAwcH12_wtd_lcld_mn_2014  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                    487.399409   \nPrince_William_Sound_13227                   488.000000   \nPrince_William_Sound_17027                   492.491116   \nPrince_William_Sound_17697                   502.494092   \nPrince_William_Sound_18357                   496.909217   \n...                                                 ...   \nCopper_River_75003900029086                  423.330805   \nCopper_River_75003900044552                  479.218491   \nCopper_River_75003900054944                  470.743883   \nCopper_River_75003900029096                  490.562411   \nCopper_River_75003900047600                  508.126298   \n\n                             NhdAwcH12_wtd_lcld_mn_2015  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                    459.335113   \nPrince_William_Sound_13227                   474.740458   \nPrince_William_Sound_17027                   453.116534   \nPrince_William_Sound_17697                   482.508580   \nPrince_William_Sound_18357                   461.282085   \n...                                                 ...   \nCopper_River_75003900029086                  414.759543   \nCopper_River_75003900044552                  414.404403   \nCopper_River_75003900054944                  423.433889   \nCopper_River_75003900029096                  485.051815   \nCopper_River_75003900047600                  510.832255   \n\n                             NhdAwcH12_wtd_lcld_mn_2016  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                    438.086274   \nPrince_William_Sound_13227                   469.880510   \nPrince_William_Sound_17027                   441.996546   \nPrince_William_Sound_17697                   475.545204   \nPrince_William_Sound_18357                   462.003602   \n...                                                 ...   \nCopper_River_75003900029086                  410.158446   \nCopper_River_75003900044552                  425.842085   \nCopper_River_75003900054944                  413.119983   \nCopper_River_75003900029096                  503.140669   \nCopper_River_75003900047600                  509.149879   \n\n                             NhdAwcH12_wtd_lcld_mn_2017  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                    491.189930   \nPrince_William_Sound_13227                   485.916087   \nPrince_William_Sound_17027                   504.222195   \nPrince_William_Sound_17697                   515.761395   \nPrince_William_Sound_18357                   506.690720   \n...                                                 ...   \nCopper_River_75003900029086                  470.742159   \nCopper_River_75003900044552                  496.148778   \nCopper_River_75003900054944                  478.510037   \nCopper_River_75003900029096                  508.203663   \nCopper_River_75003900047600                  517.992697   \n\n                             NhdAwcH12_wtd_lcld_mn_2018  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                    501.663282   \nPrince_William_Sound_13227                   492.000000   \nPrince_William_Sound_17027                   503.255956   \nPrince_William_Sound_17697                   506.677339   \nPrince_William_Sound_18357                   496.491091   \n...                                                 ...   \nCopper_River_75003900029086                  451.558074   \nCopper_River_75003900044552                  491.614218   \nCopper_River_75003900054944                  472.765282   \nCopper_River_75003900029096                  500.313407   \nCopper_River_75003900047600                  528.987450   \n\n                             NhdAwcH12_wtd_lcld_mn_2019  \ncat_ID_con                                               \nPrince_William_Sound_3038                    458.886742  \nPrince_William_Sound_13227                   486.102938  \nPrince_William_Sound_17027                   485.734227  \nPrince_William_Sound_17697                   502.772358  \nPrince_William_Sound_18357                   477.655689  \n...                                                 ...  \nCopper_River_75003900029086                  439.999561  \nCopper_River_75003900044552                  470.632806  \nCopper_River_75003900054944                  434.095321  \nCopper_River_75003900029096                  485.832311  \nCopper_River_75003900047600                  506.978774  \n\n[1018 rows x 20 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>OBJECTID</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2001</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2002</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2003</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2004</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2005</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2006</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2007</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2008</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2009</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2010</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2011</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2012</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2013</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2014</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2015</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2016</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2017</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2018</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2019</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Prince_William_Sound_3038</th>\n      <td>1</td>\n      <td>508.555029</td>\n      <td>508.128684</td>\n      <td>463.393467</td>\n      <td>500.807675</td>\n      <td>476.085032</td>\n      <td>508.915857</td>\n      <td>508.936782</td>\n      <td>524.235347</td>\n      <td>520.363026</td>\n      <td>504.248257</td>\n      <td>497.990594</td>\n      <td>519.367798</td>\n      <td>516.442898</td>\n      <td>487.399409</td>\n      <td>459.335113</td>\n      <td>438.086274</td>\n      <td>491.189930</td>\n      <td>501.663282</td>\n      <td>458.886742</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_13227</th>\n      <td>2</td>\n      <td>514.252371</td>\n      <td>505.159319</td>\n      <td>480.000000</td>\n      <td>516.000000</td>\n      <td>487.000000</td>\n      <td>511.800851</td>\n      <td>511.383761</td>\n      <td>513.995746</td>\n      <td>520.000000</td>\n      <td>506.243233</td>\n      <td>509.960170</td>\n      <td>533.761740</td>\n      <td>524.000000</td>\n      <td>488.000000</td>\n      <td>474.740458</td>\n      <td>469.880510</td>\n      <td>485.916087</td>\n      <td>492.000000</td>\n      <td>486.102938</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17027</th>\n      <td>3</td>\n      <td>515.999191</td>\n      <td>517.335258</td>\n      <td>471.393950</td>\n      <td>509.214663</td>\n      <td>492.210631</td>\n      <td>511.377111</td>\n      <td>519.209941</td>\n      <td>531.016164</td>\n      <td>522.439286</td>\n      <td>510.353149</td>\n      <td>500.020681</td>\n      <td>530.855632</td>\n      <td>524.138335</td>\n      <td>492.491116</td>\n      <td>453.116534</td>\n      <td>441.996546</td>\n      <td>504.222195</td>\n      <td>503.255956</td>\n      <td>485.734227</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17697</th>\n      <td>4</td>\n      <td>522.877156</td>\n      <td>531.425302</td>\n      <td>496.266759</td>\n      <td>521.571098</td>\n      <td>501.987227</td>\n      <td>520.330224</td>\n      <td>533.479922</td>\n      <td>554.323597</td>\n      <td>545.339405</td>\n      <td>522.740585</td>\n      <td>524.488093</td>\n      <td>548.313281</td>\n      <td>533.971525</td>\n      <td>502.494092</td>\n      <td>482.508580</td>\n      <td>475.545204</td>\n      <td>515.761395</td>\n      <td>506.677339</td>\n      <td>502.772358</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18357</th>\n      <td>5</td>\n      <td>518.928843</td>\n      <td>519.123082</td>\n      <td>479.084527</td>\n      <td>511.788717</td>\n      <td>493.635879</td>\n      <td>521.300112</td>\n      <td>529.690076</td>\n      <td>542.799450</td>\n      <td>532.419252</td>\n      <td>516.344181</td>\n      <td>510.726020</td>\n      <td>538.696188</td>\n      <td>528.862207</td>\n      <td>496.909217</td>\n      <td>461.282085</td>\n      <td>462.003602</td>\n      <td>506.690720</td>\n      <td>496.491091</td>\n      <td>477.655689</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029086</th>\n      <td>1014</td>\n      <td>428.084574</td>\n      <td>486.099145</td>\n      <td>434.007325</td>\n      <td>470.238494</td>\n      <td>426.929563</td>\n      <td>461.685259</td>\n      <td>479.305537</td>\n      <td>481.603447</td>\n      <td>482.134102</td>\n      <td>472.782352</td>\n      <td>458.794501</td>\n      <td>485.641902</td>\n      <td>487.820103</td>\n      <td>423.330805</td>\n      <td>414.759543</td>\n      <td>410.158446</td>\n      <td>470.742159</td>\n      <td>451.558074</td>\n      <td>439.999561</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900044552</th>\n      <td>1015</td>\n      <td>506.135406</td>\n      <td>501.755675</td>\n      <td>441.515220</td>\n      <td>487.940728</td>\n      <td>475.953439</td>\n      <td>497.688529</td>\n      <td>502.735879</td>\n      <td>514.357314</td>\n      <td>500.875332</td>\n      <td>505.846055</td>\n      <td>494.667803</td>\n      <td>529.897337</td>\n      <td>514.894985</td>\n      <td>479.218491</td>\n      <td>414.404403</td>\n      <td>425.842085</td>\n      <td>496.148778</td>\n      <td>491.614218</td>\n      <td>470.632806</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900054944</th>\n      <td>1016</td>\n      <td>471.212499</td>\n      <td>494.243152</td>\n      <td>422.678038</td>\n      <td>464.086918</td>\n      <td>439.834718</td>\n      <td>477.171759</td>\n      <td>486.436765</td>\n      <td>488.877583</td>\n      <td>489.949104</td>\n      <td>475.444300</td>\n      <td>476.375077</td>\n      <td>505.542194</td>\n      <td>493.379799</td>\n      <td>470.743883</td>\n      <td>423.433889</td>\n      <td>413.119983</td>\n      <td>478.510037</td>\n      <td>472.765282</td>\n      <td>434.095321</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029096</th>\n      <td>1017</td>\n      <td>516.471106</td>\n      <td>518.699512</td>\n      <td>480.499865</td>\n      <td>512.699893</td>\n      <td>497.851787</td>\n      <td>510.147052</td>\n      <td>511.157301</td>\n      <td>527.377826</td>\n      <td>530.031048</td>\n      <td>511.948393</td>\n      <td>515.507792</td>\n      <td>543.378319</td>\n      <td>537.522651</td>\n      <td>490.562411</td>\n      <td>485.051815</td>\n      <td>503.140669</td>\n      <td>508.203663</td>\n      <td>500.313407</td>\n      <td>485.832311</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900047600</th>\n      <td>1018</td>\n      <td>537.854095</td>\n      <td>530.406944</td>\n      <td>513.481196</td>\n      <td>517.581046</td>\n      <td>518.363138</td>\n      <td>530.390511</td>\n      <td>521.928085</td>\n      <td>540.397409</td>\n      <td>521.474405</td>\n      <td>526.071806</td>\n      <td>530.774082</td>\n      <td>561.578317</td>\n      <td>541.536563</td>\n      <td>508.126298</td>\n      <td>510.832255</td>\n      <td>509.149879</td>\n      <td>517.992697</td>\n      <td>528.987450</td>\n      <td>506.978774</td>\n    </tr>\n  </tbody>\n</table>\n<p>1018 rows × 20 columns</p>\n</div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to df and examine\n",
    "# Make catchment lcld df\n",
    "lcld_df = pd.DataFrame()\n",
    "lcld_field_list = []\n",
    "for field in arcpy.ListFields(lcld_table):\n",
    "    lcld_field_list.append(field.name)\n",
    "lcld_arr = arcpy.da.TableToNumPyArray(lcld_table,lcld_field_list)\n",
    "lcld_df = pd.DataFrame(lcld_arr)\n",
    "#lcld_df = lcld_df.drop([\"OBJECTID\",\"AwcHuc12_cat_elev_ZONE_CODE\"],axis=1)\n",
    "lcld_df = lcld_df.set_index('cat_ID_con')\n",
    "#dfs.append(lcld_df)\n",
    "lcld_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table exported...\n"
     ]
    }
   ],
   "source": [
    "# Export LCLD table\n",
    "arcpy.TableToTable_conversion(lcld_table,outdir,'AKSSF_AWC_HUC12_wtd_lcld_mn.csv')\n",
    "print(f'Table exported...')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Drop unnecessary fields and rename as needed from merged tables.\n",
    "- Create Key value dictionary and use update cursor to rename fields."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables merged\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Input table names/paths\n",
    "cat_elev_ztables = [t for t in arcpy.ListTables('*_NhdAwcH12_cats_ElevZstats')]\n",
    "cat_slope_ztables = [t for t in arcpy.ListTables('*_NhdAwcH12_cats_SlopeZstats')]\n",
    "wtd_elev_ztables = [t for t in arcpy.ListTables('*_NhdAwcH12_wtd_mer_ElevZstats')]\n",
    "wtd_slope_ztables = [t for t in arcpy.ListTables('*_NhdAwcH12_wtd_mer_SlopeZstats')]\n",
    "wtd_pernorth_taba_tables = [t for t in arcpy.ListTables('*_NhdAwcH12_wtd_mer_PerNorth')]\n",
    "wtd_wet_taba_tables = [t for t in arcpy.ListTables('*_NhdAwcH12_wtd_mer_PerWet')]\n",
    "wtd_glac_tabint_tables = [t for t in arcpy.ListTables('*_NhdAwcH12_wtd_mer_PerGlac')]\n",
    "wtd_lp_tabint_tables = [t for t in arcpy.ListTables('*_NhdAwcH12_wtd_mer_PerLakes')]\n",
    "\n",
    "# Output Table names/paths\n",
    "wtd_per_north_table_out = os.path.join(outgdb, 'AKSSF_awchuc12_wtd_north_per')\n",
    "cat_elev_table_out = os.path.join(outgdb,'AKSSF_awchuc12_cat_elev')\n",
    "cat_slope_table_out = os.path.join(outgdb,'AKSSF_awchuc12_cat_slope')\n",
    "wtd_elev_table_out = os.path.join(outgdb, 'AKSSF_awchuc12_wtd_elev')\n",
    "wtd_per_glac_table_out = os.path.join(outgdb, 'AKSSF_awchuc12_wtd_glacier_per')\n",
    "wtd_per_lp_table_out = os.path.join(outgdb, 'AKSSF_awchuc12_wtd_lakepond_per')\n",
    "wtd_slope_table_out = os.path.join(outgdb, 'AKSSF_awchuc12_wtd_slope')\n",
    "wtd_wet_table_out = os.path.join(outgdb, 'AKSSF_awchuc12_wtd_wetland_per')\n",
    "\n",
    "# Merge all regional tables together\n",
    "outtables = []\n",
    "wtd_per_north = arcpy.Merge_management(wtd_pernorth_taba_tables, wtd_per_north_table_out)\n",
    "arcpy.AlterField_management(wtd_per_north,\"VALUE_0\",\"AwcHuc12_non_north_area\",\"AwcHuc12_non_north_area\")\n",
    "arcpy.AlterField_management(wtd_per_north,\"VALUE_1\",\"AwcHuc12_north_area\",\"AwcHuc12_north_area\")\n",
    "outtables.append(wtd_per_north)\n",
    "cat_elev = arcpy.Merge_management(cat_elev_ztables, cat_elev_table_out)\n",
    "outtables.append(cat_elev)\n",
    "wtd_elev = arcpy.Merge_management(wtd_elev_ztables, wtd_elev_table_out)\n",
    "outtables.append(wtd_elev)\n",
    "wtd_slope = arcpy.Merge_management(wtd_slope_ztables, wtd_slope_table_out)\n",
    "outtables.append(wtd_slope)\n",
    "cat_slope = arcpy.Merge_management(cat_slope_ztables, cat_slope_table_out)\n",
    "outtables.append(cat_slope)\n",
    "wtd_wet = arcpy.Merge_management(wtd_wet_taba_tables, wtd_wet_table_out)\n",
    "arcpy.AlterField_management(wtd_wet,\"VALUE_0\",\"AwcHuc12_non_wetland_area\",\"AwcHuc12_non_wetland_area\")\n",
    "arcpy.AlterField_management(wtd_wet,\"VALUE_1\",\"AwcHuc12_wetland_area\",\"AwcHuc12_wetland_area\")\n",
    "outtables.append(wtd_wet)\n",
    "wtd_glac = arcpy.Merge_management(wtd_glac_tabint_tables, wtd_per_glac_table_out)\n",
    "outtables.append(wtd_glac)\n",
    "wtd_lp = arcpy.Merge_management(wtd_lp_tabint_tables, wtd_per_lp_table_out)\n",
    "outtables.append(wtd_lp)\n",
    "print ('Tables merged')\n",
    "print('----------')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIN AwcHuc12_wtd_elev_MIN\n",
      "MAX AwcHuc12_wtd_elev_MAX\n",
      "MEAN AwcHuc12_wtd_elev_MEAN\n",
      "STD AwcHuc12_wtd_elev_STD\n",
      "ZONE_CODE AwcHuc12_cat_elev_ZONE_CODE\n",
      "COUNT AwcHuc12_cat_elev_COUNT\n",
      "AREA AwcHuc12_cat_elev_AREA\n",
      "MIN AwcHuc12_cat_elev_MIN\n",
      "MAX AwcHuc12_cat_elev_MAX\n",
      "RANGE AwcHuc12_cat_elev_RANGE\n",
      "MEAN AwcHuc12_cat_elev_MEAN\n",
      "STD AwcHuc12_cat_elev_STD\n",
      "SUM AwcHuc12_cat_elev_SUM\n",
      "VARIETY AwcHuc12_cat_elev_VARIETY\n",
      "MAJORITY AwcHuc12_cat_elev_MAJORITY\n",
      "MINORITY AwcHuc12_cat_elev_MINORITY\n",
      "MEDIAN AwcHuc12_cat_elev_MEDIAN\n",
      "PCT90 AwcHuc12_cat_elev_PCT90\n",
      "MIN AwcHuc12_wtd_slope_MIN\n",
      "MAX AwcHuc12_wtd_slope_MAX\n",
      "MEAN AwcHuc12_wtd_slope_MEAN\n",
      "STD AwcHuc12_wtd_slope_STD\n",
      "ZONE_CODE AwcHuc12_cat_slope_ZONE_CODE\n",
      "COUNT AwcHuc12_cat_slope_COUNT\n",
      "AREA AwcHuc12_cat_slope_AREA\n",
      "MIN AwcHuc12_cat_slope_MIN\n",
      "MAX AwcHuc12_cat_slope_MAX\n",
      "RANGE AwcHuc12_cat_slope_RANGE\n",
      "MEAN AwcHuc12_cat_slope_MEAN\n",
      "STD AwcHuc12_cat_slope_STD\n",
      "SUM AwcHuc12_cat_slope_SUM\n",
      "MEDIAN AwcHuc12_cat_slope_MEDIAN\n",
      "PCT90 AwcHuc12_cat_slope_PCT90\n"
     ]
    }
   ],
   "source": [
    "#Set up field dictionary\n",
    "elevDict = { 'ZONE_CODE': ('AwcHuc12_cat_elev_ZONE_CODE', 'AwcHuc12_wtd_elev_ZONE_CODE'),\n",
    "         'COUNT': ('AwcHuc12_cat_elev_COUNT', 'AwcHuc12_wtd_elev_COUNT'),\n",
    "          'AREA': ('AwcHuc12_cat_elev_AREA', 'AwcHuc12_wtd_elev_AREA'),\n",
    "          'MIN': ('AwcHuc12_cat_elev_MIN', 'AwcHuc12_wtd_elev_MIN'),\n",
    "          'MAX': ('AwcHuc12_cat_elev_MAX', 'AwcHuc12_wtd_elev_MAX'),\n",
    "          'RANGE': ('AwcHuc12_cat_elev_RANGE', 'AwcHuc12_wtd_elev_RANGE'),\n",
    "          'MEAN': ('AwcHuc12_cat_elev_MEAN', 'AwcHuc12_wtd_elev_MEAN'),\n",
    "          'STD': ('AwcHuc12_cat_elev_STD', 'AwcHuc12_wtd_elev_STD'),\n",
    "          'SUM': ('AwcHuc12_cat_elev_SUM', 'AwcHuc12_wtd_elev_SUM'),\n",
    "          'VARIETY': ('AwcHuc12_cat_elev_VARIETY', 'AwcHuc12_wtd_elev_VARIETY'),\n",
    "          'MAJORITY': ('AwcHuc12_cat_elev_MAJORITY', 'AwcHuc12_wtd_elev_MAJORITY'),\n",
    "          'MINORITY': ('AwcHuc12_cat_elev_MINORITY', 'AwcHuc12_wtd_elev_MINORITY'),\n",
    "          'MEDIAN': ('AwcHuc12_cat_elev_MEDIAN', 'AwcHuc12_wtd_elev_MEDIAN'),\n",
    "          'PCT90': ('AwcHuc12_cat_elev_PCT90', 'AwcHuc12_wtd_elev_PCT90')\n",
    "         }\n",
    "\n",
    "slopeDict = { 'ZONE_CODE': ('AwcHuc12_cat_slope_ZONE_CODE', 'AwcHuc12_wtd_slope_ZONE_CODE'),\n",
    "         'COUNT': ('AwcHuc12_cat_slope_COUNT', 'AwcHuc12_wtd_slope_COUNT'),\n",
    "          'AREA': ('AwcHuc12_cat_slope_AREA', 'AwcHuc12_wtd_slope_AREA'),\n",
    "          'MIN': ('AwcHuc12_cat_slope_MIN', 'AwcHuc12_wtd_slope_MIN'),\n",
    "          'MAX': ('AwcHuc12_cat_slope_MAX', 'AwcHuc12_wtd_slope_MAX'),\n",
    "          'RANGE': ('AwcHuc12_cat_slope_RANGE', 'AwcHuc12_wtd_slope_RANGE'),\n",
    "          'MEAN': ('AwcHuc12_cat_slope_MEAN', 'AwcHuc12_wtd_slope_MEAN'),\n",
    "          'STD': ('AwcHuc12_cat_slope_STD', 'AwcHuc12_wtd_slope_STD'),\n",
    "          'SUM': ('AwcHuc12_cat_slope_SUM', 'AwcHuc12_wtd_slope_SUM'),\n",
    "          'VARIETY': ('AwcHuc12_cat_slope_VARIETY', 'AwcHuc12_wtd_slope_VARIETY'),\n",
    "          'MAJORITY': ('AwcHuc12_cat_slope_MAJORITY', 'AwcHuc12_wtd_slope_MAJORITY'),\n",
    "          'MINORITY': ('AwcHuc12_cat_slope_MINORITY', 'AwcHuc12_wtd_slope_MINORITY'),\n",
    "          'MEDIAN': ('AwcHuc12_cat_slope_MEDIAN', 'AwcHuc12_wtd_slope_MEDIAN'),\n",
    "          'PCT90': ('AwcHuc12_cat_slope_PCT90', 'AwcHuc12_wtd_slope_PCT90')\n",
    "         }\n",
    "\n",
    "# Rename fields for elevation tables\n",
    "for field in arcpy.ListFields(wtd_elev):\n",
    "    keyval = field.name\n",
    "    if keyval in elevDict:\n",
    "        newname = elevDict[keyval][1]\n",
    "        newalias = elevDict[keyval][1]\n",
    "        print (keyval, newname)\n",
    "        arcpy.AlterField_management(wtd_elev, keyval, newname, newalias)\n",
    "\n",
    "for field in arcpy.ListFields(cat_elev):\n",
    "    keyval = field.name\n",
    "    if keyval in elevDict:\n",
    "        newname = elevDict[keyval][0]\n",
    "        newalias = elevDict[keyval][0]\n",
    "        print (keyval, newname)\n",
    "        arcpy.AlterField_management(cat_elev, keyval, newname, newalias)\n",
    "\n",
    "# Rename fields for slope tables\n",
    "for field in arcpy.ListFields(wtd_slope):\n",
    "    keyval = field.name\n",
    "    if keyval in slopeDict:\n",
    "        newname = slopeDict[keyval][1]\n",
    "        newalias = slopeDict[keyval][1]\n",
    "        print (keyval, newname)\n",
    "        arcpy.AlterField_management(wtd_slope, keyval, newname, newalias)\n",
    "\n",
    "for field in arcpy.ListFields(cat_slope):\n",
    "    keyval = field.name\n",
    "    if keyval in slopeDict:\n",
    "        newname = slopeDict[keyval][0]\n",
    "        newalias = slopeDict[keyval][0]\n",
    "        print (keyval, newname)\n",
    "        arcpy.AlterField_management(cat_slope, keyval, newname, newalias)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_awchuc12_wtd_north_per.csv\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_awchuc12_cat_elev.csv\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_awchuc12_wtd_elev.csv\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_awchuc12_wtd_slope.csv\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_awchuc12_cat_slope.csv\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_awchuc12_wtd_wetland_per.csv\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_awchuc12_wtd_glacier_per.csv\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_awchuc12_wtd_lakepond_per.csv\n"
     ]
    }
   ],
   "source": [
    "# # Export copies of dbf tables as csv\n",
    "for table in outtables:\n",
    "    tablename = arcpy.Describe(table).basename + \".csv\"\n",
    "    tablepath = os.path.join(outdir,tablename)\n",
    "    print( tablepath)\n",
    "    arcpy.conversion.TableToTable(table, outdir, tablename)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.2f}'.format # only display 2 decimal places\n",
    "# list to store covariate data frames\n",
    "dfs = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "                             AwcHuc12_cat_elev_COUNT  AwcHuc12_cat_elev_AREA  \\\ncat_ID_con                                                                     \nPrince_William_Sound_3038                    3448.00               344800.00   \nPrince_William_Sound_13227                    297.00                29700.00   \nPrince_William_Sound_17027                   4338.00               433800.00   \nPrince_William_Sound_17697                   2137.00               213700.00   \nPrince_William_Sound_18357                     80.00                 8000.00   \n...                                              ...                     ...   \nCopper_River_75003900029086                  1469.00               146900.00   \nCopper_River_75003900044552                 11111.00              1111100.00   \nCopper_River_75003900054944                   121.00                12100.00   \nCopper_River_75003900029096                     3.00                  300.00   \nCopper_River_75003900047600                  1022.00               102200.00   \n\n                             AwcHuc12_cat_elev_MIN  AwcHuc12_cat_elev_MAX  \\\ncat_ID_con                                                                  \nPrince_William_Sound_3038                        0                     96   \nPrince_William_Sound_13227                       0                     79   \nPrince_William_Sound_17027                       0                    208   \nPrince_William_Sound_17697                       3                    118   \nPrince_William_Sound_18357                       4                     12   \n...                                            ...                    ...   \nCopper_River_75003900029086                      2                      7   \nCopper_River_75003900044552                      3                    225   \nCopper_River_75003900054944                      3                      5   \nCopper_River_75003900029096                      3                      5   \nCopper_River_75003900047600                     16                    133   \n\n                             AwcHuc12_cat_elev_RANGE  AwcHuc12_cat_elev_MEAN  \\\ncat_ID_con                                                                     \nPrince_William_Sound_3038                         96                   10.59   \nPrince_William_Sound_13227                        79                   24.72   \nPrince_William_Sound_17027                       208                   70.89   \nPrince_William_Sound_17697                       115                   61.09   \nPrince_William_Sound_18357                         8                    6.31   \n...                                              ...                     ...   \nCopper_River_75003900029086                        5                    3.88   \nCopper_River_75003900044552                      222                   75.24   \nCopper_River_75003900054944                        2                    4.11   \nCopper_River_75003900029096                        2                    3.67   \nCopper_River_75003900047600                      117                   51.84   \n\n                             AwcHuc12_cat_elev_STD  AwcHuc12_cat_elev_SUM  \\\ncat_ID_con                                                                  \nPrince_William_Sound_3038                    10.72               36518.00   \nPrince_William_Sound_13227                   12.92                7342.00   \nPrince_William_Sound_17027                   35.61              307536.00   \nPrince_William_Sound_17697                   29.40              130546.00   \nPrince_William_Sound_18357                    1.91                 505.00   \n...                                            ...                    ...   \nCopper_River_75003900029086                   0.89                5696.00   \nCopper_River_75003900044552                  57.47              836045.00   \nCopper_River_75003900054944                   0.79                 497.00   \nCopper_River_75003900029096                   0.94                  11.00   \nCopper_River_75003900047600                  34.99               52985.00   \n\n                             AwcHuc12_cat_elev_VARIETY  \\\ncat_ID_con                                               \nPrince_William_Sound_3038                           93   \nPrince_William_Sound_13227                          60   \nPrince_William_Sound_17027                         201   \nPrince_William_Sound_17697                         116   \nPrince_William_Sound_18357                           9   \n...                                                ...   \nCopper_River_75003900029086                          6   \nCopper_River_75003900044552                        223   \nCopper_River_75003900054944                          3   \nCopper_River_75003900029096                          2   \nCopper_River_75003900047600                        115   \n\n                             AwcHuc12_cat_elev_MAJORITY  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                             5   \nPrince_William_Sound_13227                           14   \nPrince_William_Sound_17027                           48   \nPrince_William_Sound_17697                            3   \nPrince_William_Sound_18357                            5   \n...                                                 ...   \nCopper_River_75003900029086                           4   \nCopper_River_75003900044552                           5   \nCopper_River_75003900054944                           5   \nCopper_River_75003900029096                           3   \nCopper_River_75003900047600                          18   \n\n                             AwcHuc12_cat_elev_MINORITY  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                            27   \nPrince_William_Sound_13227                            1   \nPrince_William_Sound_17027                            0   \nPrince_William_Sound_17697                           25   \nPrince_William_Sound_18357                           12   \n...                                                 ...   \nCopper_River_75003900029086                           7   \nCopper_River_75003900044552                         225   \nCopper_River_75003900054944                           3   \nCopper_River_75003900029096                           5   \nCopper_River_75003900047600                          53   \n\n                             AwcHuc12_cat_elev_MEDIAN  AwcHuc12_cat_elev_PCT90  \ncat_ID_con                                                                      \nPrince_William_Sound_3038                           8                       17  \nPrince_William_Sound_13227                         22                       37  \nPrince_William_Sound_17027                         61                      119  \nPrince_William_Sound_17697                         60                      101  \nPrince_William_Sound_18357                          5                        9  \n...                                               ...                      ...  \nCopper_River_75003900029086                         4                        5  \nCopper_River_75003900044552                        59                      153  \nCopper_River_75003900054944                         4                        5  \nCopper_River_75003900029096                         3                        5  \nCopper_River_75003900047600                        35                      104  \n\n[1018 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AwcHuc12_cat_elev_COUNT</th>\n      <th>AwcHuc12_cat_elev_AREA</th>\n      <th>AwcHuc12_cat_elev_MIN</th>\n      <th>AwcHuc12_cat_elev_MAX</th>\n      <th>AwcHuc12_cat_elev_RANGE</th>\n      <th>AwcHuc12_cat_elev_MEAN</th>\n      <th>AwcHuc12_cat_elev_STD</th>\n      <th>AwcHuc12_cat_elev_SUM</th>\n      <th>AwcHuc12_cat_elev_VARIETY</th>\n      <th>AwcHuc12_cat_elev_MAJORITY</th>\n      <th>AwcHuc12_cat_elev_MINORITY</th>\n      <th>AwcHuc12_cat_elev_MEDIAN</th>\n      <th>AwcHuc12_cat_elev_PCT90</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Prince_William_Sound_3038</th>\n      <td>3448.00</td>\n      <td>344800.00</td>\n      <td>0</td>\n      <td>96</td>\n      <td>96</td>\n      <td>10.59</td>\n      <td>10.72</td>\n      <td>36518.00</td>\n      <td>93</td>\n      <td>5</td>\n      <td>27</td>\n      <td>8</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_13227</th>\n      <td>297.00</td>\n      <td>29700.00</td>\n      <td>0</td>\n      <td>79</td>\n      <td>79</td>\n      <td>24.72</td>\n      <td>12.92</td>\n      <td>7342.00</td>\n      <td>60</td>\n      <td>14</td>\n      <td>1</td>\n      <td>22</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17027</th>\n      <td>4338.00</td>\n      <td>433800.00</td>\n      <td>0</td>\n      <td>208</td>\n      <td>208</td>\n      <td>70.89</td>\n      <td>35.61</td>\n      <td>307536.00</td>\n      <td>201</td>\n      <td>48</td>\n      <td>0</td>\n      <td>61</td>\n      <td>119</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17697</th>\n      <td>2137.00</td>\n      <td>213700.00</td>\n      <td>3</td>\n      <td>118</td>\n      <td>115</td>\n      <td>61.09</td>\n      <td>29.40</td>\n      <td>130546.00</td>\n      <td>116</td>\n      <td>3</td>\n      <td>25</td>\n      <td>60</td>\n      <td>101</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18357</th>\n      <td>80.00</td>\n      <td>8000.00</td>\n      <td>4</td>\n      <td>12</td>\n      <td>8</td>\n      <td>6.31</td>\n      <td>1.91</td>\n      <td>505.00</td>\n      <td>9</td>\n      <td>5</td>\n      <td>12</td>\n      <td>5</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029086</th>\n      <td>1469.00</td>\n      <td>146900.00</td>\n      <td>2</td>\n      <td>7</td>\n      <td>5</td>\n      <td>3.88</td>\n      <td>0.89</td>\n      <td>5696.00</td>\n      <td>6</td>\n      <td>4</td>\n      <td>7</td>\n      <td>4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900044552</th>\n      <td>11111.00</td>\n      <td>1111100.00</td>\n      <td>3</td>\n      <td>225</td>\n      <td>222</td>\n      <td>75.24</td>\n      <td>57.47</td>\n      <td>836045.00</td>\n      <td>223</td>\n      <td>5</td>\n      <td>225</td>\n      <td>59</td>\n      <td>153</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900054944</th>\n      <td>121.00</td>\n      <td>12100.00</td>\n      <td>3</td>\n      <td>5</td>\n      <td>2</td>\n      <td>4.11</td>\n      <td>0.79</td>\n      <td>497.00</td>\n      <td>3</td>\n      <td>5</td>\n      <td>3</td>\n      <td>4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029096</th>\n      <td>3.00</td>\n      <td>300.00</td>\n      <td>3</td>\n      <td>5</td>\n      <td>2</td>\n      <td>3.67</td>\n      <td>0.94</td>\n      <td>11.00</td>\n      <td>2</td>\n      <td>3</td>\n      <td>5</td>\n      <td>3</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900047600</th>\n      <td>1022.00</td>\n      <td>102200.00</td>\n      <td>16</td>\n      <td>133</td>\n      <td>117</td>\n      <td>51.84</td>\n      <td>34.99</td>\n      <td>52985.00</td>\n      <td>115</td>\n      <td>18</td>\n      <td>53</td>\n      <td>35</td>\n      <td>104</td>\n    </tr>\n  </tbody>\n</table>\n<p>1018 rows × 13 columns</p>\n</div>"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make catchment elev df\n",
    "cat_df = pd.DataFrame()\n",
    "cat_field_list = []\n",
    "for field in arcpy.ListFields(cat_elev):\n",
    "    cat_field_list.append(field.name)\n",
    "cat_elev_arr = arcpy.da.TableToNumPyArray(cat_elev,cat_field_list)\n",
    "cat_df = pd.DataFrame(cat_elev_arr)\n",
    "cat_df = cat_df.drop([\"OBJECTID\",\"AwcHuc12_cat_elev_ZONE_CODE\",\"region\",\"cat_ID_txt\"],axis=1)\n",
    "cat_df = cat_df.set_index('cat_ID_con')\n",
    "dfs.append(cat_df)\n",
    "cat_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "                             AwcHuc12_cat_slope_COUNT  \\\ncat_ID_con                                              \nPrince_William_Sound_3038                     3448.00   \nPrince_William_Sound_13227                     297.00   \nPrince_William_Sound_17027                    4338.00   \nPrince_William_Sound_17697                    2137.00   \nPrince_William_Sound_18357                      80.00   \n...                                               ...   \nCopper_River_75003900029086                   1469.00   \nCopper_River_75003900044552                  11111.00   \nCopper_River_75003900054944                    121.00   \nCopper_River_75003900029096                      3.00   \nCopper_River_75003900047600                   1022.00   \n\n                             AwcHuc12_cat_slope_AREA  AwcHuc12_cat_slope_MIN  \\\ncat_ID_con                                                                     \nPrince_William_Sound_3038                  344800.00                    0.00   \nPrince_William_Sound_13227                  29700.00                    0.00   \nPrince_William_Sound_17027                 433800.00                    0.00   \nPrince_William_Sound_17697                 213700.00                    0.00   \nPrince_William_Sound_18357                   8000.00                    0.00   \n...                                              ...                     ...   \nCopper_River_75003900029086                146900.00                    0.00   \nCopper_River_75003900044552               1111100.00                    0.00   \nCopper_River_75003900054944                 12100.00                    0.00   \nCopper_River_75003900029096                   300.00                    3.38   \nCopper_River_75003900047600                102200.00                    0.00   \n\n                             AwcHuc12_cat_slope_MAX  AwcHuc12_cat_slope_RANGE  \\\ncat_ID_con                                                                      \nPrince_William_Sound_3038                     24.19                     24.19   \nPrince_William_Sound_13227                    22.82                     22.82   \nPrince_William_Sound_17027                    37.53                     37.53   \nPrince_William_Sound_17697                    38.09                     38.09   \nPrince_William_Sound_18357                    11.41                     11.41   \n...                                             ...                       ...   \nCopper_River_75003900029086                    6.71                      6.71   \nCopper_River_75003900044552                   37.33                     37.33   \nCopper_River_75003900054944                    3.44                      3.44   \nCopper_River_75003900029096                    7.62                      4.23   \nCopper_River_75003900047600                   37.44                     37.44   \n\n                             AwcHuc12_cat_slope_MEAN  AwcHuc12_cat_slope_STD  \\\ncat_ID_con                                                                     \nPrince_William_Sound_3038                       5.34                    4.35   \nPrince_William_Sound_13227                      8.72                    3.92   \nPrince_William_Sound_17027                     11.51                    6.66   \nPrince_William_Sound_17697                     14.63                    7.43   \nPrince_William_Sound_18357                      3.54                    2.37   \n...                                              ...                     ...   \nCopper_River_75003900029086                     0.93                    1.49   \nCopper_River_75003900044552                    10.44                    8.06   \nCopper_River_75003900054944                     0.97                    1.32   \nCopper_River_75003900029096                     5.79                    1.78   \nCopper_River_75003900047600                    10.84                    6.88   \n\n                             AwcHuc12_cat_slope_SUM  \\\ncat_ID_con                                            \nPrince_William_Sound_3038                  18396.22   \nPrince_William_Sound_13227                  2589.60   \nPrince_William_Sound_17027                 49949.38   \nPrince_William_Sound_17697                 31268.21   \nPrince_William_Sound_18357                   282.92   \n...                                             ...   \nCopper_River_75003900029086                 1367.85   \nCopper_River_75003900044552               115974.51   \nCopper_River_75003900054944                  117.25   \nCopper_River_75003900029096                   17.37   \nCopper_River_75003900047600                11083.36   \n\n                             AwcHuc12_cat_slope_MEDIAN  \\\ncat_ID_con                                               \nPrince_William_Sound_3038                         4.04   \nPrince_William_Sound_13227                        8.50   \nPrince_William_Sound_17027                       10.36   \nPrince_William_Sound_17697                       14.78   \nPrince_William_Sound_18357                        3.20   \n...                                                ...   \nCopper_River_75003900029086                       0.00   \nCopper_River_75003900044552                       8.11   \nCopper_River_75003900054944                       0.00   \nCopper_River_75003900029096                       6.37   \nCopper_River_75003900047600                       9.58   \n\n                             AwcHuc12_cat_slope_PCT90  \ncat_ID_con                                             \nPrince_William_Sound_3038                       11.39  \nPrince_William_Sound_13227                      13.66  \nPrince_William_Sound_17027                      20.81  \nPrince_William_Sound_17697                      24.27  \nPrince_William_Sound_18357                       6.75  \n...                                               ...  \nCopper_River_75003900029086                      3.37  \nCopper_River_75003900044552                     22.92  \nCopper_River_75003900054944                      2.85  \nCopper_River_75003900029096                      7.37  \nCopper_River_75003900047600                     19.53  \n\n[1018 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AwcHuc12_cat_slope_COUNT</th>\n      <th>AwcHuc12_cat_slope_AREA</th>\n      <th>AwcHuc12_cat_slope_MIN</th>\n      <th>AwcHuc12_cat_slope_MAX</th>\n      <th>AwcHuc12_cat_slope_RANGE</th>\n      <th>AwcHuc12_cat_slope_MEAN</th>\n      <th>AwcHuc12_cat_slope_STD</th>\n      <th>AwcHuc12_cat_slope_SUM</th>\n      <th>AwcHuc12_cat_slope_MEDIAN</th>\n      <th>AwcHuc12_cat_slope_PCT90</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Prince_William_Sound_3038</th>\n      <td>3448.00</td>\n      <td>344800.00</td>\n      <td>0.00</td>\n      <td>24.19</td>\n      <td>24.19</td>\n      <td>5.34</td>\n      <td>4.35</td>\n      <td>18396.22</td>\n      <td>4.04</td>\n      <td>11.39</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_13227</th>\n      <td>297.00</td>\n      <td>29700.00</td>\n      <td>0.00</td>\n      <td>22.82</td>\n      <td>22.82</td>\n      <td>8.72</td>\n      <td>3.92</td>\n      <td>2589.60</td>\n      <td>8.50</td>\n      <td>13.66</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17027</th>\n      <td>4338.00</td>\n      <td>433800.00</td>\n      <td>0.00</td>\n      <td>37.53</td>\n      <td>37.53</td>\n      <td>11.51</td>\n      <td>6.66</td>\n      <td>49949.38</td>\n      <td>10.36</td>\n      <td>20.81</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17697</th>\n      <td>2137.00</td>\n      <td>213700.00</td>\n      <td>0.00</td>\n      <td>38.09</td>\n      <td>38.09</td>\n      <td>14.63</td>\n      <td>7.43</td>\n      <td>31268.21</td>\n      <td>14.78</td>\n      <td>24.27</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18357</th>\n      <td>80.00</td>\n      <td>8000.00</td>\n      <td>0.00</td>\n      <td>11.41</td>\n      <td>11.41</td>\n      <td>3.54</td>\n      <td>2.37</td>\n      <td>282.92</td>\n      <td>3.20</td>\n      <td>6.75</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029086</th>\n      <td>1469.00</td>\n      <td>146900.00</td>\n      <td>0.00</td>\n      <td>6.71</td>\n      <td>6.71</td>\n      <td>0.93</td>\n      <td>1.49</td>\n      <td>1367.85</td>\n      <td>0.00</td>\n      <td>3.37</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900044552</th>\n      <td>11111.00</td>\n      <td>1111100.00</td>\n      <td>0.00</td>\n      <td>37.33</td>\n      <td>37.33</td>\n      <td>10.44</td>\n      <td>8.06</td>\n      <td>115974.51</td>\n      <td>8.11</td>\n      <td>22.92</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900054944</th>\n      <td>121.00</td>\n      <td>12100.00</td>\n      <td>0.00</td>\n      <td>3.44</td>\n      <td>3.44</td>\n      <td>0.97</td>\n      <td>1.32</td>\n      <td>117.25</td>\n      <td>0.00</td>\n      <td>2.85</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029096</th>\n      <td>3.00</td>\n      <td>300.00</td>\n      <td>3.38</td>\n      <td>7.62</td>\n      <td>4.23</td>\n      <td>5.79</td>\n      <td>1.78</td>\n      <td>17.37</td>\n      <td>6.37</td>\n      <td>7.37</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900047600</th>\n      <td>1022.00</td>\n      <td>102200.00</td>\n      <td>0.00</td>\n      <td>37.44</td>\n      <td>37.44</td>\n      <td>10.84</td>\n      <td>6.88</td>\n      <td>11083.36</td>\n      <td>9.58</td>\n      <td>19.53</td>\n    </tr>\n  </tbody>\n</table>\n<p>1018 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make catchment slope df\n",
    "cat_sl_df = pd.DataFrame()\n",
    "cat_sl_field_list = []\n",
    "for field in arcpy.ListFields(cat_slope):\n",
    "    cat_sl_field_list.append(field.name)\n",
    "cat_sl_arr = arcpy.da.TableToNumPyArray(cat_slope, cat_sl_field_list)\n",
    "cat_sl_df = pd.DataFrame(cat_sl_arr)\n",
    "cat_sl_df = cat_sl_df.drop([\"OBJECTID\", \"AwcHuc12_cat_slope_ZONE_CODE\",\"region\",\"cat_ID_txt\"],axis=1)\n",
    "cat_sl_df = cat_sl_df.set_index('cat_ID_con')\n",
    "dfs.append(cat_sl_df)\n",
    "cat_sl_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "                             AwcHuc12_wtd_elev_MIN  AwcHuc12_wtd_elev_MAX  \\\ncat_ID_con                                                                  \nPrince_William_Sound_3038                        0                    678   \nPrince_William_Sound_13227                       0                    580   \nPrince_William_Sound_17027                       0                    553   \nPrince_William_Sound_17697                       3                    692   \nPrince_William_Sound_18357                       2                    813   \n...                                            ...                    ...   \nCopper_River_75003900029086                      0                     20   \nCopper_River_75003900044552                      3                    527   \nCopper_River_75003900054944                      3                     66   \nCopper_River_75003900029096                      2                    984   \nCopper_River_75003900047600                     16                   1461   \n\n                             AwcHuc12_wtd_elev_MEAN  AwcHuc12_wtd_elev_STD  \ncat_ID_con                                                                  \nPrince_William_Sound_3038                    201.13                 162.71  \nPrince_William_Sound_13227                   223.81                 125.00  \nPrince_William_Sound_17027                   206.91                 108.41  \nPrince_William_Sound_17697                   286.20                 140.33  \nPrince_William_Sound_18357                   264.07                 169.95  \n...                                             ...                    ...  \nCopper_River_75003900029086                    8.58                   3.16  \nCopper_River_75003900044552                  180.59                 118.27  \nCopper_River_75003900054944                    7.66                   6.13  \nCopper_River_75003900029096                  362.76                 234.41  \nCopper_River_75003900047600                  618.83                 314.66  \n\n[1018 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AwcHuc12_wtd_elev_MIN</th>\n      <th>AwcHuc12_wtd_elev_MAX</th>\n      <th>AwcHuc12_wtd_elev_MEAN</th>\n      <th>AwcHuc12_wtd_elev_STD</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Prince_William_Sound_3038</th>\n      <td>0</td>\n      <td>678</td>\n      <td>201.13</td>\n      <td>162.71</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_13227</th>\n      <td>0</td>\n      <td>580</td>\n      <td>223.81</td>\n      <td>125.00</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17027</th>\n      <td>0</td>\n      <td>553</td>\n      <td>206.91</td>\n      <td>108.41</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17697</th>\n      <td>3</td>\n      <td>692</td>\n      <td>286.20</td>\n      <td>140.33</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18357</th>\n      <td>2</td>\n      <td>813</td>\n      <td>264.07</td>\n      <td>169.95</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029086</th>\n      <td>0</td>\n      <td>20</td>\n      <td>8.58</td>\n      <td>3.16</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900044552</th>\n      <td>3</td>\n      <td>527</td>\n      <td>180.59</td>\n      <td>118.27</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900054944</th>\n      <td>3</td>\n      <td>66</td>\n      <td>7.66</td>\n      <td>6.13</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029096</th>\n      <td>2</td>\n      <td>984</td>\n      <td>362.76</td>\n      <td>234.41</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900047600</th>\n      <td>16</td>\n      <td>1461</td>\n      <td>618.83</td>\n      <td>314.66</td>\n    </tr>\n  </tbody>\n</table>\n<p>1018 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make watershed elev df\n",
    "wtd_df = pd.DataFrame()\n",
    "wtd_field_list = []\n",
    "for field in arcpy.ListFields(wtd_elev):\n",
    "    wtd_field_list.append(field.name)\n",
    "wtd_elev_arr = arcpy.da.TableToNumPyArray(wtd_elev,wtd_field_list)\n",
    "wtd_df = pd.DataFrame(wtd_elev_arr)\n",
    "wtd_df = wtd_df.drop([\"OBJECTID\",\"NHDPlusID\",\"cat_ID\",\"region\", \"cat_ID_txt\"],axis=1)\n",
    "wtd_df = wtd_df.set_index('cat_ID_con')\n",
    "dfs.append(wtd_df)\n",
    "wtd_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "                             AwcHuc12_wtd_slope_MIN  AwcHuc12_wtd_slope_MAX  \\\ncat_ID_con                                                                    \nPrince_William_Sound_3038                      0.00                   59.63   \nPrince_William_Sound_13227                     0.00                   57.61   \nPrince_William_Sound_17027                     0.00                   61.26   \nPrince_William_Sound_17697                     0.00                   63.16   \nPrince_William_Sound_18357                     0.00                   57.00   \n...                                             ...                     ...   \nCopper_River_75003900029086                    0.00                   16.20   \nCopper_River_75003900044552                    0.00                   55.48   \nCopper_River_75003900054944                    0.00                   26.16   \nCopper_River_75003900029096                    0.00                   74.22   \nCopper_River_75003900047600                    0.00                   75.85   \n\n                             AwcHuc12_wtd_slope_MEAN  AwcHuc12_wtd_slope_STD  \ncat_ID_con                                                                    \nPrince_William_Sound_3038                      15.49                   11.44  \nPrince_William_Sound_13227                     23.72                   10.73  \nPrince_William_Sound_17027                     15.85                   10.88  \nPrince_William_Sound_17697                     18.06                   11.76  \nPrince_William_Sound_18357                     20.20                   11.88  \n...                                              ...                     ...  \nCopper_River_75003900029086                     1.31                    1.74  \nCopper_River_75003900044552                    12.94                    8.59  \nCopper_River_75003900054944                     2.09                    2.88  \nCopper_River_75003900029096                    25.07                   14.59  \nCopper_River_75003900047600                    26.98                   13.39  \n\n[1018 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AwcHuc12_wtd_slope_MIN</th>\n      <th>AwcHuc12_wtd_slope_MAX</th>\n      <th>AwcHuc12_wtd_slope_MEAN</th>\n      <th>AwcHuc12_wtd_slope_STD</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Prince_William_Sound_3038</th>\n      <td>0.00</td>\n      <td>59.63</td>\n      <td>15.49</td>\n      <td>11.44</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_13227</th>\n      <td>0.00</td>\n      <td>57.61</td>\n      <td>23.72</td>\n      <td>10.73</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17027</th>\n      <td>0.00</td>\n      <td>61.26</td>\n      <td>15.85</td>\n      <td>10.88</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17697</th>\n      <td>0.00</td>\n      <td>63.16</td>\n      <td>18.06</td>\n      <td>11.76</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18357</th>\n      <td>0.00</td>\n      <td>57.00</td>\n      <td>20.20</td>\n      <td>11.88</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029086</th>\n      <td>0.00</td>\n      <td>16.20</td>\n      <td>1.31</td>\n      <td>1.74</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900044552</th>\n      <td>0.00</td>\n      <td>55.48</td>\n      <td>12.94</td>\n      <td>8.59</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900054944</th>\n      <td>0.00</td>\n      <td>26.16</td>\n      <td>2.09</td>\n      <td>2.88</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029096</th>\n      <td>0.00</td>\n      <td>74.22</td>\n      <td>25.07</td>\n      <td>14.59</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900047600</th>\n      <td>0.00</td>\n      <td>75.85</td>\n      <td>26.98</td>\n      <td>13.39</td>\n    </tr>\n  </tbody>\n</table>\n<p>1018 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make watershed slope df\n",
    "wtd_sl_df = pd.DataFrame()\n",
    "wtd_sl_field_list = []\n",
    "for field in arcpy.ListFields(wtd_slope):\n",
    "    wtd_sl_field_list.append(field.name)\n",
    "wtd_sl_arr = arcpy.da.TableToNumPyArray(wtd_slope, wtd_sl_field_list)\n",
    "wtd_sl_df = pd.DataFrame(wtd_sl_arr)\n",
    "wtd_sl_df = wtd_sl_df.drop([\"OBJECTID\",\"NHDPlusID\",\"cat_ID\",\"region\",\"cat_ID\",\"cat_ID_txt\",\"NHDPlusID\"],axis=1)\n",
    "wtd_sl_df = wtd_sl_df.set_index('cat_ID_con')\n",
    "dfs.append(wtd_sl_df)\n",
    "wtd_sl_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "                             AwcHuc12_non_north_area  AwcHuc12_north_area  \\\ncat_ID_con                                                                  \nPrince_William_Sound_3038                24066600.00           8352000.00   \nPrince_William_Sound_13227                 679900.00            627900.00   \nPrince_William_Sound_17027                2596000.00           1163500.00   \nPrince_William_Sound_17697                6874200.00           2365900.00   \nPrince_William_Sound_18357               15359800.00           4876600.00   \n...                                              ...                  ...   \nCopper_River_75003900029086              17465000.00           1929700.00   \nCopper_River_75003900044552              10002100.00           2113300.00   \nCopper_River_75003900054944               7381300.00           1345600.00   \nCopper_River_75003900029096              14284800.00           3542200.00   \nCopper_River_75003900047600              42358100.00          12046500.00   \n\n                             NhdAwcH12_wtd_north_per  \ncat_ID_con                                            \nPrince_William_Sound_3038                      25.76  \nPrince_William_Sound_13227                     48.01  \nPrince_William_Sound_17027                     30.95  \nPrince_William_Sound_17697                     25.60  \nPrince_William_Sound_18357                     24.10  \n...                                              ...  \nCopper_River_75003900029086                     9.95  \nCopper_River_75003900044552                    17.44  \nCopper_River_75003900054944                    15.42  \nCopper_River_75003900029096                    19.87  \nCopper_River_75003900047600                    22.14  \n\n[1018 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AwcHuc12_non_north_area</th>\n      <th>AwcHuc12_north_area</th>\n      <th>NhdAwcH12_wtd_north_per</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Prince_William_Sound_3038</th>\n      <td>24066600.00</td>\n      <td>8352000.00</td>\n      <td>25.76</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_13227</th>\n      <td>679900.00</td>\n      <td>627900.00</td>\n      <td>48.01</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17027</th>\n      <td>2596000.00</td>\n      <td>1163500.00</td>\n      <td>30.95</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17697</th>\n      <td>6874200.00</td>\n      <td>2365900.00</td>\n      <td>25.60</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18357</th>\n      <td>15359800.00</td>\n      <td>4876600.00</td>\n      <td>24.10</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029086</th>\n      <td>17465000.00</td>\n      <td>1929700.00</td>\n      <td>9.95</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900044552</th>\n      <td>10002100.00</td>\n      <td>2113300.00</td>\n      <td>17.44</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900054944</th>\n      <td>7381300.00</td>\n      <td>1345600.00</td>\n      <td>15.42</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029096</th>\n      <td>14284800.00</td>\n      <td>3542200.00</td>\n      <td>19.87</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900047600</th>\n      <td>42358100.00</td>\n      <td>12046500.00</td>\n      <td>22.14</td>\n    </tr>\n  </tbody>\n</table>\n<p>1018 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make watershed north df\n",
    "wtd_n_df = pd.DataFrame()\n",
    "wtd_n_field_list = []\n",
    "for field in arcpy.ListFields(wtd_per_north):\n",
    "    wtd_n_field_list.append(field.name)\n",
    "wtd_n_arr = arcpy.da.TableToNumPyArray(wtd_per_north,wtd_n_field_list)\n",
    "wtd_n_df = pd.DataFrame(wtd_n_arr)\n",
    "wtd_n_df = wtd_n_df.drop([\"OBJECTID\",\"region\",\"cat_ID_txt\"],axis=1)\n",
    "wtd_n_df = wtd_n_df.set_index('cat_ID_con')\n",
    "dfs.append(wtd_n_df)\n",
    "wtd_n_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "                             AwcHuc12_non_wetland_area  AwcHuc12_wetland_area  \\\ncat_ID_con                                                                      \nPrince_William_Sound_3038                  25232500.00             7186100.00   \nPrince_William_Sound_13227                  1298800.00                9000.00   \nPrince_William_Sound_17027                  3275800.00              483700.00   \nPrince_William_Sound_17697                  8549500.00              690600.00   \nPrince_William_Sound_18357                 19103600.00             1132800.00   \n...                                                ...                    ...   \nCopper_River_75003900029086                  318600.00            19076100.00   \nCopper_River_75003900044552                10373300.00             1742100.00   \nCopper_River_75003900054944                 5613800.00             3113100.00   \nCopper_River_75003900029096                17048200.00              778800.00   \nCopper_River_75003900047600                54245300.00              159300.00   \n\n                             NhdAwcH12_wtd_wet_per  \ncat_ID_con                                          \nPrince_William_Sound_3038                    22.17  \nPrince_William_Sound_13227                    0.69  \nPrince_William_Sound_17027                   12.87  \nPrince_William_Sound_17697                    7.47  \nPrince_William_Sound_18357                    5.60  \n...                                            ...  \nCopper_River_75003900029086                  98.36  \nCopper_River_75003900044552                  14.38  \nCopper_River_75003900054944                  35.67  \nCopper_River_75003900029096                   4.37  \nCopper_River_75003900047600                   0.29  \n\n[1018 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AwcHuc12_non_wetland_area</th>\n      <th>AwcHuc12_wetland_area</th>\n      <th>NhdAwcH12_wtd_wet_per</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Prince_William_Sound_3038</th>\n      <td>25232500.00</td>\n      <td>7186100.00</td>\n      <td>22.17</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_13227</th>\n      <td>1298800.00</td>\n      <td>9000.00</td>\n      <td>0.69</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17027</th>\n      <td>3275800.00</td>\n      <td>483700.00</td>\n      <td>12.87</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17697</th>\n      <td>8549500.00</td>\n      <td>690600.00</td>\n      <td>7.47</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18357</th>\n      <td>19103600.00</td>\n      <td>1132800.00</td>\n      <td>5.60</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029086</th>\n      <td>318600.00</td>\n      <td>19076100.00</td>\n      <td>98.36</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900044552</th>\n      <td>10373300.00</td>\n      <td>1742100.00</td>\n      <td>14.38</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900054944</th>\n      <td>5613800.00</td>\n      <td>3113100.00</td>\n      <td>35.67</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029096</th>\n      <td>17048200.00</td>\n      <td>778800.00</td>\n      <td>4.37</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900047600</th>\n      <td>54245300.00</td>\n      <td>159300.00</td>\n      <td>0.29</td>\n    </tr>\n  </tbody>\n</table>\n<p>1018 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make watershed wetland df\n",
    "wtd_wet_df = pd.DataFrame()\n",
    "wtd_wet_field_list = []\n",
    "for field in arcpy.ListFields(wtd_wet):\n",
    "    wtd_wet_field_list.append(field.name)\n",
    "wtd_wet_arr = arcpy.da.TableToNumPyArray(wtd_wet,wtd_wet_field_list)\n",
    "wtd_wet_df = pd.DataFrame(wtd_wet_arr)\n",
    "wtd_wet_df = wtd_wet_df.drop([\"OBJECTID\",\"region\",\"cat_ID_txt\"],axis=1)\n",
    "wtd_wet_df = wtd_wet_df.set_index('cat_ID_con')\n",
    "dfs.append(wtd_wet_df)\n",
    "wtd_wet_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "                             NhdAwcH12_wtd_lake_area_sqm  \\\ncat_ID_con                                                 \nPrince_William_Sound_17027                       5688.95   \nPrince_William_Sound_17697                      38507.61   \nPrince_William_Sound_18357                       6904.33   \nPrince_William_Sound_18547                      25771.29   \nPrince_William_Sound_18737                      90355.70   \n...                                                  ...   \nCopper_River_75019800020292                   1707529.72   \nCopper_River_75019800020572                   5727440.86   \nCopper_River_75019800020746                   7836889.55   \nCopper_River_75019800020803                   2748705.84   \nCopper_River_75019800020900                    615127.57   \n\n                             NhdAwcH12_wtd_lake_per  \ncat_ID_con                                           \nPrince_William_Sound_17027                     0.15  \nPrince_William_Sound_17697                     0.42  \nPrince_William_Sound_18357                     0.03  \nPrince_William_Sound_18547                     0.11  \nPrince_William_Sound_18737                     0.14  \n...                                             ...  \nCopper_River_75019800020292                    0.54  \nCopper_River_75019800020572                    0.61  \nCopper_River_75019800020746                    1.75  \nCopper_River_75019800020803                    5.04  \nCopper_River_75019800020900                    0.20  \n\n[967 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NhdAwcH12_wtd_lake_area_sqm</th>\n      <th>NhdAwcH12_wtd_lake_per</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Prince_William_Sound_17027</th>\n      <td>5688.95</td>\n      <td>0.15</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17697</th>\n      <td>38507.61</td>\n      <td>0.42</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18357</th>\n      <td>6904.33</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18547</th>\n      <td>25771.29</td>\n      <td>0.11</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18737</th>\n      <td>90355.70</td>\n      <td>0.14</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75019800020292</th>\n      <td>1707529.72</td>\n      <td>0.54</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75019800020572</th>\n      <td>5727440.86</td>\n      <td>0.61</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75019800020746</th>\n      <td>7836889.55</td>\n      <td>1.75</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75019800020803</th>\n      <td>2748705.84</td>\n      <td>5.04</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75019800020900</th>\n      <td>615127.57</td>\n      <td>0.20</td>\n    </tr>\n  </tbody>\n</table>\n<p>967 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make watershed lakes df\n",
    "wtd_lp_df = pd.DataFrame()\n",
    "wtd_lp_field_list = []\n",
    "for field in arcpy.ListFields(wtd_lp):\n",
    "    wtd_lp_field_list.append(field.name)\n",
    "wtd_lp_arr = arcpy.da.TableToNumPyArray(wtd_lp, wtd_lp_field_list)\n",
    "wtd_lp_df = pd.DataFrame(wtd_lp_arr)\n",
    "wtd_lp_df = wtd_lp_df.drop([\"OBJECTID\",\"region\",\"cat_ID_txt\",\"cat_ID\",\"FType\"],axis=1)\n",
    "wtd_lp_df = wtd_lp_df.set_index('cat_ID_con')\n",
    "dfs.append(wtd_lp_df)\n",
    "wtd_lp_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "data": {
      "text/plain": "                             NhdAwcH12_wtd_glacier_area_sqm  \\\ncat_ID_con                                                    \nPrince_William_Sound_18357                        255413.00   \nPrince_William_Sound_18547                         83990.36   \nPrince_William_Sound_18737                        866494.65   \nPrince_William_Sound_18747                        866494.65   \nPrince_William_Sound_27856                        176024.99   \n...                                                     ...   \nCopper_River_75019800018811                    106387407.76   \nCopper_River_75019800019142                     12957496.80   \nCopper_River_75019800019853                     12957496.80   \nCopper_River_75019800020572                    107175106.24   \nCopper_River_75019800020900                      7039959.41   \n\n                             NhdAwcH12_wtd_glacier_per  \ncat_ID_con                                              \nPrince_William_Sound_18357                        1.26  \nPrince_William_Sound_18547                        0.35  \nPrince_William_Sound_18737                        1.34  \nPrince_William_Sound_18747                        1.33  \nPrince_William_Sound_27856                        3.75  \n...                                                ...  \nCopper_River_75019800018811                      22.21  \nCopper_River_75019800019142                       2.12  \nCopper_River_75019800019853                       4.51  \nCopper_River_75019800020572                      11.44  \nCopper_River_75019800020900                       2.28  \n\n[566 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NhdAwcH12_wtd_glacier_area_sqm</th>\n      <th>NhdAwcH12_wtd_glacier_per</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Prince_William_Sound_18357</th>\n      <td>255413.00</td>\n      <td>1.26</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18547</th>\n      <td>83990.36</td>\n      <td>0.35</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18737</th>\n      <td>866494.65</td>\n      <td>1.34</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18747</th>\n      <td>866494.65</td>\n      <td>1.33</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_27856</th>\n      <td>176024.99</td>\n      <td>3.75</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75019800018811</th>\n      <td>106387407.76</td>\n      <td>22.21</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75019800019142</th>\n      <td>12957496.80</td>\n      <td>2.12</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75019800019853</th>\n      <td>12957496.80</td>\n      <td>4.51</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75019800020572</th>\n      <td>107175106.24</td>\n      <td>11.44</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75019800020900</th>\n      <td>7039959.41</td>\n      <td>2.28</td>\n    </tr>\n  </tbody>\n</table>\n<p>566 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make watershed glacier df\n",
    "wtd_glac_df = pd.DataFrame()\n",
    "wtd_glac_field_list = []\n",
    "for field in arcpy.ListFields(wtd_glac):\n",
    "    wtd_glac_field_list.append(field.name)\n",
    "wtd_glac_arr = arcpy.da.TableToNumPyArray(wtd_glac, wtd_glac_field_list)\n",
    "wtd_glac_df = pd.DataFrame(wtd_glac_arr)\n",
    "wtd_glac_df = wtd_glac_df.drop([\"OBJECTID\",\"region\",\"cat_ID_txt\",\"cat_ID\",\"O1Region\"],axis=1)\n",
    "wtd_glac_df = wtd_glac_df.set_index('cat_ID_con')\n",
    "dfs.append(wtd_glac_df)\n",
    "wtd_glac_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Merge all covariate dataframes together and drop unnecessary columns\n",
    " * Recalculate cat_ID as float64 type\n",
    " * Reorder columns\n",
    " * Export final csv\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "                             AwcHuc12_cat_elev_COUNT  AwcHuc12_cat_elev_AREA  \\\ncat_ID_con                                                                     \nPrince_William_Sound_3038                    3448.00               344800.00   \nPrince_William_Sound_13227                    297.00                29700.00   \nPrince_William_Sound_17027                   4338.00               433800.00   \nPrince_William_Sound_17697                   2137.00               213700.00   \nPrince_William_Sound_18357                     80.00                 8000.00   \n...                                              ...                     ...   \nCopper_River_75003900029086                  1469.00               146900.00   \nCopper_River_75003900044552                 11111.00              1111100.00   \nCopper_River_75003900054944                   121.00                12100.00   \nCopper_River_75003900029096                     3.00                  300.00   \nCopper_River_75003900047600                  1022.00               102200.00   \n\n                             AwcHuc12_cat_elev_MIN  AwcHuc12_cat_elev_MAX  \\\ncat_ID_con                                                                  \nPrince_William_Sound_3038                        0                     96   \nPrince_William_Sound_13227                       0                     79   \nPrince_William_Sound_17027                       0                    208   \nPrince_William_Sound_17697                       3                    118   \nPrince_William_Sound_18357                       4                     12   \n...                                            ...                    ...   \nCopper_River_75003900029086                      2                      7   \nCopper_River_75003900044552                      3                    225   \nCopper_River_75003900054944                      3                      5   \nCopper_River_75003900029096                      3                      5   \nCopper_River_75003900047600                     16                    133   \n\n                             AwcHuc12_cat_elev_RANGE  AwcHuc12_cat_elev_MEAN  \\\ncat_ID_con                                                                     \nPrince_William_Sound_3038                         96                   10.59   \nPrince_William_Sound_13227                        79                   24.72   \nPrince_William_Sound_17027                       208                   70.89   \nPrince_William_Sound_17697                       115                   61.09   \nPrince_William_Sound_18357                         8                    6.31   \n...                                              ...                     ...   \nCopper_River_75003900029086                        5                    3.88   \nCopper_River_75003900044552                      222                   75.24   \nCopper_River_75003900054944                        2                    4.11   \nCopper_River_75003900029096                        2                    3.67   \nCopper_River_75003900047600                      117                   51.84   \n\n                             AwcHuc12_cat_elev_STD  AwcHuc12_cat_elev_SUM  \\\ncat_ID_con                                                                  \nPrince_William_Sound_3038                    10.72               36518.00   \nPrince_William_Sound_13227                   12.92                7342.00   \nPrince_William_Sound_17027                   35.61              307536.00   \nPrince_William_Sound_17697                   29.40              130546.00   \nPrince_William_Sound_18357                    1.91                 505.00   \n...                                            ...                    ...   \nCopper_River_75003900029086                   0.89                5696.00   \nCopper_River_75003900044552                  57.47              836045.00   \nCopper_River_75003900054944                   0.79                 497.00   \nCopper_River_75003900029096                   0.94                  11.00   \nCopper_River_75003900047600                  34.99               52985.00   \n\n                             AwcHuc12_cat_elev_VARIETY  \\\ncat_ID_con                                               \nPrince_William_Sound_3038                           93   \nPrince_William_Sound_13227                          60   \nPrince_William_Sound_17027                         201   \nPrince_William_Sound_17697                         116   \nPrince_William_Sound_18357                           9   \n...                                                ...   \nCopper_River_75003900029086                          6   \nCopper_River_75003900044552                        223   \nCopper_River_75003900054944                          3   \nCopper_River_75003900029096                          2   \nCopper_River_75003900047600                        115   \n\n                             AwcHuc12_cat_elev_MAJORITY  ...  \\\ncat_ID_con                                               ...   \nPrince_William_Sound_3038                             5  ...   \nPrince_William_Sound_13227                           14  ...   \nPrince_William_Sound_17027                           48  ...   \nPrince_William_Sound_17697                            3  ...   \nPrince_William_Sound_18357                            5  ...   \n...                                                 ...  ...   \nCopper_River_75003900029086                           4  ...   \nCopper_River_75003900044552                           5  ...   \nCopper_River_75003900054944                           5  ...   \nCopper_River_75003900029096                           3  ...   \nCopper_River_75003900047600                          18  ...   \n\n                             AwcHuc12_non_north_area  AwcHuc12_north_area  \\\ncat_ID_con                                                                  \nPrince_William_Sound_3038                24066600.00           8352000.00   \nPrince_William_Sound_13227                 679900.00            627900.00   \nPrince_William_Sound_17027                2596000.00           1163500.00   \nPrince_William_Sound_17697                6874200.00           2365900.00   \nPrince_William_Sound_18357               15359800.00           4876600.00   \n...                                              ...                  ...   \nCopper_River_75003900029086              17465000.00           1929700.00   \nCopper_River_75003900044552              10002100.00           2113300.00   \nCopper_River_75003900054944               7381300.00           1345600.00   \nCopper_River_75003900029096              14284800.00           3542200.00   \nCopper_River_75003900047600              42358100.00          12046500.00   \n\n                             NhdAwcH12_wtd_north_per  \\\ncat_ID_con                                             \nPrince_William_Sound_3038                      25.76   \nPrince_William_Sound_13227                     48.01   \nPrince_William_Sound_17027                     30.95   \nPrince_William_Sound_17697                     25.60   \nPrince_William_Sound_18357                     24.10   \n...                                              ...   \nCopper_River_75003900029086                     9.95   \nCopper_River_75003900044552                    17.44   \nCopper_River_75003900054944                    15.42   \nCopper_River_75003900029096                    19.87   \nCopper_River_75003900047600                    22.14   \n\n                             AwcHuc12_non_wetland_area  AwcHuc12_wetland_area  \\\ncat_ID_con                                                                      \nPrince_William_Sound_3038                  25232500.00             7186100.00   \nPrince_William_Sound_13227                  1298800.00                9000.00   \nPrince_William_Sound_17027                  3275800.00              483700.00   \nPrince_William_Sound_17697                  8549500.00              690600.00   \nPrince_William_Sound_18357                 19103600.00             1132800.00   \n...                                                ...                    ...   \nCopper_River_75003900029086                  318600.00            19076100.00   \nCopper_River_75003900044552                10373300.00             1742100.00   \nCopper_River_75003900054944                 5613800.00             3113100.00   \nCopper_River_75003900029096                17048200.00              778800.00   \nCopper_River_75003900047600                54245300.00              159300.00   \n\n                             NhdAwcH12_wtd_wet_per  \\\ncat_ID_con                                           \nPrince_William_Sound_3038                    22.17   \nPrince_William_Sound_13227                    0.69   \nPrince_William_Sound_17027                   12.87   \nPrince_William_Sound_17697                    7.47   \nPrince_William_Sound_18357                    5.60   \n...                                            ...   \nCopper_River_75003900029086                  98.36   \nCopper_River_75003900044552                  14.38   \nCopper_River_75003900054944                  35.67   \nCopper_River_75003900029096                   4.37   \nCopper_River_75003900047600                   0.29   \n\n                             NhdAwcH12_wtd_lake_area_sqm  \\\ncat_ID_con                                                 \nPrince_William_Sound_3038                       61494.14   \nPrince_William_Sound_13227                           NaN   \nPrince_William_Sound_17027                       5688.95   \nPrince_William_Sound_17697                      38507.61   \nPrince_William_Sound_18357                       6904.33   \n...                                                  ...   \nCopper_River_75003900029086                    576851.52   \nCopper_River_75003900044552                    424104.69   \nCopper_River_75003900054944                    148894.93   \nCopper_River_75003900029096                    173685.96   \nCopper_River_75003900047600                    212347.89   \n\n                             NhdAwcH12_wtd_lake_per  \\\ncat_ID_con                                            \nPrince_William_Sound_3038                      0.19   \nPrince_William_Sound_13227                      NaN   \nPrince_William_Sound_17027                     0.15   \nPrince_William_Sound_17697                     0.42   \nPrince_William_Sound_18357                     0.03   \n...                                             ...   \nCopper_River_75003900029086                    2.96   \nCopper_River_75003900044552                    3.49   \nCopper_River_75003900054944                    1.70   \nCopper_River_75003900029096                    0.97   \nCopper_River_75003900047600                    0.39   \n\n                             NhdAwcH12_wtd_glacier_area_sqm  \\\ncat_ID_con                                                    \nPrince_William_Sound_3038                               NaN   \nPrince_William_Sound_13227                              NaN   \nPrince_William_Sound_17027                              NaN   \nPrince_William_Sound_17697                              NaN   \nPrince_William_Sound_18357                        255413.00   \n...                                                     ...   \nCopper_River_75003900029086                             NaN   \nCopper_River_75003900044552                             NaN   \nCopper_River_75003900054944                             NaN   \nCopper_River_75003900029096                             NaN   \nCopper_River_75003900047600                      6566375.44   \n\n                             NhdAwcH12_wtd_glacier_per  \ncat_ID_con                                              \nPrince_William_Sound_3038                          NaN  \nPrince_William_Sound_13227                         NaN  \nPrince_William_Sound_17027                         NaN  \nPrince_William_Sound_17697                         NaN  \nPrince_William_Sound_18357                        1.26  \n...                                                ...  \nCopper_River_75003900029086                        NaN  \nCopper_River_75003900044552                        NaN  \nCopper_River_75003900054944                        NaN  \nCopper_River_75003900029096                        NaN  \nCopper_River_75003900047600                      12.05  \n\n[1018 rows x 51 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AwcHuc12_cat_elev_COUNT</th>\n      <th>AwcHuc12_cat_elev_AREA</th>\n      <th>AwcHuc12_cat_elev_MIN</th>\n      <th>AwcHuc12_cat_elev_MAX</th>\n      <th>AwcHuc12_cat_elev_RANGE</th>\n      <th>AwcHuc12_cat_elev_MEAN</th>\n      <th>AwcHuc12_cat_elev_STD</th>\n      <th>AwcHuc12_cat_elev_SUM</th>\n      <th>AwcHuc12_cat_elev_VARIETY</th>\n      <th>AwcHuc12_cat_elev_MAJORITY</th>\n      <th>...</th>\n      <th>AwcHuc12_non_north_area</th>\n      <th>AwcHuc12_north_area</th>\n      <th>NhdAwcH12_wtd_north_per</th>\n      <th>AwcHuc12_non_wetland_area</th>\n      <th>AwcHuc12_wetland_area</th>\n      <th>NhdAwcH12_wtd_wet_per</th>\n      <th>NhdAwcH12_wtd_lake_area_sqm</th>\n      <th>NhdAwcH12_wtd_lake_per</th>\n      <th>NhdAwcH12_wtd_glacier_area_sqm</th>\n      <th>NhdAwcH12_wtd_glacier_per</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Prince_William_Sound_3038</th>\n      <td>3448.00</td>\n      <td>344800.00</td>\n      <td>0</td>\n      <td>96</td>\n      <td>96</td>\n      <td>10.59</td>\n      <td>10.72</td>\n      <td>36518.00</td>\n      <td>93</td>\n      <td>5</td>\n      <td>...</td>\n      <td>24066600.00</td>\n      <td>8352000.00</td>\n      <td>25.76</td>\n      <td>25232500.00</td>\n      <td>7186100.00</td>\n      <td>22.17</td>\n      <td>61494.14</td>\n      <td>0.19</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_13227</th>\n      <td>297.00</td>\n      <td>29700.00</td>\n      <td>0</td>\n      <td>79</td>\n      <td>79</td>\n      <td>24.72</td>\n      <td>12.92</td>\n      <td>7342.00</td>\n      <td>60</td>\n      <td>14</td>\n      <td>...</td>\n      <td>679900.00</td>\n      <td>627900.00</td>\n      <td>48.01</td>\n      <td>1298800.00</td>\n      <td>9000.00</td>\n      <td>0.69</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17027</th>\n      <td>4338.00</td>\n      <td>433800.00</td>\n      <td>0</td>\n      <td>208</td>\n      <td>208</td>\n      <td>70.89</td>\n      <td>35.61</td>\n      <td>307536.00</td>\n      <td>201</td>\n      <td>48</td>\n      <td>...</td>\n      <td>2596000.00</td>\n      <td>1163500.00</td>\n      <td>30.95</td>\n      <td>3275800.00</td>\n      <td>483700.00</td>\n      <td>12.87</td>\n      <td>5688.95</td>\n      <td>0.15</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17697</th>\n      <td>2137.00</td>\n      <td>213700.00</td>\n      <td>3</td>\n      <td>118</td>\n      <td>115</td>\n      <td>61.09</td>\n      <td>29.40</td>\n      <td>130546.00</td>\n      <td>116</td>\n      <td>3</td>\n      <td>...</td>\n      <td>6874200.00</td>\n      <td>2365900.00</td>\n      <td>25.60</td>\n      <td>8549500.00</td>\n      <td>690600.00</td>\n      <td>7.47</td>\n      <td>38507.61</td>\n      <td>0.42</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18357</th>\n      <td>80.00</td>\n      <td>8000.00</td>\n      <td>4</td>\n      <td>12</td>\n      <td>8</td>\n      <td>6.31</td>\n      <td>1.91</td>\n      <td>505.00</td>\n      <td>9</td>\n      <td>5</td>\n      <td>...</td>\n      <td>15359800.00</td>\n      <td>4876600.00</td>\n      <td>24.10</td>\n      <td>19103600.00</td>\n      <td>1132800.00</td>\n      <td>5.60</td>\n      <td>6904.33</td>\n      <td>0.03</td>\n      <td>255413.00</td>\n      <td>1.26</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029086</th>\n      <td>1469.00</td>\n      <td>146900.00</td>\n      <td>2</td>\n      <td>7</td>\n      <td>5</td>\n      <td>3.88</td>\n      <td>0.89</td>\n      <td>5696.00</td>\n      <td>6</td>\n      <td>4</td>\n      <td>...</td>\n      <td>17465000.00</td>\n      <td>1929700.00</td>\n      <td>9.95</td>\n      <td>318600.00</td>\n      <td>19076100.00</td>\n      <td>98.36</td>\n      <td>576851.52</td>\n      <td>2.96</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900044552</th>\n      <td>11111.00</td>\n      <td>1111100.00</td>\n      <td>3</td>\n      <td>225</td>\n      <td>222</td>\n      <td>75.24</td>\n      <td>57.47</td>\n      <td>836045.00</td>\n      <td>223</td>\n      <td>5</td>\n      <td>...</td>\n      <td>10002100.00</td>\n      <td>2113300.00</td>\n      <td>17.44</td>\n      <td>10373300.00</td>\n      <td>1742100.00</td>\n      <td>14.38</td>\n      <td>424104.69</td>\n      <td>3.49</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900054944</th>\n      <td>121.00</td>\n      <td>12100.00</td>\n      <td>3</td>\n      <td>5</td>\n      <td>2</td>\n      <td>4.11</td>\n      <td>0.79</td>\n      <td>497.00</td>\n      <td>3</td>\n      <td>5</td>\n      <td>...</td>\n      <td>7381300.00</td>\n      <td>1345600.00</td>\n      <td>15.42</td>\n      <td>5613800.00</td>\n      <td>3113100.00</td>\n      <td>35.67</td>\n      <td>148894.93</td>\n      <td>1.70</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029096</th>\n      <td>3.00</td>\n      <td>300.00</td>\n      <td>3</td>\n      <td>5</td>\n      <td>2</td>\n      <td>3.67</td>\n      <td>0.94</td>\n      <td>11.00</td>\n      <td>2</td>\n      <td>3</td>\n      <td>...</td>\n      <td>14284800.00</td>\n      <td>3542200.00</td>\n      <td>19.87</td>\n      <td>17048200.00</td>\n      <td>778800.00</td>\n      <td>4.37</td>\n      <td>173685.96</td>\n      <td>0.97</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900047600</th>\n      <td>1022.00</td>\n      <td>102200.00</td>\n      <td>16</td>\n      <td>133</td>\n      <td>117</td>\n      <td>51.84</td>\n      <td>34.99</td>\n      <td>52985.00</td>\n      <td>115</td>\n      <td>18</td>\n      <td>...</td>\n      <td>42358100.00</td>\n      <td>12046500.00</td>\n      <td>22.14</td>\n      <td>54245300.00</td>\n      <td>159300.00</td>\n      <td>0.29</td>\n      <td>212347.89</td>\n      <td>0.39</td>\n      <td>6566375.44</td>\n      <td>12.05</td>\n    </tr>\n  </tbody>\n</table>\n<p>1018 rows × 51 columns</p>\n</div>"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge all data frames together\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "df_final = reduce(lambda left,right: pd.merge(left,right,on='cat_ID_con',how=\"outer\"), dfs)\n",
    "#Generate unique column names\n",
    "def uniquify(df_final):\n",
    "    seen = set()\n",
    "    for item in df_final:\n",
    "        fudge = 1\n",
    "        newitem = item\n",
    "        while newitem in seen:\n",
    "            fudge += 1\n",
    "            newitem = \"{}_{}\".format(item, fudge)\n",
    "        yield newitem\n",
    "        seen.add(newitem)\n",
    "df_final.columns = list(uniquify(df_final))\n",
    "#List of final columns in the order to output\n",
    "# final_cols_old = ['cat_ID_txt','cat_ID','region', 'AwcHuc12_cat_slope_COUNT', 'AwcHuc12_cat_slope_AREA', 'AwcHuc12_cat_slope_MIN', 'AwcHuc12_cat_slope_MAX',\n",
    "#               'AwcHuc12_cat_slope_RANGE','AwcHuc12_cat_slope_MEAN', 'AwcHuc12_cat_slope_STD', 'AwcHuc12_cat_slope_SUM', 'AwcHuc12_cat_slope_MEDIAN', 'AwcHuc12_cat_slope_PCT90',\n",
    "#               'AwcHuc12_cat_elev_COUNT', 'AwcHuc12_cat_elev_AREA', 'AwcHuc12_cat_elev_MIN', 'AwcHuc12_cat_elev_MAX', 'AwcHuc12_cat_elev_RANGE', 'AwcHuc12_cat_elev_MEAN', 'AwcHuc12_cat_elev_STD',\n",
    "#               'AwcHuc12_cat_elev_SUM', 'AwcHuc12_cat_elev_VARIETY', 'AwcHuc12_cat_elev_MAJORITY', 'AwcHuc12_cat_elev_MINORITY', 'AwcHuc12_cat_elev_MEDIAN', 'AwcHuc12_cat_elev_PCT90',\n",
    "#               'AwcHuc12_wtd_elev_COUNT', 'AwcHuc12_wtd_elev_AREA', 'AwcHuc12_wtd_elev_MIN', 'AwcHuc12_wtd_elev_MAX', 'AwcHuc12_wtd_elev_RANGE', 'AwcHuc12_wtd_elev_MEAN',\n",
    "#               'AwcHuc12_wtd_elev_STD', 'AwcHuc12_wtd_elev_SUM', 'AwcHuc12_wtd_elev_VARIETY', 'AwcHuc12_wtd_elev_MAJORITY', 'AwcHuc12_wtd_elev_MINORITY',\n",
    "#               'AwcHuc12_wtd_elev_MEDIAN', 'AwcHuc12_wtd_elev_PCT90', 'AwcHuc12_wtd_slope_COUNT', 'AwcHuc12_wtd_slope_AREA', 'AwcHuc12_wtd_slope_MIN', 'AwcHuc12_wtd_slope_MAX',\n",
    "#               'AwcHuc12_wtd_slope_RANGE', 'AwcHuc12_wtd_slope_MEAN', 'AwcHuc12_wtd_slope_STD', 'AwcHuc12_wtd_slope_SUM', 'AwcHuc12_wtd_slope_MEDIAN', 'AwcHuc12_wtd_slope_PCT90',\n",
    "#               'AwcHuc12_non_north_area', 'AwcHuc12_north_area', 'AwcHuc12_wtd_north_per', 'non_wetland_area', 'AwcHuc12_wetland_area', 'AwcHuc12_wtd_wet_per',\n",
    "#               'AwcHuc12_wtd_lake_area_sqm', 'AwcHuc12_wtd_lake_per', 'AwcHuc12_wtd_glacier_area_sqm', 'AwcHuc12_wtd_glacier_per' ]\n",
    "final_cols = ['AwcHuc12_cat_slope_COUNT', 'AwcHuc12_cat_slope_AREA', 'AwcHuc12_cat_slope_MIN', 'AwcHuc12_cat_slope_MAX',\n",
    "              'AwcHuc12_cat_slope_RANGE','AwcHuc12_cat_slope_MEAN', 'AwcHuc12_cat_slope_STD', 'AwcHuc12_cat_slope_SUM', 'AwcHuc12_cat_slope_MEDIAN', 'AwcHuc12_cat_slope_PCT90',\n",
    "              'AwcHuc12_cat_elev_COUNT', 'AwcHuc12_cat_elev_AREA', 'AwcHuc12_cat_elev_MIN', 'AwcHuc12_cat_elev_MAX', 'AwcHuc12_cat_elev_RANGE', 'AwcHuc12_cat_elev_MEAN', 'AwcHuc12_cat_elev_STD',\n",
    "              'AwcHuc12_cat_elev_SUM', 'AwcHuc12_cat_elev_VARIETY', 'AwcHuc12_cat_elev_MAJORITY', 'AwcHuc12_cat_elev_MINORITY', 'AwcHuc12_cat_elev_MEDIAN', 'AwcHuc12_cat_elev_PCT90',\n",
    "              'AwcHuc12_wtd_elev_MIN', 'AwcHuc12_wtd_elev_MAX','AwcHuc12_wtd_elev_MEAN','AwcHuc12_wtd_elev_STD','AwcHuc12_wtd_slope_MIN', 'AwcHuc12_wtd_slope_MAX','AwcHuc12_wtd_slope_MEAN',\n",
    "              'AwcHuc12_wtd_slope_STD','AwcHuc12_non_north_area', 'AwcHuc12_north_area', 'AwcHuc12_wtd_north_per', 'non_wetland_area', 'AwcHuc12_wetland_area', 'AwcHuc12_wtd_wet_per',\n",
    "              'AwcHuc12_wtd_lake_area_sqm', 'AwcHuc12_wtd_lake_per', 'AwcHuc12_wtd_glacier_area_sqm', 'AwcHuc12_wtd_glacier_per' ]\n",
    "\n",
    "\n",
    "df_final"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export all covariates dataframe to csv complete\n"
     ]
    }
   ],
   "source": [
    "# Export merged dataframe to csv\n",
    "cov_csv_out = os.path.join(outdir,'AKSSF_AWC_HUC12s_Covariates.csv')\n",
    "df_final.to_csv(cov_csv_out, encoding = 'utf-8')\n",
    "print('Export all covariates dataframe to csv complete')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# bbay_df = df_final.filter(like='Bristol_Bay', axis = 0)\n",
    "# bbay_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # kod_df = df_final.filter(like='Kodiak', axis = 0)\n",
    "# kod_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "                            AwcHuc12_cat_elev_COUNT  AwcHuc12_cat_elev_AREA  \\\ncat_ID_con                                                                    \nPrince_William_Sound_3038                   3448.00               344800.00   \nPrince_William_Sound_13227                   297.00                29700.00   \nPrince_William_Sound_17027                  4338.00               433800.00   \nPrince_William_Sound_17697                  2137.00               213700.00   \nPrince_William_Sound_18357                    80.00                 8000.00   \n...                                             ...                     ...   \nPrince_William_Sound_91741                  1649.00               164900.00   \nPrince_William_Sound_91751                   385.00                38500.00   \nPrince_William_Sound_91921                   709.00                70900.00   \nPrince_William_Sound_92151                  1305.00               130500.00   \nPrince_William_Sound_93261                  1119.00               111900.00   \n\n                            AwcHuc12_cat_elev_MIN  AwcHuc12_cat_elev_MAX  \\\ncat_ID_con                                                                 \nPrince_William_Sound_3038                       0                     96   \nPrince_William_Sound_13227                      0                     79   \nPrince_William_Sound_17027                      0                    208   \nPrince_William_Sound_17697                      3                    118   \nPrince_William_Sound_18357                      4                     12   \n...                                           ...                    ...   \nPrince_William_Sound_91741                     82                    132   \nPrince_William_Sound_91751                     82                     91   \nPrince_William_Sound_91921                     48                     55   \nPrince_William_Sound_92151                      0                      6   \nPrince_William_Sound_93261                      3                     57   \n\n                            AwcHuc12_cat_elev_RANGE  AwcHuc12_cat_elev_MEAN  \\\ncat_ID_con                                                                    \nPrince_William_Sound_3038                        96                   10.59   \nPrince_William_Sound_13227                       79                   24.72   \nPrince_William_Sound_17027                      208                   70.89   \nPrince_William_Sound_17697                      115                   61.09   \nPrince_William_Sound_18357                        8                    6.31   \n...                                             ...                     ...   \nPrince_William_Sound_91741                       50                   90.62   \nPrince_William_Sound_91751                        9                   86.33   \nPrince_William_Sound_91921                        7                   50.90   \nPrince_William_Sound_92151                        6                    2.86   \nPrince_William_Sound_93261                       54                   12.54   \n\n                            AwcHuc12_cat_elev_STD  AwcHuc12_cat_elev_SUM  \\\ncat_ID_con                                                                 \nPrince_William_Sound_3038                   10.72               36518.00   \nPrince_William_Sound_13227                  12.92                7342.00   \nPrince_William_Sound_17027                  35.61              307536.00   \nPrince_William_Sound_17697                  29.40              130546.00   \nPrince_William_Sound_18357                   1.91                 505.00   \n...                                           ...                    ...   \nPrince_William_Sound_91741                   7.38              149431.00   \nPrince_William_Sound_91751                   2.30               33237.00   \nPrince_William_Sound_91921                   1.29               36089.00   \nPrince_William_Sound_92151                   1.55                3738.00   \nPrince_William_Sound_93261                  10.62               14035.00   \n\n                            AwcHuc12_cat_elev_VARIETY  \\\ncat_ID_con                                              \nPrince_William_Sound_3038                          93   \nPrince_William_Sound_13227                         60   \nPrince_William_Sound_17027                        201   \nPrince_William_Sound_17697                        116   \nPrince_William_Sound_18357                          9   \n...                                               ...   \nPrince_William_Sound_91741                         50   \nPrince_William_Sound_91751                         10   \nPrince_William_Sound_91921                          8   \nPrince_William_Sound_92151                          7   \nPrince_William_Sound_93261                         53   \n\n                            AwcHuc12_cat_elev_MAJORITY  ...  \\\ncat_ID_con                                              ...   \nPrince_William_Sound_3038                            5  ...   \nPrince_William_Sound_13227                          14  ...   \nPrince_William_Sound_17027                          48  ...   \nPrince_William_Sound_17697                           3  ...   \nPrince_William_Sound_18357                           5  ...   \n...                                                ...  ...   \nPrince_William_Sound_91741                          87  ...   \nPrince_William_Sound_91751                          86  ...   \nPrince_William_Sound_91921                          50  ...   \nPrince_William_Sound_92151                           4  ...   \nPrince_William_Sound_93261                           6  ...   \n\n                            AwcHuc12_non_north_area  AwcHuc12_north_area  \\\ncat_ID_con                                                                 \nPrince_William_Sound_3038               24066600.00           8352000.00   \nPrince_William_Sound_13227                679900.00            627900.00   \nPrince_William_Sound_17027               2596000.00           1163500.00   \nPrince_William_Sound_17697               6874200.00           2365900.00   \nPrince_William_Sound_18357              15359800.00           4876600.00   \n...                                             ...                  ...   \nPrince_William_Sound_91741             386812700.00         186044600.00   \nPrince_William_Sound_91751             388594100.00         186199700.00   \nPrince_William_Sound_91921             506926400.00         232421500.00   \nPrince_William_Sound_92151             630955600.00         289585800.00   \nPrince_William_Sound_93261              91090600.00          26074300.00   \n\n                            NhdAwcH12_wtd_north_per  \\\ncat_ID_con                                            \nPrince_William_Sound_3038                     25.76   \nPrince_William_Sound_13227                    48.01   \nPrince_William_Sound_17027                    30.95   \nPrince_William_Sound_17697                    25.60   \nPrince_William_Sound_18357                    24.10   \n...                                             ...   \nPrince_William_Sound_91741                    32.48   \nPrince_William_Sound_91751                    32.39   \nPrince_William_Sound_91921                    31.44   \nPrince_William_Sound_92151                    31.46   \nPrince_William_Sound_93261                    22.25   \n\n                            AwcHuc12_non_wetland_area  AwcHuc12_wetland_area  \\\ncat_ID_con                                                                     \nPrince_William_Sound_3038                 25232500.00             7186100.00   \nPrince_William_Sound_13227                 1298800.00                9000.00   \nPrince_William_Sound_17027                 3275800.00              483700.00   \nPrince_William_Sound_17697                 8549500.00              690600.00   \nPrince_William_Sound_18357                19103600.00             1132800.00   \n...                                               ...                    ...   \nPrince_William_Sound_91741               571909900.00              947400.00   \nPrince_William_Sound_91751               573840700.00              953100.00   \nPrince_William_Sound_91921               738117700.00             1230200.00   \nPrince_William_Sound_92151               916260200.00             4281200.00   \nPrince_William_Sound_93261               117067100.00               97800.00   \n\n                            NhdAwcH12_wtd_wet_per  \\\ncat_ID_con                                          \nPrince_William_Sound_3038                   22.17   \nPrince_William_Sound_13227                   0.69   \nPrince_William_Sound_17027                  12.87   \nPrince_William_Sound_17697                   7.47   \nPrince_William_Sound_18357                   5.60   \n...                                           ...   \nPrince_William_Sound_91741                   0.17   \nPrince_William_Sound_91751                   0.17   \nPrince_William_Sound_91921                   0.17   \nPrince_William_Sound_92151                   0.47   \nPrince_William_Sound_93261                   0.08   \n\n                            NhdAwcH12_wtd_lake_area_sqm  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                      61494.14   \nPrince_William_Sound_13227                          NaN   \nPrince_William_Sound_17027                      5688.95   \nPrince_William_Sound_17697                     38507.61   \nPrince_William_Sound_18357                      6904.33   \n...                                                 ...   \nPrince_William_Sound_91741                    718625.65   \nPrince_William_Sound_91751                    718625.65   \nPrince_William_Sound_91921                    722689.23   \nPrince_William_Sound_92151                    815052.24   \nPrince_William_Sound_93261                      2348.27   \n\n                            NhdAwcH12_wtd_lake_per  \\\ncat_ID_con                                           \nPrince_William_Sound_3038                     0.19   \nPrince_William_Sound_13227                     NaN   \nPrince_William_Sound_17027                    0.15   \nPrince_William_Sound_17697                    0.42   \nPrince_William_Sound_18357                    0.03   \n...                                            ...   \nPrince_William_Sound_91741                    0.13   \nPrince_William_Sound_91751                    0.13   \nPrince_William_Sound_91921                    0.10   \nPrince_William_Sound_92151                    0.09   \nPrince_William_Sound_93261                    0.00   \n\n                            NhdAwcH12_wtd_glacier_area_sqm  \\\ncat_ID_con                                                   \nPrince_William_Sound_3038                              NaN   \nPrince_William_Sound_13227                             NaN   \nPrince_William_Sound_17027                             NaN   \nPrince_William_Sound_17697                             NaN   \nPrince_William_Sound_18357                       255413.00   \n...                                                    ...   \nPrince_William_Sound_91741                    181710896.57   \nPrince_William_Sound_91751                    181710896.57   \nPrince_William_Sound_91921                    216960224.77   \nPrince_William_Sound_92151                    251036555.75   \nPrince_William_Sound_93261                     28132279.13   \n\n                            NhdAwcH12_wtd_glacier_per  \ncat_ID_con                                             \nPrince_William_Sound_3038                         NaN  \nPrince_William_Sound_13227                        NaN  \nPrince_William_Sound_17027                        NaN  \nPrince_William_Sound_17697                        NaN  \nPrince_William_Sound_18357                       1.26  \n...                                               ...  \nPrince_William_Sound_91741                      31.72  \nPrince_William_Sound_91751                      31.61  \nPrince_William_Sound_91921                      29.34  \nPrince_William_Sound_92151                      27.27  \nPrince_William_Sound_93261                      24.01  \n\n[112 rows x 51 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AwcHuc12_cat_elev_COUNT</th>\n      <th>AwcHuc12_cat_elev_AREA</th>\n      <th>AwcHuc12_cat_elev_MIN</th>\n      <th>AwcHuc12_cat_elev_MAX</th>\n      <th>AwcHuc12_cat_elev_RANGE</th>\n      <th>AwcHuc12_cat_elev_MEAN</th>\n      <th>AwcHuc12_cat_elev_STD</th>\n      <th>AwcHuc12_cat_elev_SUM</th>\n      <th>AwcHuc12_cat_elev_VARIETY</th>\n      <th>AwcHuc12_cat_elev_MAJORITY</th>\n      <th>...</th>\n      <th>AwcHuc12_non_north_area</th>\n      <th>AwcHuc12_north_area</th>\n      <th>NhdAwcH12_wtd_north_per</th>\n      <th>AwcHuc12_non_wetland_area</th>\n      <th>AwcHuc12_wetland_area</th>\n      <th>NhdAwcH12_wtd_wet_per</th>\n      <th>NhdAwcH12_wtd_lake_area_sqm</th>\n      <th>NhdAwcH12_wtd_lake_per</th>\n      <th>NhdAwcH12_wtd_glacier_area_sqm</th>\n      <th>NhdAwcH12_wtd_glacier_per</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Prince_William_Sound_3038</th>\n      <td>3448.00</td>\n      <td>344800.00</td>\n      <td>0</td>\n      <td>96</td>\n      <td>96</td>\n      <td>10.59</td>\n      <td>10.72</td>\n      <td>36518.00</td>\n      <td>93</td>\n      <td>5</td>\n      <td>...</td>\n      <td>24066600.00</td>\n      <td>8352000.00</td>\n      <td>25.76</td>\n      <td>25232500.00</td>\n      <td>7186100.00</td>\n      <td>22.17</td>\n      <td>61494.14</td>\n      <td>0.19</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_13227</th>\n      <td>297.00</td>\n      <td>29700.00</td>\n      <td>0</td>\n      <td>79</td>\n      <td>79</td>\n      <td>24.72</td>\n      <td>12.92</td>\n      <td>7342.00</td>\n      <td>60</td>\n      <td>14</td>\n      <td>...</td>\n      <td>679900.00</td>\n      <td>627900.00</td>\n      <td>48.01</td>\n      <td>1298800.00</td>\n      <td>9000.00</td>\n      <td>0.69</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17027</th>\n      <td>4338.00</td>\n      <td>433800.00</td>\n      <td>0</td>\n      <td>208</td>\n      <td>208</td>\n      <td>70.89</td>\n      <td>35.61</td>\n      <td>307536.00</td>\n      <td>201</td>\n      <td>48</td>\n      <td>...</td>\n      <td>2596000.00</td>\n      <td>1163500.00</td>\n      <td>30.95</td>\n      <td>3275800.00</td>\n      <td>483700.00</td>\n      <td>12.87</td>\n      <td>5688.95</td>\n      <td>0.15</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17697</th>\n      <td>2137.00</td>\n      <td>213700.00</td>\n      <td>3</td>\n      <td>118</td>\n      <td>115</td>\n      <td>61.09</td>\n      <td>29.40</td>\n      <td>130546.00</td>\n      <td>116</td>\n      <td>3</td>\n      <td>...</td>\n      <td>6874200.00</td>\n      <td>2365900.00</td>\n      <td>25.60</td>\n      <td>8549500.00</td>\n      <td>690600.00</td>\n      <td>7.47</td>\n      <td>38507.61</td>\n      <td>0.42</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18357</th>\n      <td>80.00</td>\n      <td>8000.00</td>\n      <td>4</td>\n      <td>12</td>\n      <td>8</td>\n      <td>6.31</td>\n      <td>1.91</td>\n      <td>505.00</td>\n      <td>9</td>\n      <td>5</td>\n      <td>...</td>\n      <td>15359800.00</td>\n      <td>4876600.00</td>\n      <td>24.10</td>\n      <td>19103600.00</td>\n      <td>1132800.00</td>\n      <td>5.60</td>\n      <td>6904.33</td>\n      <td>0.03</td>\n      <td>255413.00</td>\n      <td>1.26</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_91741</th>\n      <td>1649.00</td>\n      <td>164900.00</td>\n      <td>82</td>\n      <td>132</td>\n      <td>50</td>\n      <td>90.62</td>\n      <td>7.38</td>\n      <td>149431.00</td>\n      <td>50</td>\n      <td>87</td>\n      <td>...</td>\n      <td>386812700.00</td>\n      <td>186044600.00</td>\n      <td>32.48</td>\n      <td>571909900.00</td>\n      <td>947400.00</td>\n      <td>0.17</td>\n      <td>718625.65</td>\n      <td>0.13</td>\n      <td>181710896.57</td>\n      <td>31.72</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_91751</th>\n      <td>385.00</td>\n      <td>38500.00</td>\n      <td>82</td>\n      <td>91</td>\n      <td>9</td>\n      <td>86.33</td>\n      <td>2.30</td>\n      <td>33237.00</td>\n      <td>10</td>\n      <td>86</td>\n      <td>...</td>\n      <td>388594100.00</td>\n      <td>186199700.00</td>\n      <td>32.39</td>\n      <td>573840700.00</td>\n      <td>953100.00</td>\n      <td>0.17</td>\n      <td>718625.65</td>\n      <td>0.13</td>\n      <td>181710896.57</td>\n      <td>31.61</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_91921</th>\n      <td>709.00</td>\n      <td>70900.00</td>\n      <td>48</td>\n      <td>55</td>\n      <td>7</td>\n      <td>50.90</td>\n      <td>1.29</td>\n      <td>36089.00</td>\n      <td>8</td>\n      <td>50</td>\n      <td>...</td>\n      <td>506926400.00</td>\n      <td>232421500.00</td>\n      <td>31.44</td>\n      <td>738117700.00</td>\n      <td>1230200.00</td>\n      <td>0.17</td>\n      <td>722689.23</td>\n      <td>0.10</td>\n      <td>216960224.77</td>\n      <td>29.34</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_92151</th>\n      <td>1305.00</td>\n      <td>130500.00</td>\n      <td>0</td>\n      <td>6</td>\n      <td>6</td>\n      <td>2.86</td>\n      <td>1.55</td>\n      <td>3738.00</td>\n      <td>7</td>\n      <td>4</td>\n      <td>...</td>\n      <td>630955600.00</td>\n      <td>289585800.00</td>\n      <td>31.46</td>\n      <td>916260200.00</td>\n      <td>4281200.00</td>\n      <td>0.47</td>\n      <td>815052.24</td>\n      <td>0.09</td>\n      <td>251036555.75</td>\n      <td>27.27</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_93261</th>\n      <td>1119.00</td>\n      <td>111900.00</td>\n      <td>3</td>\n      <td>57</td>\n      <td>54</td>\n      <td>12.54</td>\n      <td>10.62</td>\n      <td>14035.00</td>\n      <td>53</td>\n      <td>6</td>\n      <td>...</td>\n      <td>91090600.00</td>\n      <td>26074300.00</td>\n      <td>22.25</td>\n      <td>117067100.00</td>\n      <td>97800.00</td>\n      <td>0.08</td>\n      <td>2348.27</td>\n      <td>0.00</td>\n      <td>28132279.13</td>\n      <td>24.01</td>\n    </tr>\n  </tbody>\n</table>\n<p>112 rows × 51 columns</p>\n</div>"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pws_df = df_final.filter(like='Prince', axis = 0)\n",
    "pws_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ci_df = df_final.filter(like='Cook', axis = 0)\n",
    "# ci_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "data": {
      "text/plain": "                             AwcHuc12_cat_elev_COUNT  AwcHuc12_cat_elev_AREA  \\\ncat_ID_con                                                                     \nCopper_River_75019800007852                  7179.00               717900.00   \nCopper_River_75019800005498                  2783.00               278300.00   \nCopper_River_75019800019853                   630.00                63000.00   \nCopper_River_75019800002596                  3851.00               385100.00   \nCopper_River_75019800019678                 39848.00              3984800.00   \n...                                              ...                     ...   \nCopper_River_75003900029086                  1469.00               146900.00   \nCopper_River_75003900044552                 11111.00              1111100.00   \nCopper_River_75003900054944                   121.00                12100.00   \nCopper_River_75003900029096                     3.00                  300.00   \nCopper_River_75003900047600                  1022.00               102200.00   \n\n                             AwcHuc12_cat_elev_MIN  AwcHuc12_cat_elev_MAX  \\\ncat_ID_con                                                                  \nCopper_River_75019800007852                   1000                   1210   \nCopper_River_75019800005498                    981                   1015   \nCopper_River_75019800019853                    794                   1140   \nCopper_River_75019800002596                    795                    904   \nCopper_River_75019800019678                    748                    978   \n...                                            ...                    ...   \nCopper_River_75003900029086                      2                      7   \nCopper_River_75003900044552                      3                    225   \nCopper_River_75003900054944                      3                      5   \nCopper_River_75003900029096                      3                      5   \nCopper_River_75003900047600                     16                    133   \n\n                             AwcHuc12_cat_elev_RANGE  AwcHuc12_cat_elev_MEAN  \\\ncat_ID_con                                                                     \nCopper_River_75019800007852                      210                 1061.17   \nCopper_River_75019800005498                       34                  987.87   \nCopper_River_75019800019853                      346                  865.00   \nCopper_River_75019800002596                      109                  832.89   \nCopper_River_75019800019678                      230                  796.09   \n...                                              ...                     ...   \nCopper_River_75003900029086                        5                    3.88   \nCopper_River_75003900044552                      222                   75.24   \nCopper_River_75003900054944                        2                    4.11   \nCopper_River_75003900029096                        2                    3.67   \nCopper_River_75003900047600                      117                   51.84   \n\n                             AwcHuc12_cat_elev_STD  AwcHuc12_cat_elev_SUM  \\\ncat_ID_con                                                                  \nCopper_River_75019800007852                  63.35             7618122.00   \nCopper_River_75019800005498                   3.63             2749250.00   \nCopper_River_75019800019853                  91.77              544952.00   \nCopper_River_75019800002596                  25.84             3207477.00   \nCopper_River_75019800019678                  31.14            31722510.00   \n...                                            ...                    ...   \nCopper_River_75003900029086                   0.89                5696.00   \nCopper_River_75003900044552                  57.47              836045.00   \nCopper_River_75003900054944                   0.79                 497.00   \nCopper_River_75003900029096                   0.94                  11.00   \nCopper_River_75003900047600                  34.99               52985.00   \n\n                             AwcHuc12_cat_elev_VARIETY  \\\ncat_ID_con                                               \nCopper_River_75019800007852                        211   \nCopper_River_75019800005498                         32   \nCopper_River_75019800019853                        197   \nCopper_River_75019800002596                        110   \nCopper_River_75019800019678                        231   \n...                                                ...   \nCopper_River_75003900029086                          6   \nCopper_River_75003900044552                        223   \nCopper_River_75003900054944                          3   \nCopper_River_75003900029096                          2   \nCopper_River_75003900047600                        115   \n\n                             AwcHuc12_cat_elev_MAJORITY  ...  \\\ncat_ID_con                                               ...   \nCopper_River_75019800007852                        1005  ...   \nCopper_River_75019800005498                         988  ...   \nCopper_River_75019800019853                         797  ...   \nCopper_River_75019800002596                         807  ...   \nCopper_River_75019800019678                         762  ...   \n...                                                 ...  ...   \nCopper_River_75003900029086                           4  ...   \nCopper_River_75003900044552                           5  ...   \nCopper_River_75003900054944                           5  ...   \nCopper_River_75003900029096                           3  ...   \nCopper_River_75003900047600                          18  ...   \n\n                             AwcHuc12_non_north_area  AwcHuc12_north_area  \\\ncat_ID_con                                                                  \nCopper_River_75019800007852              55997900.00          15343900.00   \nCopper_River_75019800005498             218281700.00          26206700.00   \nCopper_River_75019800019853             231029100.00          56257700.00   \nCopper_River_75019800002596              66925300.00          27116100.00   \nCopper_River_75019800019678             101165100.00          24739500.00   \n...                                              ...                  ...   \nCopper_River_75003900029086              17465000.00           1929700.00   \nCopper_River_75003900044552              10002100.00           2113300.00   \nCopper_River_75003900054944               7381300.00           1345600.00   \nCopper_River_75003900029096              14284800.00           3542200.00   \nCopper_River_75003900047600              42358100.00          12046500.00   \n\n                             NhdAwcH12_wtd_north_per  \\\ncat_ID_con                                             \nCopper_River_75019800007852                    21.51   \nCopper_River_75019800005498                    10.72   \nCopper_River_75019800019853                    19.58   \nCopper_River_75019800002596                    28.83   \nCopper_River_75019800019678                    19.65   \n...                                              ...   \nCopper_River_75003900029086                     9.95   \nCopper_River_75003900044552                    17.44   \nCopper_River_75003900054944                    15.42   \nCopper_River_75003900029096                    19.87   \nCopper_River_75003900047600                    22.14   \n\n                             AwcHuc12_non_wetland_area  AwcHuc12_wetland_area  \\\ncat_ID_con                                                                      \nCopper_River_75019800007852                70968900.00              372900.00   \nCopper_River_75019800005498               243275900.00             1212500.00   \nCopper_River_75019800019853               283929500.00             3357300.00   \nCopper_River_75019800002596                92845100.00             1196300.00   \nCopper_River_75019800019678               120104300.00             5800300.00   \n...                                                ...                    ...   \nCopper_River_75003900029086                  318600.00            19076100.00   \nCopper_River_75003900044552                10373300.00             1742100.00   \nCopper_River_75003900054944                 5613800.00             3113100.00   \nCopper_River_75003900029096                17048200.00              778800.00   \nCopper_River_75003900047600                54245300.00              159300.00   \n\n                             NhdAwcH12_wtd_wet_per  \\\ncat_ID_con                                           \nCopper_River_75019800007852                   0.52   \nCopper_River_75019800005498                   0.50   \nCopper_River_75019800019853                   1.17   \nCopper_River_75019800002596                   1.27   \nCopper_River_75019800019678                   4.61   \n...                                            ...   \nCopper_River_75003900029086                  98.36   \nCopper_River_75003900044552                  14.38   \nCopper_River_75003900054944                  35.67   \nCopper_River_75003900029096                   4.37   \nCopper_River_75003900047600                   0.29   \n\n                             NhdAwcH12_wtd_lake_area_sqm  \\\ncat_ID_con                                                 \nCopper_River_75019800007852                   1207912.79   \nCopper_River_75019800005498                    712726.10   \nCopper_River_75019800019853                    303776.66   \nCopper_River_75019800002596                    700598.69   \nCopper_River_75019800019678                    695198.05   \n...                                                  ...   \nCopper_River_75003900029086                    576851.52   \nCopper_River_75003900044552                    424104.69   \nCopper_River_75003900054944                    148894.93   \nCopper_River_75003900029096                    173685.96   \nCopper_River_75003900047600                    212347.89   \n\n                             NhdAwcH12_wtd_lake_per  \\\ncat_ID_con                                            \nCopper_River_75019800007852                    1.69   \nCopper_River_75019800005498                    0.29   \nCopper_River_75019800019853                    0.11   \nCopper_River_75019800002596                    0.74   \nCopper_River_75019800019678                    0.55   \n...                                             ...   \nCopper_River_75003900029086                    2.96   \nCopper_River_75003900044552                    3.49   \nCopper_River_75003900054944                    1.70   \nCopper_River_75003900029096                    0.97   \nCopper_River_75003900047600                    0.39   \n\n                             NhdAwcH12_wtd_glacier_area_sqm  \\\ncat_ID_con                                                    \nCopper_River_75019800007852                             NaN   \nCopper_River_75019800005498                    106387407.76   \nCopper_River_75019800019853                     12957496.80   \nCopper_River_75019800002596                             NaN   \nCopper_River_75019800019678                             NaN   \n...                                                     ...   \nCopper_River_75003900029086                             NaN   \nCopper_River_75003900044552                             NaN   \nCopper_River_75003900054944                             NaN   \nCopper_River_75003900029096                             NaN   \nCopper_River_75003900047600                      6566375.44   \n\n                             NhdAwcH12_wtd_glacier_per  \ncat_ID_con                                              \nCopper_River_75019800007852                        NaN  \nCopper_River_75019800005498                      43.48  \nCopper_River_75019800019853                       4.51  \nCopper_River_75019800002596                        NaN  \nCopper_River_75019800019678                        NaN  \n...                                                ...  \nCopper_River_75003900029086                        NaN  \nCopper_River_75003900044552                        NaN  \nCopper_River_75003900054944                        NaN  \nCopper_River_75003900029096                        NaN  \nCopper_River_75003900047600                      12.05  \n\n[245 rows x 51 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AwcHuc12_cat_elev_COUNT</th>\n      <th>AwcHuc12_cat_elev_AREA</th>\n      <th>AwcHuc12_cat_elev_MIN</th>\n      <th>AwcHuc12_cat_elev_MAX</th>\n      <th>AwcHuc12_cat_elev_RANGE</th>\n      <th>AwcHuc12_cat_elev_MEAN</th>\n      <th>AwcHuc12_cat_elev_STD</th>\n      <th>AwcHuc12_cat_elev_SUM</th>\n      <th>AwcHuc12_cat_elev_VARIETY</th>\n      <th>AwcHuc12_cat_elev_MAJORITY</th>\n      <th>...</th>\n      <th>AwcHuc12_non_north_area</th>\n      <th>AwcHuc12_north_area</th>\n      <th>NhdAwcH12_wtd_north_per</th>\n      <th>AwcHuc12_non_wetland_area</th>\n      <th>AwcHuc12_wetland_area</th>\n      <th>NhdAwcH12_wtd_wet_per</th>\n      <th>NhdAwcH12_wtd_lake_area_sqm</th>\n      <th>NhdAwcH12_wtd_lake_per</th>\n      <th>NhdAwcH12_wtd_glacier_area_sqm</th>\n      <th>NhdAwcH12_wtd_glacier_per</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Copper_River_75019800007852</th>\n      <td>7179.00</td>\n      <td>717900.00</td>\n      <td>1000</td>\n      <td>1210</td>\n      <td>210</td>\n      <td>1061.17</td>\n      <td>63.35</td>\n      <td>7618122.00</td>\n      <td>211</td>\n      <td>1005</td>\n      <td>...</td>\n      <td>55997900.00</td>\n      <td>15343900.00</td>\n      <td>21.51</td>\n      <td>70968900.00</td>\n      <td>372900.00</td>\n      <td>0.52</td>\n      <td>1207912.79</td>\n      <td>1.69</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75019800005498</th>\n      <td>2783.00</td>\n      <td>278300.00</td>\n      <td>981</td>\n      <td>1015</td>\n      <td>34</td>\n      <td>987.87</td>\n      <td>3.63</td>\n      <td>2749250.00</td>\n      <td>32</td>\n      <td>988</td>\n      <td>...</td>\n      <td>218281700.00</td>\n      <td>26206700.00</td>\n      <td>10.72</td>\n      <td>243275900.00</td>\n      <td>1212500.00</td>\n      <td>0.50</td>\n      <td>712726.10</td>\n      <td>0.29</td>\n      <td>106387407.76</td>\n      <td>43.48</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75019800019853</th>\n      <td>630.00</td>\n      <td>63000.00</td>\n      <td>794</td>\n      <td>1140</td>\n      <td>346</td>\n      <td>865.00</td>\n      <td>91.77</td>\n      <td>544952.00</td>\n      <td>197</td>\n      <td>797</td>\n      <td>...</td>\n      <td>231029100.00</td>\n      <td>56257700.00</td>\n      <td>19.58</td>\n      <td>283929500.00</td>\n      <td>3357300.00</td>\n      <td>1.17</td>\n      <td>303776.66</td>\n      <td>0.11</td>\n      <td>12957496.80</td>\n      <td>4.51</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75019800002596</th>\n      <td>3851.00</td>\n      <td>385100.00</td>\n      <td>795</td>\n      <td>904</td>\n      <td>109</td>\n      <td>832.89</td>\n      <td>25.84</td>\n      <td>3207477.00</td>\n      <td>110</td>\n      <td>807</td>\n      <td>...</td>\n      <td>66925300.00</td>\n      <td>27116100.00</td>\n      <td>28.83</td>\n      <td>92845100.00</td>\n      <td>1196300.00</td>\n      <td>1.27</td>\n      <td>700598.69</td>\n      <td>0.74</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75019800019678</th>\n      <td>39848.00</td>\n      <td>3984800.00</td>\n      <td>748</td>\n      <td>978</td>\n      <td>230</td>\n      <td>796.09</td>\n      <td>31.14</td>\n      <td>31722510.00</td>\n      <td>231</td>\n      <td>762</td>\n      <td>...</td>\n      <td>101165100.00</td>\n      <td>24739500.00</td>\n      <td>19.65</td>\n      <td>120104300.00</td>\n      <td>5800300.00</td>\n      <td>4.61</td>\n      <td>695198.05</td>\n      <td>0.55</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029086</th>\n      <td>1469.00</td>\n      <td>146900.00</td>\n      <td>2</td>\n      <td>7</td>\n      <td>5</td>\n      <td>3.88</td>\n      <td>0.89</td>\n      <td>5696.00</td>\n      <td>6</td>\n      <td>4</td>\n      <td>...</td>\n      <td>17465000.00</td>\n      <td>1929700.00</td>\n      <td>9.95</td>\n      <td>318600.00</td>\n      <td>19076100.00</td>\n      <td>98.36</td>\n      <td>576851.52</td>\n      <td>2.96</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900044552</th>\n      <td>11111.00</td>\n      <td>1111100.00</td>\n      <td>3</td>\n      <td>225</td>\n      <td>222</td>\n      <td>75.24</td>\n      <td>57.47</td>\n      <td>836045.00</td>\n      <td>223</td>\n      <td>5</td>\n      <td>...</td>\n      <td>10002100.00</td>\n      <td>2113300.00</td>\n      <td>17.44</td>\n      <td>10373300.00</td>\n      <td>1742100.00</td>\n      <td>14.38</td>\n      <td>424104.69</td>\n      <td>3.49</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900054944</th>\n      <td>121.00</td>\n      <td>12100.00</td>\n      <td>3</td>\n      <td>5</td>\n      <td>2</td>\n      <td>4.11</td>\n      <td>0.79</td>\n      <td>497.00</td>\n      <td>3</td>\n      <td>5</td>\n      <td>...</td>\n      <td>7381300.00</td>\n      <td>1345600.00</td>\n      <td>15.42</td>\n      <td>5613800.00</td>\n      <td>3113100.00</td>\n      <td>35.67</td>\n      <td>148894.93</td>\n      <td>1.70</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029096</th>\n      <td>3.00</td>\n      <td>300.00</td>\n      <td>3</td>\n      <td>5</td>\n      <td>2</td>\n      <td>3.67</td>\n      <td>0.94</td>\n      <td>11.00</td>\n      <td>2</td>\n      <td>3</td>\n      <td>...</td>\n      <td>14284800.00</td>\n      <td>3542200.00</td>\n      <td>19.87</td>\n      <td>17048200.00</td>\n      <td>778800.00</td>\n      <td>4.37</td>\n      <td>173685.96</td>\n      <td>0.97</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900047600</th>\n      <td>1022.00</td>\n      <td>102200.00</td>\n      <td>16</td>\n      <td>133</td>\n      <td>117</td>\n      <td>51.84</td>\n      <td>34.99</td>\n      <td>52985.00</td>\n      <td>115</td>\n      <td>18</td>\n      <td>...</td>\n      <td>42358100.00</td>\n      <td>12046500.00</td>\n      <td>22.14</td>\n      <td>54245300.00</td>\n      <td>159300.00</td>\n      <td>0.29</td>\n      <td>212347.89</td>\n      <td>0.39</td>\n      <td>6566375.44</td>\n      <td>12.05</td>\n    </tr>\n  </tbody>\n</table>\n<p>245 rows × 51 columns</p>\n</div>"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cop_df = df_final.filter(like='Copper', axis = 0)\n",
    "cop_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "                           AwcHuc12_cat_elev_COUNT  AwcHuc12_cat_elev_AREA  \\\ncat_ID_con                                                                   \nCook_Inlet_75004200000901                  3516.00               351600.00   \nCook_Inlet_75004200001724                  1410.00               141000.00   \nCook_Inlet_75004200001726                   196.00                19600.00   \nCook_Inlet_75004200001493                   525.00                52500.00   \nCook_Inlet_75004200004105                   458.00                45800.00   \n...                                            ...                     ...   \nCook_Inlet_75005400000004                 34837.00              3483700.00   \nCook_Inlet_75005400001431                  4333.00               433300.00   \nCook_Inlet_75005400031008                 17011.00              1701100.00   \nCook_Inlet_75005400024975                 13365.00              1336500.00   \nCook_Inlet_75004500000122                  3544.00               354400.00   \n\n                           AwcHuc12_cat_elev_MIN  AwcHuc12_cat_elev_MAX  \\\ncat_ID_con                                                                \nCook_Inlet_75004200000901                    143                    261   \nCook_Inlet_75004200001724                    111                    154   \nCook_Inlet_75004200001726                      2                      3   \nCook_Inlet_75004200001493                      4                    123   \nCook_Inlet_75004200004105                      0                      9   \n...                                          ...                    ...   \nCook_Inlet_75005400000004                      1                     52   \nCook_Inlet_75005400001431                      2                    107   \nCook_Inlet_75005400031008                     26                    292   \nCook_Inlet_75005400024975                     25                    306   \nCook_Inlet_75004500000122                      5                     44   \n\n                           AwcHuc12_cat_elev_RANGE  AwcHuc12_cat_elev_MEAN  \\\ncat_ID_con                                                                   \nCook_Inlet_75004200000901                      118                  175.17   \nCook_Inlet_75004200001724                       43                  121.82   \nCook_Inlet_75004200001726                        1                    2.24   \nCook_Inlet_75004200001493                      119                   26.79   \nCook_Inlet_75004200004105                        9                    3.67   \n...                                            ...                     ...   \nCook_Inlet_75005400000004                       51                   17.04   \nCook_Inlet_75005400001431                      105                   47.92   \nCook_Inlet_75005400031008                      266                   55.09   \nCook_Inlet_75005400024975                      281                   80.53   \nCook_Inlet_75004500000122                       39                   21.04   \n\n                           AwcHuc12_cat_elev_STD  AwcHuc12_cat_elev_SUM  \\\ncat_ID_con                                                                \nCook_Inlet_75004200000901                  26.46              615885.00   \nCook_Inlet_75004200001724                   7.19              171772.00   \nCook_Inlet_75004200001726                   0.43                 440.00   \nCook_Inlet_75004200001493                  24.60               14065.00   \nCook_Inlet_75004200004105                   2.14                1682.00   \n...                                          ...                    ...   \nCook_Inlet_75005400000004                   8.94              593625.00   \nCook_Inlet_75005400001431                  30.59              207650.00   \nCook_Inlet_75005400031008                  38.16              937201.00   \nCook_Inlet_75005400024975                  77.39             1076332.00   \nCook_Inlet_75004500000122                   7.88               74576.00   \n\n                           AwcHuc12_cat_elev_VARIETY  \\\ncat_ID_con                                             \nCook_Inlet_75004200000901                        119   \nCook_Inlet_75004200001724                         42   \nCook_Inlet_75004200001726                          2   \nCook_Inlet_75004200001493                         88   \nCook_Inlet_75004200004105                         10   \n...                                              ...   \nCook_Inlet_75005400000004                         52   \nCook_Inlet_75005400001431                        106   \nCook_Inlet_75005400031008                        258   \nCook_Inlet_75005400024975                        282   \nCook_Inlet_75004500000122                         40   \n\n                           AwcHuc12_cat_elev_MAJORITY  ...  \\\ncat_ID_con                                             ...   \nCook_Inlet_75004200000901                         163  ...   \nCook_Inlet_75004200001724                         115  ...   \nCook_Inlet_75004200001726                           2  ...   \nCook_Inlet_75004200001493                          15  ...   \nCook_Inlet_75004200004105                           5  ...   \n...                                               ...  ...   \nCook_Inlet_75005400000004                          16  ...   \nCook_Inlet_75005400001431                           2  ...   \nCook_Inlet_75005400031008                          33  ...   \nCook_Inlet_75005400024975                          36  ...   \nCook_Inlet_75004500000122                          11  ...   \n\n                           AwcHuc12_non_north_area  AwcHuc12_north_area  \\\ncat_ID_con                                                                \nCook_Inlet_75004200000901              31878600.00           5081600.00   \nCook_Inlet_75004200001724             126608700.00          44202600.00   \nCook_Inlet_75004200001726             439802800.00         130311400.00   \nCook_Inlet_75004200001493               8601100.00           1039700.00   \nCook_Inlet_75004200004105              12141000.00           1882800.00   \n...                                            ...                  ...   \nCook_Inlet_75005400000004              84065900.00          13340300.00   \nCook_Inlet_75005400001431             236668000.00          62550200.00   \nCook_Inlet_75005400031008             189522100.00          60275000.00   \nCook_Inlet_75005400024975             296172200.00          82432300.00   \nCook_Inlet_75004500000122              26921000.00           5184100.00   \n\n                           NhdAwcH12_wtd_north_per  AwcHuc12_non_wetland_area  \\\ncat_ID_con                                                                      \nCook_Inlet_75004200000901                    13.75                36773500.00   \nCook_Inlet_75004200001724                    25.88               168042700.00   \nCook_Inlet_75004200001726                    22.86               561341900.00   \nCook_Inlet_75004200001493                    10.78                 9640000.00   \nCook_Inlet_75004200004105                    13.43                13937200.00   \n...                                            ...                        ...   \nCook_Inlet_75005400000004                    13.70                96825500.00   \nCook_Inlet_75005400001431                    20.90               299218200.00   \nCook_Inlet_75005400031008                    24.13               249797100.00   \nCook_Inlet_75005400024975                    21.77               378604500.00   \nCook_Inlet_75004500000122                    16.15                17566100.00   \n\n                           AwcHuc12_wetland_area  NhdAwcH12_wtd_wet_per  \\\ncat_ID_con                                                                \nCook_Inlet_75004200000901              186700.00                   0.51   \nCook_Inlet_75004200001724             2768600.00                   1.62   \nCook_Inlet_75004200001726             8772300.00                   1.54   \nCook_Inlet_75004200001493                 800.00                   0.01   \nCook_Inlet_75004200004105               86600.00                   0.62   \n...                                          ...                    ...   \nCook_Inlet_75005400000004              580700.00                   0.60   \nCook_Inlet_75005400001431                   0.00                   0.00   \nCook_Inlet_75005400031008                   0.00                   0.00   \nCook_Inlet_75005400024975                   0.00                   0.00   \nCook_Inlet_75004500000122            14539000.00                  45.29   \n\n                           NhdAwcH12_wtd_lake_area_sqm  \\\ncat_ID_con                                               \nCook_Inlet_75004200000901                     15977.15   \nCook_Inlet_75004200001724                     84290.24   \nCook_Inlet_75004200001726                   4376541.86   \nCook_Inlet_75004200001493                          NaN   \nCook_Inlet_75004200004105                   1444489.01   \n...                                                ...   \nCook_Inlet_75005400000004                    319570.07   \nCook_Inlet_75005400001431                   1818188.02   \nCook_Inlet_75005400031008                     60912.69   \nCook_Inlet_75005400024975                    787710.74   \nCook_Inlet_75004500000122                   3245825.29   \n\n                           NhdAwcH12_wtd_lake_per  \\\ncat_ID_con                                          \nCook_Inlet_75004200000901                    0.04   \nCook_Inlet_75004200001724                    0.05   \nCook_Inlet_75004200001726                    0.77   \nCook_Inlet_75004200001493                     NaN   \nCook_Inlet_75004200004105                   10.30   \n...                                           ...   \nCook_Inlet_75005400000004                    0.33   \nCook_Inlet_75005400001431                    0.61   \nCook_Inlet_75005400031008                    0.02   \nCook_Inlet_75005400024975                    0.21   \nCook_Inlet_75004500000122                   10.11   \n\n                           NhdAwcH12_wtd_glacier_area_sqm  \\\ncat_ID_con                                                  \nCook_Inlet_75004200000901                      1350380.22   \nCook_Inlet_75004200001724                     25840654.84   \nCook_Inlet_75004200001726                     93381603.10   \nCook_Inlet_75004200001493                       353510.78   \nCook_Inlet_75004200004105                       306739.92   \n...                                                   ...   \nCook_Inlet_75005400000004                     50807902.37   \nCook_Inlet_75005400001431                      1600140.31   \nCook_Inlet_75005400031008                      8858865.70   \nCook_Inlet_75005400024975                             NaN   \nCook_Inlet_75004500000122                             NaN   \n\n                           NhdAwcH12_wtd_glacier_per  \ncat_ID_con                                            \nCook_Inlet_75004200000901                       3.65  \nCook_Inlet_75004200001724                      15.13  \nCook_Inlet_75004200001726                      16.38  \nCook_Inlet_75004200001493                       3.67  \nCook_Inlet_75004200004105                       2.19  \n...                                              ...  \nCook_Inlet_75005400000004                      52.16  \nCook_Inlet_75005400001431                       0.53  \nCook_Inlet_75005400031008                       3.55  \nCook_Inlet_75005400024975                        NaN  \nCook_Inlet_75004500000122                        NaN  \n\n[661 rows x 51 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AwcHuc12_cat_elev_COUNT</th>\n      <th>AwcHuc12_cat_elev_AREA</th>\n      <th>AwcHuc12_cat_elev_MIN</th>\n      <th>AwcHuc12_cat_elev_MAX</th>\n      <th>AwcHuc12_cat_elev_RANGE</th>\n      <th>AwcHuc12_cat_elev_MEAN</th>\n      <th>AwcHuc12_cat_elev_STD</th>\n      <th>AwcHuc12_cat_elev_SUM</th>\n      <th>AwcHuc12_cat_elev_VARIETY</th>\n      <th>AwcHuc12_cat_elev_MAJORITY</th>\n      <th>...</th>\n      <th>AwcHuc12_non_north_area</th>\n      <th>AwcHuc12_north_area</th>\n      <th>NhdAwcH12_wtd_north_per</th>\n      <th>AwcHuc12_non_wetland_area</th>\n      <th>AwcHuc12_wetland_area</th>\n      <th>NhdAwcH12_wtd_wet_per</th>\n      <th>NhdAwcH12_wtd_lake_area_sqm</th>\n      <th>NhdAwcH12_wtd_lake_per</th>\n      <th>NhdAwcH12_wtd_glacier_area_sqm</th>\n      <th>NhdAwcH12_wtd_glacier_per</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Cook_Inlet_75004200000901</th>\n      <td>3516.00</td>\n      <td>351600.00</td>\n      <td>143</td>\n      <td>261</td>\n      <td>118</td>\n      <td>175.17</td>\n      <td>26.46</td>\n      <td>615885.00</td>\n      <td>119</td>\n      <td>163</td>\n      <td>...</td>\n      <td>31878600.00</td>\n      <td>5081600.00</td>\n      <td>13.75</td>\n      <td>36773500.00</td>\n      <td>186700.00</td>\n      <td>0.51</td>\n      <td>15977.15</td>\n      <td>0.04</td>\n      <td>1350380.22</td>\n      <td>3.65</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004200001724</th>\n      <td>1410.00</td>\n      <td>141000.00</td>\n      <td>111</td>\n      <td>154</td>\n      <td>43</td>\n      <td>121.82</td>\n      <td>7.19</td>\n      <td>171772.00</td>\n      <td>42</td>\n      <td>115</td>\n      <td>...</td>\n      <td>126608700.00</td>\n      <td>44202600.00</td>\n      <td>25.88</td>\n      <td>168042700.00</td>\n      <td>2768600.00</td>\n      <td>1.62</td>\n      <td>84290.24</td>\n      <td>0.05</td>\n      <td>25840654.84</td>\n      <td>15.13</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004200001726</th>\n      <td>196.00</td>\n      <td>19600.00</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2.24</td>\n      <td>0.43</td>\n      <td>440.00</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>439802800.00</td>\n      <td>130311400.00</td>\n      <td>22.86</td>\n      <td>561341900.00</td>\n      <td>8772300.00</td>\n      <td>1.54</td>\n      <td>4376541.86</td>\n      <td>0.77</td>\n      <td>93381603.10</td>\n      <td>16.38</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004200001493</th>\n      <td>525.00</td>\n      <td>52500.00</td>\n      <td>4</td>\n      <td>123</td>\n      <td>119</td>\n      <td>26.79</td>\n      <td>24.60</td>\n      <td>14065.00</td>\n      <td>88</td>\n      <td>15</td>\n      <td>...</td>\n      <td>8601100.00</td>\n      <td>1039700.00</td>\n      <td>10.78</td>\n      <td>9640000.00</td>\n      <td>800.00</td>\n      <td>0.01</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>353510.78</td>\n      <td>3.67</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004200004105</th>\n      <td>458.00</td>\n      <td>45800.00</td>\n      <td>0</td>\n      <td>9</td>\n      <td>9</td>\n      <td>3.67</td>\n      <td>2.14</td>\n      <td>1682.00</td>\n      <td>10</td>\n      <td>5</td>\n      <td>...</td>\n      <td>12141000.00</td>\n      <td>1882800.00</td>\n      <td>13.43</td>\n      <td>13937200.00</td>\n      <td>86600.00</td>\n      <td>0.62</td>\n      <td>1444489.01</td>\n      <td>10.30</td>\n      <td>306739.92</td>\n      <td>2.19</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75005400000004</th>\n      <td>34837.00</td>\n      <td>3483700.00</td>\n      <td>1</td>\n      <td>52</td>\n      <td>51</td>\n      <td>17.04</td>\n      <td>8.94</td>\n      <td>593625.00</td>\n      <td>52</td>\n      <td>16</td>\n      <td>...</td>\n      <td>84065900.00</td>\n      <td>13340300.00</td>\n      <td>13.70</td>\n      <td>96825500.00</td>\n      <td>580700.00</td>\n      <td>0.60</td>\n      <td>319570.07</td>\n      <td>0.33</td>\n      <td>50807902.37</td>\n      <td>52.16</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75005400001431</th>\n      <td>4333.00</td>\n      <td>433300.00</td>\n      <td>2</td>\n      <td>107</td>\n      <td>105</td>\n      <td>47.92</td>\n      <td>30.59</td>\n      <td>207650.00</td>\n      <td>106</td>\n      <td>2</td>\n      <td>...</td>\n      <td>236668000.00</td>\n      <td>62550200.00</td>\n      <td>20.90</td>\n      <td>299218200.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1818188.02</td>\n      <td>0.61</td>\n      <td>1600140.31</td>\n      <td>0.53</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75005400031008</th>\n      <td>17011.00</td>\n      <td>1701100.00</td>\n      <td>26</td>\n      <td>292</td>\n      <td>266</td>\n      <td>55.09</td>\n      <td>38.16</td>\n      <td>937201.00</td>\n      <td>258</td>\n      <td>33</td>\n      <td>...</td>\n      <td>189522100.00</td>\n      <td>60275000.00</td>\n      <td>24.13</td>\n      <td>249797100.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>60912.69</td>\n      <td>0.02</td>\n      <td>8858865.70</td>\n      <td>3.55</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75005400024975</th>\n      <td>13365.00</td>\n      <td>1336500.00</td>\n      <td>25</td>\n      <td>306</td>\n      <td>281</td>\n      <td>80.53</td>\n      <td>77.39</td>\n      <td>1076332.00</td>\n      <td>282</td>\n      <td>36</td>\n      <td>...</td>\n      <td>296172200.00</td>\n      <td>82432300.00</td>\n      <td>21.77</td>\n      <td>378604500.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>787710.74</td>\n      <td>0.21</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004500000122</th>\n      <td>3544.00</td>\n      <td>354400.00</td>\n      <td>5</td>\n      <td>44</td>\n      <td>39</td>\n      <td>21.04</td>\n      <td>7.88</td>\n      <td>74576.00</td>\n      <td>40</td>\n      <td>11</td>\n      <td>...</td>\n      <td>26921000.00</td>\n      <td>5184100.00</td>\n      <td>16.15</td>\n      <td>17566100.00</td>\n      <td>14539000.00</td>\n      <td>45.29</td>\n      <td>3245825.29</td>\n      <td>10.11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>661 rows × 51 columns</p>\n</div>"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ci_df = df_final.filter(like='Cook', axis = 0)\n",
    "ci_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8caab41e",
   "language": "python",
   "display_name": "PyCharm (AKSSF)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}