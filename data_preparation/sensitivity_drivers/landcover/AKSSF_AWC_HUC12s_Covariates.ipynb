{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a id='top'></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Watershed metrics for all Huc12 subwatersheds that intersect AWC recorded streams\n",
    "Iterate over AKSSF regions and identify all HUC12 sub-watersheds that intersect an AWC recorded stream. Identify the downstream-most/outlet catchment for each Huc12 from this pool and convert the polygon to INSIDE centroid point.  Calculate the distance to coastline as the straight line distance in Km from centroid point to NHD recorded coastline and export this as a feature class/table.  Next use the outlet catchments unique identifier to query the appropriate dataset and build watersheds for each outlet catchment.  Calculate watershed metrics listed in the covariate section and export final merged csv using the catchment unique identifier field \"cat_ID_con\" to link the metric back to the source catchment/HUC12.  Merge watersheds together and use to calculate covariates.\n",
    "## Covariates\n",
    "Covariates needed for prediction on AWC-HUC12 outlets are as follows:\n",
    "### Summer Precipitation\n",
    "To be calculated in R using the outlet catchment centroid point feature class exported during outlet identification process.\n",
    "### Watershed Slope Metrics\n",
    "Regional Slope grids created in AKSSF_merge_grids.ipynb script.\n",
    "Run zonal statistics on slope grid using merged watershed as zone feature.\n",
    "Field names and descriptions:\n",
    "* **awc_huc12s_wtd_slope_mn = mean watershed slope**\n",
    "* **awc_huc12s_wtd_slope_min = min watershed slope**\n",
    "* **awc_huc12s_wtd_slope_max = max watershed slope**\n",
    "* **awc_huc12s_wtd_slope_sd (or cv) = standard deviation of watershed slope**\n",
    "### Watershed Percent North Aspect\n",
    "Regional North grids created in AKSSF_merge_grids.ipynb scripts.\n",
    "North = aspects from 315-45 degrees and calculate the percentage of land area facing north for each watershed. Run tabulate area on north grid using merged watershed as zone feature and calculate percentage from area.\n",
    "Field names and descriptions:\n",
    "* **awc_huc12s_north_wtd = percent watershed with north aspect**\n",
    "### Watershed Percent Lake Cover\n",
    "Lakes feature classes for each network datatype (NHDPlus vs TauDEM) stored in AKSSF hydrography database on the T:\n",
    "Calculate percentage of watershed that is covered by lakes/ponds using tabulate interesection between lake features and watersheds.\n",
    "Field names and descriptions:\n",
    "* **awc_huc12s_wtd_lake_per = percent watershed covered by lakes**\n",
    "### Watershed Percent Glacier Cover\n",
    "Use input glacier fc (from previous covariate calculations) stored in regional gdbs an calculate percent of watershed with glacial coverage using tabulate intersection between lake features and watersheds.\n",
    "Field names and descriptions:\n",
    "* **awc_huc12s_wtd_glac_per = percent watershed covered by glaciers**\n",
    "### Watershed LCLD\n",
    "LCLD rasters created in AKSSF_MODIS_lcld_ipynb.\n",
    "Iterate over LCLD input rasters to produce yearly means for watersheds using zonal statistics.\n",
    "Field names and descriptions:\n",
    "* **awc_huc12s_wtd_lcld_mn_YYYY = mean lcld**\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import modules\n",
    "Set initial environments and import modules\n",
    "Print system paths"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports complete\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sys paths ['C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\AKSSF\\\\data_preparation\\\\sensitivity_drivers\\\\landcover', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\Resources\\\\ArcPy', 'C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\AKSSF', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\python37.zip', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\DLLs', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3', '', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\Resources\\\\ArcToolbox\\\\Scripts', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\Resources\\\\ArcToolBox\\\\Scripts', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\Resources\\\\ArcToolBox\\\\Scripts\\\\archydro', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\Resources\\\\ArcToolBox\\\\Scripts\\\\GRAIP', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\future-0.18.2-py3.7.egg', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\pytz-2020.1-py3.7.egg', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\pywin32_ctypes-0.2.0-py3.7.egg', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\pywin32security', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\sympy-1.5.1-py3.7.egg', 'C:\\\\Users\\\\dwmerrigan\\\\AppData\\\\Local\\\\Programs\\\\ArcGIS\\\\Pro\\\\bin\\\\Python\\\\envs\\\\arcgispro-py3\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\dwmerrigan\\\\.ipython']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Python Environment set to - C:\\Users\\dwmerrigan\\AppData\\Local\\Programs\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "2022-02-09 17:16:38.731405\n",
      "CSV table output directory set to C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\n"
     ]
    }
   ],
   "source": [
    "import os, arcpy, sys,datetime\n",
    "arcpy.env.overwriteOutput = True\n",
    "sr = arcpy.SpatialReference(3338)  #'NAD_1983_Alaska_Albers'\n",
    "arcpy.env.outputCoordinateSystem = sr\n",
    "\n",
    "print('imports complete')\n",
    "print(f'{(\"-\"*100)}')\n",
    "print(f'sys paths {sys.path}')\n",
    "print(f'{(\"-\"*100)}')\n",
    "print(f'Python Environment set to - {sys.base_exec_prefix}')\n",
    "print(f'{(\"-\"*100)}')\n",
    "print (datetime.datetime.now())\n",
    "outdir = os.path.dirname(os.getcwd())\n",
    "print(f'CSV table output directory set to {outdir}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functions\n",
    "Define any functions that will be used"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Function to add key, value pairs to dictionary\n",
    "def append_value(dict_obj, key, value):\n",
    "    # Check if key exist in dict or not\n",
    "    if key in dict_obj:\n",
    "        # Key exist in dict.\n",
    "        # Check if type of value of key is list or not\n",
    "        if not isinstance(dict_obj[key], list):\n",
    "            # If type is not list then make it list\n",
    "            dict_obj[key] = [dict_obj[key]]\n",
    "        # Append the value in list\n",
    "        dict_obj[key].append(value)\n",
    "    else:\n",
    "        # As key is not in dict,\n",
    "        # so, add key-value pair\n",
    "        dict_obj[key] = value\n",
    "# Function to remove parenthesis from user inputs\n",
    "def replace_all(userinput, dic):\n",
    "    for i, j in dic.items():\n",
    "        userinput = userinput.replace(i, j)\n",
    "    return userinput\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 1\n",
    "### Set input datasets, output locations, and scratch workspaces\n",
    "User to input paths for necessary input data and output locations\n",
    "Scratch workspaces and output workspaces will be automatically created if they do not already exist."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NHDPlus lakes set to D:\\Basedata\\AKSSF_Basedata\\AKSSF_Basedata.gdb\\AKSSF_NHDPlus_LakePond_alb\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "NHD_H_Alaska lakes for TauDEM regions set to D:\\Basedata\\AKSSF_Basedata\\AKSSF_Basedata.gdb\\AKSSF_NHDPlus_LakePond_alb\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "AKSSF parent directory set to D:\\GIS\\AKSSF\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "AWC events feature class set to D:\\Basedata\\AWC\\AWC_2021_SpeciesEvents.gdb\\awcEventArcs\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Output locations will be created at D:\\GIS\\\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "LCLD subfolders located at D:\\Basedata\\LCLD_rasters_archive\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Working Folder already created D:\\GIS\\AKSSF_awcHuc12_cv\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Output location already exists D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\n",
      " ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Get user inputs\n",
    "# Used to format user inputs\n",
    "inputDict = {\"'\":\"\",'\"':\"\"}\n",
    "\n",
    "# Specify path to nhdPlus lakes\n",
    "while True:\n",
    "    try:\n",
    "        userinput7 = replace_all((input('Input path to NHDPlus lakes feature class.\\nHydrography database on T: has copy\\nLeave blank and hit enter to use the default location.\\nDefault = D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\AKSSF_NHDPlus_LakePond_alb') or 'D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\AKSSF_NHDPlus_LakePond_alb'),inputDict)\n",
    "        if not arcpy.Exists(userinput7):\n",
    "            print('Path specified does not exist!\\nPlease re-enter a valid path')\n",
    "            continue\n",
    "        else:\n",
    "            nhd_lakes_fc = userinput7\n",
    "            break\n",
    "    except KeyboardInterrupt:\n",
    "        print('interrupted!')\n",
    "        sys.exit()\n",
    "\n",
    "print(f'NHDPlus lakes set to {nhd_lakes_fc}\\n {\"-\"*100}')\n",
    "\n",
    "# Specify path to nhd lakes for tau regions\n",
    "while True:\n",
    "    try:\n",
    "        userinput8 = replace_all((input('Input path to NHD_H_Alaska_State_GDB lakes feature class.\\nHydrography database on T: has copy\\nLeave blank and hit enter to use the default location.\\nDefault = D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\AKSSF_NHD_LakesPonds_alb') or 'D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\AKSSF_NHD_LakesPonds_alb'),inputDict)\n",
    "        if not arcpy.Exists(userinput8):\n",
    "            print('Path specified does not exist!\\nPlease re-enter a valid path')\n",
    "            continue\n",
    "        else:\n",
    "            tau_lakes_fc = userinput8\n",
    "            break\n",
    "    except KeyboardInterrupt:\n",
    "        print('interrupted!')\n",
    "        sys.exit()\n",
    "print(f'NHD_H_Alaska lakes for TauDEM regions set to {nhd_lakes_fc}\\n {\"-\"*100}')\n",
    "\n",
    "# Specify path to AKSSF parent directory\n",
    "while True:\n",
    "    try:\n",
    "        userinput = replace_all((input('Input AKSSF parent directory containing regional sub-folders.\\nLeave blank and hit enter to use the default location.\\nDefault = D:\\\\GIS\\\\AKSSF\\\\') or 'D:\\\\GIS\\\\AKSSF'),inputDict)\n",
    "        if not arcpy.Exists(userinput):\n",
    "            print('Path specified does not exist!\\nPlease re-enter a valid path')\n",
    "            continue\n",
    "        else:\n",
    "            data_dir = userinput\n",
    "            break\n",
    "    except KeyboardInterrupt:\n",
    "        print('interrupted!')\n",
    "        sys.exit()\n",
    "\n",
    "print(f'AKSSF parent directory set to {data_dir}\\n {\"-\"*100}')\n",
    "\n",
    "# Specify path to AWC events fc\n",
    "while True:\n",
    "    try:\n",
    "        userinput2 = replace_all((input('Input path to awc events feature class or shapefile.\\nLeave blank and hit enter to use the default location.\\nDefault = D:\\\\Basedata\\\\AWC\\\\AWC_2021_SpeciesEvents.gdb\\\\awcEventArcs') or \"D:\\\\Basedata\\\\AWC\\\\AWC_2021_SpeciesEvents.gdb\\\\awcEventArcs\"), inputDict)\n",
    "        if not arcpy.Exists(userinput2):\n",
    "            print('Path specified does not exist!\\nPlease re-enter a valid path')\n",
    "            continue\n",
    "        else:\n",
    "            awc_events = userinput2\n",
    "            break\n",
    "    except KeyboardInterrupt:\n",
    "        print('interrupted!')\n",
    "        sys.exit()\n",
    "print(f'AWC events feature class set to {awc_events}\\n {\"-\"*100}')\n",
    "\n",
    "# Enter output destination  - to create working folders and gdbs\n",
    "while True:\n",
    "    try:\n",
    "        userinput3 = replace_all((input('Input path to create working folders.\\nLeave blank and hit enter to use the default location.\\nDefault = D:\\\\GIS\\\\') or 'D:\\\\GIS\\\\'),inputDict)\n",
    "        if not arcpy.Exists(userinput):\n",
    "            print('Path specified does not exist!\\nPlease re-enter a valid path')\n",
    "            continue\n",
    "        else:\n",
    "            temp_path = userinput3\n",
    "            print(f'Output locations will be created at {temp_path}\\n {\"-\"*100}')\n",
    "            break\n",
    "    except KeyboardInterrupt:\n",
    "        print('interrupted!')\n",
    "        sys.exit()\n",
    "\n",
    "\n",
    "# Path to lcld rasters\n",
    "lcld_folder = r'D:\\\\Basedata\\\\LCLD_rasters_archive'\n",
    "# Enter output destination  - to create working folders and gdbs\n",
    "while True:\n",
    "    try:\n",
    "        userinput4 = replace_all((input('Input path to LCLD raster parent folder.\\nLeave blank and hit enter to use the default location.\\nDefault = D:\\\\Basedata\\\\LCLD_rasters_archive\\\\') or 'D:\\\\Basedata\\\\LCLD_rasters_archive'),inputDict)\n",
    "        if not arcpy.Exists(userinput):\n",
    "            print('Path specified does not exist!\\nPlease re-enter a valid path')\n",
    "            continue\n",
    "        else:\n",
    "            lcld_folder = userinput4\n",
    "            print(f'LCLD subfolders located at {lcld_folder}\\n {\"-\"*100}')\n",
    "            break\n",
    "    except KeyboardInterrupt:\n",
    "        print('interrupted!')\n",
    "        sys.exit()\n",
    "\n",
    "## Create working output location to store intermediate data\n",
    "dirname = 'AKSSF_awcHuc12_cv'\n",
    "tempgdbname = 'AKSSF_awcHuc12_cv.gdb'\n",
    "temp_dir = os.path.join(temp_path, dirname)\n",
    "\n",
    "# Create temporary working gdb\n",
    "if not arcpy.Exists(temp_dir):\n",
    "    os.makedirs(temp_dir)\n",
    "else:\n",
    "    print(f'Working Folder already created {temp_dir}\\n {\"-\"*100}')\n",
    "\n",
    "outcheck = os.path.join(temp_dir, tempgdbname)\n",
    "\n",
    "if arcpy.Exists(outcheck):\n",
    "    print (f'Output location already exists {outcheck}\\n {\"-\"*100}')\n",
    "    outgdb = outcheck\n",
    "if not arcpy.Exists(outcheck):\n",
    "    print(f'Creating output GDB\\n {\"-\"*100}')\n",
    "    tempgdb = arcpy.CreateFileGDB_management(temp_dir,tempgdbname)\n",
    "    print (f'Output geodatabase created at {outcheck}\\n {\"-\"*100}')\n",
    "    outgdb = tempgdb.getOutput(0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 1.1\n",
    "### Set and create local copies of additional input data\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tau Region Hucs D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\\NHD_H_HUC12 located and exists = True\n",
      "NHDPlus Hucs D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\\NHDPlusHUC12 located and exists = True\n"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "arcpy.env.overwriteOutput = True\n",
    "sr = arcpy.SpatialReference(3338)  #'NAD_1983_Alaska_Albers'\n",
    "arcpy.env.outputCoordinateSystem = sr\n",
    "\n",
    "nhdplusfol = []\n",
    "tahuc12=[]\n",
    "\n",
    "# Create and set HUC12 data if it does not already exist\n",
    "nhdplushucs = os.path.join(outgdb, 'NHDPlusHUC12')\n",
    "tauhucs = os.path.join(outgdb, 'NHD_H_HUC12')\n",
    "\n",
    "if not arcpy.Exists(tauhucs):\n",
    "    print(f'Huc12 data for Tau Regions not yet created')\n",
    "    #Enter path to WBDHU12 from NHD_H gdb\n",
    "    while True:\n",
    "        try:\n",
    "            userinput6 = replace_all((input('Input path to source WBDHU12 for state of Alaska.\\nLeave blank and hit enter to use the default location.\\nDefault = D:\\\\Basedata\\\\NHD_H_Alaska_State_GDB.gdb\\\\WBD\\\\WBDHU12') or 'D:\\\\Basedata\\\\NHD_H_Alaska_State_GDB.gdb\\\\WBD\\\\WBDHU12'),inputDict)\n",
    "            if not arcpy.Exists(userinput6):\n",
    "                print('Path specified does not exist!\\nPlease re-enter a valid path')\n",
    "                continue\n",
    "            else:\n",
    "                tauhuc12 = userinput6\n",
    "                arcpy.CopyFeatures_management(tauhuc12,tauhucs)\n",
    "                print(f'WBD Huc12  copied to {tauhucs}\\n {\"-\"*100}')\n",
    "                break\n",
    "        except KeyboardInterrupt:\n",
    "            print('interrupted!')\n",
    "            sys.exit()\n",
    "\n",
    "else:\n",
    "    print(f'Tau Region Hucs {tauhucs} located and exists = {arcpy.Exists(tauhucs)}')\n",
    "\n",
    "if not arcpy.Exists(nhdplushucs):\n",
    "    print(f'Huc12 data for NHDPlus Regions not yet created')\n",
    "    #Enter NHDplus data folder\n",
    "    while True:\n",
    "        try:\n",
    "            userinput5 = replace_all((input('Input path to source NHDPlus parent folder.\\nLeave blank and hit enter to use the default location.\\nDefault = D:\\\\Basedata\\\\NHDPlus') or 'D:\\\\Basedata\\\\NHDPlus'),inputDict)\n",
    "            if not arcpy.Exists(userinput5):\n",
    "                print('Path specified does not exist!\\nPlease re-enter a valid path')\n",
    "                continue\n",
    "            else:\n",
    "                nhdplusfol = userinput5\n",
    "                print(f'NHD HUC12 will be copied to {nhdplushucs}\\n {\"-\"*100}')\n",
    "                hucs = []\n",
    "                walk = arcpy.da.Walk(nhdplusfol, datatype=\"FeatureClass\", type=\"Polygon\")\n",
    "\n",
    "                for dirpath, dirnames, filenames in walk:\n",
    "                    for filename in filenames:\n",
    "                        if filename == 'WBDHU12':\n",
    "                            hucs.append(os.path.join(dirpath, filename))\n",
    "                arcpy.Merge_management(hucs,nhdplushucs,'','ADD_SOURCE_INFO')\n",
    "                break\n",
    "        except KeyboardInterrupt:\n",
    "            print('interrupted!')\n",
    "            sys.exit()\n",
    "else:\n",
    "    print(f'NHDPlus Hucs {nhdplushucs} located and exists = {arcpy.Exists(nhdplushucs)}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 2\n",
    "### By Region\n",
    "Identify downstream-most catchment for each Huc 12\n",
    " * Select by location and select catchment with most us contributing area\n",
    "    * NHDPlus\n",
    "        * Use update cursor to join TotalDrainageAreaSqKm from vaa table to catchment\n",
    "        * Find max value from selection and save as outlet catchment for that HUC12\n",
    "    * TauDEM\n",
    "        * DSContArea - Drainage area at the downstream end of the link. Generally this is one grid cell upstream of the downstream end because the drainage area at the downstream end grid cell includes the area of the stream being joined.\n",
    " * Generate Centroid point and append to centroid dataset\n",
    "    * Retain cat_id and Huc12-id\n",
    " * Append to HUC12 catchment dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prince_William_Sound\n",
      "Prince_William_Sound using data from Prince_William_Sound folder\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Region Prince_William_Sound will not be processed\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "158 huc12s in Prince_William_Sound\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "112 Huc12s in Prince_William_Sound intersect awc events input\n",
      "****************************************************************************************************\n",
      "Processing HUC 190202011602\n",
      "1. Finding outlet for HUC 190202011602 out of 253 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011604\n",
      "2. Finding outlet for HUC 190202011604 out of 105 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012506\n",
      "3. Finding outlet for HUC 190202012506 out of 132 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011106\n",
      "4. Finding outlet for HUC 190202011106 out of 155 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012304\n",
      "5. Finding outlet for HUC 190202012304 out of 490 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010602\n",
      "6. Finding outlet for HUC 190202010602 out of 123 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012502\n",
      "7. Finding outlet for HUC 190202012502 out of 161 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011307\n",
      "8. Finding outlet for HUC 190202011307 out of 656 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012001\n",
      "9. Finding outlet for HUC 190202012001 out of 88 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010301\n",
      "10. Finding outlet for HUC 190202010301 out of 277 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011603\n",
      "11. Finding outlet for HUC 190202011603 out of 38 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012309\n",
      "12. Finding outlet for HUC 190202012309 out of 261 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011108\n",
      "13. Finding outlet for HUC 190202011108 out of 130 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011503\n",
      "14. Finding outlet for HUC 190202011503 out of 234 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011804\n",
      "15. Finding outlet for HUC 190202011804 out of 481 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012508\n",
      "16. Finding outlet for HUC 190202012508 out of 342 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011601\n",
      "17. Finding outlet for HUC 190202011601 out of 82 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012101\n",
      "18. Finding outlet for HUC 190202012101 out of 102 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010703\n",
      "19. Finding outlet for HUC 190202010703 out of 128 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011107\n",
      "20. Finding outlet for HUC 190202011107 out of 192 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010105\n",
      "21. Finding outlet for HUC 190202010105 out of 281 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012103\n",
      "22. Finding outlet for HUC 190202012103 out of 50 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010603\n",
      "23. Finding outlet for HUC 190202010603 out of 59 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011403\n",
      "24. Finding outlet for HUC 190202011403 out of 145 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010907\n",
      "25. Finding outlet for HUC 190202010907 out of 272 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010701\n",
      "26. Finding outlet for HUC 190202010701 out of 244 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011105\n",
      "27. Finding outlet for HUC 190202011105 out of 395 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012204\n",
      "28. Finding outlet for HUC 190202012204 out of 288 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012307\n",
      "29. Finding outlet for HUC 190202012307 out of 97 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010905\n",
      "30. Finding outlet for HUC 190202010905 out of 289 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011308\n",
      "31. Finding outlet for HUC 190202011308 out of 137 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012102\n",
      "32. Finding outlet for HUC 190202012102 out of 185 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011504\n",
      "33. Finding outlet for HUC 190202011504 out of 186 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011805\n",
      "34. Finding outlet for HUC 190202011805 out of 460 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011505\n",
      "35. Finding outlet for HUC 190202011505 out of 525 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010704\n",
      "36. Finding outlet for HUC 190202010704 out of 90 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011906\n",
      "37. Finding outlet for HUC 190202011906 out of 321 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010601\n",
      "38. Finding outlet for HUC 190202010601 out of 113 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010804\n",
      "39. Finding outlet for HUC 190202010804 out of 149 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011102\n",
      "40. Finding outlet for HUC 190202011102 out of 286 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011401\n",
      "41. Finding outlet for HUC 190202011401 out of 253 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012507\n",
      "42. Finding outlet for HUC 190202012507 out of 148 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012505\n",
      "43. Finding outlet for HUC 190202012505 out of 91 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010702\n",
      "44. Finding outlet for HUC 190202010702 out of 166 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011103\n",
      "45. Finding outlet for HUC 190202011103 out of 154 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011402\n",
      "46. Finding outlet for HUC 190202011402 out of 159 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012501\n",
      "47. Finding outlet for HUC 190202012501 out of 123 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010102\n",
      "48. Finding outlet for HUC 190202010102 out of 337 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010401\n",
      "49. Finding outlet for HUC 190202010401 out of 85 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012301\n",
      "50. Finding outlet for HUC 190202012301 out of 390 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010302\n",
      "51. Finding outlet for HUC 190202010302 out of 149 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010908\n",
      "52. Finding outlet for HUC 190202010908 out of 603 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011109\n",
      "53. Finding outlet for HUC 190202011109 out of 146 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011110\n",
      "54. Finding outlet for HUC 190202011110 out of 74 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012104\n",
      "55. Finding outlet for HUC 190202012104 out of 332 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011104\n",
      "56. Finding outlet for HUC 190202011104 out of 508 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012002\n",
      "57. Finding outlet for HUC 190202012002 out of 328 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011606\n",
      "58. Finding outlet for HUC 190202011606 out of 85 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010604\n",
      "59. Finding outlet for HUC 190202010604 out of 325 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010402\n",
      "60. Finding outlet for HUC 190202010402 out of 212 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011101\n",
      "61. Finding outlet for HUC 190202011101 out of 131 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011202\n",
      "62. Finding outlet for HUC 190202011202 out of 219 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010200\n",
      "63. Finding outlet for HUC 190202010200 out of 402 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012504\n",
      "64. Finding outlet for HUC 190202012504 out of 217 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012510\n",
      "65. Finding outlet for HUC 190202012510 out of 185 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012310\n",
      "66. Finding outlet for HUC 190202012310 out of 281 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011404\n",
      "67. Finding outlet for HUC 190202011404 out of 128 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012105\n",
      "68. Finding outlet for HUC 190202012105 out of 350 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011201\n",
      "69. Finding outlet for HUC 190202011201 out of 134 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012509\n",
      "70. Finding outlet for HUC 190202012509 out of 156 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010705\n",
      "71. Finding outlet for HUC 190202010705 out of 461 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012003\n",
      "72. Finding outlet for HUC 190202012003 out of 400 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012511\n",
      "73. Finding outlet for HUC 190202012511 out of 67 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012306\n",
      "74. Finding outlet for HUC 190202012306 out of 97 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202012308\n",
      "75. Finding outlet for HUC 190202012308 out of 105 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010503\n",
      "76. Finding outlet for HUC 190202010503 out of 502 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010303\n",
      "77. Finding outlet for HUC 190202010303 out of 48 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202010906\n",
      "78. Finding outlet for HUC 190202010906 out of 231 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202011605\n",
      "79. Finding outlet for HUC 190202011605 out of 209 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030105\n",
      "80. Finding outlet for HUC 190202030105 out of 302 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030208\n",
      "81. Finding outlet for HUC 190202030208 out of 85 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030302\n",
      "82. Finding outlet for HUC 190202030302 out of 46 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030204\n",
      "83. Finding outlet for HUC 190202030204 out of 65 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030205\n",
      "84. Finding outlet for HUC 190202030205 out of 144 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030304\n",
      "85. Finding outlet for HUC 190202030304 out of 232 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030202\n",
      "86. Finding outlet for HUC 190202030202 out of 135 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030207\n",
      "87. Finding outlet for HUC 190202030207 out of 93 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030701\n",
      "88. Finding outlet for HUC 190202030701 out of 278 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030104\n",
      "89. Finding outlet for HUC 190202030104 out of 108 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030502\n",
      "90. Finding outlet for HUC 190202030502 out of 99 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030503\n",
      "91. Finding outlet for HUC 190202030503 out of 377 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030206\n",
      "92. Finding outlet for HUC 190202030206 out of 48 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030201\n",
      "93. Finding outlet for HUC 190202030201 out of 103 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030409\n",
      "94. Finding outlet for HUC 190202030409 out of 218 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030403\n",
      "95. Finding outlet for HUC 190202030403 out of 159 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030101\n",
      "96. Finding outlet for HUC 190202030101 out of 476 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030203\n",
      "97. Finding outlet for HUC 190202030203 out of 122 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030406\n",
      "98. Finding outlet for HUC 190202030406 out of 445 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030305\n",
      "99. Finding outlet for HUC 190202030305 out of 47 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030102\n",
      "100. Finding outlet for HUC 190202030102 out of 284 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030306\n",
      "101. Finding outlet for HUC 190202030306 out of 67 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030702\n",
      "102. Finding outlet for HUC 190202030702 out of 1016 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030209\n",
      "103. Finding outlet for HUC 190202030209 out of 147 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030303\n",
      "104. Finding outlet for HUC 190202030303 out of 157 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030103\n",
      "105. Finding outlet for HUC 190202030103 out of 233 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030408\n",
      "106. Finding outlet for HUC 190202030408 out of 188 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030402\n",
      "107. Finding outlet for HUC 190202030402 out of 240 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030405\n",
      "108. Finding outlet for HUC 190202030405 out of 207 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030401\n",
      "109. Finding outlet for HUC 190202030401 out of 106 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030404\n",
      "110. Finding outlet for HUC 190202030404 out of 62 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030301\n",
      "111. Finding outlet for HUC 190202030301 out of 88 catchments.\n",
      "************************************************************\n",
      "Processing HUC 190202030407\n",
      "112. Finding outlet for HUC 190202030407 out of 136 catchments.\n",
      "************************************************************\n",
      "Creating copy of 112 outlet catchments for Region Prince_William_Sound at D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\\Prince_William_Sound_TauAwcH12_cats_outlets\n",
      "****************************************************************************************************\n",
      "Prince_William_Sound Elapsed time: (0:00:30)\n",
      "************************************************************\n",
      "Process complete\n",
      "Process completed at 2022-02-09 18:12 (Elapsed time: 0:00:30)\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "import arcpy, time, os, datetime, operator\n",
    "\n",
    "arcpy.env.workspace = data_dir\n",
    "regions = arcpy.ListWorkspaces()\n",
    "\n",
    "# Dictionaries and lists\n",
    "nhdplusoutlets = []\n",
    "tauoutlets = []\n",
    "nhdplusawccatouts = []\n",
    "tauawccatouts = []\n",
    "vaaDict = {}\n",
    "strDict = {}\n",
    "catsDict = {}\n",
    "huc12Dict = {}\n",
    "nhdidDict = {}\n",
    "tauidDict = {}\n",
    "tauhuc12Dict = {}\n",
    "\n",
    "# Separate data by source type\n",
    "nhdplus_dat = ['Cook_Inlet','Copper_River']\n",
    "tauDem_dat = ['Bristol_Bay', 'Kodiak', 'Prince_William_Sound']\n",
    "\n",
    "# Loop through all processing areas\n",
    "# rois = nhdplus_dat + tauDem_dat\n",
    "\n",
    "# Or comment above and specify below specific subset\n",
    "#regions = ['D:\\\\GIS\\\\AKSSF\\\\Cook_Inlet', 'D:\\\\GIS\\\\AKSSF\\\\Copper_River' ]\n",
    "regions = ['Prince_William_Sound']\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "\n",
    "for region in regions:\n",
    "    roi = os.path.basename(region)\n",
    "    print(roi)\n",
    "    if roi in nhdplus_dat:\n",
    "        # Start roi time\n",
    "        roi_start = time.time()\n",
    "        hucs = nhdplushucs\n",
    "        catsList = []\n",
    "        outletList = []\n",
    "        print(f'{roi} using data from {region} folder')\n",
    "        # Set workspace to region folder\n",
    "        arcpy.env.workspace = region\n",
    "        gdb = arcpy.ListWorkspaces(workspace_type='FileGDB')\n",
    "        sourcegdb = gdb[0]\n",
    "        walk = arcpy.da.Walk(sourcegdb, datatype = ['FeatureClass','Table'])\n",
    "        for dirpath, dirnames, filenames in walk:\n",
    "            for filename in filenames:\n",
    "                if filename == 'cats_merge':\n",
    "                    cats  = os.path.join(dirpath, filename)\n",
    "                    append_value(catsDict,roi,cats)\n",
    "                elif filename == 'vaa_merge':\n",
    "                    vaas = os.path.join(dirpath, filename)\n",
    "                    append_value(vaaDict, roi, vaas)\n",
    "        #Output names and paths\n",
    "        outletcatsname = roi + '_NhdAwcH12_cats_outlets'\n",
    "        outcatspath = os.path.join(outgdb,outletcatsname)\n",
    "        outcatspath2 = os.path.join(sourcegdb,'awc_huc12_catchment_outlets')\n",
    "        outletcatptsname = roi + '_NhdAwcH12_cats_outlets_pts'\n",
    "        outcatptspath = os.path.join(outgdb,outletcatptsname)\n",
    "        outcatptspath2 = os.path.join(sourcegdb,'awc_huc12_catchment_outlets_pts')\n",
    "\n",
    "        if not arcpy.Exists(outcatspath):\n",
    "            # Build Value dictionary to relate NHDPlus id to contributing area\n",
    "            fields = ['NHDPlusID','TotDASqKm']\n",
    "            fields2 = fields + ['cat_ID_con']\n",
    "            valueDict = {int(r[0]):(r[1]) for r in arcpy.da.SearchCursor(vaas, fields)}\n",
    "            where_clause=f'\"MERGE_SRC\" LIKE \\'%{roi}%\\''\n",
    "            print(f'where_clause = {where_clause}')\n",
    "            huclayer = arcpy.MakeFeatureLayer_management(hucs,'huclayer',where_clause = where_clause)\n",
    "            print(f'{arcpy.GetCount_management(huclayer)} huc12s in {roi}')\n",
    "            print(('*'*100))\n",
    "            hucselect = arcpy.SelectLayerByLocation_management(huclayer,'INTERSECT',awc_events,'','SUBSET_SELECTION')\n",
    "            print(('*'*100))\n",
    "            print(f'{arcpy.GetCount_management(hucselect)} Huc12s in {roi} intersect awc events input')\n",
    "            print(('*'*100))\n",
    "            hucFields = [f for f in arcpy.ListFields(hucselect)]\n",
    "            vcount =1\n",
    "            with arcpy.da.SearchCursor(hucselect,['HUC12','SHAPE@']) as cur:\n",
    "                for row in cur:\n",
    "                    print(f'Processing HUC {row[0]}')\n",
    "                    inhuc = row[1]\n",
    "                    cat_layer = arcpy.MakeFeatureLayer_management(cats,'cat_layer')\n",
    "                    # Select by location using awc and huc 12\n",
    "                    arcpy.SelectLayerByLocation_management(cat_layer,'HAVE_THEIR_CENTER_IN',inhuc,'','NEW_SELECTION')\n",
    "                    print(f'{vcount}. Finding outlet for HUC {row[0]} out of {arcpy.GetCount_management(cat_layer)} catchments.\\n{(\"*\" * 60)}')\n",
    "                    catList = [r[0] for r in arcpy.da.SearchCursor(cat_layer, 'NHDPlusID')]\n",
    "                    intersect = list(set(catList).intersection(valueDict))\n",
    "                    catDict = {int(i):(valueDict[i]) for i in intersect}\n",
    "                    # Find Catchment with max drainage area\n",
    "                    outcatch = max(catDict.items(), key = operator.itemgetter(1))[0]\n",
    "                    append_value(huc12Dict, row[0], [int(outcatch),roi,valueDict[int(outcatch)]])\n",
    "                    append_value(nhdidDict,int(outcatch),[roi,row[0], valueDict[int(outcatch)]])\n",
    "                    outletList.append(int(outcatch))\n",
    "                    vcount+=1\n",
    "                del(row)\n",
    "            del(cur)\n",
    "\n",
    "            outlet_cats = arcpy.MakeFeatureLayer_management(cats,'outlet_cats')\n",
    "            out_expression ='\"NHDPlusID\" IN ' + str(tuple(outletList))\n",
    "            #print(out_expression)\n",
    "            outlet_cats_select = arcpy.SelectLayerByAttribute_management(outlet_cats,'NEW_SELECTION', out_expression)\n",
    "            print(f'Creating copy of {arcpy.GetCount_management(outlet_cats)} outlet catchments for Region {roi} at {outcatspath}')\n",
    "            print(('*'*100))\n",
    "\n",
    "            # Copy outputs\n",
    "            arcpy.FeatureClassToFeatureClass_conversion(outlet_cats_select,outgdb,outletcatsname)\n",
    "            arcpy.FeatureToPoint_management(outcatspath, outcatptspath, 'INSIDE')\n",
    "            # Create Copies to akssf data_dir regional gdbs also\n",
    "            arcpy.FeatureClassToFeatureClass_conversion(outlet_cats_select,sourcegdb,'awc_huc12_catchment_outlets')\n",
    "            arcpy.FeatureToPoint_management(outcatspath2, outcatptspath2, 'INSIDE')\n",
    "            nhdplusoutlets.append(outcatptspath)\n",
    "            nhdplusawccatouts.append(outcatspath)\n",
    "            # Add total drainage km from value dict to feature classes and cat_ID_con from regDict\n",
    "            upfcs = [outcatspath, outcatptspath,outcatptspath2,outcatptspath2]\n",
    "            for upfc in upfcs:\n",
    "                arcpy.AddField_management(upfc,fields[1],'TEXT')\n",
    "                arcpy.AddField_management(upfc,fields2[2],'TEXT')\n",
    "                with arcpy.da.UpdateCursor(upfc,fields2) as cur:\n",
    "                    for row in cur:\n",
    "                        row[1] = valueDict[row[0]]\n",
    "                        row[2] = roi + '_' + str(int(row[0]))\n",
    "                        cur.updateRow(row)\n",
    "                    del(row)\n",
    "                del(cur)\n",
    "\n",
    "            # End roi time\n",
    "            roi_stop = time.time()\n",
    "            roi_time = int (roi_stop - roi_start)\n",
    "            print(f'{roi} Elapsed time: ({datetime.timedelta(seconds=roi_time)})')\n",
    "            print(f'{\"*\"*60}')\n",
    "        else:\n",
    "            print(f'Catchments for {roi} already created at {outcatspath2}')\n",
    "\n",
    "    elif roi in tauDem_dat:\n",
    "        # Start roi time\n",
    "        roi_start = time.time()\n",
    "        hucs = tauhucs\n",
    "        catsList = []\n",
    "        outletList = []\n",
    "        print(f'{roi} using data from {region} folder')\n",
    "        # Set workspace to region folder\n",
    "        arcpy.env.workspace = region\n",
    "        gdb = arcpy.ListWorkspaces(workspace_type='FileGDB')\n",
    "        sourcegdb = gdb[0]\n",
    "        walk = arcpy.da.Walk(sourcegdb, datatype = ['FeatureClass','Table'])\n",
    "        for dirpath, dirnames, filenames in walk:\n",
    "            for filename in filenames:\n",
    "                if filename == 'cats_merge':\n",
    "                    cats  = os.path.join(dirpath, filename)\n",
    "                    append_value(catsDict,roi,cats)\n",
    "                elif filename == 'streams_merge':\n",
    "                    streams = os.path.join(dirpath, filename)\n",
    "                    append_value(strDict, roi, streams)\n",
    "\n",
    "        #Output names and paths\n",
    "        outletcatsname = roi + '_TauAwcH12_cats_outlets'\n",
    "        outcatspath = os.path.join(outgdb,outletcatsname)\n",
    "        outcatspath2 = os.path.join(sourcegdb,'awc_huc12_catchment_outlets')\n",
    "        outletcatptsname = roi + '_TauAwcH12_cats_outlets_pts'\n",
    "        outcatptspath = os.path.join(outgdb,outletcatptsname)\n",
    "        outcatptspath2 = os.path.join(sourcegdb,'awc_huc12_catchment_outlets_pts')\n",
    "        print(('-'*100),'\\n')\n",
    "        if not arcpy.Exists(outcatspath):\n",
    "            # Build Value dictionary to relate NHDPlus id to contributing area\n",
    "            fields = ['LINKNO','DSContArea']\n",
    "            fields2 = fields + ['cat_ID_con']\n",
    "            fields3 = ['gridcode','DSContArea','cat_ID_con']\n",
    "            valueDict = {int(r[0]):(r[1]) for r in arcpy.da.SearchCursor(streams, fields)}\n",
    "            huclayer = arcpy.MakeFeatureLayer_management(hucs,'huclayer')\n",
    "            hucselect_reg = arcpy.SelectLayerByLocation_management(huclayer,'INTERSECT',streams,'','NEW_SELECTION')\n",
    "            print(f'{arcpy.GetCount_management(huclayer)} huc12s in {roi}')\n",
    "            print(('*'*100))\n",
    "            hucselect = arcpy.SelectLayerByLocation_management(hucselect_reg,'INTERSECT',awc_events,'','SUBSET_SELECTION')\n",
    "            print(('*'*100))\n",
    "            print(f'{arcpy.GetCount_management(hucselect)} Huc12s in {roi} intersect awc events input')\n",
    "            print(('*'*100))\n",
    "            hucFields = [f for f in arcpy.ListFields(hucselect)]\n",
    "            vcount =1\n",
    "            with arcpy.da.SearchCursor(hucselect,['HUC12','SHAPE@']) as cur:\n",
    "                for row in cur:\n",
    "                    print(f'Processing HUC {row[0]}')\n",
    "                    inhuc = row[1]\n",
    "                    cat_layer = arcpy.MakeFeatureLayer_management(cats,'cat_layer')\n",
    "                    # Select by location using awc and huc 12\n",
    "                    arcpy.SelectLayerByLocation_management(cat_layer,'HAVE_THEIR_CENTER_IN',inhuc,'','NEW_SELECTION')\n",
    "                    print(f'{vcount}. Finding outlet for HUC {row[0]} out of {arcpy.GetCount_management(cat_layer)} catchments.\\n{(\"*\" * 60)}')\n",
    "                    catList = [r[0] for r in arcpy.da.SearchCursor(cat_layer, 'gridcode')]\n",
    "                    intersect = list(set(catList).intersection(valueDict))\n",
    "                    catDict = {int(i):(valueDict[i]) for i in intersect}\n",
    "                    # Find Catchment with max drainage area\n",
    "                    outcatch = max(catDict.items(), key = operator.itemgetter(1))[0]\n",
    "                    append_value(tauhuc12Dict, row[0], [int(outcatch),roi,valueDict[int(outcatch)]])\n",
    "                    append_value(tauidDict,int(outcatch),[roi,row[0], valueDict[int(outcatch)]])\n",
    "                    outletList.append(int(outcatch))\n",
    "                    vcount+=1\n",
    "                del(row)\n",
    "            del(cur)\n",
    "            outlet_cats = arcpy.MakeFeatureLayer_management(cats,'outlet_cats')\n",
    "            out_expression ='\"gridcode\" IN ' + str(tuple(outletList))\n",
    "            #print(out_expression)\n",
    "            outlet_cats_select = arcpy.SelectLayerByAttribute_management(outlet_cats,'NEW_SELECTION', out_expression)\n",
    "            print(f'Creating copy of {arcpy.GetCount_management(outlet_cats)} outlet catchments for Region {roi} at {outcatspath}')\n",
    "            print(('*'*100))\n",
    "\n",
    "            # Copy outputs\n",
    "            arcpy.FeatureClassToFeatureClass_conversion(outlet_cats_select,outgdb,outletcatsname)\n",
    "            arcpy.FeatureToPoint_management(outcatspath, outcatptspath, 'INSIDE')\n",
    "            # Create Copies to akssf data_dir regional gdbs also\n",
    "            arcpy.FeatureClassToFeatureClass_conversion(outlet_cats_select,sourcegdb,'awc_huc12_catchment_outlets')\n",
    "            arcpy.FeatureToPoint_management(outcatspath2, outcatptspath2, 'INSIDE')\n",
    "            tauoutlets.append(outcatptspath)\n",
    "            tauawccatouts.append(outcatspath)\n",
    "            # Add total drainage km from value dict to feature classes and cat_ID_con from regDict\n",
    "            upfcs = [outcatspath, outcatptspath,outcatptspath2,outcatptspath2]\n",
    "            for upfc in upfcs:\n",
    "                arcpy.AddField_management(upfc,fields[1],'TEXT')\n",
    "                arcpy.AddField_management(upfc,fields2[2],'TEXT')\n",
    "                with arcpy.da.UpdateCursor(upfc,fields3) as cur:\n",
    "                    for row in cur:\n",
    "                        row[1] = valueDict[row[0]]\n",
    "                        row[2] = roi + '_' + str(int(row[0]))\n",
    "                        cur.updateRow(row)\n",
    "                    del(row)\n",
    "                del(cur)\n",
    "\n",
    "            # End roi time\n",
    "            roi_stop = time.time()\n",
    "            roi_time = int (roi_stop - roi_start)\n",
    "            print(f'{roi} Elapsed time: ({datetime.timedelta(seconds=roi_time)})')\n",
    "            print(f'{\"*\"*60}')\n",
    "\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "print(f'Process complete')\n",
    "\n",
    "# Report success\n",
    "print(f'Process completed at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "      f'(Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print(f'{\"*\"*100}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 2.1\n",
    "### Merge all outlet points together and calculate distance to coastline\n",
    "Calculate Distance to Coast from outlet catchment point to the nearest coastline as a straight line distance\n",
    " * Generate near table and export as seperate csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "NHDPlus Section\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlet points already created at D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\\AKSSF_NHDPlus_awcHuc12_outlet_cats_points\n"
     ]
    }
   ],
   "source": [
    "import arcpy, datetime\n",
    "import numpy as pd\n",
    "\n",
    "# Input path to coastline\n",
    "coast = r\"D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\NHD_H_Alaska_Coastline_alb\"\n",
    "\n",
    "# Merge all catchment outlet centroids together\n",
    "nhdoutletsname = 'AKSSF_NHDPlus_awcHuc12_outlet_cats_points'\n",
    "nhdoutletspath = os.path.join(outgdb, nhdoutletsname)\n",
    "\n",
    "if not arcpy.Exists(nhdoutletspath):\n",
    "    all_nhd_outlet_pts = arcpy.Merge_management(nhdplusoutlets,nhdoutletspath)\n",
    "    # Start timing function\n",
    "    start = datetime.datetime.now()\n",
    "    print(f'Getting distance to coast {datetime.datetime.now()}...')\n",
    "    arcpy.analysis.Near(all_nhd_outlet_pts, coast, None, \"NO_LOCATION\", \"NO_ANGLE\", \"GEODESIC\", \"NEAR_DIST NEAR_DIST\")\n",
    "    arcpy.AlterField_management(all_nhd_outlet_pts,'NEAR_DIST','dist_catch_coast_km','dist_catch_coast_km' )\n",
    "    arcpy.AddField_management(all_nhd_outlet_pts,'HUC12','TEXT')\n",
    "\n",
    "    # Convert distance in meters to km\n",
    "    with arcpy.da.UpdateCursor(all_nhd_outlet_pts,['dist_catch_coast_km','NHDPlusID','HUC12']) as cur:\n",
    "        for row in cur:\n",
    "            row[0] = row[0] * 0.001\n",
    "            row[2] = nhdidDict[row[1]][1]\n",
    "            cur.updateRow(row)\n",
    "        del(row)\n",
    "    del(cur)\n",
    "    print(f'Process complete')\n",
    "else:\n",
    "    print(f'Outlet points already created at {nhdoutletspath}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TauDEM Section\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting distance to coast 2022-02-09 18:22:59.855894...\n",
      "Process complete\n"
     ]
    }
   ],
   "source": [
    "import arcpy, datetime\n",
    "import numpy as pd\n",
    "\n",
    "# Input path to coastline\n",
    "coast = r\"D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\NHD_H_Alaska_Coastline_alb\"\n",
    "\n",
    "# Merge all catchment outlet centroids together\n",
    "tauoutname = 'AKSSF_TauDEM_awcHuc12_outlet_cats_points'\n",
    "tauoutpath = os.path.join(outgdb, tauoutname)\n",
    "\n",
    "if not arcpy.Exists(tauoutpath):\n",
    "    all_tau_outpts = arcpy.Merge_management(tauoutlets,tauoutpath)\n",
    "    # Start timing function\n",
    "    start = datetime.datetime.now()\n",
    "    print(f'Getting distance to coast {datetime.datetime.now()}...')\n",
    "    arcpy.analysis.Near(all_tau_outpts, coast, None, \"NO_LOCATION\", \"NO_ANGLE\", \"GEODESIC\", \"NEAR_DIST NEAR_DIST\")\n",
    "    arcpy.AlterField_management(all_tau_outpts,'NEAR_DIST','dist_catch_coast_km','dist_catch_coast_km' )\n",
    "    arcpy.AddField_management(all_tau_outpts,'HUC12','TEXT')\n",
    "    arcpy.AddField_management(all_tau_outpts,'DSContAreaSqKM','DOUBLE')\n",
    "\n",
    "    # Convert distance in meters to km\n",
    "    with arcpy.da.UpdateCursor(all_tau_outpts,['dist_catch_coast_km','gridcode','HUC12','DSContArea','DSContAreaSqKM']) as cur:\n",
    "        for row in cur:\n",
    "            row[0] = row[0] * 0.001\n",
    "            row[2] = tauidDict[row[1]][1]\n",
    "            row[4] = int(row[3])/1000000 #convert sq meters to sq km\n",
    "            cur.updateRow(row)\n",
    "        del(row)\n",
    "    del(cur)\n",
    "    print(f'Process complete')\n",
    "else:\n",
    "    print(f'Outlet points already created at {tauoutpath}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Merge NHD and Tau points together and export as CSV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging all available catchment outlet points\n"
     ]
    }
   ],
   "source": [
    "# NHDPoints\n",
    "nhdoutletsname = 'AKSSF_NHDPlus_awcHuc12_outlet_cats_points'\n",
    "nhdoutletspath = os.path.join(outgdb, nhdoutletsname)\n",
    "\n",
    "# Taupoints\n",
    "tauoutname = 'AKSSF_TauDEM_awcHuc12_outlet_cats_points'\n",
    "tauoutpath = os.path.join(outgdb, tauoutname)\n",
    "\n",
    "# All points\n",
    "catpointsname = 'AKSSF_awcHuc12_outlet_cats_points'\n",
    "catpointspath = os.path.join(outgdb, catpointsname)\n",
    "\n",
    "# Create FieldMappings object to manage merge output fields\n",
    "out_fms = arcpy.FieldMappings()\n",
    "\n",
    "# Add all fields from both point fcs\n",
    "out_fms.addTable(nhdoutletspath)\n",
    "out_fms.addTable(tauoutpath)\n",
    "\n",
    "# Add input fields\n",
    "out_fm_dsdrain = arcpy.FieldMap()\n",
    "out_fm_dsdrain.addInputField(nhdoutletspath,'TotDASqKm')\n",
    "out_fm_dsdrain.addInputField(tauoutpath,'DSContAreaSqKM')\n",
    "\n",
    "# Set name of new output field \"Street_Name\"\n",
    "dsdrain = out_fm_dsdrain.outputField\n",
    "dsdrain.name = \"DsContAreaSqKm\"\n",
    "out_fm_dsdrain.outputField = dsdrain\n",
    "\n",
    "# add to field mappings\n",
    "out_fms.addFieldMap(out_fm_dsdrain)\n",
    "\n",
    "for field in out_fms.fields:\n",
    "    if field.name not in ['cat_ID_con', 'DsContAreaSqKm','dist_catch_coast_km', 'HUC12']:\n",
    "        out_fms.removeFieldMap(out_fms.findFieldMapIndex(field.name))\n",
    "\n",
    "#if not arcpy.Exists(catpointspath):\n",
    "addSourceInfo = \"ADD_SOURCE_INFO\"\n",
    "cats_outlets = arcpy.Merge_management([nhdoutletspath,tauoutpath],\n",
    "                                      catpointspath,\n",
    "                                      out_fms,\n",
    "                                      addSourceInfo)\n",
    "print(f'Merging all available catchment outlet points')\n",
    "#else:\n",
    "#    print(f'AKSSF AWC Catchment outlets already identified and exported to {catpointspath}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Convert to df and examine"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJECTID\n",
      "Shape\n",
      "cat_ID_con\n",
      "dist_catch_coast_km\n",
      "HUC12\n",
      "DsContAreaSqKm\n",
      "MERGE_SRC\n"
     ]
    },
    {
     "data": {
      "text/plain": "                            dist_catch_coast_km DsContAreaSqKm         HUC12\ncat_ID_con                                                                  \nCook_Inlet_75004200000901             21.633384    36.96257508  190202020501\nCook_Inlet_75004200001724             17.599013   170.81217492  190202020503\nCook_Inlet_75004200001726              0.128861    570.1149751  190202020508\nCook_Inlet_75004200001493              0.147499         9.6406  190202020303\nCook_Inlet_75004200004105              0.137137    14.02302496  190202020102\n...                                         ...            ...           ...\nPrince_William_Sound_91741            17.543384      572.85728  190202010906\nPrince_William_Sound_91751            17.338805     574.793792  190202010905\nPrince_William_Sound_91921            12.177571     739.347904  190202010907\nPrince_William_Sound_92151             0.047172     920.540288  190202010908\nPrince_William_Sound_93261             0.020080       117.1584  190202011102\n\n[1018 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dist_catch_coast_km</th>\n      <th>DsContAreaSqKm</th>\n      <th>HUC12</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Cook_Inlet_75004200000901</th>\n      <td>21.633384</td>\n      <td>36.96257508</td>\n      <td>190202020501</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004200001724</th>\n      <td>17.599013</td>\n      <td>170.81217492</td>\n      <td>190202020503</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004200001726</th>\n      <td>0.128861</td>\n      <td>570.1149751</td>\n      <td>190202020508</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004200001493</th>\n      <td>0.147499</td>\n      <td>9.6406</td>\n      <td>190202020303</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004200004105</th>\n      <td>0.137137</td>\n      <td>14.02302496</td>\n      <td>190202020102</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_91741</th>\n      <td>17.543384</td>\n      <td>572.85728</td>\n      <td>190202010906</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_91751</th>\n      <td>17.338805</td>\n      <td>574.793792</td>\n      <td>190202010905</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_91921</th>\n      <td>12.177571</td>\n      <td>739.347904</td>\n      <td>190202010907</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_92151</th>\n      <td>0.047172</td>\n      <td>920.540288</td>\n      <td>190202010908</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_93261</th>\n      <td>0.020080</td>\n      <td>117.1584</td>\n      <td>190202011102</td>\n    </tr>\n  </tbody>\n</table>\n<p>1018 rows  3 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "\n",
    "# Make catchment points df\n",
    "cat_df = pd.DataFrame()\n",
    "cat_field_list = []\n",
    "\n",
    "for field in arcpy.ListFields(catpointspath):\n",
    "    print(field.name)\n",
    "    cat_field_list.append(field.name)\n",
    "cat_arr = arcpy.da.TableToNumPyArray(catpointspath, ['cat_ID_con','dist_catch_coast_km','DsContAreaSqKm','HUC12'])\n",
    "cat_df = pd.DataFrame(cat_arr)\n",
    "cat_df = cat_df.set_index('cat_ID_con')\n",
    "cat_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Export csv of outlet points for NHDPlus regions\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV export complete\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#Export CSV to read into R\n",
    "catpts_outname = 'AKSSF_awcHuc12_dist_catch_coast_km.csv'\n",
    "outlets_csv = os.path.join(outdir,catpts_outname)\n",
    "if not arcpy.Exists(outlets_csv):\n",
    "    arcpy.da.NumPyArrayToTable(cat_arr,outlets_csv)\n",
    "    print('CSV export complete')\n",
    "else:\n",
    "    print(f'Csv of catchment outlet points already exported to {outlets_csv}')\n",
    "print('----------')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 3\n",
    "### Watersheds\n",
    "Generate Watersheds\n",
    "* If watersheds have already been created there is no need to run this section again in order for subsequent process to run."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prince_William_Sound\n",
      "D:\\GIS\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\\cats_merge Indexed\n",
      "OBJECTID\n",
      "Shape\n",
      "LINKNO\n",
      "DSLINKNO\n",
      "USLINKNO1\n",
      "USLINKNO2\n",
      "DSNODEID\n",
      "strmOrder\n",
      "Length\n",
      "Magnitude\n",
      "DSContArea\n",
      "strmDrop\n",
      "Slope\n",
      "StraightL\n",
      "USContArea\n",
      "WSNO\n",
      "DOUTEND\n",
      "DOUTSTART\n",
      "DOUTMID\n",
      "Shape_Length\n",
      "1. Starting watershed for HUC 3038 (111 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "2. Starting watershed for HUC 13227 (110 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "3. Starting watershed for HUC 17027 (109 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "4. Starting watershed for HUC 17697 (108 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "5. Starting watershed for HUC 18357 (107 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "6. Starting watershed for HUC 18547 (106 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "7. Starting watershed for HUC 18737 (105 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "8. Starting watershed for HUC 18747 (104 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "9. Starting watershed for HUC 22134 (103 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "10. Starting watershed for HUC 23854 (102 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "11. Starting watershed for HUC 25516 (101 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "12. Starting watershed for HUC 26246 (100 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "13. Starting watershed for HUC 26334 (99 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "14. Starting watershed for HUC 27856 (98 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "15. Starting watershed for HUC 28576 (97 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "16. Starting watershed for HUC 29954 (96 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "17. Starting watershed for HUC 30084 (95 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "18. Starting watershed for HUC 30114 (94 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "19. Starting watershed for HUC 30596 (93 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "20. Starting watershed for HUC 30774 (92 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "21. Starting watershed for HUC 30886 (91 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "22. Starting watershed for HUC 30934 (90 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "23. Starting watershed for HUC 31226 (89 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "24. Starting watershed for HUC 31916 (88 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "25. Starting watershed for HUC 32766 (87 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "26. Starting watershed for HUC 33106 (86 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "27. Starting watershed for HUC 33396 (85 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "28. Starting watershed for HUC 33616 (84 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "29. Starting watershed for HUC 34003 (83 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "30. Starting watershed for HUC 34455 (82 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "31. Starting watershed for HUC 37373 (81 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "32. Starting watershed for HUC 37815 (80 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "33. Starting watershed for HUC 38615 (79 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "34. Starting watershed for HUC 39065 (78 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "35. Starting watershed for HUC 39565 (77 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "36. Starting watershed for HUC 40615 (76 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "37. Starting watershed for HUC 40743 (75 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "38. Starting watershed for HUC 41123 (74 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "39. Starting watershed for HUC 41143 (73 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "40. Starting watershed for HUC 41515 (72 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "41. Starting watershed for HUC 41525 (71 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "42. Starting watershed for HUC 41963 (70 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "43. Starting watershed for HUC 41995 (69 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "44. Starting watershed for HUC 42005 (68 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "45. Starting watershed for HUC 42455 (67 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "46. Starting watershed for HUC 42595 (66 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "47. Starting watershed for HUC 43085 (65 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "48. Starting watershed for HUC 43125 (64 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "49. Starting watershed for HUC 43195 (63 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "50. Starting watershed for HUC 43255 (62 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "51. Starting watershed for HUC 43473 (61 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "52. Starting watershed for HUC 43513 (60 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:01)\n",
      "************************************************************\n",
      "53. Starting watershed for HUC 43535 (59 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "54. Starting watershed for HUC 43705 (58 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "55. Starting watershed for HUC 43793 (57 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "56. Starting watershed for HUC 43933 (56 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "57. Starting watershed for HUC 44113 (55 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "58. Starting watershed for HUC 44273 (54 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "59. Starting watershed for HUC 44503 (53 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "60. Starting watershed for HUC 44545 (52 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "61. Starting watershed for HUC 44595 (51 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "62. Starting watershed for HUC 44605 (50 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "63. Starting watershed for HUC 44633 (49 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "64. Starting watershed for HUC 44663 (48 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "65. Starting watershed for HUC 45473 (47 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "66. Starting watershed for HUC 45835 (46 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "67. Starting watershed for HUC 45863 (45 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "68. Starting watershed for HUC 45915 (44 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "69. Starting watershed for HUC 45925 (43 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "70. Starting watershed for HUC 46065 (42 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "71. Starting watershed for HUC 46103 (41 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "72. Starting watershed for HUC 46293 (40 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "73. Starting watershed for HUC 46483 (39 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "74. Starting watershed for HUC 46513 (38 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "75. Starting watershed for HUC 46613 (37 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "76. Starting watershed for HUC 46623 (36 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "77. Starting watershed for HUC 62232 (35 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "78. Starting watershed for HUC 64192 (34 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "79. Starting watershed for HUC 66912 (33 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "80. Starting watershed for HUC 67552 (32 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "81. Starting watershed for HUC 70762 (31 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "82. Starting watershed for HUC 71952 (30 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "83. Starting watershed for HUC 72402 (29 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "84. Starting watershed for HUC 72972 (28 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "85. Starting watershed for HUC 74042 (27 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "86. Starting watershed for HUC 74542 (26 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "87. Starting watershed for HUC 74602 (25 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "88. Starting watershed for HUC 75002 (24 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "89. Starting watershed for HUC 75422 (23 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "90. Starting watershed for HUC 75432 (22 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "91. Starting watershed for HUC 76622 (21 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "92. Starting watershed for HUC 76652 (20 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "93. Starting watershed for HUC 76692 (19 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "94. Starting watershed for HUC 76812 (18 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "95. Starting watershed for HUC 77292 (17 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "96. Starting watershed for HUC 77992 (16 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "97. Starting watershed for HUC 78522 (15 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "98. Starting watershed for HUC 79531 (14 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "99. Starting watershed for HUC 79792 (13 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "100. Starting watershed for HUC 79972 (12 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "101. Starting watershed for HUC 80112 (11 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:05)\n",
      "************************************************************\n",
      "102. Starting watershed for HUC 80272 (10 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "103. Starting watershed for HUC 82471 (9 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "104. Starting watershed for HUC 84641 (8 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "105. Starting watershed for HUC 86871 (7 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "106. Starting watershed for HUC 87851 (6 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "107. Starting watershed for HUC 89681 (5 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:03)\n",
      "************************************************************\n",
      "108. Starting watershed for HUC 91741 (4 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:04)\n",
      "************************************************************\n",
      "109. Starting watershed for HUC 91751 (3 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:04)\n",
      "************************************************************\n",
      "110. Starting watershed for HUC 91921 (2 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:04)\n",
      "************************************************************\n",
      "111. Starting watershed for HUC 92151 (1 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:04)\n",
      "************************************************************\n",
      "112. Starting watershed for HUC 93261 (0 remaining)\n",
      "Starting dissolve\n",
      "Elapsed time: (0:00:02)\n",
      "************************************************************\n",
      "A column was specified that does not exist.\n",
      "Process completed at 2022-02-09 21:08 (Elapsed time: 0:04:26)\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# NHDPLUS Watersheds\n",
    "\n",
    "import arcpy, time, datetime, os\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import arcpy, time, os, datetime, operator\n",
    "\n",
    "arcpy.env.workspace = data_dir\n",
    "regions = arcpy.ListWorkspaces()\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.qualifiedFieldNames = False\n",
    "sr = arcpy.SpatialReference(3338)  #'NAD_1983_Alaska_Albers'\n",
    "arcpy.env.outputCoordinateSystem = sr\n",
    "\n",
    "wtdDict = {}\n",
    "\n",
    "# Separate data by source type\n",
    "nhdplus_dat = ['Cook_Inlet','Copper_River']\n",
    "# Limit to Cook inlet for testing\n",
    "# regions = ['D:\\\\GIS\\\\AKSSF\\\\Copper_River','D:\\\\GIS\\\\AKSSF\\\\Cook_Inlet']\n",
    "regions = ['D:\\\\GIS\\\\AKSSF\\\\Prince_William_Sound']\n",
    "\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "\n",
    "for region in regions:\n",
    "    reg_start = time.time()\n",
    "    roi = os.path.basename(region)\n",
    "    print(roi)\n",
    "    if roi in nhdplus_dat:\n",
    "        try:\n",
    "            wtdList = []\n",
    "            arcpy.env.workspace = region\n",
    "            gdb = arcpy.ListWorkspaces(workspace_type='FileGDB')\n",
    "            ingdb = gdb[0]\n",
    "            # set inputs\n",
    "            vaa = os.path.join(ingdb, \"vaa_merge\")\n",
    "            cats = os.path.join(ingdb, \"cats_merge\")\n",
    "            streams = os.path.join(ingdb, \"NHDFlowline_merge\")\n",
    "            outcats = os.path.join(ingdb, \"awc_huc12_catchment_outlets\")\n",
    "            # Create list of nhdplus ids for outlet catchments\n",
    "            idList = [int(row[0]) for row in arcpy.da.SearchCursor(outcats,'NHDPlusID')]\n",
    "            #Make test list of few small catchments\n",
    "            #idList = [75004400004166,75004400004344, 75004400010328]\n",
    "            # Get list of index names for cats merge and add index if not already created\n",
    "            index_names = [i.name for i in arcpy.ListIndexes(cats)]\n",
    "            print(index_names)\n",
    "            if 'NHDPlusID_index' not in index_names:\n",
    "                print (f'Creating index for {cats}')\n",
    "                arcpy.AddIndex_management(cats,'NHDPlusID','NHDPlusID_index')\n",
    "            else:\n",
    "                print(f'{cats} Indexed')\n",
    "\n",
    "            #watersheds feature dataset for storing fcs\n",
    "            fdatname = roi + '_Watersheds'\n",
    "            fdat = os.path.join(outgdb,fdatname)\n",
    "            if not arcpy.Exists(fdat):\n",
    "                arcpy.management.CreateFeatureDataset(outgdb, fdatname, sr)\n",
    "            else:\n",
    "                print(f'{fdat} exists for {roi}')\n",
    "\n",
    "            vaa_df1 = pd.DataFrame(arcpy.da.TableToNumPyArray(vaa, (\"NHDPlusID\", \"FromNode\", \"ToNode\", \"StartFlag\")))\n",
    "            stream_df = pd.DataFrame(arcpy.da.TableToNumPyArray(streams, (\"NHDPlusID\", \"FType\")))\n",
    "            dfs = [vaa_df1, stream_df]\n",
    "            vaa_df = reduce(lambda left,right: pd.merge(left,right,on='NHDPlusID',how=\"outer\"), dfs)\n",
    "            # remove pipelines\n",
    "            vaa_df = vaa_df[(vaa_df['FType'] != 428 )]\n",
    "            vaa_df\n",
    "\n",
    "            c=1\n",
    "            for id in idList:\n",
    "                iteration_start = time.time()\n",
    "                print(f'{c}. Starting watershed for HUC {str(id)} ({(len(idList) - c)} remaining)')\n",
    "                rec = [id]\n",
    "                up_ids = []\n",
    "                up_ids.append(rec)\n",
    "                rec_len = len(rec)\n",
    "                hws_sum = 0\n",
    "\n",
    "                while rec_len != hws_sum:\n",
    "                    fromnode = vaa_df.loc[vaa_df[\"NHDPlusID\"].isin(rec), \"FromNode\"]\n",
    "                    rec = vaa_df.loc[vaa_df[\"ToNode\"].isin(fromnode), \"NHDPlusID\"]\n",
    "                    rec_len = len(rec)\n",
    "                    rec_hws = vaa_df.loc[vaa_df[\"ToNode\"].isin(fromnode), \"StartFlag\"]\n",
    "                    hws_sum = sum(rec_hws)\n",
    "                    up_ids.append(rec)\n",
    "                #up_ids is a list with more than numbers, use extend to only keep numeric nhdplusids\n",
    "                newup_ids = []\n",
    "                for x in up_ids:\n",
    "                    newup_ids.extend(x)\n",
    "\n",
    "                tempLayer = \"catsLyr\"\n",
    "                expression = '\"NHDPlusID\" IN ({0})'.format(', '.join(map(str, newup_ids)) or 'NULL')\n",
    "                arcpy.MakeFeatureLayer_management(cats, tempLayer, where_clause=expression)\n",
    "                outdis = \"memory/wtd_\" + str(round(id))\n",
    "                outwtd = os.path.join(fdat,f'{roi}_wtd_{str(int(id))}')\n",
    "                dis = arcpy.Dissolve_management(tempLayer, outdis)\n",
    "                watershed = arcpy.EliminatePolygonPart_management(dis, outwtd,\"PERCENT\", \"0 SquareKilometers\", 90, \"CONTAINED_ONLY\")\n",
    "                wtdList.append(outwtd)\n",
    "                append_value(wtdDict,roi,outwtd)\n",
    "\n",
    "                # Stop iteration timer\n",
    "                iteration_stop = time.time()\n",
    "                iter_time = int (iteration_stop - iteration_start)\n",
    "                print(f'Elapsed time: ({datetime.timedelta(seconds=iter_time)})')\n",
    "                print(f'{\"*\"*60}')\n",
    "                c+=1\n",
    "\n",
    "            wtd_merge = arcpy.Merge_management(wtdList, os.path.join(ingdb,'awc_huc12_wtds_merge'),'','ADD_SOURCE_INFO')\n",
    "            arcpy.AddField_management(wtd_merge,'cat_ID_con','TEXT')\n",
    "            arcpy.AddField_management(wtd_merge,'cat_ID','DOUBLE')\n",
    "            arcpy.AddField_management(wtd_merge,'cat_ID_txt','TEXT')\n",
    "            arcpy.AddField_management(wtd_merge,'NHDPlusID','DOUBLE')\n",
    "            with arcpy.da.UpdateCursor(wtd_merge,['MERGE_SRC','NHDPlusID','cat_ID_con','cat_ID','cat_ID_txt']) as cur:\n",
    "                for row in cur:\n",
    "                    # Pull nhdplus id from merge source and calculate fields\n",
    "                    nhdplusid= int(row[0].split('_')[-1])\n",
    "                    row[1] = nhdplusid\n",
    "                    row[2] = roi + '_' + str(nhdplusid)\n",
    "                    row[3] = nhdplusid\n",
    "                    row[4] = str(nhdplusid)\n",
    "                    cur.updateRow(row)\n",
    "                del(row)\n",
    "            del(cur)\n",
    "            arcpy.CopyFeatures_management(wtd_merge,os.path.join(outgdb,f'{roi}_NhdAwcH12_wtds_merge' ))\n",
    "\n",
    "            # Stop iteration timer\n",
    "            reg_stop = time.time()\n",
    "            reg_time = int (reg_stop - reg_start)\n",
    "            print(f'{roi} Elapsed time: ({datetime.timedelta(seconds=reg_time)})')\n",
    "            print(f'{\"*\"*100}')\n",
    "\n",
    "        except:\n",
    "            e = sys.exc_info()[1]\n",
    "            print(e.args[0])\n",
    "            arcpy.AddError(e.args[0])\n",
    "\n",
    "    elif roi in tauDem_dat:\n",
    "        try:\n",
    "            reg_start = time.time()\n",
    "            wtdList = []\n",
    "            arcpy.env.workspace = region\n",
    "            gdb = arcpy.ListWorkspaces(workspace_type='FileGDB')\n",
    "            ingdb = gdb[0]\n",
    "            # set inputs\n",
    "            cats = os.path.join(ingdb, \"cats_merge\")\n",
    "            streams = os.path.join(ingdb, \"streams_merge\")\n",
    "            outcats = os.path.join(ingdb, \"awc_huc12_catchment_outlets\")\n",
    "            # Create list of nhdplus ids for outlet catchments\n",
    "            idList = [int(row[0]) for row in arcpy.da.SearchCursor(outcats,'gridcode')]\n",
    "            index_names = [i.name for i in arcpy.ListIndexes(cats)]\n",
    "            if 'catid_index' not in index_names:\n",
    "                print (f'Creating index for {cats}')\n",
    "                arcpy.AddIndex_management(cats, \"catID\", \"catid_index\")\n",
    "            else:\n",
    "                print(f'{cats} Indexed')\n",
    "            #watersheds feature dataset for storing fcs\n",
    "            fdatname = roi + '_Watersheds'\n",
    "            fdat = os.path.join(outgdb,fdatname)\n",
    "            if not arcpy.Exists(fdat):\n",
    "                arcpy.management.CreateFeatureDataset(outgdb, fdatname, sr)\n",
    "            else:\n",
    "                print(f'{fdat} exists for {roi}')\n",
    "            fields = arcpy.ListFields(streams)\n",
    "            str_df = pd.DataFrame(arcpy.da.FeatureClassToNumPyArray(streams, (\"LINKNO\", \"USLINKNO1\", \"USLINKNO2\")))\n",
    "            hws_codes = [-1]\n",
    "\n",
    "            # Generate watersheds\n",
    "            c=1\n",
    "            for id in idList:\n",
    "                iteration_start = time.time()\n",
    "                print(f'{c}. Starting watershed for HUC {str(id)} ({(len(idList) - c)} remaining)')\n",
    "                rec = [id]\n",
    "                up_ids = []\n",
    "                sum_rec = sum(rec)\n",
    "                while(sum_rec > 0):\n",
    "                    up_ids.append(rec)\n",
    "                    rec = str_df.loc[str_df[\"LINKNO\"].isin(rec), (\"USLINKNO1\", \"USLINKNO2\")]\n",
    "                    rec = pd.concat([rec['USLINKNO1'], rec['USLINKNO2']])\n",
    "                    sum_rec = sum(rec)\n",
    "                # up_ids is a list with more than numbers, use extend to only keep numeric nhdplusids\n",
    "                newup_ids = []\n",
    "                for x in up_ids:\n",
    "                    newup_ids.extend(x)\n",
    "\n",
    "                tempLayer = \"catsLyr\"\n",
    "                expression = '\"gridcode\" IN ({0})'.format(', '.join(map(str, newup_ids)) or 'NULL')\n",
    "                arcpy.MakeFeatureLayer_management(cats, tempLayer)\n",
    "                arcpy.management.SelectLayerByAttribute(tempLayer, \"NEW_SELECTION\", expression, None)\n",
    "                print(\"Starting dissolve\")\n",
    "                outdis = \"memory/wtd_\" + str(round(id))\n",
    "                outwtd = os.path.join(fdat,f'{roi}_wtd_{str(int(id))}')\n",
    "                dis = arcpy.Dissolve_management(tempLayer, outdis)\n",
    "                watershed = arcpy.EliminatePolygonPart_management(dis, outwtd,\"PERCENT\", \"0 SquareKilometers\", 90, \"CONTAINED_ONLY\")\n",
    "                wtdList.append(watershed)\n",
    "                append_value(wtdDict,roi,outwtd)\n",
    "\n",
    "                # Stop iteration timer\n",
    "                iteration_stop = time.time()\n",
    "                iter_time = int (iteration_stop - iteration_start)\n",
    "                print(f'Elapsed time: ({datetime.timedelta(seconds=iter_time)})')\n",
    "                print(f'{\"*\"*60}')\n",
    "                c+=1\n",
    "\n",
    "            wtd_merge = arcpy.Merge_management(wtdList, os.path.join(ingdb,'awc_huc12_wtds_merge'),'','ADD_SOURCE_INFO')\n",
    "            arcpy.AddField_management(wtd_merge,'cat_ID_con','TEXT')\n",
    "            arcpy.AddField_management(wtd_merge,'cat_ID','DOUBLE')\n",
    "            arcpy.AddField_management(wtd_merge,'cat_ID_txt','TEXT')\n",
    "            with arcpy.da.UpdateCursor(wtd_merge,['MERGE_SRC','cat_ID_con','cat_ID','cat_ID_txt']) as cur:\n",
    "                for row in cur:\n",
    "                    gridcode= int(row[0].split('_')[-1])\n",
    "                    row[1] = roi + '_' + str(gridcode)\n",
    "                    row[2] = int(gridcode)\n",
    "                    row[3] = str(gridcode)\n",
    "                    cur.updateRow(row)\n",
    "                del(row)\n",
    "            del(cur)\n",
    "            arcpy.CopyFeatures_management(wtd_merge,os.path.join(outgdb, f'{roi}_NhdAwcH12_wtds_merge' ))\n",
    "\n",
    "            # Stop iteration timer\n",
    "            reg_stop = time.time()\n",
    "            reg_time = int (reg_stop - reg_start)\n",
    "            print(f'{roi} Elapsed time: ({datetime.timedelta(seconds=reg_time)})')\n",
    "            print(f'{\"*\"*100}')\n",
    "\n",
    "        except:\n",
    "            e = sys.exc_info()[1]\n",
    "            print(e.args[0])\n",
    "            arcpy.AddError(e.args[0])\n",
    "    else:\n",
    "        print(f'{roi} not found - check inputs')\n",
    "        sys.exit(f'{roi} not found - check inputs')\n",
    "\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "\n",
    "# Report success\n",
    "print(f'Process completed at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "      f'(Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print(f'{\"*\"*100}')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TROUBLESHOOTING BLOCK\n",
    "### Zonal statistics as table is failing with unknown error when run on watershed_merge and slope/elev rasters if using 'ALL' statistics.\n",
    "Try alternative methods.  Below is test chunk for iterating over a list of stats individually and join results back to a copy of the merged watershed table.\n",
    "* Cannot Run ZonalStatistics because tool does not process overlapping polygons as individual features whereas ZonalStatistics as table will\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "### TEST CHUNK###\n",
    "\n",
    "import os, arcpy,time, datetime\n",
    "from arcpy.sa import *\n",
    "arcpy.env.overwriteOutput = True\n",
    "#\n",
    "# testoutgdb = r\"C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\ArcGIS_Default\\\\ArcGIS_Default.gdb\"\n",
    "# wtd_merge = r\"D:\\\\GIS\\\\AKSSF_awcHuc12_cv\\\\AKSSF_awcHuc12_cv.gdb\\\\Cook_Inlet_NhdAwcH12_wtds_merge\"\n",
    "# wtd_cur_fields = ['cat_ID_txt', 'cat_ID',\"cat_ID_con\"]\n",
    "# elev_rast = r\"D:\\\\GIS\\\\AKSSF\\\\Cook_Inlet\\\\elev.tif\"\n",
    "# zstats = ['MIN_MAX_MEAN','STD']\n",
    "# roi = 'Cook_Inlet'\n",
    "#\n",
    "# # Elevation variables\n",
    "# wtd_merge_elev_table_name = roi + \"_Watersheds_Merge_ElevZstats\"\n",
    "# wtd_merge_elev_table_path = os.path.join(testoutgdb, wtd_merge_elev_table_name)\n",
    "#\n",
    "# # list to store zonal stat tables\n",
    "# wtdelevstats =[]\n",
    "#\n",
    "# # Create field mappings\n",
    "# elev_fm = arcpy.FieldMap()\n",
    "# elev_fms = arcpy.FieldMappings()\n",
    "# for field in arcpy.ListFields(wtd_merge)[6:]:\n",
    "#     elev_fm = arcpy.FieldMap()\n",
    "#     elev_fm.addInputField(wtd_merge,field.name)\n",
    "#     elev_fm.mergeRule = 'First'\n",
    "#     # Set properties of the output name.\n",
    "#     f_name = elev_fm.outputField\n",
    "#     f_name.name = field.name\n",
    "#     f_name.aliasName = field.name\n",
    "#     elev_fm.outputField = f_name\n",
    "#     elev_fms.addFieldMap(elev_fm)\n",
    "#\n",
    "# # Make copy of watershed merge input as table to join stats fields\n",
    "# wtd_elev_metrics_table = arcpy.TableToTable_conversion(wtd_merge,\n",
    "#                                                        testoutgdb,\n",
    "#                                                        wtd_merge_elev_table_name,\n",
    "#                                                        '',\n",
    "#                                                        elev_fms,\n",
    "#                                                        )\n",
    "# # Add region identifier field for watershed tables                                                )\n",
    "# arcpy.AddField_management(wtd_elev_metrics_table,'region',field_type='TEXT')\n",
    "# # expression to calculate region field with roi name\n",
    "# exp =  '\"'+roi+'\"'\n",
    "# arcpy.CalculateField_management(wtd_elev_metrics_table,'region',exp)\n",
    "#\n",
    "# zstat_start = time.time()\n",
    "# for stat in zstats:\n",
    "#     outstattable = os.path.join(testoutgdb,f'{roi}_wtdElev{stat}')\n",
    "#     zstat_start1 = time.time()\n",
    "#     try:\n",
    "#         print (f'running {stat}')\n",
    "#         stat_table = ZonalStatisticsAsTable(in_zone_data = wtdmerge,\n",
    "#                                             zone_field = wtd_cur_fields[0],\n",
    "#                                             in_value_raster = elev_rast,\n",
    "#                                             out_table = outstattable,\n",
    "#                                             statistics_type=stat\n",
    "#                                             )\n",
    "#\n",
    "#         stat_fields = [f.name for f in arcpy.ListFields(stat_table)]\n",
    "#         arcpy.JoinField_management(wtd_elev_metrics_table,\n",
    "#                                wtd_cur_fields[0],\n",
    "#                                stat_table,\n",
    "#                                wtd_cur_fields[0],\n",
    "#                                stat_fields[5:]\n",
    "#                                )\n",
    "#\n",
    "#         # Report time\n",
    "#         zstat_stop1 = time.time()\n",
    "#         zstat_time1 = int (zstat_stop1 - zstat_start1)\n",
    "#         print(f'Watershed elev Zonal Stats for {stat} Elapsed time: ({datetime.timedelta(seconds=zstat_time1)})')\n",
    "#         print(f'{\"*\"*100}')\n",
    "#     except:\n",
    "#         e = sys.exc_info()[1]\n",
    "#         print(e.args[0])\n",
    "#         arcpy.AddError(e.args[0])\n",
    "# # Report time\n",
    "# zstat_stop = time.time()\n",
    "# zstat_time = int (zstat_stop - zstat_start)\n",
    "# print(f'Watershed elev Zonal Stats for {roi} Elapsed time: ({datetime.timedelta(seconds=zstat_time)})')\n",
    "# print(f'{\"*\"*100}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 4\n",
    "Calculate Covariates\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prince_William_Sound in ['Bristol_Bay', 'Kodiak', 'Prince_William_Sound'] TauDEM list, using cat_fields ['cat_ID_txt', 'gridcode', 'cat_ID_con'] and watershed fields ['cat_ID_txt', 'cat_ID', 'cat_ID_con']\n",
      "****************************************************************************************************\n",
      "cat_ID_txt field already in dataset D:\\GIS\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\\awc_huc12_catchment_outlets\n",
      "****************************************************************************************************\n",
      "cat_ID_con field already in dataset D:\\GIS\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\\awc_huc12_catchment_outlets\n",
      "****************************************************************************************************\n",
      "Merged watershed dataset awc_huc12_wtds_merge found\n",
      "****************************************************************************************************\n",
      "cat_ID_txt field already in dataset\n",
      "****************************************************************************************************\n",
      "cat_ID_con field already in dataset D:\\GIS\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\\awc_huc12_wtds_merge\n",
      "****************************************************************************************************\n",
      "Calculating topographic metrics for catchments & watersheds of interest in Prince_William_Sound region\n",
      "----------\n",
      "Geodatabase: D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\n",
      "----------\n",
      "Watershed Merge: D:\\GIS\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\\awc_huc12_wtds_merge\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "HUC12 Catchment Outlets: D:\\GIS\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\\awc_huc12_catchment_outlets\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Elevation Raster: D:\\GIS\\AKSSF\\Prince_William_Sound\\elev.tif\n",
      "  Projection: NAD_1983_Alaska_Albers\n",
      "----------\n",
      "North Aspect Raster: D:\\GIS\\AKSSF\\Prince_William_Sound\\north.tif\n",
      "  Projection: NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Wetlands Raster: D:\\GIS\\AKSSF\\Prince_William_Sound\\wetlands.tif\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Slope Raster: D:\\GIS\\AKSSF\\Prince_William_Sound\\slope.tif\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Lakes Ponds fc: D:\\Basedata\\AKSSF_Basedata\\AKSSF_Basedata.gdb\\AKSSF_NHD_LakesPonds_alb\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Glaciers fc: D:\\GIS\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\\glaciers \n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "112 Watersheds to process\n",
      "----------\n",
      "Catchment intersect D:\\GIS\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\\awc_huc12_catchment_outlets selected\n",
      "----------\n",
      "Begin Slope zonal statistics min/mean/max std dev for watersheds and catchments in Prince_William_Sound region\n",
      "Calculating Prince_William_Sound watershed slope zonal stats...\n",
      "running MIN_MAX_MEAN\n",
      "Watershed Slope Zonal MIN_MAX_MEAN for Prince_William_Sound complete.\n",
      "Elapsed time: (0:00:10)\n",
      "****************************************************************************************************\n",
      "running STD\n",
      "Watershed Slope Zonal STD for Prince_William_Sound complete.\n",
      "Elapsed time: (0:00:10)\n",
      "****************************************************************************************************\n",
      "Begin Elevation zonal statistics min/mean/max std dev for watersheds and catchments in Prince_William_Sound region\n",
      "running MIN_MAX_MEAN\n",
      "Watershed Elevation Zonal MIN_MAX_MEAN for Prince_William_Sound complete.\n",
      "Elapsed time: (0:00:12)\n",
      "****************************************************************************************************\n",
      "running STD\n",
      "Watershed Elevation Zonal STD for Prince_William_Sound complete.\n",
      "Elapsed time: (0:00:24)\n",
      "****************************************************************************************************\n",
      "Calculating Prince_William_Sound catchment elevation zonal stats...\n",
      "Elevation Zonal Stats for Prince_William_Sound catchments complete.\n",
      "Elapsed time: (0:00:05)\n",
      "****************************************************************************************************\n",
      "Calculating Prince_William_Sound catchment slope zonal stats...\n",
      "Slope Zonal Stats for Prince_William_Sound catchments complete.\n",
      "Elapsed time: (0:00:05)\n",
      "****************************************************************************************************\n",
      "All Zonal Stats for Prince_William_Sound Elapsed time: (0:00:58)\n",
      "****************************************************************************************************\n",
      "Begin tabulate area of north facing cells for watersheds and catchments in Prince_William_Sound region\n",
      "****************************************************************************************************\n",
      "Watershed percent north Tabulate area/intersections for Prince_William_Sound complete.\n",
      "Elapsed time: (0:00:15)\n",
      "****************************************************************************************************\n",
      "Begin watershed percent lakes ponds for Prince_William_Sound\n",
      "Percent Lakes Tabulate area/intersections for Prince_William_Sound complete.\n",
      "Elapsed time: (0:00:03)\n",
      "****************************************************************************************************\n",
      "Begin tabulate intersection between D:\\GIS\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\\glaciers and watersheds in Prince_William_Sound region\n",
      "****************************************************************************************************\n",
      "Percent Glacier Tabulate area/intersections for Prince_William_Sound complete.\n",
      "Elapsed time: (0:00:05)\n",
      "****************************************************************************************************\n",
      "Begin tabulate intersection between D:\\GIS\\AKSSF\\Prince_William_Sound\\wetlands.tif and watersheds in Prince_William_Sound region\n",
      "****************************************************************************************************\n",
      "Percent Wetlands Tabulate area/intersections for Prince_William_Sound complete.\n",
      "Elapsed time: (0:00:14)\n",
      "****************************************************************************************************\n",
      "Tabulate area/intersections for Prince_William_Sound complete\n",
      "Elapsed time: (0:00:38)\n",
      "****************************************************************************************************\n",
      "Year: 2001 - raster path D:\\Basedata\\LCLD_rasters_archive\\2001_lcld_32.tif\n",
      "Calculating 2001_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2001_lcld_32.tif\n",
      "Zonal Stats for 2001_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2002 - raster path D:\\Basedata\\LCLD_rasters_archive\\2002_lcld_32.tif\n",
      "Calculating 2002_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2002_lcld_32.tif\n",
      "Zonal Stats for 2002_lcld_32.tif - Elapsed time: (0:00:09)\n",
      "Year: 2003 - raster path D:\\Basedata\\LCLD_rasters_archive\\2003_lcld_32.tif\n",
      "Calculating 2003_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2003_lcld_32.tif\n",
      "Zonal Stats for 2003_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2004 - raster path D:\\Basedata\\LCLD_rasters_archive\\2004_lcld_32.tif\n",
      "Calculating 2004_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2004_lcld_32.tif\n",
      "Zonal Stats for 2004_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2005 - raster path D:\\Basedata\\LCLD_rasters_archive\\2005_lcld_32.tif\n",
      "Calculating 2005_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2005_lcld_32.tif\n",
      "Zonal Stats for 2005_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2006 - raster path D:\\Basedata\\LCLD_rasters_archive\\2006_lcld_32.tif\n",
      "Calculating 2006_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2006_lcld_32.tif\n",
      "Zonal Stats for 2006_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2007 - raster path D:\\Basedata\\LCLD_rasters_archive\\2007_lcld_32.tif\n",
      "Calculating 2007_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2007_lcld_32.tif\n",
      "Zonal Stats for 2007_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2008 - raster path D:\\Basedata\\LCLD_rasters_archive\\2008_lcld_32.tif\n",
      "Calculating 2008_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2008_lcld_32.tif\n",
      "Zonal Stats for 2008_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2009 - raster path D:\\Basedata\\LCLD_rasters_archive\\2009_lcld_32.tif\n",
      "Calculating 2009_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2009_lcld_32.tif\n",
      "Zonal Stats for 2009_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2010 - raster path D:\\Basedata\\LCLD_rasters_archive\\2010_lcld_32.tif\n",
      "Calculating 2010_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2010_lcld_32.tif\n",
      "Zonal Stats for 2010_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2011 - raster path D:\\Basedata\\LCLD_rasters_archive\\2011_lcld_32.tif\n",
      "Calculating 2011_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2011_lcld_32.tif\n",
      "Zonal Stats for 2011_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2012 - raster path D:\\Basedata\\LCLD_rasters_archive\\2012_lcld_32.tif\n",
      "Calculating 2012_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2012_lcld_32.tif\n",
      "Zonal Stats for 2012_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2013 - raster path D:\\Basedata\\LCLD_rasters_archive\\2013_lcld_32.tif\n",
      "Calculating 2013_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2013_lcld_32.tif\n",
      "Zonal Stats for 2013_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2014 - raster path D:\\Basedata\\LCLD_rasters_archive\\2014_lcld_32.tif\n",
      "Calculating 2014_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2014_lcld_32.tif\n",
      "Zonal Stats for 2014_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2015 - raster path D:\\Basedata\\LCLD_rasters_archive\\2015_lcld_32.tif\n",
      "Calculating 2015_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2015_lcld_32.tif\n",
      "Zonal Stats for 2015_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2016 - raster path D:\\Basedata\\LCLD_rasters_archive\\2016_lcld_32.tif\n",
      "Calculating 2016_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2016_lcld_32.tif\n",
      "Zonal Stats for 2016_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2017 - raster path D:\\Basedata\\LCLD_rasters_archive\\2017_lcld_32.tif\n",
      "Calculating 2017_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2017_lcld_32.tif\n",
      "Zonal Stats for 2017_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2018 - raster path D:\\Basedata\\LCLD_rasters_archive\\2018_lcld_32.tif\n",
      "Calculating 2018_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2018_lcld_32.tif\n",
      "Zonal Stats for 2018_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "Year: 2019 - raster path D:\\Basedata\\LCLD_rasters_archive\\2019_lcld_32.tif\n",
      "Calculating 2019_lcld_32.tif zonal stats for all Prince_William_Sound watersheds...\n",
      "Begin zonal stats for 2019_lcld_32.tif\n",
      "Zonal Stats for 2019_lcld_32.tif - Elapsed time: (0:00:08)\n",
      "All Covariates for Prince_William_Sound completed.\n",
      "Elapsed time: (0:04:16)\n",
      "****************************************************************************************************\n",
      "Cook_Inlet in ['Cook_Inlet', 'Copper_River'] AKSSF list, using cat_fields ['cat_ID_txt', 'NHDPlusID', 'cat_ID_con'] and watershed fields ['cat_ID_txt', 'cat_ID', 'cat_ID_con']\n",
      "****************************************************************************************************\n",
      "cat_ID_txt field already in dataset D:\\GIS\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb\\awc_huc12_catchment_outlets\n",
      "****************************************************************************************************\n",
      "cat_ID_con field already in dataset D:\\GIS\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb\\awc_huc12_catchment_outlets\n",
      "****************************************************************************************************\n",
      "Merged watershed dataset awc_huc12_wtds_merge found\n",
      "****************************************************************************************************\n",
      "cat_ID_txt field already in dataset\n",
      "****************************************************************************************************\n",
      "cat_ID_con field already in dataset D:\\GIS\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb\\awc_huc12_wtds_merge\n",
      "****************************************************************************************************\n",
      "Calculating topographic metrics for catchments & watersheds of interest in Cook_Inlet region\n",
      "----------\n",
      "Geodatabase: D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\n",
      "----------\n",
      "Watershed Merge: D:\\GIS\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb\\awc_huc12_wtds_merge\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "HUC12 Catchment Outlets: D:\\GIS\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb\\awc_huc12_catchment_outlets\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Elevation Raster: D:\\GIS\\AKSSF\\Cook_Inlet\\elev.tif\n",
      "  Projection: NAD_1983_Alaska_Albers\n",
      "----------\n",
      "North Aspect Raster: D:\\GIS\\AKSSF\\Cook_Inlet\\north.tif\n",
      "  Projection: NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Wetlands Raster: D:\\GIS\\AKSSF\\Cook_Inlet\\wetlands.tif\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Slope Raster: D:\\GIS\\AKSSF\\Cook_Inlet\\slope.tif\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Lakes Ponds fc: D:\\Basedata\\AKSSF_Basedata\\AKSSF_Basedata.gdb\\AKSSF_NHDPlus_LakePond_alb\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Glaciers fc: D:\\GIS\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb\\glaciers \n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "661 Watersheds to process\n",
      "----------\n",
      "Catchment intersect D:\\GIS\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb\\awc_huc12_catchment_outlets selected\n",
      "----------\n",
      "Begin Slope zonal statistics min/mean/max std dev for watersheds and catchments in Cook_Inlet region\n",
      "Calculating Cook_Inlet watershed slope zonal stats...\n",
      "running MIN_MAX_MEAN\n",
      "Watershed Slope Zonal MIN_MAX_MEAN for Cook_Inlet complete.\n",
      "Elapsed time: (0:03:08)\n",
      "****************************************************************************************************\n",
      "running STD\n",
      "Watershed Slope Zonal STD for Cook_Inlet complete.\n",
      "Elapsed time: (0:02:14)\n",
      "****************************************************************************************************\n",
      "Begin Elevation zonal statistics min/mean/max std dev for watersheds and catchments in Cook_Inlet region\n",
      "running MIN_MAX_MEAN\n",
      "Watershed Elevation Zonal MIN_MAX_MEAN for Cook_Inlet complete.\n",
      "Elapsed time: (0:02:51)\n",
      "****************************************************************************************************\n",
      "running STD\n",
      "Watershed Elevation Zonal STD for Cook_Inlet complete.\n",
      "Elapsed time: (0:05:21)\n",
      "****************************************************************************************************\n",
      "Calculating Cook_Inlet catchment elevation zonal stats...\n",
      "Elevation Zonal Stats for Cook_Inlet catchments complete.\n",
      "Elapsed time: (0:00:36)\n",
      "****************************************************************************************************\n",
      "Calculating Cook_Inlet catchment slope zonal stats...\n",
      "Slope Zonal Stats for Cook_Inlet catchments complete.\n",
      "Elapsed time: (0:00:23)\n",
      "****************************************************************************************************\n",
      "All Zonal Stats for Cook_Inlet Elapsed time: (0:11:48)\n",
      "****************************************************************************************************\n",
      "Begin tabulate area of north facing cells for watersheds and catchments in Cook_Inlet region\n",
      "****************************************************************************************************\n",
      "Watershed percent north Tabulate area/intersections for Cook_Inlet complete.\n",
      "Elapsed time: (0:02:39)\n",
      "****************************************************************************************************\n",
      "Begin watershed percent lakes ponds for Cook_Inlet\n",
      "Percent Lakes Tabulate area/intersections for Cook_Inlet complete.\n",
      "Elapsed time: (0:02:02)\n",
      "****************************************************************************************************\n",
      "Begin tabulate intersection between D:\\GIS\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb\\glaciers and watersheds in Cook_Inlet region\n",
      "****************************************************************************************************\n",
      "Percent Glacier Tabulate area/intersections for Cook_Inlet complete.\n",
      "Elapsed time: (0:00:50)\n",
      "****************************************************************************************************\n",
      "Begin tabulate intersection between D:\\GIS\\AKSSF\\Cook_Inlet\\wetlands.tif and watersheds in Cook_Inlet region\n",
      "****************************************************************************************************\n",
      "Percent Wetlands Tabulate area/intersections for Cook_Inlet complete.\n",
      "Elapsed time: (0:02:35)\n",
      "****************************************************************************************************\n",
      "Tabulate area/intersections for Cook_Inlet complete\n",
      "Elapsed time: (0:08:07)\n",
      "****************************************************************************************************\n",
      "Year: 2001 - raster path D:\\Basedata\\LCLD_rasters_archive\\2001_lcld_32.tif\n",
      "Calculating 2001_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2001_lcld_32.tif\n",
      "Zonal Stats for 2001_lcld_32.tif - Elapsed time: (0:01:59)\n",
      "Year: 2002 - raster path D:\\Basedata\\LCLD_rasters_archive\\2002_lcld_32.tif\n",
      "Calculating 2002_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2002_lcld_32.tif\n",
      "Zonal Stats for 2002_lcld_32.tif - Elapsed time: (0:02:00)\n",
      "Year: 2003 - raster path D:\\Basedata\\LCLD_rasters_archive\\2003_lcld_32.tif\n",
      "Calculating 2003_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2003_lcld_32.tif\n",
      "Zonal Stats for 2003_lcld_32.tif - Elapsed time: (0:02:01)\n",
      "Year: 2004 - raster path D:\\Basedata\\LCLD_rasters_archive\\2004_lcld_32.tif\n",
      "Calculating 2004_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2004_lcld_32.tif\n",
      "Zonal Stats for 2004_lcld_32.tif - Elapsed time: (0:02:01)\n",
      "Year: 2005 - raster path D:\\Basedata\\LCLD_rasters_archive\\2005_lcld_32.tif\n",
      "Calculating 2005_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2005_lcld_32.tif\n",
      "Zonal Stats for 2005_lcld_32.tif - Elapsed time: (0:02:02)\n",
      "Year: 2006 - raster path D:\\Basedata\\LCLD_rasters_archive\\2006_lcld_32.tif\n",
      "Calculating 2006_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2006_lcld_32.tif\n",
      "Zonal Stats for 2006_lcld_32.tif - Elapsed time: (0:02:01)\n",
      "Year: 2007 - raster path D:\\Basedata\\LCLD_rasters_archive\\2007_lcld_32.tif\n",
      "Calculating 2007_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2007_lcld_32.tif\n",
      "Zonal Stats for 2007_lcld_32.tif - Elapsed time: (0:02:02)\n",
      "Year: 2008 - raster path D:\\Basedata\\LCLD_rasters_archive\\2008_lcld_32.tif\n",
      "Calculating 2008_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2008_lcld_32.tif\n",
      "Zonal Stats for 2008_lcld_32.tif - Elapsed time: (0:02:01)\n",
      "Year: 2009 - raster path D:\\Basedata\\LCLD_rasters_archive\\2009_lcld_32.tif\n",
      "Calculating 2009_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2009_lcld_32.tif\n",
      "Zonal Stats for 2009_lcld_32.tif - Elapsed time: (0:02:01)\n",
      "Year: 2010 - raster path D:\\Basedata\\LCLD_rasters_archive\\2010_lcld_32.tif\n",
      "Calculating 2010_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2010_lcld_32.tif\n",
      "Zonal Stats for 2010_lcld_32.tif - Elapsed time: (0:02:02)\n",
      "Year: 2011 - raster path D:\\Basedata\\LCLD_rasters_archive\\2011_lcld_32.tif\n",
      "Calculating 2011_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2011_lcld_32.tif\n",
      "Zonal Stats for 2011_lcld_32.tif - Elapsed time: (0:02:02)\n",
      "Year: 2012 - raster path D:\\Basedata\\LCLD_rasters_archive\\2012_lcld_32.tif\n",
      "Calculating 2012_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2012_lcld_32.tif\n",
      "Zonal Stats for 2012_lcld_32.tif - Elapsed time: (0:02:01)\n",
      "Year: 2013 - raster path D:\\Basedata\\LCLD_rasters_archive\\2013_lcld_32.tif\n",
      "Calculating 2013_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2013_lcld_32.tif\n",
      "Zonal Stats for 2013_lcld_32.tif - Elapsed time: (0:02:02)\n",
      "Year: 2014 - raster path D:\\Basedata\\LCLD_rasters_archive\\2014_lcld_32.tif\n",
      "Calculating 2014_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2014_lcld_32.tif\n",
      "Zonal Stats for 2014_lcld_32.tif - Elapsed time: (0:01:59)\n",
      "Year: 2015 - raster path D:\\Basedata\\LCLD_rasters_archive\\2015_lcld_32.tif\n",
      "Calculating 2015_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2015_lcld_32.tif\n",
      "Zonal Stats for 2015_lcld_32.tif - Elapsed time: (0:02:01)\n",
      "Year: 2016 - raster path D:\\Basedata\\LCLD_rasters_archive\\2016_lcld_32.tif\n",
      "Calculating 2016_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2016_lcld_32.tif\n",
      "Zonal Stats for 2016_lcld_32.tif - Elapsed time: (0:02:00)\n",
      "Year: 2017 - raster path D:\\Basedata\\LCLD_rasters_archive\\2017_lcld_32.tif\n",
      "Calculating 2017_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2017_lcld_32.tif\n",
      "Zonal Stats for 2017_lcld_32.tif - Elapsed time: (0:02:00)\n",
      "Year: 2018 - raster path D:\\Basedata\\LCLD_rasters_archive\\2018_lcld_32.tif\n",
      "Calculating 2018_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2018_lcld_32.tif\n",
      "Zonal Stats for 2018_lcld_32.tif - Elapsed time: (0:02:00)\n",
      "Year: 2019 - raster path D:\\Basedata\\LCLD_rasters_archive\\2019_lcld_32.tif\n",
      "Calculating 2019_lcld_32.tif zonal stats for all Cook_Inlet watersheds...\n",
      "Begin zonal stats for 2019_lcld_32.tif\n",
      "Zonal Stats for 2019_lcld_32.tif - Elapsed time: (0:02:00)\n",
      "All Covariates for Cook_Inlet completed.\n",
      "Elapsed time: (0:58:24)\n",
      "****************************************************************************************************\n",
      "Copper_River in ['Cook_Inlet', 'Copper_River'] AKSSF list, using cat_fields ['cat_ID_txt', 'NHDPlusID', 'cat_ID_con'] and watershed fields ['cat_ID_txt', 'cat_ID', 'cat_ID_con']\n",
      "****************************************************************************************************\n",
      "cat_ID_txt field already in dataset D:\\GIS\\AKSSF\\Copper_River\\Copper_River.gdb\\awc_huc12_catchment_outlets\n",
      "****************************************************************************************************\n",
      "cat_ID_con field already in dataset D:\\GIS\\AKSSF\\Copper_River\\Copper_River.gdb\\awc_huc12_catchment_outlets\n",
      "****************************************************************************************************\n",
      "Merged watershed dataset awc_huc12_wtds_merge found\n",
      "****************************************************************************************************\n",
      "cat_ID_txt field already in dataset\n",
      "****************************************************************************************************\n",
      "cat_ID_con field already in dataset D:\\GIS\\AKSSF\\Copper_River\\Copper_River.gdb\\awc_huc12_wtds_merge\n",
      "****************************************************************************************************\n",
      "Calculating topographic metrics for catchments & watersheds of interest in Copper_River region\n",
      "----------\n",
      "Geodatabase: D:\\GIS\\AKSSF_awcHuc12_cv\\AKSSF_awcHuc12_cv.gdb\n",
      "----------\n",
      "Watershed Merge: D:\\GIS\\AKSSF\\Copper_River\\Copper_River.gdb\\awc_huc12_wtds_merge\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "HUC12 Catchment Outlets: D:\\GIS\\AKSSF\\Copper_River\\Copper_River.gdb\\awc_huc12_catchment_outlets\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Elevation Raster: D:\\GIS\\AKSSF\\Copper_River\\elev.tif\n",
      "  Projection: NAD_1983_Alaska_Albers\n",
      "----------\n",
      "North Aspect Raster: D:\\GIS\\AKSSF\\Copper_River\\north.tif\n",
      "  Projection: NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Wetlands Raster: D:\\GIS\\AKSSF\\Copper_River\\wetlands.tif\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Slope Raster: D:\\GIS\\AKSSF\\Copper_River\\slope.tif\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Lakes Ponds fc: D:\\Basedata\\AKSSF_Basedata\\AKSSF_Basedata.gdb\\AKSSF_NHDPlus_LakePond_alb\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Glaciers fc: D:\\GIS\\AKSSF\\Copper_River\\Copper_River.gdb\\glaciers \n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "245 Watersheds to process\n",
      "----------\n",
      "Catchment intersect D:\\GIS\\AKSSF\\Copper_River\\Copper_River.gdb\\awc_huc12_catchment_outlets selected\n",
      "----------\n",
      "Begin Slope zonal statistics min/mean/max std dev for watersheds and catchments in Copper_River region\n",
      "Calculating Copper_River watershed slope zonal stats...\n",
      "running MIN_MAX_MEAN\n",
      "Watershed Slope Zonal MIN_MAX_MEAN for Copper_River complete.\n",
      "Elapsed time: (0:03:33)\n",
      "****************************************************************************************************\n",
      "running STD\n",
      "Watershed Slope Zonal STD for Copper_River complete.\n",
      "Elapsed time: (0:02:59)\n",
      "****************************************************************************************************\n",
      "Begin Elevation zonal statistics min/mean/max std dev for watersheds and catchments in Copper_River region\n",
      "running MIN_MAX_MEAN\n",
      "Watershed Elevation Zonal MIN_MAX_MEAN for Copper_River complete.\n",
      "Elapsed time: (0:03:17)\n",
      "****************************************************************************************************\n",
      "running STD\n",
      "Watershed Elevation Zonal STD for Copper_River complete.\n",
      "Elapsed time: (0:06:24)\n",
      "****************************************************************************************************\n",
      "Calculating Copper_River catchment elevation zonal stats...\n",
      "Elevation Zonal Stats for Copper_River catchments complete.\n",
      "Elapsed time: (0:00:17)\n",
      "****************************************************************************************************\n",
      "Calculating Copper_River catchment slope zonal stats...\n",
      "Slope Zonal Stats for Copper_River catchments complete.\n",
      "Elapsed time: (0:00:11)\n",
      "****************************************************************************************************\n",
      "All Zonal Stats for Copper_River Elapsed time: (0:13:28)\n",
      "****************************************************************************************************\n",
      "Begin tabulate area of north facing cells for watersheds and catchments in Copper_River region\n",
      "****************************************************************************************************\n",
      "Watershed percent north Tabulate area/intersections for Copper_River complete.\n",
      "Elapsed time: (0:03:12)\n",
      "****************************************************************************************************\n",
      "Begin watershed percent lakes ponds for Copper_River\n",
      "Percent Lakes Tabulate area/intersections for Copper_River complete.\n",
      "Elapsed time: (0:00:36)\n",
      "****************************************************************************************************\n",
      "Begin tabulate intersection between D:\\GIS\\AKSSF\\Copper_River\\Copper_River.gdb\\glaciers and watersheds in Copper_River region\n",
      "****************************************************************************************************\n",
      "Percent Glacier Tabulate area/intersections for Copper_River complete.\n",
      "Elapsed time: (0:00:27)\n",
      "****************************************************************************************************\n",
      "Begin tabulate intersection between D:\\GIS\\AKSSF\\Copper_River\\wetlands.tif and watersheds in Copper_River region\n",
      "****************************************************************************************************\n",
      "Percent Wetlands Tabulate area/intersections for Copper_River complete.\n",
      "Elapsed time: (0:03:09)\n",
      "****************************************************************************************************\n",
      "Tabulate area/intersections for Copper_River complete\n",
      "Elapsed time: (0:07:26)\n",
      "****************************************************************************************************\n",
      "Year: 2001 - raster path D:\\Basedata\\LCLD_rasters_archive\\2001_lcld_32.tif\n",
      "Calculating 2001_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2001_lcld_32.tif\n",
      "Zonal Stats for 2001_lcld_32.tif - Elapsed time: (0:02:51)\n",
      "Year: 2002 - raster path D:\\Basedata\\LCLD_rasters_archive\\2002_lcld_32.tif\n",
      "Calculating 2002_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2002_lcld_32.tif\n",
      "Zonal Stats for 2002_lcld_32.tif - Elapsed time: (0:02:51)\n",
      "Year: 2003 - raster path D:\\Basedata\\LCLD_rasters_archive\\2003_lcld_32.tif\n",
      "Calculating 2003_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2003_lcld_32.tif\n",
      "Zonal Stats for 2003_lcld_32.tif - Elapsed time: (0:02:52)\n",
      "Year: 2004 - raster path D:\\Basedata\\LCLD_rasters_archive\\2004_lcld_32.tif\n",
      "Calculating 2004_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2004_lcld_32.tif\n",
      "Zonal Stats for 2004_lcld_32.tif - Elapsed time: (0:02:51)\n",
      "Year: 2005 - raster path D:\\Basedata\\LCLD_rasters_archive\\2005_lcld_32.tif\n",
      "Calculating 2005_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2005_lcld_32.tif\n",
      "Zonal Stats for 2005_lcld_32.tif - Elapsed time: (0:02:51)\n",
      "Year: 2006 - raster path D:\\Basedata\\LCLD_rasters_archive\\2006_lcld_32.tif\n",
      "Calculating 2006_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2006_lcld_32.tif\n",
      "Zonal Stats for 2006_lcld_32.tif - Elapsed time: (0:02:51)\n",
      "Year: 2007 - raster path D:\\Basedata\\LCLD_rasters_archive\\2007_lcld_32.tif\n",
      "Calculating 2007_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2007_lcld_32.tif\n",
      "Zonal Stats for 2007_lcld_32.tif - Elapsed time: (0:02:51)\n",
      "Year: 2008 - raster path D:\\Basedata\\LCLD_rasters_archive\\2008_lcld_32.tif\n",
      "Calculating 2008_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2008_lcld_32.tif\n",
      "Zonal Stats for 2008_lcld_32.tif - Elapsed time: (0:02:51)\n",
      "Year: 2009 - raster path D:\\Basedata\\LCLD_rasters_archive\\2009_lcld_32.tif\n",
      "Calculating 2009_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2009_lcld_32.tif\n",
      "Zonal Stats for 2009_lcld_32.tif - Elapsed time: (0:02:50)\n",
      "Year: 2010 - raster path D:\\Basedata\\LCLD_rasters_archive\\2010_lcld_32.tif\n",
      "Calculating 2010_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2010_lcld_32.tif\n",
      "Zonal Stats for 2010_lcld_32.tif - Elapsed time: (0:02:51)\n",
      "Year: 2011 - raster path D:\\Basedata\\LCLD_rasters_archive\\2011_lcld_32.tif\n",
      "Calculating 2011_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2011_lcld_32.tif\n",
      "Zonal Stats for 2011_lcld_32.tif - Elapsed time: (0:02:51)\n",
      "Year: 2012 - raster path D:\\Basedata\\LCLD_rasters_archive\\2012_lcld_32.tif\n",
      "Calculating 2012_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2012_lcld_32.tif\n",
      "Zonal Stats for 2012_lcld_32.tif - Elapsed time: (0:02:51)\n",
      "Year: 2013 - raster path D:\\Basedata\\LCLD_rasters_archive\\2013_lcld_32.tif\n",
      "Calculating 2013_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2013_lcld_32.tif\n",
      "Zonal Stats for 2013_lcld_32.tif - Elapsed time: (0:02:50)\n",
      "Year: 2014 - raster path D:\\Basedata\\LCLD_rasters_archive\\2014_lcld_32.tif\n",
      "Calculating 2014_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2014_lcld_32.tif\n",
      "Zonal Stats for 2014_lcld_32.tif - Elapsed time: (0:02:50)\n",
      "Year: 2015 - raster path D:\\Basedata\\LCLD_rasters_archive\\2015_lcld_32.tif\n",
      "Calculating 2015_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2015_lcld_32.tif\n",
      "Zonal Stats for 2015_lcld_32.tif - Elapsed time: (0:02:51)\n",
      "Year: 2016 - raster path D:\\Basedata\\LCLD_rasters_archive\\2016_lcld_32.tif\n",
      "Calculating 2016_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2016_lcld_32.tif\n",
      "Zonal Stats for 2016_lcld_32.tif - Elapsed time: (0:02:51)\n",
      "Year: 2017 - raster path D:\\Basedata\\LCLD_rasters_archive\\2017_lcld_32.tif\n",
      "Calculating 2017_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2017_lcld_32.tif\n",
      "Zonal Stats for 2017_lcld_32.tif - Elapsed time: (0:02:53)\n",
      "Year: 2018 - raster path D:\\Basedata\\LCLD_rasters_archive\\2018_lcld_32.tif\n",
      "Calculating 2018_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2018_lcld_32.tif\n",
      "Zonal Stats for 2018_lcld_32.tif - Elapsed time: (0:02:51)\n",
      "Year: 2019 - raster path D:\\Basedata\\LCLD_rasters_archive\\2019_lcld_32.tif\n",
      "Calculating 2019_lcld_32.tif zonal stats for all Copper_River watersheds...\n",
      "Begin zonal stats for 2019_lcld_32.tif\n",
      "Zonal Stats for 2019_lcld_32.tif - Elapsed time: (0:02:51)\n",
      "All Covariates for Copper_River completed.\n",
      "Elapsed time: (1:15:13)\n",
      "****************************************************************************************************\n",
      "Process completed at 2022-02-10 00:09 (Elapsed time: 2:17:54)\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "from arcpy.sa import *\n",
    "arcpy.env.workspace = data_dir\n",
    "arcpy.env.overwriteOutput = True\n",
    "sr = arcpy.SpatialReference(3338) #'NAD_1983_Alaska_Albers'\n",
    "arcpy.env.outputCoordinateSystem = sr\n",
    "regions  = arcpy.ListWorkspaces(workspace_type=\"Folder\")\n",
    "\n",
    "# Lists for variables not needed at present time\n",
    "#cat_asp_ztables = []\n",
    "#wtd_asp_ztables = []\n",
    "#cat_pernorth_taba_tables=[]\n",
    "\n",
    "# Lists to store output tables\n",
    "wtd_pernorth_taba_tables=[]\n",
    "wtd_lp_tabint_tables = []\n",
    "wtd_glac_tabint_tables = []\n",
    "wtd_wet_taba_tables = []\n",
    "cat_elev_ztables = []\n",
    "wtd_elev_ztables = []\n",
    "cat_slope_ztables = []\n",
    "wtd_slope_ztables = []\n",
    "lcld_Ztables = []\n",
    "\n",
    "# Clear lists\n",
    "cat_cur_fields = []\n",
    "wtd_cur_fields = []\n",
    "\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "\n",
    "# Split data by type\n",
    "nhdplus_dat = ['Cook_Inlet','Copper_River']\n",
    "tauDem_dat = ['Bristol_Bay', 'Kodiak', 'Prince_William_Sound']\n",
    "\n",
    "#Limit to ci for testing\n",
    "#regions = ['D:\\\\GIS\\\\AKSSF\\\\Cook_Inlet','D:\\\\GIS\\\\AKSSF\\\\Copper_River']\n",
    "#Try with both data types\n",
    "regions = ['D:\\\\GIS\\\\AKSSF\\\\Prince_William_Sound','D:\\\\GIS\\\\AKSSF\\\\Cook_Inlet','D:\\\\GIS\\\\AKSSF\\\\Copper_River']\n",
    "\n",
    "for region in regions:\n",
    "    roi = os.path.basename(region)\n",
    "    # expression to calculate region field with roi name\n",
    "    exp =  '\"'+roi+'\"'\n",
    "    if roi in nhdplus_dat:\n",
    "        lakes_fc = nhd_lakes_fc\n",
    "        # Fields for update cursor\n",
    "        cat_cur_fields = ['cat_ID_txt', 'NHDPlusID',\"cat_ID_con\"]\n",
    "        wtd_cur_fields = ['cat_ID_txt', 'cat_ID',\"cat_ID_con\"]\n",
    "        print (f'{roi} in {nhdplus_dat} AKSSF list, using cat_fields {cat_cur_fields} and watershed fields {wtd_cur_fields}')\n",
    "        print(f'{\"*\"*100}')\n",
    "    # Set data and variables unique to regions with TauDEM Data\n",
    "    elif roi in tauDem_dat:\n",
    "        lakes_fc = tau_lakes_fc\n",
    "        # Fields for update cursor\n",
    "        if roi == 'Bristol_Bay':\n",
    "            cat_cur_fields = ['cat_ID_txt', 'catID',\"cat_ID_con\"]\n",
    "            wtd_cur_fields = ['cat_ID_txt', 'cat_ID',\"cat_ID_con\"]\n",
    "        else:\n",
    "            cat_cur_fields = ['cat_ID_txt', 'gridcode',\"cat_ID_con\"]\n",
    "            wtd_cur_fields = ['cat_ID_txt', 'cat_ID',\"cat_ID_con\"]\n",
    "        print (f'{roi} in {tauDem_dat} TauDEM list, using cat_fields {cat_cur_fields} and watershed fields {wtd_cur_fields}')\n",
    "        print(f'{\"*\"*100}')\n",
    "    # Start iter timing function\n",
    "    iteration_start = time.time()\n",
    "    # Set workspace to region folder\n",
    "    arcpy.env.workspace = region\n",
    "    walk = arcpy.da.Walk(region, datatype = ['FeatureClass','RasterDataset'])\n",
    "    for dirpath, dirnames, filenames in walk:\n",
    "        for filename in filenames:\n",
    "            # Set merged watersheds dataset\n",
    "            if 'awc_huc12_wtds_merge'== filename:\n",
    "                wtdpath = os.path.join(dirpath,filename)\n",
    "                wtdname = roi +'_'+ filename\n",
    "                # Make local copy projected in AKAlbers\n",
    "                wtd_merge = os.path.join(dirpath, filename)\n",
    "                print(f'Merged watershed dataset {filename} found')\n",
    "                print(f'{\"*\"*100}')\n",
    "                wtdfieldnames = []\n",
    "                wtdlstFields = arcpy.ListFields(wtd_merge)\n",
    "                for field in wtdlstFields:\n",
    "                    wtdfieldnames.append(field.name)\n",
    "                if str(wtd_cur_fields[0]) in wtdfieldnames:\n",
    "                    print (f'{wtd_cur_fields[0]} field already in dataset')\n",
    "                    print(f'{\"*\"*100}')\n",
    "                else:\n",
    "                    print (f'Adding {wtd_cur_fields[0]} field to watershed dataset {wtd_merge}')\n",
    "                    print(f'{\"*\"*100}')\n",
    "                    # add cat_ID_txt field and concat cat_ID + region\n",
    "                    arcpy.AddField_management(wtd_merge, str(wtd_cur_fields[0]),field_type='TEXT')\n",
    "                    # populate cat_ID_txt\n",
    "                    with arcpy.da.UpdateCursor(wtd_merge, wtd_cur_fields[0:2]) as cur:\n",
    "                        for row in cur:\n",
    "                            strval = str(row[1])\n",
    "                            row[0] = strval.replace('.0',\"\")\n",
    "                            # Update rows\n",
    "                            cur.updateRow(row)\n",
    "                        del(row)\n",
    "                    del(cur)\n",
    "                if str(wtd_cur_fields[2]) in wtdfieldnames:\n",
    "                    print (f'{wtd_cur_fields[2]} field already in dataset {wtd_merge}')\n",
    "                    print(f'{\"*\"*100}')\n",
    "                else:\n",
    "                    print (f'Adding {wtd_cur_fields[2]} field to watershed dataset {wtd_merge}')\n",
    "                    print(f'{\"*\"*100}')\n",
    "                    # add cat_ID_con field and concat cat_ID + region\n",
    "                    arcpy.AddField_management(wtd_merge, str(wtd_cur_fields[2]),field_type='TEXT')\n",
    "                    # populate cat_ID_txt\n",
    "                    with arcpy.da.UpdateCursor(wtd_merge, wtd_cur_fields) as cur:\n",
    "                        for row in cur:\n",
    "                            strval = str(row[1])\n",
    "                            row[2] = str(roi) +'_'+ strval.replace(\".0\",\"\")\n",
    "                            # Update rows\n",
    "                            cur.updateRow(row)\n",
    "                        del(row)\n",
    "                    del(cur)\n",
    "\n",
    "            # Select glaciers fc\n",
    "            elif 'glaciers' == filename:\n",
    "                # Make local copy projected in AKAlbers\n",
    "                glacpath = os.path.join(dirpath, filename)\n",
    "                glacname = roi+'_'+filename\n",
    "                glac_fc = glacpath\n",
    "\n",
    "            # Select elevation raster\n",
    "            elif 'elev.tif' == filename:\n",
    "                elev_rast = os.path.join(dirpath, filename)\n",
    "\n",
    "            # # Select aspect raster\n",
    "            # elif 'aspect' in filename:\n",
    "            #     asp_rast = os.path.join(dirpath, filename)\n",
    "\n",
    "            # Select north raster\n",
    "            elif 'north.tif' == filename:\n",
    "                nor_rast = os.path.join(dirpath, filename)\n",
    "\n",
    "            # Select slope raster\n",
    "            elif 'slope.tif' == filename:\n",
    "                slope_rast = os.path.join(dirpath, filename)\n",
    "\n",
    "            # Select wetland raster\n",
    "            elif 'wetlands.tif' == filename:\n",
    "                wet_rast = os.path.join(dirpath, filename)\n",
    "\n",
    "            # Select catch_int fc (catchments of interest for region) and make a copy\n",
    "            elif 'awc_huc12_catchment_outlets' == filename:\n",
    "                # Make local copy projected in AKAlbers\n",
    "                catspath = os.path.join(dirpath,filename)\n",
    "                catsname = roi +\"_\"+filename\n",
    "                cats = catspath\n",
    "                catlstfields = arcpy.ListFields(cats)\n",
    "                catfieldnames = []\n",
    "                for field in catlstfields:\n",
    "                    catfieldnames.append(field.name)\n",
    "                if str(cat_cur_fields[0]) in catfieldnames:\n",
    "                    print (f'{cat_cur_fields[0]} field already in dataset {cats}')\n",
    "                    print(f'{\"*\"*100}')\n",
    "                else:\n",
    "                    print (f'Adding {cat_cur_fields[0]} field to catchment dataset {cats}')\n",
    "                    print(f'{\"*\"*100}')\n",
    "                    # add cat_ID_txt field\n",
    "                    arcpy.AddField_management(cats, str(cat_cur_fields[0]), field_type='TEXT')\n",
    "                    # populate cat_ID_txt\n",
    "                    with arcpy.da.UpdateCursor(cats, cat_cur_fields[0:2]) as cur:\n",
    "                        for row in cur:\n",
    "                            strval = str(row[1])\n",
    "                            row[0] = strval.replace('.0',\"\")\n",
    "                            # Update rows\n",
    "                            cur.updateRow(row)\n",
    "                        del(row)\n",
    "                    del(cur)\n",
    "                if str(cat_cur_fields[2]) in catfieldnames:\n",
    "                    print (f'{cat_cur_fields[2]} field already in dataset {cats}')\n",
    "                    print(f'{\"*\"*100}')\n",
    "                else:\n",
    "                    print (f'Adding {cat_cur_fields[2]} field to catchment dataset {cats}')\n",
    "                    print(f'{\"*\"*100}')\n",
    "                    # add cat_ID_txt field & cat_ID + region concat field\n",
    "                    arcpy.AddField_management(cats,str(cat_cur_fields[2]),field_type='TEXT')\n",
    "                    # populate cat_ID_con\n",
    "                    with arcpy.da.UpdateCursor(cats, cat_cur_fields) as cur:\n",
    "                        for row in cur:\n",
    "                            strval = str(row[1])\n",
    "                            row[2] = str(roi) +'_'+ strval.replace('.0',\"\")\n",
    "                            # Update rows\n",
    "                            cur.updateRow(row)\n",
    "                        del(row)\n",
    "                    del(cur)\n",
    "\n",
    "    print (f'Calculating topographic metrics for catchments & watersheds of interest in {roi} region')\n",
    "    print ('----------')\n",
    "    print(f'Geodatabase: {outgdb}')\n",
    "    print ('----------')\n",
    "    print (f'Watershed Merge: {wtd_merge}')\n",
    "    print (f'  Projection {arcpy.Describe(wtd_merge).spatialReference.name}')\n",
    "    print ('----------')\n",
    "    print (f'HUC12 Catchment Outlets: {cats}')\n",
    "    print (f'  Projection {arcpy.Describe(cats).spatialReference.name}')\n",
    "    print ('----------')\n",
    "    print (f'Elevation Raster: {elev_rast}')\n",
    "    print (f'  Projection: {arcpy.Describe(elev_rast).spatialReference.name}')\n",
    "    print ('----------')\n",
    "    print (f'North Aspect Raster: {nor_rast}')\n",
    "    print (f'  Projection: {arcpy.Describe(nor_rast).spatialReference.name}')\n",
    "    print ('----------')\n",
    "    print (f'Wetlands Raster: {wet_rast}')\n",
    "    print (f'  Projection {arcpy.Describe(wet_rast).spatialReference.name}')\n",
    "    print ('----------')\n",
    "    print (f'Slope Raster: {slope_rast}')\n",
    "    print (f'  Projection {arcpy.Describe(slope_rast).spatialReference.name}')\n",
    "    print ('----------')\n",
    "    print (f'Lakes Ponds fc: {lakes_fc}')\n",
    "    print (f'  Projection {arcpy.Describe(lakes_fc).spatialReference.name}')\n",
    "    print ('----------')\n",
    "    print (f'Glaciers fc: {glac_fc} ')\n",
    "    print (f'  Projection {arcpy.Describe(glac_fc).spatialReference.name}')\n",
    "    print ('----------')\n",
    "    print (f'{arcpy.GetCount_management(wtd_merge)} Watersheds to process')\n",
    "    print ('----------')\n",
    "    print (f'Catchment intersect {cats} selected')\n",
    "    print ('----------')\n",
    "\n",
    "    # # Aspect variables\n",
    "    # wtd_merge_asp_table_name = roi + \"_NhdAwcH12_wtd_mer_AspectZstats\"\n",
    "    # wtd_merge_asp_table_path = os.path.join(outgdb, wtd_merge_asp_table_name)\n",
    "    # cat_asp_table_name = roi + \"_NhdAwcH12_cats_AspectZstats\"\n",
    "    # cat_asp_table_path = os.path.join(outgdb, cat_asp_table_name)\n",
    "\n",
    "    # Percent North variables\n",
    "    wtd_merge_pernorth_table_name = roi + \"_NhdAwcH12_wtd_mer_PerNorth\"\n",
    "    wtd_merge_pernorth_table_path = os.path.join(outgdb, wtd_merge_pernorth_table_name)\n",
    "    # cat_pernorth_table_name = roi + \"_NhdAwcH12_cats_PercentNorth\"\n",
    "    # cat_pernorth_table_path = os.path.join(outgdb, cat_pernorth_table_name)\n",
    "\n",
    "    # Elevation variables\n",
    "    wtd_merge_elev_table_name = roi + \"_NhdAwcH12_wtd_mer_ElevZstats\"\n",
    "    wtd_merge_elev_table_path = os.path.join(outgdb, wtd_merge_elev_table_name)\n",
    "    cat_elev_table_name = roi + \"_NhdAwcH12_cats_ElevZstats\"\n",
    "    cat_elev_table_path = os.path.join(outgdb, cat_elev_table_name)\n",
    "\n",
    "    # Slope variables\n",
    "    wtd_merge_slope_table_name = roi + \"_NhdAwcH12_wtd_mer_SlopeZstats\"\n",
    "    wtd_merge_slope_table_path = os.path.join(outgdb, wtd_merge_slope_table_name)\n",
    "    cat_slope_table_name = roi + \"_NhdAwcH12_cats_SlopeZstats\"\n",
    "    cat_slope_table_path = os.path.join(outgdb, cat_slope_table_name)\n",
    "\n",
    "    # Lakes Ponds variables\n",
    "    wtd_merge_lp_table_name = roi + \"_NhdAwcH12_wtd_mer_PerLakes\"\n",
    "    wtd_merge_lp_table_path = os.path.join(outgdb, wtd_merge_lp_table_name)\n",
    "    cat_lp_table_name = roi + \"_NhdAwcH12_cats_PerLakes\"\n",
    "    cat_lp_path = os.path.join(outgdb, cat_lp_table_name)\n",
    "\n",
    "    # Wetlands variables\n",
    "    wtd_merge_wetlands_table_name = roi + \"_NhdAwcH12_wtd_mer_PerWet\"\n",
    "    wtd_merge_wetlands_table_path = os.path.join(outgdb, wtd_merge_wetlands_table_name)\n",
    "    cat_wetlands_table_name = roi + \"NhdAwcH12_cats_PerWet\"\n",
    "    cat_wetlands_table_path = os.path.join(outgdb, cat_wetlands_table_name)\n",
    "\n",
    "    # Glaciers\n",
    "    wtd_merge_glac_table_name = roi + \"_NhdAwcH12_wtd_mer_PerGlac\"\n",
    "    wtd_merge_glac_table_path = os.path.join(outgdb, wtd_merge_glac_table_name)\n",
    "    cat_glac_table_name = roi + \"_NhdAwcH12_cats_Glaciers\"\n",
    "    cat_glac_table_path = os.path.join(outgdb, cat_glac_table_name)\n",
    "\n",
    "    try: # Zonal Stats section\n",
    "        print(f'Begin Slope zonal statistics min/mean/max std dev for watersheds and catchments in {roi}'\n",
    "              f' region')\n",
    "        # Statistics to run for watersheds - 'ALL' is not an option at this time as tool will fail with unknown error\n",
    "        zstats = ['MIN_MAX_MEAN','STD']\n",
    "        # Begin Zonal Stats\n",
    "        zstat_start = time.time()\n",
    "        zstat_start1 = time.time()\n",
    "\n",
    "        # Watershed slope Zonal Statistics\n",
    "        print(f'Calculating {roi} watershed slope zonal stats...')\n",
    "        arcpy.env.snapRaster = slope_rast\n",
    "        arcpy.env.cellSize = slope_rast\n",
    "\n",
    "        # Create field mappings\n",
    "        slope_fm = arcpy.FieldMap()\n",
    "        slope_fms = arcpy.FieldMappings()\n",
    "        for field in arcpy.ListFields(wtd_merge)[6:]:\n",
    "            slope_fm = arcpy.FieldMap()\n",
    "            slope_fm.addInputField(wtd_merge,field.name)\n",
    "            slope_fm.mergeRule = 'First'\n",
    "            # Set properties of the output name.\n",
    "            f_name = slope_fm.outputField\n",
    "            f_name.name = field.name\n",
    "            f_name.aliasName = field.name\n",
    "            slope_fm.outputField = f_name\n",
    "            slope_fms.addFieldMap(slope_fm)\n",
    "\n",
    "        # Make copy of watershed merge input as table to join stats fields\n",
    "        wtd_slope_metrics_table = arcpy.TableToTable_conversion(wtd_merge,\n",
    "                                                               outgdb,\n",
    "                                                               wtd_merge_slope_table_name,\n",
    "                                                               '',\n",
    "                                                               slope_fms,\n",
    "                                                               )\n",
    "        # Add region identifier field for watershed tables                                                )\n",
    "        arcpy.AddField_management(wtd_slope_metrics_table,'region',field_type='TEXT')\n",
    "        arcpy.CalculateField_management(wtd_slope_metrics_table,'region',exp)\n",
    "\n",
    "        for stat in zstats:\n",
    "            outstattable = os.path.join(outgdb,f'{roi}_wtdSlope_{stat}')\n",
    "            zstat_start1 = time.time()\n",
    "            print (f'running {stat}')\n",
    "            stat_table = ZonalStatisticsAsTable(in_zone_data = wtd_merge,\n",
    "                                                zone_field = wtd_cur_fields[0],\n",
    "                                                in_value_raster = slope_rast,\n",
    "                                                out_table = outstattable,\n",
    "                                                statistics_type=stat\n",
    "                                                )\n",
    "\n",
    "            stat_fields = [f.name for f in arcpy.ListFields(stat_table)]\n",
    "            arcpy.JoinField_management(wtd_slope_metrics_table,\n",
    "                                   wtd_cur_fields[0],\n",
    "                                   stat_table,\n",
    "                                   wtd_cur_fields[0],\n",
    "                                   stat_fields[5:] # Keep only stat field/s\n",
    "                                   )\n",
    "\n",
    "            # Report time\n",
    "            zstat_stop1 = time.time()\n",
    "            zstat_time1 = int (zstat_stop1 - zstat_start1)\n",
    "            print(f'Watershed Slope Zonal {stat} for {roi} complete.\\nElapsed time: ({datetime.timedelta(seconds=zstat_time1)})')\n",
    "            print(f'{\"*\"*100}')\n",
    "\n",
    "        # Append watershed slope table to list\n",
    "        wtd_slope_ztables.append(wtd_slope_metrics_table)\n",
    "\n",
    "\n",
    "        # Elevation Zonal statistics  for watersheds\n",
    "        print(f'Begin Elevation zonal statistics min/mean/max std dev for watersheds and catchments in {roi}'\n",
    "              f' region')\n",
    "        zstat_start2 = time.time()\n",
    "        arcpy.env.snapRaster = elev_rast\n",
    "        arcpy.env.cellSize = elev_rast\n",
    "\n",
    "        # Create field mappings\n",
    "        elev_fm = arcpy.FieldMap()\n",
    "        elev_fms = arcpy.FieldMappings()\n",
    "        for field in arcpy.ListFields(wtd_merge)[6:]:\n",
    "            elev_fm = arcpy.FieldMap()\n",
    "            elev_fm.addInputField(wtd_merge,field.name)\n",
    "            elev_fm.mergeRule = 'First'\n",
    "            # Set properties of the output name.\n",
    "            f_name = elev_fm.outputField\n",
    "            f_name.name = field.name\n",
    "            f_name.aliasName = field.name\n",
    "            elev_fm.outputField = f_name\n",
    "            elev_fms.addFieldMap(elev_fm)\n",
    "\n",
    "        # Make copy of watershed merge input as table to join stats fields\n",
    "        wtd_elev_metrics_table = arcpy.TableToTable_conversion(wtd_merge,\n",
    "                                                               outgdb,\n",
    "                                                               wtd_merge_elev_table_name,\n",
    "                                                               '',\n",
    "                                                               elev_fms,\n",
    "                                                               )\n",
    "        # Add region identifier field for watershed tables                                                )\n",
    "        arcpy.AddField_management(wtd_elev_metrics_table,'region',field_type='TEXT')\n",
    "        arcpy.CalculateField_management(wtd_elev_metrics_table,'region',exp)\n",
    "\n",
    "        for stat in zstats:\n",
    "            outstattable = os.path.join(outgdb,f'{roi}_wtdElev_{stat}')\n",
    "            zstat_start1 = time.time()\n",
    "            print (f'running {stat}')\n",
    "            stat_table = ZonalStatisticsAsTable(in_zone_data = wtd_merge,\n",
    "                                                zone_field = wtd_cur_fields[0],\n",
    "                                                in_value_raster = elev_rast,\n",
    "                                                out_table = outstattable,\n",
    "                                                statistics_type=stat\n",
    "                                                )\n",
    "\n",
    "            stat_fields = [f.name for f in arcpy.ListFields(stat_table)]\n",
    "            arcpy.JoinField_management(wtd_elev_metrics_table,\n",
    "                                   wtd_cur_fields[0],\n",
    "                                   stat_table,\n",
    "                                   wtd_cur_fields[0],\n",
    "                                   stat_fields[5:] # Keep only stat field/s\n",
    "                                   )\n",
    "\n",
    "            # Report time\n",
    "            zstat_stop2 = time.time()\n",
    "            zstat_time2 = int (zstat_stop2 - zstat_start2)\n",
    "            print(f'Watershed Elevation Zonal {stat} for {roi} complete.\\nElapsed time: ({datetime.timedelta(seconds=zstat_time2)})')\n",
    "            print(f'{\"*\"*100}')\n",
    "        # Append watershed elev table to list\n",
    "        wtd_elev_ztables.append(wtd_elev_metrics_table)\n",
    "\n",
    "\n",
    "        # Elevation zonal statistics for catchments\n",
    "        print(f'Calculating {roi} catchment elevation zonal stats...')\n",
    "        zstat_start3 = time.time()\n",
    "        arcpy.env.snapRaster = elev_rast\n",
    "        arcpy.env.cellSize = elev_rast\n",
    "        cat_elev_metrics_table = ZonalStatisticsAsTable(in_zone_data = cats ,\n",
    "                                                        zone_field = cat_cur_fields[0],\n",
    "                                                        in_value_raster = elev_rast,\n",
    "                                                        out_table = cat_elev_table_path,\n",
    "                                                        statistics_type='ALL'\n",
    "                                                        )\n",
    "        # Add region identifier field for catchment table\n",
    "        arcpy.AddField_management(cat_elev_metrics_table,'region',field_type='TEXT')\n",
    "        # Add cat_ID_Con field\n",
    "        arcpy.AddField_management(cat_elev_metrics_table,'cat_ID_con',field_type='TEXT')\n",
    "\n",
    "        # Update fields\n",
    "        with arcpy.da.UpdateCursor(cat_elev_metrics_table,['region','cat_ID_txt','cat_ID_con']) as cur:\n",
    "            for row in cur:\n",
    "                row[0] = roi\n",
    "                strval = str(row[1])\n",
    "                row[2] = roi+\"_\"+strval.replace(\".0\",\"\")\n",
    "                # Update\n",
    "                cur.updateRow(row)\n",
    "            del(row)\n",
    "        del(cur)\n",
    "        # Append catchment elev table to list\n",
    "        cat_elev_ztables.append(cat_elev_metrics_table)\n",
    "        # Report time\n",
    "        zstat_stop3 = time.time()\n",
    "        zstat_time3 = int (zstat_stop3 - zstat_start3)\n",
    "        print(f'Elevation Zonal Stats for {roi} catchments complete.\\nElapsed time: ({datetime.timedelta(seconds=zstat_time3)})')\n",
    "        print(f'{\"*\"*100}')\n",
    "\n",
    "        # Slope zonal statistics for catchments\n",
    "        zstat_start4 = time.time()\n",
    "        print(f'Calculating {roi} catchment slope zonal stats...')\n",
    "        arcpy.env.snapRaster = slope_rast\n",
    "        arcpy.env.cellSize = slope_rast\n",
    "        cat_slope_metrics_table = ZonalStatisticsAsTable(in_zone_data = cats ,\n",
    "                                                        zone_field = cat_cur_fields[0],\n",
    "                                                        in_value_raster = slope_rast,\n",
    "                                                        out_table = cat_slope_table_path,\n",
    "                                                        statistics_type='ALL'\n",
    "                                                        )\n",
    "        # Add region identifier field for catchment table\n",
    "        arcpy.AddField_management(cat_slope_metrics_table,'region',field_type='TEXT')\n",
    "        # Add cat_ID_Con field\n",
    "        arcpy.AddField_management(cat_slope_metrics_table,'cat_ID_con',field_type='TEXT')\n",
    "\n",
    "        # Update region field\n",
    "        with arcpy.da.UpdateCursor(cat_slope_metrics_table,['region','cat_ID_txt','cat_ID_con']) as cur:\n",
    "            for row in cur:\n",
    "                row[0] = roi\n",
    "                strval =str(row[1])\n",
    "                row[2] = roi+\"_\"+strval.replace(\".0\",\"\")\n",
    "                # Update\n",
    "                cur.updateRow(row)\n",
    "            del(row)\n",
    "        del(cur)\n",
    "        # Append catchment slope table to list\n",
    "        cat_slope_ztables.append(cat_slope_metrics_table)\n",
    "        # Report time\n",
    "        zstat_stop4 = time.time()\n",
    "        zstat_time4 = int (zstat_stop4 - zstat_start4)\n",
    "        print(f'Slope Zonal Stats for {roi} catchments complete.\\nElapsed time: ({datetime.timedelta(seconds=zstat_time4)})')\n",
    "        print(f'{\"*\"*100}')\n",
    "\n",
    "\n",
    "        # # Aspect Zonal statistics  for watersheds\n",
    "        # print(f'Calculating {roi} watershed aspect zonal stats...')\n",
    "        # wtd_asp_metrics_table = ZonalStatisticsAsTable(in_zone_data = wtd_merge, zone_field =\"cat_ID_txt\",\n",
    "        #                                                in_value_raster = asp_rast, out_table = wtd_merge_asp_table_path,\n",
    "        #                                                statistics_type='ALL')\n",
    "        # arcpy.AddField_management(wtd_asp_metrics_table, 'region', field_type='TEXT')\n",
    "        # Add cat_ID_Con field\n",
    "        # arcpy.AddField_management(wtd_asp_metrics_table,'cat_ID_con',field_type='TEXT')\n",
    "        # arcpy.CalculateField_management(wtd_asp_metrics_table, 'region', 'roi')\n",
    "        # Update region field\n",
    "        # with arcpy.da.UpdateCursor(wtd_asp_metrics_table,['region','cat_ID_txt','cat_ID_con']) as cur:\n",
    "        #     for row in cur:\n",
    "        #         row[0] = roi\n",
    "        #         strval = str(row[1])\n",
    "        #         row[2] = roi+\"_\"+strval.replace(\".0\",\"\")\n",
    "        #         # Update\n",
    "        #         cur.updateRow(row)\n",
    "        #     del(row)\n",
    "        # del(cur)\n",
    "        # wtd_asp_ztables.append(wtd_asp_metrics_table)\n",
    "\n",
    "        # # Aspect Zonal statistics for catchments\n",
    "        # print(f'Calculating {roi} catchment aspect zonal stats...')\n",
    "        # cat_asp_metrics_table = ZonalStatisticsAsTable(in_zone_data = cats, zone_field =\"cat_ID_txt\",\n",
    "        #                                                in_value_raster = asp_rast, out_table = cat_asp_table_path,\n",
    "        #                                                statistics_type='ALL')\n",
    "        # arcpy.AddField_management(cat_asp_metrics_table, 'region', field_type='TEXT')\n",
    "        # Add cat_ID_Con field\n",
    "        # arcpy.AddField_management(cat_asp_metrics_table,'cat_ID_con',field_type='TEXT')\n",
    "        # arcpy.CalculateField_management(cat_asp_metrics_table, 'region', 'roi')\n",
    "        # Update region field\n",
    "        # with arcpy.da.UpdateCursor(cat_asp_metrics_table,['region','cat_ID_txt','cat_ID_con']) as cur:\n",
    "        #     for row in cur:\n",
    "        #         strval = str(row[1])\n",
    "        #         row[2] = roi+\"_\"+strval.replace(\".0\",\"\")\n",
    "        #         # Update\n",
    "        #         cur.updateRow(row)\n",
    "        #     del(row)\n",
    "        # del(cur)\n",
    "        # cat_asp_ztables.append(cat_asp_metrics_table)\n",
    "\n",
    "        zstat_stop = time.time()\n",
    "        zstat_time = int (zstat_stop - zstat_start)\n",
    "        print(f'All Zonal Stats for {roi} Elapsed time: ({datetime.timedelta(seconds=zstat_time)})')\n",
    "        print(f'{\"*\"*100}')\n",
    "\n",
    "        # Tabulate Area with north grid and watersheds\n",
    "        tabarea_start = time.time()\n",
    "        tabarea_start1 = time.time()\n",
    "        print(f'Begin tabulate area of north facing cells for watersheds and catchments in {roi} region')\n",
    "        print(f'{\"*\"*100}')\n",
    "        # Percent North Tabulate area for watersheds\n",
    "        wtd_per_north_tabarea = arcpy.sa.TabulateArea(in_zone_data= wtd_merge,\n",
    "                                                      zone_field= wtd_cur_fields[0],\n",
    "                                                      in_class_data=nor_rast,\n",
    "                                                      class_field=\"Value\",\n",
    "                                                      out_table = wtd_merge_pernorth_table_path\n",
    "                                                      )\n",
    "        # Add region and percent north fields\n",
    "        arcpy.AlterField_management(wtd_per_north_tabarea,'CAT_ID_TXT','CAT_ID_TXT_DEL','CAT_ID_TXT_DEL')\n",
    "        arcpy.AddField_management(wtd_per_north_tabarea, 'region', field_type='TEXT')\n",
    "        arcpy.AddField_management(wtd_per_north_tabarea, 'NhdAwcH12_wtd_north_per', field_type='Float')\n",
    "        arcpy.AddField_management(wtd_per_north_tabarea, wtd_cur_fields[0], field_type='TEXT')\n",
    "        arcpy.AddField_management(wtd_per_north_tabarea, wtd_cur_fields[2], field_type='TEXT')\n",
    "        wtdnorfields = [f.name for f in arcpy.ListFields(wtd_per_north_tabarea)]\n",
    "        #print (wtdnorfields)\n",
    "        with arcpy.da.UpdateCursor(wtd_per_north_tabarea, wtdnorfields) as cur:\n",
    "            for row in cur:\n",
    "                strval = str(row[1])\n",
    "                row[4] = roi\n",
    "                row[5] = row[3]/(row[3]+row[2])*100\n",
    "                row[6] = strval.replace('.0','')\n",
    "                row[7] = roi +'_'+ strval.replace(\".0\",\"\")\n",
    "                # Update\n",
    "                cur.updateRow(row)\n",
    "            del(row)\n",
    "        del(cur)\n",
    "        # Drop UPPERCASE field form tab area\n",
    "        arcpy.DeleteField_management(wtd_per_north_tabarea,'CAT_ID_TXT_DEL')\n",
    "        # Append watershed percent north table to list\n",
    "        wtd_pernorth_taba_tables.append(wtd_per_north_tabarea)\n",
    "        # Report tab area times\n",
    "        tabarea_stop1 = time.time()\n",
    "        tabarea_time1 = int (tabarea_stop1 - tabarea_start1)\n",
    "        print(f'Watershed percent north Tabulate area/intersections for {roi} complete.\\nElapsed time: ({datetime.timedelta(seconds=tabarea_time1)})')\n",
    "        print(f'{\"*\"*100}')\n",
    "\n",
    "        # Percent Lakes Ponds using Tabulate Intersection for watersheds\n",
    "        print(f'Begin watershed percent lakes ponds for {roi}')\n",
    "        tabarea_start2 = time.time()\n",
    "        wtd_lp_tabint = arcpy.TabulateIntersection_analysis(wtd_merge,\n",
    "                                                            zone_fields=wtd_cur_fields[0],\n",
    "                                                            in_class_features=lakes_fc,\n",
    "                                                            out_table=wtd_merge_lp_table_path,\n",
    "                                                            class_fields='Ftype',\n",
    "                                                            out_units=\"SQUARE_METERS\"\n",
    "                                                            )\n",
    "        # Add region and cat id fields\n",
    "        arcpy.AlterField_management(wtd_lp_tabint,'PERCENTAGE','NhdAwcH12_wtd_lake_per','NhdAwcH12_wtd_lake_per')\n",
    "        arcpy.AlterField_management(wtd_lp_tabint,'AREA','NhdAwcH12_wtd_lake_area_sqm','NhdAwcH12_wtd_lake_area_sqm')\n",
    "        arcpy.AddField_management(wtd_lp_tabint, 'region', field_type='TEXT')\n",
    "        arcpy.AddField_management(wtd_lp_tabint, wtd_cur_fields[1], field_type='TEXT')\n",
    "        arcpy.AddField_management(wtd_lp_tabint, wtd_cur_fields[2], field_type='TEXT')\n",
    "        wtdlpfields = [f.name for f in arcpy.ListFields(wtd_lp_tabint)]\n",
    "        #print (wtdlpfields)\n",
    "        with arcpy.da.UpdateCursor(wtd_lp_tabint, wtdlpfields) as cur:\n",
    "            for row in cur:\n",
    "                strval = str(row[1])\n",
    "                row[5] = roi\n",
    "                row[6] = strval.replace('.0','')\n",
    "                row[7] = roi +'_'+ strval.replace(\".0\",\"\")\n",
    "                # Update\n",
    "                cur.updateRow(row)\n",
    "            del(row)\n",
    "        del(cur)\n",
    "\n",
    "        # Append watershed lakes ponds table to list\n",
    "        wtd_lp_tabint_tables.append(wtd_lp_tabint)\n",
    "        # Report tab area times\n",
    "        tabarea_stop2 = time.time()\n",
    "        tabarea_time2 = int (tabarea_stop2 - tabarea_start2)\n",
    "        print(f'Percent Lakes Tabulate area/intersections for {roi} complete.\\nElapsed time: ({datetime.timedelta(seconds=tabarea_time2)})')\n",
    "        print(f'{\"*\"*100}')\n",
    "\n",
    "        # Percent glaciers using Tabulate Intersection for watersheds\n",
    "        tabarea_start3 = time.time()\n",
    "        print(f'Begin tabulate intersection between {glac_fc} and watersheds in {roi} region')\n",
    "        print(f'{\"*\"*100}')\n",
    "        wtd_glac_tabint = arcpy.TabulateIntersection_analysis(wtd_merge,\n",
    "                                                            zone_fields=wtd_cur_fields[0],\n",
    "                                                            in_class_features=glac_fc,\n",
    "                                                            out_table=wtd_merge_glac_table_path,\n",
    "                                                            class_fields='O1Region',\n",
    "                                                            out_units=\"SQUARE_METERS\"\n",
    "                                                            )\n",
    "        # Add region and cat id fields\n",
    "        arcpy.AlterField_management(wtd_glac_tabint,'PERCENTAGE','NhdAwcH12_wtd_glacier_per','NhdAwcH12_wtd_glacier_per')\n",
    "        arcpy.AlterField_management(wtd_glac_tabint,'AREA','NhdAwcH12_wtd_glacier_area_sqm','NhdAwcH12_wtd_glacier_area_sqm')\n",
    "        arcpy.AddField_management(wtd_glac_tabint, 'region', field_type='TEXT')\n",
    "        arcpy.AddField_management(wtd_glac_tabint, wtd_cur_fields[1], field_type='TEXT')\n",
    "        arcpy.AddField_management(wtd_glac_tabint, wtd_cur_fields[2], field_type='TEXT')\n",
    "        wtdglacfields = [f.name for f in arcpy.ListFields(wtd_glac_tabint)]\n",
    "        #print (wtdglacfields)\n",
    "        with arcpy.da.UpdateCursor(wtd_glac_tabint, wtdglacfields) as cur:\n",
    "            for row in cur:\n",
    "                strval = str(row[1])\n",
    "                row[5] = roi\n",
    "                row[6] = strval.replace('.0','')\n",
    "                row[7] = roi +'_'+ strval.replace(\".0\",\"\")\n",
    "                # Update\n",
    "                cur.updateRow(row)\n",
    "            del(row)\n",
    "        del(cur)\n",
    "        # Append watershed percent glacier table to list\n",
    "        wtd_glac_tabint_tables.append(wtd_glac_tabint)\n",
    "        # Report tab area times\n",
    "        tabarea_stop3 = time.time()\n",
    "        tabarea_time3 = int (tabarea_stop3 - tabarea_start3)\n",
    "        print(f'Percent Glacier Tabulate area/intersections for {roi} complete.\\nElapsed time: ({datetime.timedelta(seconds=tabarea_time3)})')\n",
    "        print(f'{\"*\"*100}')\n",
    "\n",
    "        # Tabulate Area with wetlands grid and watersheds\n",
    "        tabarea_start4 = time.time()\n",
    "        print(f'Begin tabulate intersection between {wet_rast} and watersheds in {roi} region')\n",
    "        print(f'{\"*\"*100}')\n",
    "        # Wetlands tabulate area for watersheds\n",
    "        wtd_per_wet_tabarea = arcpy.sa.TabulateArea(in_zone_data= wtd_merge,\n",
    "                                                      zone_field= wtd_cur_fields[0],\n",
    "                                                      in_class_data=wet_rast,\n",
    "                                                      class_field=\"Value\",\n",
    "                                                      out_table=wtd_merge_wetlands_table_path\n",
    "                                                      )\n",
    "        # Add region and percent wet fields\n",
    "        arcpy.AlterField_management(wtd_per_wet_tabarea,'CAT_ID_TXT','CAT_ID_TXT_DEL','CAT_ID_TXT_DEL')\n",
    "        arcpy.AddField_management(wtd_per_wet_tabarea, 'region', field_type='TEXT')\n",
    "        arcpy.AddField_management(wtd_per_wet_tabarea, 'NhdAwcH12_wtd_wet_per', field_type='Float')\n",
    "        arcpy.AddField_management(wtd_per_wet_tabarea, wtd_cur_fields[0], field_type='TEXT')\n",
    "        arcpy.AddField_management(wtd_per_wet_tabarea, wtd_cur_fields[2], field_type='TEXT')\n",
    "        wtdwetfields = [f.name for f in arcpy.ListFields(wtd_per_wet_tabarea)]\n",
    "        #print (wtdwetfields)\n",
    "        with arcpy.da.UpdateCursor(wtd_per_wet_tabarea, wtdwetfields) as cur:\n",
    "            for row in cur:\n",
    "                strval = str(row[1])\n",
    "                row[4] = roi\n",
    "                row[5] = row[3]/(row[3]+row[2])*100\n",
    "                row[6] = strval.replace('.0','')\n",
    "                row[7] = roi +'_'+ strval.replace(\".0\",\"\")\n",
    "                # Update\n",
    "                cur.updateRow(row)\n",
    "            del(row)\n",
    "        del(cur)\n",
    "        # Drop UPPERCASE field form tab area\n",
    "        arcpy.DeleteField_management(wtd_per_wet_tabarea,'CAT_ID_TXT_DEL')\n",
    "        # Append watershed percent wetlands table to list\n",
    "        wtd_wet_taba_tables.append(wtd_per_wet_tabarea)\n",
    "        # Report tab area times\n",
    "        tabarea_stop4 = time.time()\n",
    "        tabarea_time4 = int (tabarea_stop4 - tabarea_start4)\n",
    "        print(f'Percent Wetlands Tabulate area/intersections for {roi} complete.\\nElapsed time: ({datetime.timedelta(seconds=tabarea_time4)})')\n",
    "        print(f'{\"*\"*100}')\n",
    "\n",
    "        # # Percent North Tabulate Area for catchments\n",
    "        # cat_per_north_tabarea = arcpy.sa.TabulateArea(in_zone_data= cats, zone_field='cat_ID_con',\n",
    "        #                                             in_class_data=nor_rast,\"Value\",\n",
    "        #                                             out_table=cat_pernorth_table_path)\n",
    "\n",
    "        # # Add and calculate region identifier field for catchment table\n",
    "        # arcpy.AlterField_management(cat_per_north_tabarea,'CAT_ID_TXT','CAT_ID_TXT_DEL','CAT_ID_TXT_DEL')\n",
    "        # arcpy.AddField_management(cat_per_north_tabarea, 'region', field_type='TEXT')\n",
    "        # arcpy.AddField_management(cat_per_north_tabarea, 'cat_north_per', field_type='Float')\n",
    "        # arcpy.AddField_management(cat_per_north_tabarea, cat_cur_fields[0], field_type='TEXT')\n",
    "        # arcpy.AddField_management(cat_per_north_tabarea, cat_cur_fields[2], field_type='TEXT')\n",
    "        # catnorfields = [f.name for f in arcpy.ListFields(cat_per_north_tabarea)]\n",
    "        # print (catnorfields)\n",
    "        # with arcpy.da.UpdateCursor(cat_per_north_tabarea,catnorfields) as cur:\n",
    "        #     for row in cur:\n",
    "        #         strval = str(row[1])\n",
    "        #         row[4] = roi\n",
    "        #         row[5] = row[3]/(row[3]+row[2])*100\n",
    "        #         row[6] = strval.replace('.0','')\n",
    "        #         row[7] = roi +'_'+ strval.replace(\".0\",\"\")\n",
    "        #         # Update\n",
    "        #         cur.updateRow(row)\n",
    "        #     del(row)\n",
    "        # del(cur)\n",
    "        # Drop UPPERCASE field form tab area\n",
    "        # arcpy.DeleteField_management(cat_per_north_tabarea,'CAT_ID_TXT_DEL')\n",
    "        # # Append catchment percent north table to list\n",
    "        # cat_pernorth_taba_tables.append(cat_per_north_tabarea)\n",
    "        # Report tab area times\n",
    "        tabarea_stop = time.time()\n",
    "        tabarea_time = int (tabarea_stop - tabarea_start)\n",
    "        print(f'Tabulate area/intersections for {roi} complete\\nElapsed time: ({datetime.timedelta(seconds=tabarea_time)})')\n",
    "        print(f'{\"*\"*100}')\n",
    "\n",
    "        # Begin LCLD calculations\n",
    "        walk = arcpy.da.Walk(lcld_folder, datatype='RasterDataset')\n",
    "        for dirpath, dirnames, filenames in walk:\n",
    "            for filename in filenames:\n",
    "                raspath = os.path.join(dirpath, filename)\n",
    "                year = filename[0:4]\n",
    "                lcld_outname = roi+'NhdAwcH12_lcld_'+str(year)+'_zStats'\n",
    "                lcld_outpath = os.path.join(outgdb, lcld_outname)\n",
    "                print(f'Year: {year} - raster path {raspath}')\n",
    "                colname = 'NhdAwcH12_wtd_lcld_mn_' + str(year)\n",
    "                # lcld zonal statistics as table for all akssf watersheds\n",
    "                print(f'Calculating {filename} zonal stats for all {roi} watersheds...')\n",
    "                #arcpy.env.snapRaster = raspath\n",
    "                #arcpy.env.cellSize = raspath\n",
    "\n",
    "                # Begin Zonal Stats\n",
    "                lcldzstat_start = time.time()\n",
    "                print(f'Begin zonal stats for {filename}')\n",
    "                lcld_table = ZonalStatisticsAsTable(in_zone_data = wtd_merge,\n",
    "                                                                zone_field = 'cat_ID_con',\n",
    "                                                                in_value_raster = raspath,\n",
    "                                                                out_table = lcld_outpath,\n",
    "                                                                statistics_type='MEAN'\n",
    "                                                                )\n",
    "                # Append zTable to table list\n",
    "                lcld_Ztables.append(lcld_outpath)\n",
    "                arcpy.AlterField_management(lcld_table,'MEAN', colname,colname)\n",
    "                proc_list = [row[0] for row in arcpy.da.SearchCursor(lcld_table,'cat_ID_con')]\n",
    "                lcldzstat_stop = time.time()\n",
    "                lcldzstat_time = int (lcldzstat_stop - lcldzstat_start)\n",
    "                print(f'Zonal Stats for {filename} - Elapsed time: ({datetime.timedelta(seconds=lcldzstat_time)})')\n",
    "\n",
    "\n",
    "    except:\n",
    "        e = sys.exc_info()[1]\n",
    "        print(f'ERRFLAG!!! = {e.args[0]}')\n",
    "        arcpy.AddError(e.args[0])\n",
    "\n",
    "    iter_stop = time.time()\n",
    "    iter_time = int(iter_stop - iteration_start)\n",
    "    print(f'All Covariates for {roi} completed.\\nElapsed time: ({datetime.timedelta(seconds=iter_time)})')\n",
    "    print(f'{\"*\"*100}')\n",
    "\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "\n",
    "# Report success\n",
    "print(f'Process completed at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "      f'(Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print(f'{\"*\"*100}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Examine LCLD tables and merge/export\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lcld_2001_zStats\n",
      "lcld_2002_zStats\n",
      "lcld_2003_zStats\n",
      "lcld_2004_zStats\n",
      "lcld_2005_zStats\n",
      "lcld_2006_zStats\n",
      "lcld_2007_zStats\n",
      "lcld_2008_zStats\n",
      "lcld_2009_zStats\n",
      "lcld_2010_zStats\n",
      "lcld_2011_zStats\n",
      "lcld_2012_zStats\n",
      "lcld_2013_zStats\n",
      "lcld_2014_zStats\n",
      "lcld_2015_zStats\n",
      "lcld_2016_zStats\n",
      "lcld_2017_zStats\n",
      "lcld_2018_zStats\n",
      "lcld_2019_zStats\n",
      "lcld_2001_zStats\n",
      "lcld_2002_zStats\n",
      "lcld_2003_zStats\n",
      "lcld_2004_zStats\n",
      "lcld_2005_zStats\n",
      "lcld_2006_zStats\n",
      "lcld_2007_zStats\n",
      "lcld_2008_zStats\n",
      "lcld_2009_zStats\n",
      "lcld_2010_zStats\n",
      "lcld_2011_zStats\n",
      "lcld_2012_zStats\n",
      "lcld_2013_zStats\n",
      "lcld_2014_zStats\n",
      "lcld_2015_zStats\n",
      "lcld_2016_zStats\n",
      "lcld_2017_zStats\n",
      "lcld_2018_zStats\n",
      "lcld_2019_zStats\n",
      "lcld_2001_zStats\n",
      "lcld_2002_zStats\n",
      "lcld_2003_zStats\n",
      "lcld_2004_zStats\n",
      "lcld_2005_zStats\n",
      "lcld_2006_zStats\n",
      "lcld_2007_zStats\n",
      "lcld_2008_zStats\n",
      "lcld_2009_zStats\n",
      "lcld_2010_zStats\n",
      "lcld_2011_zStats\n",
      "lcld_2012_zStats\n",
      "lcld_2013_zStats\n",
      "lcld_2014_zStats\n",
      "lcld_2015_zStats\n",
      "lcld_2016_zStats\n",
      "lcld_2017_zStats\n",
      "lcld_2018_zStats\n",
      "lcld_2019_zStats\n"
     ]
    },
    {
     "data": {
      "text/plain": "                             NhdAwcH12_wtd_lcld_mn_2001_x  \\\ncat_ID_con                                                  \nPrince_William_Sound_3038                      508.555029   \nPrince_William_Sound_13227                     514.252371   \nPrince_William_Sound_17027                     515.999191   \nPrince_William_Sound_17697                     522.877156   \nPrince_William_Sound_18357                     518.928843   \n...                                                   ...   \nCopper_River_75003900029086                           NaN   \nCopper_River_75003900044552                           NaN   \nCopper_River_75003900054944                           NaN   \nCopper_River_75003900029096                           NaN   \nCopper_River_75003900047600                           NaN   \n\n                             NhdAwcH12_wtd_lcld_mn_2002_x  \\\ncat_ID_con                                                  \nPrince_William_Sound_3038                      508.128684   \nPrince_William_Sound_13227                     505.159319   \nPrince_William_Sound_17027                     517.335258   \nPrince_William_Sound_17697                     531.425302   \nPrince_William_Sound_18357                     519.123082   \n...                                                   ...   \nCopper_River_75003900029086                           NaN   \nCopper_River_75003900044552                           NaN   \nCopper_River_75003900054944                           NaN   \nCopper_River_75003900029096                           NaN   \nCopper_River_75003900047600                           NaN   \n\n                             NhdAwcH12_wtd_lcld_mn_2003_x  \\\ncat_ID_con                                                  \nPrince_William_Sound_3038                      463.393467   \nPrince_William_Sound_13227                     480.000000   \nPrince_William_Sound_17027                     471.393950   \nPrince_William_Sound_17697                     496.266759   \nPrince_William_Sound_18357                     479.084527   \n...                                                   ...   \nCopper_River_75003900029086                           NaN   \nCopper_River_75003900044552                           NaN   \nCopper_River_75003900054944                           NaN   \nCopper_River_75003900029096                           NaN   \nCopper_River_75003900047600                           NaN   \n\n                             NhdAwcH12_wtd_lcld_mn_2004_x  \\\ncat_ID_con                                                  \nPrince_William_Sound_3038                      500.807675   \nPrince_William_Sound_13227                     516.000000   \nPrince_William_Sound_17027                     509.214663   \nPrince_William_Sound_17697                     521.571098   \nPrince_William_Sound_18357                     511.788717   \n...                                                   ...   \nCopper_River_75003900029086                           NaN   \nCopper_River_75003900044552                           NaN   \nCopper_River_75003900054944                           NaN   \nCopper_River_75003900029096                           NaN   \nCopper_River_75003900047600                           NaN   \n\n                             NhdAwcH12_wtd_lcld_mn_2005_x  \\\ncat_ID_con                                                  \nPrince_William_Sound_3038                      476.085032   \nPrince_William_Sound_13227                     487.000000   \nPrince_William_Sound_17027                     492.210631   \nPrince_William_Sound_17697                     501.987227   \nPrince_William_Sound_18357                     493.635879   \n...                                                   ...   \nCopper_River_75003900029086                           NaN   \nCopper_River_75003900044552                           NaN   \nCopper_River_75003900054944                           NaN   \nCopper_River_75003900029096                           NaN   \nCopper_River_75003900047600                           NaN   \n\n                             NhdAwcH12_wtd_lcld_mn_2006_x  \\\ncat_ID_con                                                  \nPrince_William_Sound_3038                      508.915857   \nPrince_William_Sound_13227                     511.800851   \nPrince_William_Sound_17027                     511.377111   \nPrince_William_Sound_17697                     520.330224   \nPrince_William_Sound_18357                     521.300112   \n...                                                   ...   \nCopper_River_75003900029086                           NaN   \nCopper_River_75003900044552                           NaN   \nCopper_River_75003900054944                           NaN   \nCopper_River_75003900029096                           NaN   \nCopper_River_75003900047600                           NaN   \n\n                             NhdAwcH12_wtd_lcld_mn_2007_x  \\\ncat_ID_con                                                  \nPrince_William_Sound_3038                      508.936782   \nPrince_William_Sound_13227                     511.383761   \nPrince_William_Sound_17027                     519.209941   \nPrince_William_Sound_17697                     533.479922   \nPrince_William_Sound_18357                     529.690076   \n...                                                   ...   \nCopper_River_75003900029086                           NaN   \nCopper_River_75003900044552                           NaN   \nCopper_River_75003900054944                           NaN   \nCopper_River_75003900029096                           NaN   \nCopper_River_75003900047600                           NaN   \n\n                             NhdAwcH12_wtd_lcld_mn_2008_x  \\\ncat_ID_con                                                  \nPrince_William_Sound_3038                      524.235347   \nPrince_William_Sound_13227                     513.995746   \nPrince_William_Sound_17027                     531.016164   \nPrince_William_Sound_17697                     554.323597   \nPrince_William_Sound_18357                     542.799450   \n...                                                   ...   \nCopper_River_75003900029086                           NaN   \nCopper_River_75003900044552                           NaN   \nCopper_River_75003900054944                           NaN   \nCopper_River_75003900029096                           NaN   \nCopper_River_75003900047600                           NaN   \n\n                             NhdAwcH12_wtd_lcld_mn_2009_x  \\\ncat_ID_con                                                  \nPrince_William_Sound_3038                      520.363026   \nPrince_William_Sound_13227                     520.000000   \nPrince_William_Sound_17027                     522.439286   \nPrince_William_Sound_17697                     545.339405   \nPrince_William_Sound_18357                     532.419252   \n...                                                   ...   \nCopper_River_75003900029086                           NaN   \nCopper_River_75003900044552                           NaN   \nCopper_River_75003900054944                           NaN   \nCopper_River_75003900029096                           NaN   \nCopper_River_75003900047600                           NaN   \n\n                             NhdAwcH12_wtd_lcld_mn_2010_x  ...  \\\ncat_ID_con                                                 ...   \nPrince_William_Sound_3038                      504.248257  ...   \nPrince_William_Sound_13227                     506.243233  ...   \nPrince_William_Sound_17027                     510.353149  ...   \nPrince_William_Sound_17697                     522.740585  ...   \nPrince_William_Sound_18357                     516.344181  ...   \n...                                                   ...  ...   \nCopper_River_75003900029086                           NaN  ...   \nCopper_River_75003900044552                           NaN  ...   \nCopper_River_75003900054944                           NaN  ...   \nCopper_River_75003900029096                           NaN  ...   \nCopper_River_75003900047600                           NaN  ...   \n\n                             NhdAwcH12_wtd_lcld_mn_2010  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                           NaN   \nPrince_William_Sound_13227                          NaN   \nPrince_William_Sound_17027                          NaN   \nPrince_William_Sound_17697                          NaN   \nPrince_William_Sound_18357                          NaN   \n...                                                 ...   \nCopper_River_75003900029086                  472.782352   \nCopper_River_75003900044552                  505.846055   \nCopper_River_75003900054944                  475.444300   \nCopper_River_75003900029096                  511.948393   \nCopper_River_75003900047600                  526.071806   \n\n                             NhdAwcH12_wtd_lcld_mn_2011  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                           NaN   \nPrince_William_Sound_13227                          NaN   \nPrince_William_Sound_17027                          NaN   \nPrince_William_Sound_17697                          NaN   \nPrince_William_Sound_18357                          NaN   \n...                                                 ...   \nCopper_River_75003900029086                  458.794501   \nCopper_River_75003900044552                  494.667803   \nCopper_River_75003900054944                  476.375077   \nCopper_River_75003900029096                  515.507792   \nCopper_River_75003900047600                  530.774082   \n\n                             NhdAwcH12_wtd_lcld_mn_2012  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                           NaN   \nPrince_William_Sound_13227                          NaN   \nPrince_William_Sound_17027                          NaN   \nPrince_William_Sound_17697                          NaN   \nPrince_William_Sound_18357                          NaN   \n...                                                 ...   \nCopper_River_75003900029086                  485.641902   \nCopper_River_75003900044552                  529.897337   \nCopper_River_75003900054944                  505.542194   \nCopper_River_75003900029096                  543.378319   \nCopper_River_75003900047600                  561.578317   \n\n                             NhdAwcH12_wtd_lcld_mn_2013  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                           NaN   \nPrince_William_Sound_13227                          NaN   \nPrince_William_Sound_17027                          NaN   \nPrince_William_Sound_17697                          NaN   \nPrince_William_Sound_18357                          NaN   \n...                                                 ...   \nCopper_River_75003900029086                  487.820103   \nCopper_River_75003900044552                  514.894985   \nCopper_River_75003900054944                  493.379799   \nCopper_River_75003900029096                  537.522651   \nCopper_River_75003900047600                  541.536563   \n\n                             NhdAwcH12_wtd_lcld_mn_2014  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                           NaN   \nPrince_William_Sound_13227                          NaN   \nPrince_William_Sound_17027                          NaN   \nPrince_William_Sound_17697                          NaN   \nPrince_William_Sound_18357                          NaN   \n...                                                 ...   \nCopper_River_75003900029086                  423.330805   \nCopper_River_75003900044552                  479.218491   \nCopper_River_75003900054944                  470.743883   \nCopper_River_75003900029096                  490.562411   \nCopper_River_75003900047600                  508.126298   \n\n                             NhdAwcH12_wtd_lcld_mn_2015  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                           NaN   \nPrince_William_Sound_13227                          NaN   \nPrince_William_Sound_17027                          NaN   \nPrince_William_Sound_17697                          NaN   \nPrince_William_Sound_18357                          NaN   \n...                                                 ...   \nCopper_River_75003900029086                  414.759543   \nCopper_River_75003900044552                  414.404403   \nCopper_River_75003900054944                  423.433889   \nCopper_River_75003900029096                  485.051815   \nCopper_River_75003900047600                  510.832255   \n\n                             NhdAwcH12_wtd_lcld_mn_2016  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                           NaN   \nPrince_William_Sound_13227                          NaN   \nPrince_William_Sound_17027                          NaN   \nPrince_William_Sound_17697                          NaN   \nPrince_William_Sound_18357                          NaN   \n...                                                 ...   \nCopper_River_75003900029086                  410.158446   \nCopper_River_75003900044552                  425.842085   \nCopper_River_75003900054944                  413.119983   \nCopper_River_75003900029096                  503.140669   \nCopper_River_75003900047600                  509.149879   \n\n                             NhdAwcH12_wtd_lcld_mn_2017  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                           NaN   \nPrince_William_Sound_13227                          NaN   \nPrince_William_Sound_17027                          NaN   \nPrince_William_Sound_17697                          NaN   \nPrince_William_Sound_18357                          NaN   \n...                                                 ...   \nCopper_River_75003900029086                  470.742159   \nCopper_River_75003900044552                  496.148778   \nCopper_River_75003900054944                  478.510037   \nCopper_River_75003900029096                  508.203663   \nCopper_River_75003900047600                  517.992697   \n\n                             NhdAwcH12_wtd_lcld_mn_2018  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                           NaN   \nPrince_William_Sound_13227                          NaN   \nPrince_William_Sound_17027                          NaN   \nPrince_William_Sound_17697                          NaN   \nPrince_William_Sound_18357                          NaN   \n...                                                 ...   \nCopper_River_75003900029086                  451.558074   \nCopper_River_75003900044552                  491.614218   \nCopper_River_75003900054944                  472.765282   \nCopper_River_75003900029096                  500.313407   \nCopper_River_75003900047600                  528.987450   \n\n                             NhdAwcH12_wtd_lcld_mn_2019  \ncat_ID_con                                               \nPrince_William_Sound_3038                           NaN  \nPrince_William_Sound_13227                          NaN  \nPrince_William_Sound_17027                          NaN  \nPrince_William_Sound_17697                          NaN  \nPrince_William_Sound_18357                          NaN  \n...                                                 ...  \nCopper_River_75003900029086                  439.999561  \nCopper_River_75003900044552                  470.632806  \nCopper_River_75003900054944                  434.095321  \nCopper_River_75003900029096                  485.832311  \nCopper_River_75003900047600                  506.978774  \n\n[1018 rows x 57 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NhdAwcH12_wtd_lcld_mn_2001_x</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2002_x</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2003_x</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2004_x</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2005_x</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2006_x</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2007_x</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2008_x</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2009_x</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2010_x</th>\n      <th>...</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2010</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2011</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2012</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2013</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2014</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2015</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2016</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2017</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2018</th>\n      <th>NhdAwcH12_wtd_lcld_mn_2019</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Prince_William_Sound_3038</th>\n      <td>508.555029</td>\n      <td>508.128684</td>\n      <td>463.393467</td>\n      <td>500.807675</td>\n      <td>476.085032</td>\n      <td>508.915857</td>\n      <td>508.936782</td>\n      <td>524.235347</td>\n      <td>520.363026</td>\n      <td>504.248257</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_13227</th>\n      <td>514.252371</td>\n      <td>505.159319</td>\n      <td>480.000000</td>\n      <td>516.000000</td>\n      <td>487.000000</td>\n      <td>511.800851</td>\n      <td>511.383761</td>\n      <td>513.995746</td>\n      <td>520.000000</td>\n      <td>506.243233</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17027</th>\n      <td>515.999191</td>\n      <td>517.335258</td>\n      <td>471.393950</td>\n      <td>509.214663</td>\n      <td>492.210631</td>\n      <td>511.377111</td>\n      <td>519.209941</td>\n      <td>531.016164</td>\n      <td>522.439286</td>\n      <td>510.353149</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17697</th>\n      <td>522.877156</td>\n      <td>531.425302</td>\n      <td>496.266759</td>\n      <td>521.571098</td>\n      <td>501.987227</td>\n      <td>520.330224</td>\n      <td>533.479922</td>\n      <td>554.323597</td>\n      <td>545.339405</td>\n      <td>522.740585</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18357</th>\n      <td>518.928843</td>\n      <td>519.123082</td>\n      <td>479.084527</td>\n      <td>511.788717</td>\n      <td>493.635879</td>\n      <td>521.300112</td>\n      <td>529.690076</td>\n      <td>542.799450</td>\n      <td>532.419252</td>\n      <td>516.344181</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029086</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>472.782352</td>\n      <td>458.794501</td>\n      <td>485.641902</td>\n      <td>487.820103</td>\n      <td>423.330805</td>\n      <td>414.759543</td>\n      <td>410.158446</td>\n      <td>470.742159</td>\n      <td>451.558074</td>\n      <td>439.999561</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900044552</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>505.846055</td>\n      <td>494.667803</td>\n      <td>529.897337</td>\n      <td>514.894985</td>\n      <td>479.218491</td>\n      <td>414.404403</td>\n      <td>425.842085</td>\n      <td>496.148778</td>\n      <td>491.614218</td>\n      <td>470.632806</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900054944</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>475.444300</td>\n      <td>476.375077</td>\n      <td>505.542194</td>\n      <td>493.379799</td>\n      <td>470.743883</td>\n      <td>423.433889</td>\n      <td>413.119983</td>\n      <td>478.510037</td>\n      <td>472.765282</td>\n      <td>434.095321</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029096</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>511.948393</td>\n      <td>515.507792</td>\n      <td>543.378319</td>\n      <td>537.522651</td>\n      <td>490.562411</td>\n      <td>485.051815</td>\n      <td>503.140669</td>\n      <td>508.203663</td>\n      <td>500.313407</td>\n      <td>485.832311</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900047600</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>526.071806</td>\n      <td>530.774082</td>\n      <td>561.578317</td>\n      <td>541.536563</td>\n      <td>508.126298</td>\n      <td>510.832255</td>\n      <td>509.149879</td>\n      <td>517.992697</td>\n      <td>528.987450</td>\n      <td>506.978774</td>\n    </tr>\n  </tbody>\n</table>\n<p>1018 rows  57 columns</p>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for table in lcld_Ztables:\n",
    "    tblname = table[-16:]\n",
    "    print(tblname)\n",
    "    dfname = tblname + '_arr'\n",
    "    # Make df\n",
    "    dfname = pd.DataFrame()\n",
    "    lcld_field_list = []\n",
    "    for field in arcpy.ListFields(table):\n",
    "        lcld_field_list.append(field.name)\n",
    "        #print(f'{field.name}')\n",
    "    lcld_arr = arcpy.da.TableToNumPyArray(table, lcld_field_list)\n",
    "    dfname = pd.DataFrame(lcld_arr)\n",
    "    dfname = dfname.drop(['OBJECTID','ZONE_CODE', 'AREA', 'COUNT'],axis=1)\n",
    "    dfname = dfname.set_index('cat_ID_con')\n",
    "    dfs.append(dfname)\n",
    "\n",
    "# Merge all data frames together\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "lcld_df = reduce(lambda left,right: pd.merge(left,right,on='cat_ID_con',how=\"outer\"), dfs)\n",
    "lcld_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Export merged dataframe to csv\n",
    "lcld_csv_out = os.path.join(outdir,'AKSSF_AWC_HUC12_wtd_lcld_mn.csv')\n",
    "lcld_df.to_csv(lcld_csv_out, encoding = 'utf-8')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Drop unnecessary fields and rename as needed from merged tables.\n",
    "- Create Key value dictionary and use update cursor to rename fields."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables merged\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Table names/paths\n",
    "wtd_per_north_table_out = os.path.join(outgdb, 'AKSSF_awchuc12_wtd_north_per')\n",
    "cat_elev_table_out = os.path.join(outgdb,'AKSSF_awchuc12_cat_elev')\n",
    "cat_slope_table_out = os.path.join(outgdb,'AKSSF_awchuc12_cat_slope')\n",
    "wtd_elev_table_out = os.path.join(outgdb, 'AKSSF_awchuc12_wtd_elev')\n",
    "wtd_per_glac_table_out = os.path.join(outgdb, 'AKSSF_awchuc12_wtd_glacier_per')\n",
    "wtd_per_lp_table_out = os.path.join(outgdb, 'AKSSF_awchuc12_wtd_lakepond_per')\n",
    "wtd_slope_table_out = os.path.join(outgdb, 'AKSSF_awchuc12_wtd_slope')\n",
    "wtd_wet_table_out = os.path.join(outgdb, 'AKSSF_awchuc12_wtd_wetland_per')\n",
    "\n",
    "# Merge all regional tables together\n",
    "outtables = []\n",
    "wtd_per_north = arcpy.Merge_management(wtd_pernorth_taba_tables, wtd_per_north_table_out)\n",
    "arcpy.AlterField_management(wtd_per_north,\"VALUE_0\",\"AwcHuc12_non_north_area\",\"AwcHuc12_non_north_area\")\n",
    "arcpy.AlterField_management(wtd_per_north,\"VALUE_1\",\"AwcHuc12_north_area\",\"AwcHuc12_north_area\")\n",
    "outtables.append(wtd_per_north)\n",
    "cat_elev = arcpy.Merge_management(cat_elev_ztables, cat_elev_table_out)\n",
    "outtables.append(cat_elev)\n",
    "wtd_elev = arcpy.Merge_management(wtd_elev_ztables, wtd_elev_table_out)\n",
    "outtables.append(wtd_elev)\n",
    "wtd_slope = arcpy.Merge_management(wtd_slope_ztables, wtd_slope_table_out)\n",
    "outtables.append(wtd_slope)\n",
    "cat_slope = arcpy.Merge_management(cat_slope_ztables, cat_slope_table_out)\n",
    "outtables.append(cat_slope)\n",
    "wtd_wet = arcpy.Merge_management(wtd_wet_taba_tables, wtd_wet_table_out)\n",
    "arcpy.AlterField_management(wtd_wet,\"VALUE_0\",\"AwcHuc12_non_wetland_area\",\"AwcHuc12_non_wetland_area\")\n",
    "arcpy.AlterField_management(wtd_wet,\"VALUE_1\",\"AwcHuc12_wetland_area\",\"AwcHuc12_wetland_area\")\n",
    "outtables.append(wtd_wet)\n",
    "wtd_glac = arcpy.Merge_management(wtd_glac_tabint_tables, wtd_per_glac_table_out)\n",
    "outtables.append(wtd_glac)\n",
    "wtd_lp = arcpy.Merge_management(wtd_lp_tabint_tables, wtd_per_lp_table_out)\n",
    "outtables.append(wtd_lp)\n",
    "print ('Tables merged')\n",
    "print('----------')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIN AwcHuc12_wtd_elev_MIN\n",
      "MAX AwcHuc12_wtd_elev_MAX\n",
      "MEAN AwcHuc12_wtd_elev_MEAN\n",
      "STD AwcHuc12_wtd_elev_STD\n",
      "ZONE_CODE AwcHuc12_cat_elev_ZONE_CODE\n",
      "COUNT AwcHuc12_cat_elev_COUNT\n",
      "AREA AwcHuc12_cat_elev_AREA\n",
      "MIN AwcHuc12_cat_elev_MIN\n",
      "MAX AwcHuc12_cat_elev_MAX\n",
      "RANGE AwcHuc12_cat_elev_RANGE\n",
      "MEAN AwcHuc12_cat_elev_MEAN\n",
      "STD AwcHuc12_cat_elev_STD\n",
      "SUM AwcHuc12_cat_elev_SUM\n",
      "VARIETY AwcHuc12_cat_elev_VARIETY\n",
      "MAJORITY AwcHuc12_cat_elev_MAJORITY\n",
      "MINORITY AwcHuc12_cat_elev_MINORITY\n",
      "MEDIAN AwcHuc12_cat_elev_MEDIAN\n",
      "PCT90 AwcHuc12_cat_elev_PCT90\n",
      "MIN AwcHuc12_wtd_slope_MIN\n",
      "MAX AwcHuc12_wtd_slope_MAX\n",
      "MEAN AwcHuc12_wtd_slope_MEAN\n",
      "STD AwcHuc12_wtd_slope_STD\n",
      "ZONE_CODE AwcHuc12_cat_slope_ZONE_CODE\n",
      "COUNT AwcHuc12_cat_slope_COUNT\n",
      "AREA AwcHuc12_cat_slope_AREA\n",
      "MIN AwcHuc12_cat_slope_MIN\n",
      "MAX AwcHuc12_cat_slope_MAX\n",
      "RANGE AwcHuc12_cat_slope_RANGE\n",
      "MEAN AwcHuc12_cat_slope_MEAN\n",
      "STD AwcHuc12_cat_slope_STD\n",
      "SUM AwcHuc12_cat_slope_SUM\n",
      "MEDIAN AwcHuc12_cat_slope_MEDIAN\n",
      "PCT90 AwcHuc12_cat_slope_PCT90\n"
     ]
    }
   ],
   "source": [
    "#Set up field dictionary\n",
    "elevDict = { 'ZONE_CODE': ('AwcHuc12_cat_elev_ZONE_CODE', 'AwcHuc12_wtd_elev_ZONE_CODE'),\n",
    "         'COUNT': ('AwcHuc12_cat_elev_COUNT', 'AwcHuc12_wtd_elev_COUNT'),\n",
    "          'AREA': ('AwcHuc12_cat_elev_AREA', 'AwcHuc12_wtd_elev_AREA'),\n",
    "          'MIN': ('AwcHuc12_cat_elev_MIN', 'AwcHuc12_wtd_elev_MIN'),\n",
    "          'MAX': ('AwcHuc12_cat_elev_MAX', 'AwcHuc12_wtd_elev_MAX'),\n",
    "          'RANGE': ('AwcHuc12_cat_elev_RANGE', 'AwcHuc12_wtd_elev_RANGE'),\n",
    "          'MEAN': ('AwcHuc12_cat_elev_MEAN', 'AwcHuc12_wtd_elev_MEAN'),\n",
    "          'STD': ('AwcHuc12_cat_elev_STD', 'AwcHuc12_wtd_elev_STD'),\n",
    "          'SUM': ('AwcHuc12_cat_elev_SUM', 'AwcHuc12_wtd_elev_SUM'),\n",
    "          'VARIETY': ('AwcHuc12_cat_elev_VARIETY', 'AwcHuc12_wtd_elev_VARIETY'),\n",
    "          'MAJORITY': ('AwcHuc12_cat_elev_MAJORITY', 'AwcHuc12_wtd_elev_MAJORITY'),\n",
    "          'MINORITY': ('AwcHuc12_cat_elev_MINORITY', 'AwcHuc12_wtd_elev_MINORITY'),\n",
    "          'MEDIAN': ('AwcHuc12_cat_elev_MEDIAN', 'AwcHuc12_wtd_elev_MEDIAN'),\n",
    "          'PCT90': ('AwcHuc12_cat_elev_PCT90', 'AwcHuc12_wtd_elev_PCT90')\n",
    "         }\n",
    "\n",
    "slopeDict = { 'ZONE_CODE': ('AwcHuc12_cat_slope_ZONE_CODE', 'AwcHuc12_wtd_slope_ZONE_CODE'),\n",
    "         'COUNT': ('AwcHuc12_cat_slope_COUNT', 'AwcHuc12_wtd_slope_COUNT'),\n",
    "          'AREA': ('AwcHuc12_cat_slope_AREA', 'AwcHuc12_wtd_slope_AREA'),\n",
    "          'MIN': ('AwcHuc12_cat_slope_MIN', 'AwcHuc12_wtd_slope_MIN'),\n",
    "          'MAX': ('AwcHuc12_cat_slope_MAX', 'AwcHuc12_wtd_slope_MAX'),\n",
    "          'RANGE': ('AwcHuc12_cat_slope_RANGE', 'AwcHuc12_wtd_slope_RANGE'),\n",
    "          'MEAN': ('AwcHuc12_cat_slope_MEAN', 'AwcHuc12_wtd_slope_MEAN'),\n",
    "          'STD': ('AwcHuc12_cat_slope_STD', 'AwcHuc12_wtd_slope_STD'),\n",
    "          'SUM': ('AwcHuc12_cat_slope_SUM', 'AwcHuc12_wtd_slope_SUM'),\n",
    "          'VARIETY': ('AwcHuc12_cat_slope_VARIETY', 'AwcHuc12_wtd_slope_VARIETY'),\n",
    "          'MAJORITY': ('AwcHuc12_cat_slope_MAJORITY', 'AwcHuc12_wtd_slope_MAJORITY'),\n",
    "          'MINORITY': ('AwcHuc12_cat_slope_MINORITY', 'AwcHuc12_wtd_slope_MINORITY'),\n",
    "          'MEDIAN': ('AwcHuc12_cat_slope_MEDIAN', 'AwcHuc12_wtd_slope_MEDIAN'),\n",
    "          'PCT90': ('AwcHuc12_cat_slope_PCT90', 'AwcHuc12_wtd_slope_PCT90')\n",
    "         }\n",
    "\n",
    "# Rename fields for elevation tables\n",
    "for field in arcpy.ListFields(wtd_elev):\n",
    "    keyval = field.name\n",
    "    if keyval in elevDict:\n",
    "        newname = elevDict[keyval][1]\n",
    "        newalias = elevDict[keyval][1]\n",
    "        print (keyval, newname)\n",
    "        arcpy.AlterField_management(wtd_elev, keyval, newname, newalias)\n",
    "\n",
    "for field in arcpy.ListFields(cat_elev):\n",
    "    keyval = field.name\n",
    "    if keyval in elevDict:\n",
    "        newname = elevDict[keyval][0]\n",
    "        newalias = elevDict[keyval][0]\n",
    "        print (keyval, newname)\n",
    "        arcpy.AlterField_management(cat_elev, keyval, newname, newalias)\n",
    "\n",
    "# Rename fields for slope tables\n",
    "for field in arcpy.ListFields(wtd_slope):\n",
    "    keyval = field.name\n",
    "    if keyval in slopeDict:\n",
    "        newname = slopeDict[keyval][1]\n",
    "        newalias = slopeDict[keyval][1]\n",
    "        print (keyval, newname)\n",
    "        arcpy.AlterField_management(wtd_slope, keyval, newname, newalias)\n",
    "\n",
    "for field in arcpy.ListFields(cat_slope):\n",
    "    keyval = field.name\n",
    "    if keyval in slopeDict:\n",
    "        newname = slopeDict[keyval][0]\n",
    "        newalias = slopeDict[keyval][0]\n",
    "        print (keyval, newname)\n",
    "        arcpy.AlterField_management(cat_slope, keyval, newname, newalias)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_awchuc12_wtd_north_per.csv\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_awchuc12_cat_elev.csv\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_awchuc12_wtd_elev.csv\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_awchuc12_wtd_slope.csv\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_awchuc12_cat_slope.csv\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_awchuc12_wtd_wetland_per.csv\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_awchuc12_wtd_glacier_per.csv\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_awchuc12_wtd_lakepond_per.csv\n"
     ]
    }
   ],
   "source": [
    "# # Export copies of dbf tables as csv\n",
    "for table in outtables:\n",
    "    tablename = arcpy.Describe(table).basename + \".csv\"\n",
    "    tablepath = os.path.join(outdir,tablename)\n",
    "    print( tablepath)\n",
    "    arcpy.conversion.TableToTable(table, outdir, tablename)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.2f}'.format # only display 2 decimal places\n",
    "# list to store covariate data frames\n",
    "dfs = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "                                 cat_ID_txt  AwcHuc12_cat_elev_COUNT  \\\ncat_ID_con                                                             \nPrince_William_Sound_3038              3038                  3448.00   \nPrince_William_Sound_13227            13227                   297.00   \nPrince_William_Sound_17027            17027                  4338.00   \nPrince_William_Sound_17697            17697                  2137.00   \nPrince_William_Sound_18357            18357                    80.00   \n...                                     ...                      ...   \nCopper_River_75003900029086  75003900029086                  1469.00   \nCopper_River_75003900044552  75003900044552                 11111.00   \nCopper_River_75003900054944  75003900054944                   121.00   \nCopper_River_75003900029096  75003900029096                     3.00   \nCopper_River_75003900047600  75003900047600                  1022.00   \n\n                             AwcHuc12_cat_elev_AREA  AwcHuc12_cat_elev_MIN  \\\ncat_ID_con                                                                   \nPrince_William_Sound_3038                 344800.00                      0   \nPrince_William_Sound_13227                 29700.00                      0   \nPrince_William_Sound_17027                433800.00                      0   \nPrince_William_Sound_17697                213700.00                      3   \nPrince_William_Sound_18357                  8000.00                      4   \n...                                             ...                    ...   \nCopper_River_75003900029086               146900.00                      2   \nCopper_River_75003900044552              1111100.00                      3   \nCopper_River_75003900054944                12100.00                      3   \nCopper_River_75003900029096                  300.00                      3   \nCopper_River_75003900047600               102200.00                     16   \n\n                             AwcHuc12_cat_elev_MAX  AwcHuc12_cat_elev_RANGE  \\\ncat_ID_con                                                                    \nPrince_William_Sound_3038                       96                       96   \nPrince_William_Sound_13227                      79                       79   \nPrince_William_Sound_17027                     208                      208   \nPrince_William_Sound_17697                     118                      115   \nPrince_William_Sound_18357                      12                        8   \n...                                            ...                      ...   \nCopper_River_75003900029086                      7                        5   \nCopper_River_75003900044552                    225                      222   \nCopper_River_75003900054944                      5                        2   \nCopper_River_75003900029096                      5                        2   \nCopper_River_75003900047600                    133                      117   \n\n                             AwcHuc12_cat_elev_MEAN  AwcHuc12_cat_elev_STD  \\\ncat_ID_con                                                                   \nPrince_William_Sound_3038                     10.59                  10.72   \nPrince_William_Sound_13227                    24.72                  12.92   \nPrince_William_Sound_17027                    70.89                  35.61   \nPrince_William_Sound_17697                    61.09                  29.40   \nPrince_William_Sound_18357                     6.31                   1.91   \n...                                             ...                    ...   \nCopper_River_75003900029086                    3.88                   0.89   \nCopper_River_75003900044552                   75.24                  57.47   \nCopper_River_75003900054944                    4.11                   0.79   \nCopper_River_75003900029096                    3.67                   0.94   \nCopper_River_75003900047600                   51.84                  34.99   \n\n                             AwcHuc12_cat_elev_SUM  AwcHuc12_cat_elev_VARIETY  \\\ncat_ID_con                                                                      \nPrince_William_Sound_3038                 36518.00                         93   \nPrince_William_Sound_13227                 7342.00                         60   \nPrince_William_Sound_17027               307536.00                        201   \nPrince_William_Sound_17697               130546.00                        116   \nPrince_William_Sound_18357                  505.00                          9   \n...                                            ...                        ...   \nCopper_River_75003900029086                5696.00                          6   \nCopper_River_75003900044552              836045.00                        223   \nCopper_River_75003900054944                 497.00                          3   \nCopper_River_75003900029096                  11.00                          2   \nCopper_River_75003900047600               52985.00                        115   \n\n                             AwcHuc12_cat_elev_MAJORITY  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                             5   \nPrince_William_Sound_13227                           14   \nPrince_William_Sound_17027                           48   \nPrince_William_Sound_17697                            3   \nPrince_William_Sound_18357                            5   \n...                                                 ...   \nCopper_River_75003900029086                           4   \nCopper_River_75003900044552                           5   \nCopper_River_75003900054944                           5   \nCopper_River_75003900029096                           3   \nCopper_River_75003900047600                          18   \n\n                             AwcHuc12_cat_elev_MINORITY  \\\ncat_ID_con                                                \nPrince_William_Sound_3038                            27   \nPrince_William_Sound_13227                            1   \nPrince_William_Sound_17027                            0   \nPrince_William_Sound_17697                           25   \nPrince_William_Sound_18357                           12   \n...                                                 ...   \nCopper_River_75003900029086                           7   \nCopper_River_75003900044552                         225   \nCopper_River_75003900054944                           3   \nCopper_River_75003900029096                           5   \nCopper_River_75003900047600                          53   \n\n                             AwcHuc12_cat_elev_MEDIAN  \\\ncat_ID_con                                              \nPrince_William_Sound_3038                           8   \nPrince_William_Sound_13227                         22   \nPrince_William_Sound_17027                         61   \nPrince_William_Sound_17697                         60   \nPrince_William_Sound_18357                          5   \n...                                               ...   \nCopper_River_75003900029086                         4   \nCopper_River_75003900044552                        59   \nCopper_River_75003900054944                         4   \nCopper_River_75003900029096                         3   \nCopper_River_75003900047600                        35   \n\n                             AwcHuc12_cat_elev_PCT90                region  \ncat_ID_con                                                                  \nPrince_William_Sound_3038                         17  Prince_William_Sound  \nPrince_William_Sound_13227                        37  Prince_William_Sound  \nPrince_William_Sound_17027                       119  Prince_William_Sound  \nPrince_William_Sound_17697                       101  Prince_William_Sound  \nPrince_William_Sound_18357                         9  Prince_William_Sound  \n...                                              ...                   ...  \nCopper_River_75003900029086                        5          Copper_River  \nCopper_River_75003900044552                      153          Copper_River  \nCopper_River_75003900054944                        5          Copper_River  \nCopper_River_75003900029096                        5          Copper_River  \nCopper_River_75003900047600                      104          Copper_River  \n\n[1018 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat_ID_txt</th>\n      <th>AwcHuc12_cat_elev_COUNT</th>\n      <th>AwcHuc12_cat_elev_AREA</th>\n      <th>AwcHuc12_cat_elev_MIN</th>\n      <th>AwcHuc12_cat_elev_MAX</th>\n      <th>AwcHuc12_cat_elev_RANGE</th>\n      <th>AwcHuc12_cat_elev_MEAN</th>\n      <th>AwcHuc12_cat_elev_STD</th>\n      <th>AwcHuc12_cat_elev_SUM</th>\n      <th>AwcHuc12_cat_elev_VARIETY</th>\n      <th>AwcHuc12_cat_elev_MAJORITY</th>\n      <th>AwcHuc12_cat_elev_MINORITY</th>\n      <th>AwcHuc12_cat_elev_MEDIAN</th>\n      <th>AwcHuc12_cat_elev_PCT90</th>\n      <th>region</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Prince_William_Sound_3038</th>\n      <td>3038</td>\n      <td>3448.00</td>\n      <td>344800.00</td>\n      <td>0</td>\n      <td>96</td>\n      <td>96</td>\n      <td>10.59</td>\n      <td>10.72</td>\n      <td>36518.00</td>\n      <td>93</td>\n      <td>5</td>\n      <td>27</td>\n      <td>8</td>\n      <td>17</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_13227</th>\n      <td>13227</td>\n      <td>297.00</td>\n      <td>29700.00</td>\n      <td>0</td>\n      <td>79</td>\n      <td>79</td>\n      <td>24.72</td>\n      <td>12.92</td>\n      <td>7342.00</td>\n      <td>60</td>\n      <td>14</td>\n      <td>1</td>\n      <td>22</td>\n      <td>37</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17027</th>\n      <td>17027</td>\n      <td>4338.00</td>\n      <td>433800.00</td>\n      <td>0</td>\n      <td>208</td>\n      <td>208</td>\n      <td>70.89</td>\n      <td>35.61</td>\n      <td>307536.00</td>\n      <td>201</td>\n      <td>48</td>\n      <td>0</td>\n      <td>61</td>\n      <td>119</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17697</th>\n      <td>17697</td>\n      <td>2137.00</td>\n      <td>213700.00</td>\n      <td>3</td>\n      <td>118</td>\n      <td>115</td>\n      <td>61.09</td>\n      <td>29.40</td>\n      <td>130546.00</td>\n      <td>116</td>\n      <td>3</td>\n      <td>25</td>\n      <td>60</td>\n      <td>101</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18357</th>\n      <td>18357</td>\n      <td>80.00</td>\n      <td>8000.00</td>\n      <td>4</td>\n      <td>12</td>\n      <td>8</td>\n      <td>6.31</td>\n      <td>1.91</td>\n      <td>505.00</td>\n      <td>9</td>\n      <td>5</td>\n      <td>12</td>\n      <td>5</td>\n      <td>9</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029086</th>\n      <td>75003900029086</td>\n      <td>1469.00</td>\n      <td>146900.00</td>\n      <td>2</td>\n      <td>7</td>\n      <td>5</td>\n      <td>3.88</td>\n      <td>0.89</td>\n      <td>5696.00</td>\n      <td>6</td>\n      <td>4</td>\n      <td>7</td>\n      <td>4</td>\n      <td>5</td>\n      <td>Copper_River</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900044552</th>\n      <td>75003900044552</td>\n      <td>11111.00</td>\n      <td>1111100.00</td>\n      <td>3</td>\n      <td>225</td>\n      <td>222</td>\n      <td>75.24</td>\n      <td>57.47</td>\n      <td>836045.00</td>\n      <td>223</td>\n      <td>5</td>\n      <td>225</td>\n      <td>59</td>\n      <td>153</td>\n      <td>Copper_River</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900054944</th>\n      <td>75003900054944</td>\n      <td>121.00</td>\n      <td>12100.00</td>\n      <td>3</td>\n      <td>5</td>\n      <td>2</td>\n      <td>4.11</td>\n      <td>0.79</td>\n      <td>497.00</td>\n      <td>3</td>\n      <td>5</td>\n      <td>3</td>\n      <td>4</td>\n      <td>5</td>\n      <td>Copper_River</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029096</th>\n      <td>75003900029096</td>\n      <td>3.00</td>\n      <td>300.00</td>\n      <td>3</td>\n      <td>5</td>\n      <td>2</td>\n      <td>3.67</td>\n      <td>0.94</td>\n      <td>11.00</td>\n      <td>2</td>\n      <td>3</td>\n      <td>5</td>\n      <td>3</td>\n      <td>5</td>\n      <td>Copper_River</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900047600</th>\n      <td>75003900047600</td>\n      <td>1022.00</td>\n      <td>102200.00</td>\n      <td>16</td>\n      <td>133</td>\n      <td>117</td>\n      <td>51.84</td>\n      <td>34.99</td>\n      <td>52985.00</td>\n      <td>115</td>\n      <td>18</td>\n      <td>53</td>\n      <td>35</td>\n      <td>104</td>\n      <td>Copper_River</td>\n    </tr>\n  </tbody>\n</table>\n<p>1018 rows  15 columns</p>\n</div>"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make catchment elev df\n",
    "cat_df = pd.DataFrame()\n",
    "cat_field_list = []\n",
    "for field in arcpy.ListFields(cat_elev):\n",
    "    cat_field_list.append(field.name)\n",
    "cat_elev_arr = arcpy.da.TableToNumPyArray(cat_elev,cat_field_list)\n",
    "cat_df = pd.DataFrame(cat_elev_arr)\n",
    "cat_df = cat_df.drop([\"OBJECTID\",\"AwcHuc12_cat_elev_ZONE_CODE\"],axis=1)\n",
    "cat_df = cat_df.set_index('cat_ID_con')\n",
    "dfs.append(cat_df)\n",
    "cat_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "                                 cat_ID_txt  AwcHuc12_cat_slope_COUNT  \\\ncat_ID_con                                                              \nPrince_William_Sound_3038              3038                   3448.00   \nPrince_William_Sound_13227            13227                    297.00   \nPrince_William_Sound_17027            17027                   4338.00   \nPrince_William_Sound_17697            17697                   2137.00   \nPrince_William_Sound_18357            18357                     80.00   \n...                                     ...                       ...   \nCopper_River_75003900029086  75003900029086                   1469.00   \nCopper_River_75003900044552  75003900044552                  11111.00   \nCopper_River_75003900054944  75003900054944                    121.00   \nCopper_River_75003900029096  75003900029096                      3.00   \nCopper_River_75003900047600  75003900047600                   1022.00   \n\n                             AwcHuc12_cat_slope_AREA  AwcHuc12_cat_slope_MIN  \\\ncat_ID_con                                                                     \nPrince_William_Sound_3038                  344800.00                    0.00   \nPrince_William_Sound_13227                  29700.00                    0.00   \nPrince_William_Sound_17027                 433800.00                    0.00   \nPrince_William_Sound_17697                 213700.00                    0.00   \nPrince_William_Sound_18357                   8000.00                    0.00   \n...                                              ...                     ...   \nCopper_River_75003900029086                146900.00                    0.00   \nCopper_River_75003900044552               1111100.00                    0.00   \nCopper_River_75003900054944                 12100.00                    0.00   \nCopper_River_75003900029096                   300.00                    3.38   \nCopper_River_75003900047600                102200.00                    0.00   \n\n                             AwcHuc12_cat_slope_MAX  AwcHuc12_cat_slope_RANGE  \\\ncat_ID_con                                                                      \nPrince_William_Sound_3038                     24.19                     24.19   \nPrince_William_Sound_13227                    22.82                     22.82   \nPrince_William_Sound_17027                    37.53                     37.53   \nPrince_William_Sound_17697                    38.09                     38.09   \nPrince_William_Sound_18357                    11.41                     11.41   \n...                                             ...                       ...   \nCopper_River_75003900029086                    6.71                      6.71   \nCopper_River_75003900044552                   37.33                     37.33   \nCopper_River_75003900054944                    3.44                      3.44   \nCopper_River_75003900029096                    7.62                      4.23   \nCopper_River_75003900047600                   37.44                     37.44   \n\n                             AwcHuc12_cat_slope_MEAN  AwcHuc12_cat_slope_STD  \\\ncat_ID_con                                                                     \nPrince_William_Sound_3038                       5.34                    4.35   \nPrince_William_Sound_13227                      8.72                    3.92   \nPrince_William_Sound_17027                     11.51                    6.66   \nPrince_William_Sound_17697                     14.63                    7.43   \nPrince_William_Sound_18357                      3.54                    2.37   \n...                                              ...                     ...   \nCopper_River_75003900029086                     0.93                    1.49   \nCopper_River_75003900044552                    10.44                    8.06   \nCopper_River_75003900054944                     0.97                    1.32   \nCopper_River_75003900029096                     5.79                    1.78   \nCopper_River_75003900047600                    10.84                    6.88   \n\n                             AwcHuc12_cat_slope_SUM  \\\ncat_ID_con                                            \nPrince_William_Sound_3038                  18396.22   \nPrince_William_Sound_13227                  2589.60   \nPrince_William_Sound_17027                 49949.38   \nPrince_William_Sound_17697                 31268.21   \nPrince_William_Sound_18357                   282.92   \n...                                             ...   \nCopper_River_75003900029086                 1367.85   \nCopper_River_75003900044552               115974.51   \nCopper_River_75003900054944                  117.25   \nCopper_River_75003900029096                   17.37   \nCopper_River_75003900047600                11083.36   \n\n                             AwcHuc12_cat_slope_MEDIAN  \\\ncat_ID_con                                               \nPrince_William_Sound_3038                         4.04   \nPrince_William_Sound_13227                        8.50   \nPrince_William_Sound_17027                       10.36   \nPrince_William_Sound_17697                       14.78   \nPrince_William_Sound_18357                        3.20   \n...                                                ...   \nCopper_River_75003900029086                       0.00   \nCopper_River_75003900044552                       8.11   \nCopper_River_75003900054944                       0.00   \nCopper_River_75003900029096                       6.37   \nCopper_River_75003900047600                       9.58   \n\n                             AwcHuc12_cat_slope_PCT90                region  \ncat_ID_con                                                                   \nPrince_William_Sound_3038                       11.39  Prince_William_Sound  \nPrince_William_Sound_13227                      13.66  Prince_William_Sound  \nPrince_William_Sound_17027                      20.81  Prince_William_Sound  \nPrince_William_Sound_17697                      24.27  Prince_William_Sound  \nPrince_William_Sound_18357                       6.75  Prince_William_Sound  \n...                                               ...                   ...  \nCopper_River_75003900029086                      3.37          Copper_River  \nCopper_River_75003900044552                     22.92          Copper_River  \nCopper_River_75003900054944                      2.85          Copper_River  \nCopper_River_75003900029096                      7.37          Copper_River  \nCopper_River_75003900047600                     19.53          Copper_River  \n\n[1018 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat_ID_txt</th>\n      <th>AwcHuc12_cat_slope_COUNT</th>\n      <th>AwcHuc12_cat_slope_AREA</th>\n      <th>AwcHuc12_cat_slope_MIN</th>\n      <th>AwcHuc12_cat_slope_MAX</th>\n      <th>AwcHuc12_cat_slope_RANGE</th>\n      <th>AwcHuc12_cat_slope_MEAN</th>\n      <th>AwcHuc12_cat_slope_STD</th>\n      <th>AwcHuc12_cat_slope_SUM</th>\n      <th>AwcHuc12_cat_slope_MEDIAN</th>\n      <th>AwcHuc12_cat_slope_PCT90</th>\n      <th>region</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Prince_William_Sound_3038</th>\n      <td>3038</td>\n      <td>3448.00</td>\n      <td>344800.00</td>\n      <td>0.00</td>\n      <td>24.19</td>\n      <td>24.19</td>\n      <td>5.34</td>\n      <td>4.35</td>\n      <td>18396.22</td>\n      <td>4.04</td>\n      <td>11.39</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_13227</th>\n      <td>13227</td>\n      <td>297.00</td>\n      <td>29700.00</td>\n      <td>0.00</td>\n      <td>22.82</td>\n      <td>22.82</td>\n      <td>8.72</td>\n      <td>3.92</td>\n      <td>2589.60</td>\n      <td>8.50</td>\n      <td>13.66</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17027</th>\n      <td>17027</td>\n      <td>4338.00</td>\n      <td>433800.00</td>\n      <td>0.00</td>\n      <td>37.53</td>\n      <td>37.53</td>\n      <td>11.51</td>\n      <td>6.66</td>\n      <td>49949.38</td>\n      <td>10.36</td>\n      <td>20.81</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17697</th>\n      <td>17697</td>\n      <td>2137.00</td>\n      <td>213700.00</td>\n      <td>0.00</td>\n      <td>38.09</td>\n      <td>38.09</td>\n      <td>14.63</td>\n      <td>7.43</td>\n      <td>31268.21</td>\n      <td>14.78</td>\n      <td>24.27</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18357</th>\n      <td>18357</td>\n      <td>80.00</td>\n      <td>8000.00</td>\n      <td>0.00</td>\n      <td>11.41</td>\n      <td>11.41</td>\n      <td>3.54</td>\n      <td>2.37</td>\n      <td>282.92</td>\n      <td>3.20</td>\n      <td>6.75</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029086</th>\n      <td>75003900029086</td>\n      <td>1469.00</td>\n      <td>146900.00</td>\n      <td>0.00</td>\n      <td>6.71</td>\n      <td>6.71</td>\n      <td>0.93</td>\n      <td>1.49</td>\n      <td>1367.85</td>\n      <td>0.00</td>\n      <td>3.37</td>\n      <td>Copper_River</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900044552</th>\n      <td>75003900044552</td>\n      <td>11111.00</td>\n      <td>1111100.00</td>\n      <td>0.00</td>\n      <td>37.33</td>\n      <td>37.33</td>\n      <td>10.44</td>\n      <td>8.06</td>\n      <td>115974.51</td>\n      <td>8.11</td>\n      <td>22.92</td>\n      <td>Copper_River</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900054944</th>\n      <td>75003900054944</td>\n      <td>121.00</td>\n      <td>12100.00</td>\n      <td>0.00</td>\n      <td>3.44</td>\n      <td>3.44</td>\n      <td>0.97</td>\n      <td>1.32</td>\n      <td>117.25</td>\n      <td>0.00</td>\n      <td>2.85</td>\n      <td>Copper_River</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029096</th>\n      <td>75003900029096</td>\n      <td>3.00</td>\n      <td>300.00</td>\n      <td>3.38</td>\n      <td>7.62</td>\n      <td>4.23</td>\n      <td>5.79</td>\n      <td>1.78</td>\n      <td>17.37</td>\n      <td>6.37</td>\n      <td>7.37</td>\n      <td>Copper_River</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900047600</th>\n      <td>75003900047600</td>\n      <td>1022.00</td>\n      <td>102200.00</td>\n      <td>0.00</td>\n      <td>37.44</td>\n      <td>37.44</td>\n      <td>10.84</td>\n      <td>6.88</td>\n      <td>11083.36</td>\n      <td>9.58</td>\n      <td>19.53</td>\n      <td>Copper_River</td>\n    </tr>\n  </tbody>\n</table>\n<p>1018 rows  12 columns</p>\n</div>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make catchment slope df\n",
    "cat_sl_df = pd.DataFrame()\n",
    "cat_sl_field_list = []\n",
    "for field in arcpy.ListFields(cat_slope):\n",
    "    cat_sl_field_list.append(field.name)\n",
    "cat_sl_arr = arcpy.da.TableToNumPyArray(cat_slope, cat_sl_field_list)\n",
    "cat_sl_df = pd.DataFrame(cat_sl_arr)\n",
    "cat_sl_df = cat_sl_df.drop([\"OBJECTID\", \"AwcHuc12_cat_slope_ZONE_CODE\"],axis=1)\n",
    "cat_sl_df = cat_sl_df.set_index('cat_ID_con')\n",
    "dfs.append(cat_sl_df)\n",
    "cat_sl_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "                                       cat_ID      cat_ID_txt  \\\ncat_ID_con                                                      \nPrince_William_Sound_3038             3038.00            3038   \nPrince_William_Sound_13227           13227.00           13227   \nPrince_William_Sound_17027           17027.00           17027   \nPrince_William_Sound_17697           17697.00           17697   \nPrince_William_Sound_18357           18357.00           18357   \n...                                       ...             ...   \nCopper_River_75003900029086 75003900029086.00  75003900029086   \nCopper_River_75003900044552 75003900044552.00  75003900044552   \nCopper_River_75003900054944 75003900054944.00  75003900054944   \nCopper_River_75003900029096 75003900029096.00  75003900029096   \nCopper_River_75003900047600 75003900047600.00  75003900047600   \n\n                                           region  AwcHuc12_wtd_elev_MIN  \\\ncat_ID_con                                                                 \nPrince_William_Sound_3038    Prince_William_Sound                      0   \nPrince_William_Sound_13227   Prince_William_Sound                      0   \nPrince_William_Sound_17027   Prince_William_Sound                      0   \nPrince_William_Sound_17697   Prince_William_Sound                      3   \nPrince_William_Sound_18357   Prince_William_Sound                      2   \n...                                           ...                    ...   \nCopper_River_75003900029086          Copper_River                      0   \nCopper_River_75003900044552          Copper_River                      3   \nCopper_River_75003900054944          Copper_River                      3   \nCopper_River_75003900029096          Copper_River                      2   \nCopper_River_75003900047600          Copper_River                     16   \n\n                             AwcHuc12_wtd_elev_MAX  AwcHuc12_wtd_elev_MEAN  \\\ncat_ID_con                                                                   \nPrince_William_Sound_3038                      678                  201.13   \nPrince_William_Sound_13227                     580                  223.81   \nPrince_William_Sound_17027                     553                  206.91   \nPrince_William_Sound_17697                     692                  286.20   \nPrince_William_Sound_18357                     813                  264.07   \n...                                            ...                     ...   \nCopper_River_75003900029086                     20                    8.58   \nCopper_River_75003900044552                    527                  180.59   \nCopper_River_75003900054944                     66                    7.66   \nCopper_River_75003900029096                    984                  362.76   \nCopper_River_75003900047600                   1461                  618.83   \n\n                             AwcHuc12_wtd_elev_STD         NHDPlusID  \ncat_ID_con                                                            \nPrince_William_Sound_3038                   162.71               NaN  \nPrince_William_Sound_13227                  125.00               NaN  \nPrince_William_Sound_17027                  108.41               NaN  \nPrince_William_Sound_17697                  140.33               NaN  \nPrince_William_Sound_18357                  169.95               NaN  \n...                                            ...               ...  \nCopper_River_75003900029086                   3.16 75003900029086.00  \nCopper_River_75003900044552                 118.27 75003900044552.00  \nCopper_River_75003900054944                   6.13 75003900054944.00  \nCopper_River_75003900029096                 234.41 75003900029096.00  \nCopper_River_75003900047600                 314.66 75003900047600.00  \n\n[1018 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat_ID</th>\n      <th>cat_ID_txt</th>\n      <th>region</th>\n      <th>AwcHuc12_wtd_elev_MIN</th>\n      <th>AwcHuc12_wtd_elev_MAX</th>\n      <th>AwcHuc12_wtd_elev_MEAN</th>\n      <th>AwcHuc12_wtd_elev_STD</th>\n      <th>NHDPlusID</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Prince_William_Sound_3038</th>\n      <td>3038.00</td>\n      <td>3038</td>\n      <td>Prince_William_Sound</td>\n      <td>0</td>\n      <td>678</td>\n      <td>201.13</td>\n      <td>162.71</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_13227</th>\n      <td>13227.00</td>\n      <td>13227</td>\n      <td>Prince_William_Sound</td>\n      <td>0</td>\n      <td>580</td>\n      <td>223.81</td>\n      <td>125.00</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17027</th>\n      <td>17027.00</td>\n      <td>17027</td>\n      <td>Prince_William_Sound</td>\n      <td>0</td>\n      <td>553</td>\n      <td>206.91</td>\n      <td>108.41</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17697</th>\n      <td>17697.00</td>\n      <td>17697</td>\n      <td>Prince_William_Sound</td>\n      <td>3</td>\n      <td>692</td>\n      <td>286.20</td>\n      <td>140.33</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18357</th>\n      <td>18357.00</td>\n      <td>18357</td>\n      <td>Prince_William_Sound</td>\n      <td>2</td>\n      <td>813</td>\n      <td>264.07</td>\n      <td>169.95</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029086</th>\n      <td>75003900029086.00</td>\n      <td>75003900029086</td>\n      <td>Copper_River</td>\n      <td>0</td>\n      <td>20</td>\n      <td>8.58</td>\n      <td>3.16</td>\n      <td>75003900029086.00</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900044552</th>\n      <td>75003900044552.00</td>\n      <td>75003900044552</td>\n      <td>Copper_River</td>\n      <td>3</td>\n      <td>527</td>\n      <td>180.59</td>\n      <td>118.27</td>\n      <td>75003900044552.00</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900054944</th>\n      <td>75003900054944.00</td>\n      <td>75003900054944</td>\n      <td>Copper_River</td>\n      <td>3</td>\n      <td>66</td>\n      <td>7.66</td>\n      <td>6.13</td>\n      <td>75003900054944.00</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029096</th>\n      <td>75003900029096.00</td>\n      <td>75003900029096</td>\n      <td>Copper_River</td>\n      <td>2</td>\n      <td>984</td>\n      <td>362.76</td>\n      <td>234.41</td>\n      <td>75003900029096.00</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900047600</th>\n      <td>75003900047600.00</td>\n      <td>75003900047600</td>\n      <td>Copper_River</td>\n      <td>16</td>\n      <td>1461</td>\n      <td>618.83</td>\n      <td>314.66</td>\n      <td>75003900047600.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>1018 rows  8 columns</p>\n</div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make watershed elev df\n",
    "wtd_df = pd.DataFrame()\n",
    "wtd_field_list = []\n",
    "for field in arcpy.ListFields(wtd_elev):\n",
    "    wtd_field_list.append(field.name)\n",
    "wtd_elev_arr = arcpy.da.TableToNumPyArray(wtd_elev,wtd_field_list)\n",
    "wtd_df = pd.DataFrame(wtd_elev_arr)\n",
    "wtd_df = wtd_df.drop([\"OBJECTID\"],axis=1)\n",
    "wtd_df = wtd_df.set_index('cat_ID_con')\n",
    "dfs.append(wtd_df)\n",
    "wtd_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "                                       cat_ID      cat_ID_txt  \\\ncat_ID_con                                                      \nPrince_William_Sound_3038             3038.00            3038   \nPrince_William_Sound_13227           13227.00           13227   \nPrince_William_Sound_17027           17027.00           17027   \nPrince_William_Sound_17697           17697.00           17697   \nPrince_William_Sound_18357           18357.00           18357   \n...                                       ...             ...   \nCopper_River_75003900029086 75003900029086.00  75003900029086   \nCopper_River_75003900044552 75003900044552.00  75003900044552   \nCopper_River_75003900054944 75003900054944.00  75003900054944   \nCopper_River_75003900029096 75003900029096.00  75003900029096   \nCopper_River_75003900047600 75003900047600.00  75003900047600   \n\n                                           region  AwcHuc12_wtd_slope_MIN  \\\ncat_ID_con                                                                  \nPrince_William_Sound_3038    Prince_William_Sound                    0.00   \nPrince_William_Sound_13227   Prince_William_Sound                    0.00   \nPrince_William_Sound_17027   Prince_William_Sound                    0.00   \nPrince_William_Sound_17697   Prince_William_Sound                    0.00   \nPrince_William_Sound_18357   Prince_William_Sound                    0.00   \n...                                           ...                     ...   \nCopper_River_75003900029086          Copper_River                    0.00   \nCopper_River_75003900044552          Copper_River                    0.00   \nCopper_River_75003900054944          Copper_River                    0.00   \nCopper_River_75003900029096          Copper_River                    0.00   \nCopper_River_75003900047600          Copper_River                    0.00   \n\n                             AwcHuc12_wtd_slope_MAX  AwcHuc12_wtd_slope_MEAN  \\\ncat_ID_con                                                                     \nPrince_William_Sound_3038                     59.63                    15.49   \nPrince_William_Sound_13227                    57.61                    23.72   \nPrince_William_Sound_17027                    61.26                    15.85   \nPrince_William_Sound_17697                    63.16                    18.06   \nPrince_William_Sound_18357                    57.00                    20.20   \n...                                             ...                      ...   \nCopper_River_75003900029086                   16.20                     1.31   \nCopper_River_75003900044552                   55.48                    12.94   \nCopper_River_75003900054944                   26.16                     2.09   \nCopper_River_75003900029096                   74.22                    25.07   \nCopper_River_75003900047600                   75.85                    26.98   \n\n                             AwcHuc12_wtd_slope_STD         NHDPlusID  \ncat_ID_con                                                             \nPrince_William_Sound_3038                     11.44               NaN  \nPrince_William_Sound_13227                    10.73               NaN  \nPrince_William_Sound_17027                    10.88               NaN  \nPrince_William_Sound_17697                    11.76               NaN  \nPrince_William_Sound_18357                    11.88               NaN  \n...                                             ...               ...  \nCopper_River_75003900029086                    1.74 75003900029086.00  \nCopper_River_75003900044552                    8.59 75003900044552.00  \nCopper_River_75003900054944                    2.88 75003900054944.00  \nCopper_River_75003900029096                   14.59 75003900029096.00  \nCopper_River_75003900047600                   13.39 75003900047600.00  \n\n[1018 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat_ID</th>\n      <th>cat_ID_txt</th>\n      <th>region</th>\n      <th>AwcHuc12_wtd_slope_MIN</th>\n      <th>AwcHuc12_wtd_slope_MAX</th>\n      <th>AwcHuc12_wtd_slope_MEAN</th>\n      <th>AwcHuc12_wtd_slope_STD</th>\n      <th>NHDPlusID</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Prince_William_Sound_3038</th>\n      <td>3038.00</td>\n      <td>3038</td>\n      <td>Prince_William_Sound</td>\n      <td>0.00</td>\n      <td>59.63</td>\n      <td>15.49</td>\n      <td>11.44</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_13227</th>\n      <td>13227.00</td>\n      <td>13227</td>\n      <td>Prince_William_Sound</td>\n      <td>0.00</td>\n      <td>57.61</td>\n      <td>23.72</td>\n      <td>10.73</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17027</th>\n      <td>17027.00</td>\n      <td>17027</td>\n      <td>Prince_William_Sound</td>\n      <td>0.00</td>\n      <td>61.26</td>\n      <td>15.85</td>\n      <td>10.88</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17697</th>\n      <td>17697.00</td>\n      <td>17697</td>\n      <td>Prince_William_Sound</td>\n      <td>0.00</td>\n      <td>63.16</td>\n      <td>18.06</td>\n      <td>11.76</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18357</th>\n      <td>18357.00</td>\n      <td>18357</td>\n      <td>Prince_William_Sound</td>\n      <td>0.00</td>\n      <td>57.00</td>\n      <td>20.20</td>\n      <td>11.88</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029086</th>\n      <td>75003900029086.00</td>\n      <td>75003900029086</td>\n      <td>Copper_River</td>\n      <td>0.00</td>\n      <td>16.20</td>\n      <td>1.31</td>\n      <td>1.74</td>\n      <td>75003900029086.00</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900044552</th>\n      <td>75003900044552.00</td>\n      <td>75003900044552</td>\n      <td>Copper_River</td>\n      <td>0.00</td>\n      <td>55.48</td>\n      <td>12.94</td>\n      <td>8.59</td>\n      <td>75003900044552.00</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900054944</th>\n      <td>75003900054944.00</td>\n      <td>75003900054944</td>\n      <td>Copper_River</td>\n      <td>0.00</td>\n      <td>26.16</td>\n      <td>2.09</td>\n      <td>2.88</td>\n      <td>75003900054944.00</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029096</th>\n      <td>75003900029096.00</td>\n      <td>75003900029096</td>\n      <td>Copper_River</td>\n      <td>0.00</td>\n      <td>74.22</td>\n      <td>25.07</td>\n      <td>14.59</td>\n      <td>75003900029096.00</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900047600</th>\n      <td>75003900047600.00</td>\n      <td>75003900047600</td>\n      <td>Copper_River</td>\n      <td>0.00</td>\n      <td>75.85</td>\n      <td>26.98</td>\n      <td>13.39</td>\n      <td>75003900047600.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>1018 rows  8 columns</p>\n</div>"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make watershed slope df\n",
    "wtd_sl_df = pd.DataFrame()\n",
    "wtd_sl_field_list = []\n",
    "for field in arcpy.ListFields(wtd_slope):\n",
    "    wtd_sl_field_list.append(field.name)\n",
    "wtd_sl_arr = arcpy.da.TableToNumPyArray(wtd_slope, wtd_sl_field_list)\n",
    "wtd_sl_df = pd.DataFrame(wtd_sl_arr)\n",
    "wtd_sl_df = wtd_sl_df.drop([\"OBJECTID\"],axis=1)\n",
    "wtd_sl_df = wtd_sl_df.set_index('cat_ID_con')\n",
    "dfs.append(wtd_sl_df)\n",
    "wtd_sl_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "                             AwcHuc12_non_north_area  AwcHuc12_north_area  \\\ncat_ID_con                                                                  \nPrince_William_Sound_3038                24066600.00           8352000.00   \nPrince_William_Sound_13227                 679900.00            627900.00   \nPrince_William_Sound_17027                2596000.00           1163500.00   \nPrince_William_Sound_17697                6874200.00           2365900.00   \nPrince_William_Sound_18357               15359800.00           4876600.00   \n...                                              ...                  ...   \nCopper_River_75003900029086              17465000.00           1929700.00   \nCopper_River_75003900044552              10002100.00           2113300.00   \nCopper_River_75003900054944               7381300.00           1345600.00   \nCopper_River_75003900029096              14284800.00           3542200.00   \nCopper_River_75003900047600              42358100.00          12046500.00   \n\n                                           region  NhdAwcH12_wtd_north_per  \\\ncat_ID_con                                                                   \nPrince_William_Sound_3038    Prince_William_Sound                    25.76   \nPrince_William_Sound_13227   Prince_William_Sound                    48.01   \nPrince_William_Sound_17027   Prince_William_Sound                    30.95   \nPrince_William_Sound_17697   Prince_William_Sound                    25.60   \nPrince_William_Sound_18357   Prince_William_Sound                    24.10   \n...                                           ...                      ...   \nCopper_River_75003900029086          Copper_River                     9.95   \nCopper_River_75003900044552          Copper_River                    17.44   \nCopper_River_75003900054944          Copper_River                    15.42   \nCopper_River_75003900029096          Copper_River                    19.87   \nCopper_River_75003900047600          Copper_River                    22.14   \n\n                                 cat_ID_txt  \ncat_ID_con                                   \nPrince_William_Sound_3038              3038  \nPrince_William_Sound_13227            13227  \nPrince_William_Sound_17027            17027  \nPrince_William_Sound_17697            17697  \nPrince_William_Sound_18357            18357  \n...                                     ...  \nCopper_River_75003900029086  75003900029086  \nCopper_River_75003900044552  75003900044552  \nCopper_River_75003900054944  75003900054944  \nCopper_River_75003900029096  75003900029096  \nCopper_River_75003900047600  75003900047600  \n\n[1018 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AwcHuc12_non_north_area</th>\n      <th>AwcHuc12_north_area</th>\n      <th>region</th>\n      <th>NhdAwcH12_wtd_north_per</th>\n      <th>cat_ID_txt</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Prince_William_Sound_3038</th>\n      <td>24066600.00</td>\n      <td>8352000.00</td>\n      <td>Prince_William_Sound</td>\n      <td>25.76</td>\n      <td>3038</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_13227</th>\n      <td>679900.00</td>\n      <td>627900.00</td>\n      <td>Prince_William_Sound</td>\n      <td>48.01</td>\n      <td>13227</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17027</th>\n      <td>2596000.00</td>\n      <td>1163500.00</td>\n      <td>Prince_William_Sound</td>\n      <td>30.95</td>\n      <td>17027</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17697</th>\n      <td>6874200.00</td>\n      <td>2365900.00</td>\n      <td>Prince_William_Sound</td>\n      <td>25.60</td>\n      <td>17697</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18357</th>\n      <td>15359800.00</td>\n      <td>4876600.00</td>\n      <td>Prince_William_Sound</td>\n      <td>24.10</td>\n      <td>18357</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029086</th>\n      <td>17465000.00</td>\n      <td>1929700.00</td>\n      <td>Copper_River</td>\n      <td>9.95</td>\n      <td>75003900029086</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900044552</th>\n      <td>10002100.00</td>\n      <td>2113300.00</td>\n      <td>Copper_River</td>\n      <td>17.44</td>\n      <td>75003900044552</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900054944</th>\n      <td>7381300.00</td>\n      <td>1345600.00</td>\n      <td>Copper_River</td>\n      <td>15.42</td>\n      <td>75003900054944</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029096</th>\n      <td>14284800.00</td>\n      <td>3542200.00</td>\n      <td>Copper_River</td>\n      <td>19.87</td>\n      <td>75003900029096</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900047600</th>\n      <td>42358100.00</td>\n      <td>12046500.00</td>\n      <td>Copper_River</td>\n      <td>22.14</td>\n      <td>75003900047600</td>\n    </tr>\n  </tbody>\n</table>\n<p>1018 rows  5 columns</p>\n</div>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make watershed north df\n",
    "wtd_n_df = pd.DataFrame()\n",
    "wtd_n_field_list = []\n",
    "for field in arcpy.ListFields(wtd_per_north):\n",
    "    wtd_n_field_list.append(field.name)\n",
    "wtd_n_arr = arcpy.da.TableToNumPyArray(wtd_per_north,wtd_n_field_list)\n",
    "wtd_n_df = pd.DataFrame(wtd_n_arr)\n",
    "wtd_n_df = wtd_n_df.drop(\"OBJECTID\",axis=1)\n",
    "wtd_n_df = wtd_n_df.set_index('cat_ID_con')\n",
    "dfs.append(wtd_n_df)\n",
    "wtd_n_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "                             AwcHuc12_non_wetland_area  AwcHuc12_wetland_area  \\\ncat_ID_con                                                                      \nPrince_William_Sound_3038                  25232500.00             7186100.00   \nPrince_William_Sound_13227                  1298800.00                9000.00   \nPrince_William_Sound_17027                  3275800.00              483700.00   \nPrince_William_Sound_17697                  8549500.00              690600.00   \nPrince_William_Sound_18357                 19103600.00             1132800.00   \n...                                                ...                    ...   \nCopper_River_75003900029086                  318600.00            19076100.00   \nCopper_River_75003900044552                10373300.00             1742100.00   \nCopper_River_75003900054944                 5613800.00             3113100.00   \nCopper_River_75003900029096                17048200.00              778800.00   \nCopper_River_75003900047600                54245300.00              159300.00   \n\n                                           region  NhdAwcH12_wtd_wet_per  \\\ncat_ID_con                                                                 \nPrince_William_Sound_3038    Prince_William_Sound                  22.17   \nPrince_William_Sound_13227   Prince_William_Sound                   0.69   \nPrince_William_Sound_17027   Prince_William_Sound                  12.87   \nPrince_William_Sound_17697   Prince_William_Sound                   7.47   \nPrince_William_Sound_18357   Prince_William_Sound                   5.60   \n...                                           ...                    ...   \nCopper_River_75003900029086          Copper_River                  98.36   \nCopper_River_75003900044552          Copper_River                  14.38   \nCopper_River_75003900054944          Copper_River                  35.67   \nCopper_River_75003900029096          Copper_River                   4.37   \nCopper_River_75003900047600          Copper_River                   0.29   \n\n                                 cat_ID_txt  \ncat_ID_con                                   \nPrince_William_Sound_3038              3038  \nPrince_William_Sound_13227            13227  \nPrince_William_Sound_17027            17027  \nPrince_William_Sound_17697            17697  \nPrince_William_Sound_18357            18357  \n...                                     ...  \nCopper_River_75003900029086  75003900029086  \nCopper_River_75003900044552  75003900044552  \nCopper_River_75003900054944  75003900054944  \nCopper_River_75003900029096  75003900029096  \nCopper_River_75003900047600  75003900047600  \n\n[1018 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AwcHuc12_non_wetland_area</th>\n      <th>AwcHuc12_wetland_area</th>\n      <th>region</th>\n      <th>NhdAwcH12_wtd_wet_per</th>\n      <th>cat_ID_txt</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Prince_William_Sound_3038</th>\n      <td>25232500.00</td>\n      <td>7186100.00</td>\n      <td>Prince_William_Sound</td>\n      <td>22.17</td>\n      <td>3038</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_13227</th>\n      <td>1298800.00</td>\n      <td>9000.00</td>\n      <td>Prince_William_Sound</td>\n      <td>0.69</td>\n      <td>13227</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17027</th>\n      <td>3275800.00</td>\n      <td>483700.00</td>\n      <td>Prince_William_Sound</td>\n      <td>12.87</td>\n      <td>17027</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17697</th>\n      <td>8549500.00</td>\n      <td>690600.00</td>\n      <td>Prince_William_Sound</td>\n      <td>7.47</td>\n      <td>17697</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18357</th>\n      <td>19103600.00</td>\n      <td>1132800.00</td>\n      <td>Prince_William_Sound</td>\n      <td>5.60</td>\n      <td>18357</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029086</th>\n      <td>318600.00</td>\n      <td>19076100.00</td>\n      <td>Copper_River</td>\n      <td>98.36</td>\n      <td>75003900029086</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900044552</th>\n      <td>10373300.00</td>\n      <td>1742100.00</td>\n      <td>Copper_River</td>\n      <td>14.38</td>\n      <td>75003900044552</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900054944</th>\n      <td>5613800.00</td>\n      <td>3113100.00</td>\n      <td>Copper_River</td>\n      <td>35.67</td>\n      <td>75003900054944</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029096</th>\n      <td>17048200.00</td>\n      <td>778800.00</td>\n      <td>Copper_River</td>\n      <td>4.37</td>\n      <td>75003900029096</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900047600</th>\n      <td>54245300.00</td>\n      <td>159300.00</td>\n      <td>Copper_River</td>\n      <td>0.29</td>\n      <td>75003900047600</td>\n    </tr>\n  </tbody>\n</table>\n<p>1018 rows  5 columns</p>\n</div>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make watershed wetland df\n",
    "wtd_wet_df = pd.DataFrame()\n",
    "wtd_wet_field_list = []\n",
    "for field in arcpy.ListFields(wtd_wet):\n",
    "    wtd_wet_field_list.append(field.name)\n",
    "wtd_wet_arr = arcpy.da.TableToNumPyArray(wtd_wet,wtd_wet_field_list)\n",
    "wtd_wet_df = pd.DataFrame(wtd_wet_arr)\n",
    "wtd_wet_df = wtd_wet_df.drop(\"OBJECTID\",axis=1)\n",
    "wtd_wet_df = wtd_wet_df.set_index('cat_ID_con')\n",
    "dfs.append(wtd_wet_df)\n",
    "wtd_wet_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "                                 cat_ID_txt  FType  \\\ncat_ID_con                                           \nPrince_William_Sound_17027            17027    390   \nPrince_William_Sound_17697            17697    390   \nPrince_William_Sound_18357            18357    390   \nPrince_William_Sound_18547            18547    390   \nPrince_William_Sound_18737            18737    390   \n...                                     ...    ...   \nCopper_River_75019800020292  75019800020292    390   \nCopper_River_75019800020572  75019800020572    390   \nCopper_River_75019800020746  75019800020746    390   \nCopper_River_75019800020803  75019800020803    390   \nCopper_River_75019800020900  75019800020900    390   \n\n                             NhdAwcH12_wtd_lake_area_sqm  \\\ncat_ID_con                                                 \nPrince_William_Sound_17027                       5688.95   \nPrince_William_Sound_17697                      38507.61   \nPrince_William_Sound_18357                       6904.33   \nPrince_William_Sound_18547                      25771.29   \nPrince_William_Sound_18737                      90355.70   \n...                                                  ...   \nCopper_River_75019800020292                   1707529.72   \nCopper_River_75019800020572                   5727440.86   \nCopper_River_75019800020746                   7836889.55   \nCopper_River_75019800020803                   2748705.84   \nCopper_River_75019800020900                    615127.57   \n\n                             NhdAwcH12_wtd_lake_per                region  \\\ncat_ID_con                                                                  \nPrince_William_Sound_17027                     0.15  Prince_William_Sound   \nPrince_William_Sound_17697                     0.42  Prince_William_Sound   \nPrince_William_Sound_18357                     0.03  Prince_William_Sound   \nPrince_William_Sound_18547                     0.11  Prince_William_Sound   \nPrince_William_Sound_18737                     0.14  Prince_William_Sound   \n...                                             ...                   ...   \nCopper_River_75019800020292                    0.54          Copper_River   \nCopper_River_75019800020572                    0.61          Copper_River   \nCopper_River_75019800020746                    1.75          Copper_River   \nCopper_River_75019800020803                    5.04          Copper_River   \nCopper_River_75019800020900                    0.20          Copper_River   \n\n                                     cat_ID  \ncat_ID_con                                   \nPrince_William_Sound_17027            17027  \nPrince_William_Sound_17697            17697  \nPrince_William_Sound_18357            18357  \nPrince_William_Sound_18547            18547  \nPrince_William_Sound_18737            18737  \n...                                     ...  \nCopper_River_75019800020292  75019800020292  \nCopper_River_75019800020572  75019800020572  \nCopper_River_75019800020746  75019800020746  \nCopper_River_75019800020803  75019800020803  \nCopper_River_75019800020900  75019800020900  \n\n[967 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat_ID_txt</th>\n      <th>FType</th>\n      <th>NhdAwcH12_wtd_lake_area_sqm</th>\n      <th>NhdAwcH12_wtd_lake_per</th>\n      <th>region</th>\n      <th>cat_ID</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Prince_William_Sound_17027</th>\n      <td>17027</td>\n      <td>390</td>\n      <td>5688.95</td>\n      <td>0.15</td>\n      <td>Prince_William_Sound</td>\n      <td>17027</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17697</th>\n      <td>17697</td>\n      <td>390</td>\n      <td>38507.61</td>\n      <td>0.42</td>\n      <td>Prince_William_Sound</td>\n      <td>17697</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18357</th>\n      <td>18357</td>\n      <td>390</td>\n      <td>6904.33</td>\n      <td>0.03</td>\n      <td>Prince_William_Sound</td>\n      <td>18357</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18547</th>\n      <td>18547</td>\n      <td>390</td>\n      <td>25771.29</td>\n      <td>0.11</td>\n      <td>Prince_William_Sound</td>\n      <td>18547</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18737</th>\n      <td>18737</td>\n      <td>390</td>\n      <td>90355.70</td>\n      <td>0.14</td>\n      <td>Prince_William_Sound</td>\n      <td>18737</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75019800020292</th>\n      <td>75019800020292</td>\n      <td>390</td>\n      <td>1707529.72</td>\n      <td>0.54</td>\n      <td>Copper_River</td>\n      <td>75019800020292</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75019800020572</th>\n      <td>75019800020572</td>\n      <td>390</td>\n      <td>5727440.86</td>\n      <td>0.61</td>\n      <td>Copper_River</td>\n      <td>75019800020572</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75019800020746</th>\n      <td>75019800020746</td>\n      <td>390</td>\n      <td>7836889.55</td>\n      <td>1.75</td>\n      <td>Copper_River</td>\n      <td>75019800020746</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75019800020803</th>\n      <td>75019800020803</td>\n      <td>390</td>\n      <td>2748705.84</td>\n      <td>5.04</td>\n      <td>Copper_River</td>\n      <td>75019800020803</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75019800020900</th>\n      <td>75019800020900</td>\n      <td>390</td>\n      <td>615127.57</td>\n      <td>0.20</td>\n      <td>Copper_River</td>\n      <td>75019800020900</td>\n    </tr>\n  </tbody>\n</table>\n<p>967 rows  6 columns</p>\n</div>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make watershed lakes df\n",
    "wtd_lp_df = pd.DataFrame()\n",
    "wtd_lp_field_list = []\n",
    "for field in arcpy.ListFields(wtd_lp):\n",
    "    wtd_lp_field_list.append(field.name)\n",
    "wtd_lp_arr = arcpy.da.TableToNumPyArray(wtd_lp, wtd_lp_field_list)\n",
    "wtd_lp_df = pd.DataFrame(wtd_lp_arr)\n",
    "wtd_lp_df = wtd_lp_df.drop(\"OBJECTID\",axis=1)\n",
    "wtd_lp_df = wtd_lp_df.set_index('cat_ID_con')\n",
    "dfs.append(wtd_lp_df)\n",
    "wtd_lp_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "                                 cat_ID_txt O1Region  \\\ncat_ID_con                                             \nPrince_William_Sound_18357            18357        1   \nPrince_William_Sound_18547            18547        1   \nPrince_William_Sound_18737            18737        1   \nPrince_William_Sound_18747            18747        1   \nPrince_William_Sound_27856            27856        1   \n...                                     ...      ...   \nCopper_River_75019800018811  75019800018811        1   \nCopper_River_75019800019142  75019800019142        1   \nCopper_River_75019800019853  75019800019853        1   \nCopper_River_75019800020572  75019800020572        1   \nCopper_River_75019800020900  75019800020900        1   \n\n                             NhdAwcH12_wtd_glacier_area_sqm  \\\ncat_ID_con                                                    \nPrince_William_Sound_18357                        255413.00   \nPrince_William_Sound_18547                         83990.36   \nPrince_William_Sound_18737                        866494.65   \nPrince_William_Sound_18747                        866494.65   \nPrince_William_Sound_27856                        176024.99   \n...                                                     ...   \nCopper_River_75019800018811                    106387407.76   \nCopper_River_75019800019142                     12957496.80   \nCopper_River_75019800019853                     12957496.80   \nCopper_River_75019800020572                    107175106.24   \nCopper_River_75019800020900                      7039959.41   \n\n                             NhdAwcH12_wtd_glacier_per                region  \\\ncat_ID_con                                                                     \nPrince_William_Sound_18357                        1.26  Prince_William_Sound   \nPrince_William_Sound_18547                        0.35  Prince_William_Sound   \nPrince_William_Sound_18737                        1.34  Prince_William_Sound   \nPrince_William_Sound_18747                        1.33  Prince_William_Sound   \nPrince_William_Sound_27856                        3.75  Prince_William_Sound   \n...                                                ...                   ...   \nCopper_River_75019800018811                      22.21          Copper_River   \nCopper_River_75019800019142                       2.12          Copper_River   \nCopper_River_75019800019853                       4.51          Copper_River   \nCopper_River_75019800020572                      11.44          Copper_River   \nCopper_River_75019800020900                       2.28          Copper_River   \n\n                                     cat_ID  \ncat_ID_con                                   \nPrince_William_Sound_18357            18357  \nPrince_William_Sound_18547            18547  \nPrince_William_Sound_18737            18737  \nPrince_William_Sound_18747            18747  \nPrince_William_Sound_27856            27856  \n...                                     ...  \nCopper_River_75019800018811  75019800018811  \nCopper_River_75019800019142  75019800019142  \nCopper_River_75019800019853  75019800019853  \nCopper_River_75019800020572  75019800020572  \nCopper_River_75019800020900  75019800020900  \n\n[566 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat_ID_txt</th>\n      <th>O1Region</th>\n      <th>NhdAwcH12_wtd_glacier_area_sqm</th>\n      <th>NhdAwcH12_wtd_glacier_per</th>\n      <th>region</th>\n      <th>cat_ID</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Prince_William_Sound_18357</th>\n      <td>18357</td>\n      <td>1</td>\n      <td>255413.00</td>\n      <td>1.26</td>\n      <td>Prince_William_Sound</td>\n      <td>18357</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18547</th>\n      <td>18547</td>\n      <td>1</td>\n      <td>83990.36</td>\n      <td>0.35</td>\n      <td>Prince_William_Sound</td>\n      <td>18547</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18737</th>\n      <td>18737</td>\n      <td>1</td>\n      <td>866494.65</td>\n      <td>1.34</td>\n      <td>Prince_William_Sound</td>\n      <td>18737</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18747</th>\n      <td>18747</td>\n      <td>1</td>\n      <td>866494.65</td>\n      <td>1.33</td>\n      <td>Prince_William_Sound</td>\n      <td>18747</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_27856</th>\n      <td>27856</td>\n      <td>1</td>\n      <td>176024.99</td>\n      <td>3.75</td>\n      <td>Prince_William_Sound</td>\n      <td>27856</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75019800018811</th>\n      <td>75019800018811</td>\n      <td>1</td>\n      <td>106387407.76</td>\n      <td>22.21</td>\n      <td>Copper_River</td>\n      <td>75019800018811</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75019800019142</th>\n      <td>75019800019142</td>\n      <td>1</td>\n      <td>12957496.80</td>\n      <td>2.12</td>\n      <td>Copper_River</td>\n      <td>75019800019142</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75019800019853</th>\n      <td>75019800019853</td>\n      <td>1</td>\n      <td>12957496.80</td>\n      <td>4.51</td>\n      <td>Copper_River</td>\n      <td>75019800019853</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75019800020572</th>\n      <td>75019800020572</td>\n      <td>1</td>\n      <td>107175106.24</td>\n      <td>11.44</td>\n      <td>Copper_River</td>\n      <td>75019800020572</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75019800020900</th>\n      <td>75019800020900</td>\n      <td>1</td>\n      <td>7039959.41</td>\n      <td>2.28</td>\n      <td>Copper_River</td>\n      <td>75019800020900</td>\n    </tr>\n  </tbody>\n</table>\n<p>566 rows  6 columns</p>\n</div>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make watershed glacier df\n",
    "wtd_glac_df = pd.DataFrame()\n",
    "wtd_glac_field_list = []\n",
    "for field in arcpy.ListFields(wtd_glac):\n",
    "    wtd_glac_field_list.append(field.name)\n",
    "wtd_glac_arr = arcpy.da.TableToNumPyArray(wtd_glac, wtd_glac_field_list)\n",
    "wtd_glac_df = pd.DataFrame(wtd_glac_arr)\n",
    "wtd_glac_df = wtd_glac_df.drop(\"OBJECTID\",axis=1)\n",
    "wtd_glac_df = wtd_glac_df.set_index('cat_ID_con')\n",
    "dfs.append(wtd_glac_df)\n",
    "wtd_glac_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Merge all covariate dataframes together and drop unnecessary columns\n",
    " * Recalculate cat_ID as float64 type\n",
    " * Reorder columns\n",
    " * Export final csv\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "                                 cat_ID_txt            cat_ID  \\\ncat_ID_con                                                      \nPrince_William_Sound_3038              3038           3038.00   \nPrince_William_Sound_13227            13227          13227.00   \nPrince_William_Sound_17027            17027          17027.00   \nPrince_William_Sound_17697            17697          17697.00   \nPrince_William_Sound_18357            18357          18357.00   \n...                                     ...               ...   \nCopper_River_75003900029086  75003900029086 75003900029086.00   \nCopper_River_75003900044552  75003900044552 75003900044552.00   \nCopper_River_75003900054944  75003900054944 75003900054944.00   \nCopper_River_75003900029096  75003900029096 75003900029096.00   \nCopper_River_75003900047600  75003900047600 75003900047600.00   \n\n                                           region  AwcHuc12_cat_slope_COUNT  \\\ncat_ID_con                                                                    \nPrince_William_Sound_3038    Prince_William_Sound                   3448.00   \nPrince_William_Sound_13227   Prince_William_Sound                    297.00   \nPrince_William_Sound_17027   Prince_William_Sound                   4338.00   \nPrince_William_Sound_17697   Prince_William_Sound                   2137.00   \nPrince_William_Sound_18357   Prince_William_Sound                     80.00   \n...                                           ...                       ...   \nCopper_River_75003900029086          Copper_River                   1469.00   \nCopper_River_75003900044552          Copper_River                  11111.00   \nCopper_River_75003900054944          Copper_River                    121.00   \nCopper_River_75003900029096          Copper_River                      3.00   \nCopper_River_75003900047600          Copper_River                   1022.00   \n\n                             AwcHuc12_cat_slope_AREA  AwcHuc12_cat_slope_MIN  \\\ncat_ID_con                                                                     \nPrince_William_Sound_3038                  344800.00                    0.00   \nPrince_William_Sound_13227                  29700.00                    0.00   \nPrince_William_Sound_17027                 433800.00                    0.00   \nPrince_William_Sound_17697                 213700.00                    0.00   \nPrince_William_Sound_18357                   8000.00                    0.00   \n...                                              ...                     ...   \nCopper_River_75003900029086                146900.00                    0.00   \nCopper_River_75003900044552               1111100.00                    0.00   \nCopper_River_75003900054944                 12100.00                    0.00   \nCopper_River_75003900029096                   300.00                    3.38   \nCopper_River_75003900047600                102200.00                    0.00   \n\n                             AwcHuc12_cat_slope_MAX  AwcHuc12_cat_slope_RANGE  \\\ncat_ID_con                                                                      \nPrince_William_Sound_3038                     24.19                     24.19   \nPrince_William_Sound_13227                    22.82                     22.82   \nPrince_William_Sound_17027                    37.53                     37.53   \nPrince_William_Sound_17697                    38.09                     38.09   \nPrince_William_Sound_18357                    11.41                     11.41   \n...                                             ...                       ...   \nCopper_River_75003900029086                    6.71                      6.71   \nCopper_River_75003900044552                   37.33                     37.33   \nCopper_River_75003900054944                    3.44                      3.44   \nCopper_River_75003900029096                    7.62                      4.23   \nCopper_River_75003900047600                   37.44                     37.44   \n\n                             AwcHuc12_cat_slope_MEAN  AwcHuc12_cat_slope_STD  \\\ncat_ID_con                                                                     \nPrince_William_Sound_3038                       5.34                    4.35   \nPrince_William_Sound_13227                      8.72                    3.92   \nPrince_William_Sound_17027                     11.51                    6.66   \nPrince_William_Sound_17697                     14.63                    7.43   \nPrince_William_Sound_18357                      3.54                    2.37   \n...                                              ...                     ...   \nCopper_River_75003900029086                     0.93                    1.49   \nCopper_River_75003900044552                    10.44                    8.06   \nCopper_River_75003900054944                     0.97                    1.32   \nCopper_River_75003900029096                     5.79                    1.78   \nCopper_River_75003900047600                    10.84                    6.88   \n\n                             ...  AwcHuc12_non_north_area  \\\ncat_ID_con                   ...                            \nPrince_William_Sound_3038    ...              24066600.00   \nPrince_William_Sound_13227   ...                679900.00   \nPrince_William_Sound_17027   ...               2596000.00   \nPrince_William_Sound_17697   ...               6874200.00   \nPrince_William_Sound_18357   ...              15359800.00   \n...                          ...                      ...   \nCopper_River_75003900029086  ...              17465000.00   \nCopper_River_75003900044552  ...              10002100.00   \nCopper_River_75003900054944  ...               7381300.00   \nCopper_River_75003900029096  ...              14284800.00   \nCopper_River_75003900047600  ...              42358100.00   \n\n                             AwcHuc12_north_area  AwcHuc12_wtd_north_per  \\\ncat_ID_con                                                                 \nPrince_William_Sound_3038             8352000.00                     NaN   \nPrince_William_Sound_13227             627900.00                     NaN   \nPrince_William_Sound_17027            1163500.00                     NaN   \nPrince_William_Sound_17697            2365900.00                     NaN   \nPrince_William_Sound_18357            4876600.00                     NaN   \n...                                          ...                     ...   \nCopper_River_75003900029086           1929700.00                     NaN   \nCopper_River_75003900044552           2113300.00                     NaN   \nCopper_River_75003900054944           1345600.00                     NaN   \nCopper_River_75003900029096           3542200.00                     NaN   \nCopper_River_75003900047600          12046500.00                     NaN   \n\n                             non_wetland_area  AwcHuc12_wetland_area  \\\ncat_ID_con                                                             \nPrince_William_Sound_3038                 NaN             7186100.00   \nPrince_William_Sound_13227                NaN                9000.00   \nPrince_William_Sound_17027                NaN              483700.00   \nPrince_William_Sound_17697                NaN              690600.00   \nPrince_William_Sound_18357                NaN             1132800.00   \n...                                       ...                    ...   \nCopper_River_75003900029086               NaN            19076100.00   \nCopper_River_75003900044552               NaN             1742100.00   \nCopper_River_75003900054944               NaN             3113100.00   \nCopper_River_75003900029096               NaN              778800.00   \nCopper_River_75003900047600               NaN              159300.00   \n\n                             AwcHuc12_wtd_wet_per  AwcHuc12_wtd_lake_area_sqm  \\\ncat_ID_con                                                                      \nPrince_William_Sound_3038                     NaN                         NaN   \nPrince_William_Sound_13227                    NaN                         NaN   \nPrince_William_Sound_17027                    NaN                         NaN   \nPrince_William_Sound_17697                    NaN                         NaN   \nPrince_William_Sound_18357                    NaN                         NaN   \n...                                           ...                         ...   \nCopper_River_75003900029086                   NaN                         NaN   \nCopper_River_75003900044552                   NaN                         NaN   \nCopper_River_75003900054944                   NaN                         NaN   \nCopper_River_75003900029096                   NaN                         NaN   \nCopper_River_75003900047600                   NaN                         NaN   \n\n                             AwcHuc12_wtd_lake_per  \\\ncat_ID_con                                           \nPrince_William_Sound_3038                      NaN   \nPrince_William_Sound_13227                     NaN   \nPrince_William_Sound_17027                     NaN   \nPrince_William_Sound_17697                     NaN   \nPrince_William_Sound_18357                     NaN   \n...                                            ...   \nCopper_River_75003900029086                    NaN   \nCopper_River_75003900044552                    NaN   \nCopper_River_75003900054944                    NaN   \nCopper_River_75003900029096                    NaN   \nCopper_River_75003900047600                    NaN   \n\n                             AwcHuc12_wtd_glacier_area_sqm  \\\ncat_ID_con                                                   \nPrince_William_Sound_3038                              NaN   \nPrince_William_Sound_13227                             NaN   \nPrince_William_Sound_17027                             NaN   \nPrince_William_Sound_17697                             NaN   \nPrince_William_Sound_18357                             NaN   \n...                                                    ...   \nCopper_River_75003900029086                            NaN   \nCopper_River_75003900044552                            NaN   \nCopper_River_75003900054944                            NaN   \nCopper_River_75003900029096                            NaN   \nCopper_River_75003900047600                            NaN   \n\n                             AwcHuc12_wtd_glacier_per  \ncat_ID_con                                             \nPrince_William_Sound_3038                         NaN  \nPrince_William_Sound_13227                        NaN  \nPrince_William_Sound_17027                        NaN  \nPrince_William_Sound_17697                        NaN  \nPrince_William_Sound_18357                        NaN  \n...                                               ...  \nCopper_River_75003900029086                       NaN  \nCopper_River_75003900044552                       NaN  \nCopper_River_75003900054944                       NaN  \nCopper_River_75003900029096                       NaN  \nCopper_River_75003900047600                       NaN  \n\n[1018 rows x 44 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat_ID_txt</th>\n      <th>cat_ID</th>\n      <th>region</th>\n      <th>AwcHuc12_cat_slope_COUNT</th>\n      <th>AwcHuc12_cat_slope_AREA</th>\n      <th>AwcHuc12_cat_slope_MIN</th>\n      <th>AwcHuc12_cat_slope_MAX</th>\n      <th>AwcHuc12_cat_slope_RANGE</th>\n      <th>AwcHuc12_cat_slope_MEAN</th>\n      <th>AwcHuc12_cat_slope_STD</th>\n      <th>...</th>\n      <th>AwcHuc12_non_north_area</th>\n      <th>AwcHuc12_north_area</th>\n      <th>AwcHuc12_wtd_north_per</th>\n      <th>non_wetland_area</th>\n      <th>AwcHuc12_wetland_area</th>\n      <th>AwcHuc12_wtd_wet_per</th>\n      <th>AwcHuc12_wtd_lake_area_sqm</th>\n      <th>AwcHuc12_wtd_lake_per</th>\n      <th>AwcHuc12_wtd_glacier_area_sqm</th>\n      <th>AwcHuc12_wtd_glacier_per</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Prince_William_Sound_3038</th>\n      <td>3038</td>\n      <td>3038.00</td>\n      <td>Prince_William_Sound</td>\n      <td>3448.00</td>\n      <td>344800.00</td>\n      <td>0.00</td>\n      <td>24.19</td>\n      <td>24.19</td>\n      <td>5.34</td>\n      <td>4.35</td>\n      <td>...</td>\n      <td>24066600.00</td>\n      <td>8352000.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7186100.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_13227</th>\n      <td>13227</td>\n      <td>13227.00</td>\n      <td>Prince_William_Sound</td>\n      <td>297.00</td>\n      <td>29700.00</td>\n      <td>0.00</td>\n      <td>22.82</td>\n      <td>22.82</td>\n      <td>8.72</td>\n      <td>3.92</td>\n      <td>...</td>\n      <td>679900.00</td>\n      <td>627900.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9000.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17027</th>\n      <td>17027</td>\n      <td>17027.00</td>\n      <td>Prince_William_Sound</td>\n      <td>4338.00</td>\n      <td>433800.00</td>\n      <td>0.00</td>\n      <td>37.53</td>\n      <td>37.53</td>\n      <td>11.51</td>\n      <td>6.66</td>\n      <td>...</td>\n      <td>2596000.00</td>\n      <td>1163500.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>483700.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17697</th>\n      <td>17697</td>\n      <td>17697.00</td>\n      <td>Prince_William_Sound</td>\n      <td>2137.00</td>\n      <td>213700.00</td>\n      <td>0.00</td>\n      <td>38.09</td>\n      <td>38.09</td>\n      <td>14.63</td>\n      <td>7.43</td>\n      <td>...</td>\n      <td>6874200.00</td>\n      <td>2365900.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>690600.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18357</th>\n      <td>18357</td>\n      <td>18357.00</td>\n      <td>Prince_William_Sound</td>\n      <td>80.00</td>\n      <td>8000.00</td>\n      <td>0.00</td>\n      <td>11.41</td>\n      <td>11.41</td>\n      <td>3.54</td>\n      <td>2.37</td>\n      <td>...</td>\n      <td>15359800.00</td>\n      <td>4876600.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1132800.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029086</th>\n      <td>75003900029086</td>\n      <td>75003900029086.00</td>\n      <td>Copper_River</td>\n      <td>1469.00</td>\n      <td>146900.00</td>\n      <td>0.00</td>\n      <td>6.71</td>\n      <td>6.71</td>\n      <td>0.93</td>\n      <td>1.49</td>\n      <td>...</td>\n      <td>17465000.00</td>\n      <td>1929700.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>19076100.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900044552</th>\n      <td>75003900044552</td>\n      <td>75003900044552.00</td>\n      <td>Copper_River</td>\n      <td>11111.00</td>\n      <td>1111100.00</td>\n      <td>0.00</td>\n      <td>37.33</td>\n      <td>37.33</td>\n      <td>10.44</td>\n      <td>8.06</td>\n      <td>...</td>\n      <td>10002100.00</td>\n      <td>2113300.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1742100.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900054944</th>\n      <td>75003900054944</td>\n      <td>75003900054944.00</td>\n      <td>Copper_River</td>\n      <td>121.00</td>\n      <td>12100.00</td>\n      <td>0.00</td>\n      <td>3.44</td>\n      <td>3.44</td>\n      <td>0.97</td>\n      <td>1.32</td>\n      <td>...</td>\n      <td>7381300.00</td>\n      <td>1345600.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3113100.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029096</th>\n      <td>75003900029096</td>\n      <td>75003900029096.00</td>\n      <td>Copper_River</td>\n      <td>3.00</td>\n      <td>300.00</td>\n      <td>3.38</td>\n      <td>7.62</td>\n      <td>4.23</td>\n      <td>5.79</td>\n      <td>1.78</td>\n      <td>...</td>\n      <td>14284800.00</td>\n      <td>3542200.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>778800.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900047600</th>\n      <td>75003900047600</td>\n      <td>75003900047600.00</td>\n      <td>Copper_River</td>\n      <td>1022.00</td>\n      <td>102200.00</td>\n      <td>0.00</td>\n      <td>37.44</td>\n      <td>37.44</td>\n      <td>10.84</td>\n      <td>6.88</td>\n      <td>...</td>\n      <td>42358100.00</td>\n      <td>12046500.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>159300.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>1018 rows  44 columns</p>\n</div>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge all data frames together\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "df_final = reduce(lambda left,right: pd.merge(left,right,on='cat_ID_con',how=\"outer\"), dfs)\n",
    "#Generate unique column names\n",
    "def uniquify(df_final):\n",
    "    seen = set()\n",
    "    for item in df_final:\n",
    "        fudge = 1\n",
    "        newitem = item\n",
    "        while newitem in seen:\n",
    "            fudge += 1\n",
    "            newitem = \"{}_{}\".format(item, fudge)\n",
    "        yield newitem\n",
    "        seen.add(newitem)\n",
    "df_final.columns = list(uniquify(df_final))\n",
    "#List of final columns in the order to output\n",
    "# final_cols_old = ['cat_ID_txt','cat_ID','region', 'AwcHuc12_cat_slope_COUNT', 'AwcHuc12_cat_slope_AREA', 'AwcHuc12_cat_slope_MIN', 'AwcHuc12_cat_slope_MAX',\n",
    "#               'AwcHuc12_cat_slope_RANGE','AwcHuc12_cat_slope_MEAN', 'AwcHuc12_cat_slope_STD', 'AwcHuc12_cat_slope_SUM', 'AwcHuc12_cat_slope_MEDIAN', 'AwcHuc12_cat_slope_PCT90',\n",
    "#               'AwcHuc12_cat_elev_COUNT', 'AwcHuc12_cat_elev_AREA', 'AwcHuc12_cat_elev_MIN', 'AwcHuc12_cat_elev_MAX', 'AwcHuc12_cat_elev_RANGE', 'AwcHuc12_cat_elev_MEAN', 'AwcHuc12_cat_elev_STD',\n",
    "#               'AwcHuc12_cat_elev_SUM', 'AwcHuc12_cat_elev_VARIETY', 'AwcHuc12_cat_elev_MAJORITY', 'AwcHuc12_cat_elev_MINORITY', 'AwcHuc12_cat_elev_MEDIAN', 'AwcHuc12_cat_elev_PCT90',\n",
    "#               'AwcHuc12_wtd_elev_COUNT', 'AwcHuc12_wtd_elev_AREA', 'AwcHuc12_wtd_elev_MIN', 'AwcHuc12_wtd_elev_MAX', 'AwcHuc12_wtd_elev_RANGE', 'AwcHuc12_wtd_elev_MEAN',\n",
    "#               'AwcHuc12_wtd_elev_STD', 'AwcHuc12_wtd_elev_SUM', 'AwcHuc12_wtd_elev_VARIETY', 'AwcHuc12_wtd_elev_MAJORITY', 'AwcHuc12_wtd_elev_MINORITY',\n",
    "#               'AwcHuc12_wtd_elev_MEDIAN', 'AwcHuc12_wtd_elev_PCT90', 'AwcHuc12_wtd_slope_COUNT', 'AwcHuc12_wtd_slope_AREA', 'AwcHuc12_wtd_slope_MIN', 'AwcHuc12_wtd_slope_MAX',\n",
    "#               'AwcHuc12_wtd_slope_RANGE', 'AwcHuc12_wtd_slope_MEAN', 'AwcHuc12_wtd_slope_STD', 'AwcHuc12_wtd_slope_SUM', 'AwcHuc12_wtd_slope_MEDIAN', 'AwcHuc12_wtd_slope_PCT90',\n",
    "#               'AwcHuc12_non_north_area', 'AwcHuc12_north_area', 'AwcHuc12_wtd_north_per', 'non_wetland_area', 'AwcHuc12_wetland_area', 'AwcHuc12_wtd_wet_per',\n",
    "#               'AwcHuc12_wtd_lake_area_sqm', 'AwcHuc12_wtd_lake_per', 'AwcHuc12_wtd_glacier_area_sqm', 'AwcHuc12_wtd_glacier_per' ]\n",
    "final_cols = ['cat_ID_txt','cat_ID','region', 'AwcHuc12_cat_slope_COUNT', 'AwcHuc12_cat_slope_AREA', 'AwcHuc12_cat_slope_MIN', 'AwcHuc12_cat_slope_MAX',\n",
    "              'AwcHuc12_cat_slope_RANGE','AwcHuc12_cat_slope_MEAN', 'AwcHuc12_cat_slope_STD', 'AwcHuc12_cat_slope_SUM', 'AwcHuc12_cat_slope_MEDIAN', 'AwcHuc12_cat_slope_PCT90',\n",
    "              'AwcHuc12_cat_elev_COUNT', 'AwcHuc12_cat_elev_AREA', 'AwcHuc12_cat_elev_MIN', 'AwcHuc12_cat_elev_MAX', 'AwcHuc12_cat_elev_RANGE', 'AwcHuc12_cat_elev_MEAN', 'AwcHuc12_cat_elev_STD',\n",
    "              'AwcHuc12_cat_elev_SUM', 'AwcHuc12_cat_elev_VARIETY', 'AwcHuc12_cat_elev_MAJORITY', 'AwcHuc12_cat_elev_MINORITY', 'AwcHuc12_cat_elev_MEDIAN', 'AwcHuc12_cat_elev_PCT90',\n",
    "              'AwcHuc12_wtd_elev_MIN', 'AwcHuc12_wtd_elev_MAX','AwcHuc12_wtd_elev_MEAN','AwcHuc12_wtd_elev_STD','AwcHuc12_wtd_slope_MIN', 'AwcHuc12_wtd_slope_MAX','AwcHuc12_wtd_slope_MEAN',\n",
    "              'AwcHuc12_wtd_slope_STD','AwcHuc12_non_north_area', 'AwcHuc12_north_area', 'AwcHuc12_wtd_north_per', 'non_wetland_area', 'AwcHuc12_wetland_area', 'AwcHuc12_wtd_wet_per',\n",
    "              'AwcHuc12_wtd_lake_area_sqm', 'AwcHuc12_wtd_lake_per', 'AwcHuc12_wtd_glacier_area_sqm', 'AwcHuc12_wtd_glacier_per' ]\n",
    "\n",
    "#Create list of duplicate column names and drop\n",
    "drop_cols = ['cat_ID_txt_y', 'region_y', 'cat_ID_txt_x_2', 'region_x_2', 'region_y_2', 'cat_ID_txt_y_2', 'region_x_3',\n",
    "             'cat_ID_txt_x_3', 'cat_ID_txt_y_3', 'FType', 'region_y_3','cat_ID_txt_x_4', 'O1Region', 'region_x_4',\n",
    "             'cat_ID_y', 'cat_ID_txt_y_4', 'region_y_4']\n",
    "df_final.drop(columns=drop_cols, axis = 1, inplace=True)\n",
    "#rename columns\n",
    "df_final.rename({'cat_ID_txt_x':'cat_ID_txt','cat_ID_x':'cat_ID','region_x':'region'},axis=1, inplace=True)\n",
    "#Recalculate cat_ID\n",
    "df_final['cat_ID'] = df_final['cat_ID_txt'].astype(np.float64)\n",
    "# reorder cols\n",
    "df_final = df_final.reindex(columns=final_cols)\n",
    "df_final"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export all covariates dataframe to csv complete\n"
     ]
    }
   ],
   "source": [
    "# Export merged dataframe to csv\n",
    "cov_csv_out = os.path.join(outdir,'AKSSF_AWC_HUC12s_Covariates.csv')\n",
    "df_final.to_csv(cov_csv_out, encoding = 'utf-8')\n",
    "print('Export all covariates dataframe to csv complete')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# bbay_df = df_final.filter(like='Bristol_Bay', axis = 0)\n",
    "# bbay_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # kod_df = df_final.filter(like='Kodiak', axis = 0)\n",
    "# kod_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "                           cat_ID_txt   cat_ID                region  \\\ncat_ID_con                                                             \nPrince_William_Sound_3038        3038  3038.00  Prince_William_Sound   \nPrince_William_Sound_13227      13227 13227.00  Prince_William_Sound   \nPrince_William_Sound_17027      17027 17027.00  Prince_William_Sound   \nPrince_William_Sound_17697      17697 17697.00  Prince_William_Sound   \nPrince_William_Sound_18357      18357 18357.00  Prince_William_Sound   \n...                               ...      ...                   ...   \nPrince_William_Sound_91741      91741 91741.00  Prince_William_Sound   \nPrince_William_Sound_91751      91751 91751.00  Prince_William_Sound   \nPrince_William_Sound_91921      91921 91921.00  Prince_William_Sound   \nPrince_William_Sound_92151      92151 92151.00  Prince_William_Sound   \nPrince_William_Sound_93261      93261 93261.00  Prince_William_Sound   \n\n                            AwcHuc12_cat_slope_COUNT  AwcHuc12_cat_slope_AREA  \\\ncat_ID_con                                                                      \nPrince_William_Sound_3038                    3448.00                344800.00   \nPrince_William_Sound_13227                    297.00                 29700.00   \nPrince_William_Sound_17027                   4338.00                433800.00   \nPrince_William_Sound_17697                   2137.00                213700.00   \nPrince_William_Sound_18357                     80.00                  8000.00   \n...                                              ...                      ...   \nPrince_William_Sound_91741                   1649.00                164900.00   \nPrince_William_Sound_91751                    385.00                 38500.00   \nPrince_William_Sound_91921                    709.00                 70900.00   \nPrince_William_Sound_92151                   1305.00                130500.00   \nPrince_William_Sound_93261                   1119.00                111900.00   \n\n                            AwcHuc12_cat_slope_MIN  AwcHuc12_cat_slope_MAX  \\\ncat_ID_con                                                                   \nPrince_William_Sound_3038                     0.00                   24.19   \nPrince_William_Sound_13227                    0.00                   22.82   \nPrince_William_Sound_17027                    0.00                   37.53   \nPrince_William_Sound_17697                    0.00                   38.09   \nPrince_William_Sound_18357                    0.00                   11.41   \n...                                            ...                     ...   \nPrince_William_Sound_91741                    0.00                   27.10   \nPrince_William_Sound_91751                    0.00                    8.76   \nPrince_William_Sound_91921                    0.00                    5.73   \nPrince_William_Sound_92151                    0.00                   13.27   \nPrince_William_Sound_93261                    0.00                   25.31   \n\n                            AwcHuc12_cat_slope_RANGE  AwcHuc12_cat_slope_MEAN  \\\ncat_ID_con                                                                      \nPrince_William_Sound_3038                      24.19                     5.34   \nPrince_William_Sound_13227                     22.82                     8.72   \nPrince_William_Sound_17027                     37.53                    11.51   \nPrince_William_Sound_17697                     38.09                    14.63   \nPrince_William_Sound_18357                     11.41                     3.54   \n...                                              ...                      ...   \nPrince_William_Sound_91741                     27.10                     5.03   \nPrince_William_Sound_91751                      8.76                     2.23   \nPrince_William_Sound_91921                      5.73                     1.04   \nPrince_William_Sound_92151                     13.27                     3.13   \nPrince_William_Sound_93261                     25.31                     6.02   \n\n                            AwcHuc12_cat_slope_STD  ...  \\\ncat_ID_con                                          ...   \nPrince_William_Sound_3038                     4.35  ...   \nPrince_William_Sound_13227                    3.92  ...   \nPrince_William_Sound_17027                    6.66  ...   \nPrince_William_Sound_17697                    7.43  ...   \nPrince_William_Sound_18357                    2.37  ...   \n...                                            ...  ...   \nPrince_William_Sound_91741                    4.59  ...   \nPrince_William_Sound_91751                    2.14  ...   \nPrince_William_Sound_91921                    1.38  ...   \nPrince_William_Sound_92151                    3.67  ...   \nPrince_William_Sound_93261                    5.51  ...   \n\n                            AwcHuc12_non_north_area  AwcHuc12_north_area  \\\ncat_ID_con                                                                 \nPrince_William_Sound_3038               24066600.00           8352000.00   \nPrince_William_Sound_13227                679900.00            627900.00   \nPrince_William_Sound_17027               2596000.00           1163500.00   \nPrince_William_Sound_17697               6874200.00           2365900.00   \nPrince_William_Sound_18357              15359800.00           4876600.00   \n...                                             ...                  ...   \nPrince_William_Sound_91741             386812700.00         186044600.00   \nPrince_William_Sound_91751             388594100.00         186199700.00   \nPrince_William_Sound_91921             506926400.00         232421500.00   \nPrince_William_Sound_92151             630955600.00         289585800.00   \nPrince_William_Sound_93261              91090600.00          26074300.00   \n\n                            AwcHuc12_wtd_north_per  non_wetland_area  \\\ncat_ID_con                                                             \nPrince_William_Sound_3038                      NaN               NaN   \nPrince_William_Sound_13227                     NaN               NaN   \nPrince_William_Sound_17027                     NaN               NaN   \nPrince_William_Sound_17697                     NaN               NaN   \nPrince_William_Sound_18357                     NaN               NaN   \n...                                            ...               ...   \nPrince_William_Sound_91741                     NaN               NaN   \nPrince_William_Sound_91751                     NaN               NaN   \nPrince_William_Sound_91921                     NaN               NaN   \nPrince_William_Sound_92151                     NaN               NaN   \nPrince_William_Sound_93261                     NaN               NaN   \n\n                            AwcHuc12_wetland_area  AwcHuc12_wtd_wet_per  \\\ncat_ID_con                                                                \nPrince_William_Sound_3038              7186100.00                   NaN   \nPrince_William_Sound_13227                9000.00                   NaN   \nPrince_William_Sound_17027              483700.00                   NaN   \nPrince_William_Sound_17697              690600.00                   NaN   \nPrince_William_Sound_18357             1132800.00                   NaN   \n...                                           ...                   ...   \nPrince_William_Sound_91741              947400.00                   NaN   \nPrince_William_Sound_91751              953100.00                   NaN   \nPrince_William_Sound_91921             1230200.00                   NaN   \nPrince_William_Sound_92151             4281200.00                   NaN   \nPrince_William_Sound_93261               97800.00                   NaN   \n\n                            AwcHuc12_wtd_lake_area_sqm  AwcHuc12_wtd_lake_per  \\\ncat_ID_con                                                                      \nPrince_William_Sound_3038                          NaN                    NaN   \nPrince_William_Sound_13227                         NaN                    NaN   \nPrince_William_Sound_17027                         NaN                    NaN   \nPrince_William_Sound_17697                         NaN                    NaN   \nPrince_William_Sound_18357                         NaN                    NaN   \n...                                                ...                    ...   \nPrince_William_Sound_91741                         NaN                    NaN   \nPrince_William_Sound_91751                         NaN                    NaN   \nPrince_William_Sound_91921                         NaN                    NaN   \nPrince_William_Sound_92151                         NaN                    NaN   \nPrince_William_Sound_93261                         NaN                    NaN   \n\n                            AwcHuc12_wtd_glacier_area_sqm  \\\ncat_ID_con                                                  \nPrince_William_Sound_3038                             NaN   \nPrince_William_Sound_13227                            NaN   \nPrince_William_Sound_17027                            NaN   \nPrince_William_Sound_17697                            NaN   \nPrince_William_Sound_18357                            NaN   \n...                                                   ...   \nPrince_William_Sound_91741                            NaN   \nPrince_William_Sound_91751                            NaN   \nPrince_William_Sound_91921                            NaN   \nPrince_William_Sound_92151                            NaN   \nPrince_William_Sound_93261                            NaN   \n\n                            AwcHuc12_wtd_glacier_per  \ncat_ID_con                                            \nPrince_William_Sound_3038                        NaN  \nPrince_William_Sound_13227                       NaN  \nPrince_William_Sound_17027                       NaN  \nPrince_William_Sound_17697                       NaN  \nPrince_William_Sound_18357                       NaN  \n...                                              ...  \nPrince_William_Sound_91741                       NaN  \nPrince_William_Sound_91751                       NaN  \nPrince_William_Sound_91921                       NaN  \nPrince_William_Sound_92151                       NaN  \nPrince_William_Sound_93261                       NaN  \n\n[112 rows x 44 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat_ID_txt</th>\n      <th>cat_ID</th>\n      <th>region</th>\n      <th>AwcHuc12_cat_slope_COUNT</th>\n      <th>AwcHuc12_cat_slope_AREA</th>\n      <th>AwcHuc12_cat_slope_MIN</th>\n      <th>AwcHuc12_cat_slope_MAX</th>\n      <th>AwcHuc12_cat_slope_RANGE</th>\n      <th>AwcHuc12_cat_slope_MEAN</th>\n      <th>AwcHuc12_cat_slope_STD</th>\n      <th>...</th>\n      <th>AwcHuc12_non_north_area</th>\n      <th>AwcHuc12_north_area</th>\n      <th>AwcHuc12_wtd_north_per</th>\n      <th>non_wetland_area</th>\n      <th>AwcHuc12_wetland_area</th>\n      <th>AwcHuc12_wtd_wet_per</th>\n      <th>AwcHuc12_wtd_lake_area_sqm</th>\n      <th>AwcHuc12_wtd_lake_per</th>\n      <th>AwcHuc12_wtd_glacier_area_sqm</th>\n      <th>AwcHuc12_wtd_glacier_per</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Prince_William_Sound_3038</th>\n      <td>3038</td>\n      <td>3038.00</td>\n      <td>Prince_William_Sound</td>\n      <td>3448.00</td>\n      <td>344800.00</td>\n      <td>0.00</td>\n      <td>24.19</td>\n      <td>24.19</td>\n      <td>5.34</td>\n      <td>4.35</td>\n      <td>...</td>\n      <td>24066600.00</td>\n      <td>8352000.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7186100.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_13227</th>\n      <td>13227</td>\n      <td>13227.00</td>\n      <td>Prince_William_Sound</td>\n      <td>297.00</td>\n      <td>29700.00</td>\n      <td>0.00</td>\n      <td>22.82</td>\n      <td>22.82</td>\n      <td>8.72</td>\n      <td>3.92</td>\n      <td>...</td>\n      <td>679900.00</td>\n      <td>627900.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9000.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17027</th>\n      <td>17027</td>\n      <td>17027.00</td>\n      <td>Prince_William_Sound</td>\n      <td>4338.00</td>\n      <td>433800.00</td>\n      <td>0.00</td>\n      <td>37.53</td>\n      <td>37.53</td>\n      <td>11.51</td>\n      <td>6.66</td>\n      <td>...</td>\n      <td>2596000.00</td>\n      <td>1163500.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>483700.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_17697</th>\n      <td>17697</td>\n      <td>17697.00</td>\n      <td>Prince_William_Sound</td>\n      <td>2137.00</td>\n      <td>213700.00</td>\n      <td>0.00</td>\n      <td>38.09</td>\n      <td>38.09</td>\n      <td>14.63</td>\n      <td>7.43</td>\n      <td>...</td>\n      <td>6874200.00</td>\n      <td>2365900.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>690600.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_18357</th>\n      <td>18357</td>\n      <td>18357.00</td>\n      <td>Prince_William_Sound</td>\n      <td>80.00</td>\n      <td>8000.00</td>\n      <td>0.00</td>\n      <td>11.41</td>\n      <td>11.41</td>\n      <td>3.54</td>\n      <td>2.37</td>\n      <td>...</td>\n      <td>15359800.00</td>\n      <td>4876600.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1132800.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_91741</th>\n      <td>91741</td>\n      <td>91741.00</td>\n      <td>Prince_William_Sound</td>\n      <td>1649.00</td>\n      <td>164900.00</td>\n      <td>0.00</td>\n      <td>27.10</td>\n      <td>27.10</td>\n      <td>5.03</td>\n      <td>4.59</td>\n      <td>...</td>\n      <td>386812700.00</td>\n      <td>186044600.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>947400.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_91751</th>\n      <td>91751</td>\n      <td>91751.00</td>\n      <td>Prince_William_Sound</td>\n      <td>385.00</td>\n      <td>38500.00</td>\n      <td>0.00</td>\n      <td>8.76</td>\n      <td>8.76</td>\n      <td>2.23</td>\n      <td>2.14</td>\n      <td>...</td>\n      <td>388594100.00</td>\n      <td>186199700.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>953100.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_91921</th>\n      <td>91921</td>\n      <td>91921.00</td>\n      <td>Prince_William_Sound</td>\n      <td>709.00</td>\n      <td>70900.00</td>\n      <td>0.00</td>\n      <td>5.73</td>\n      <td>5.73</td>\n      <td>1.04</td>\n      <td>1.38</td>\n      <td>...</td>\n      <td>506926400.00</td>\n      <td>232421500.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1230200.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_92151</th>\n      <td>92151</td>\n      <td>92151.00</td>\n      <td>Prince_William_Sound</td>\n      <td>1305.00</td>\n      <td>130500.00</td>\n      <td>0.00</td>\n      <td>13.27</td>\n      <td>13.27</td>\n      <td>3.13</td>\n      <td>3.67</td>\n      <td>...</td>\n      <td>630955600.00</td>\n      <td>289585800.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4281200.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Prince_William_Sound_93261</th>\n      <td>93261</td>\n      <td>93261.00</td>\n      <td>Prince_William_Sound</td>\n      <td>1119.00</td>\n      <td>111900.00</td>\n      <td>0.00</td>\n      <td>25.31</td>\n      <td>25.31</td>\n      <td>6.02</td>\n      <td>5.51</td>\n      <td>...</td>\n      <td>91090600.00</td>\n      <td>26074300.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>97800.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>112 rows  44 columns</p>\n</div>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pws_df = df_final.filter(like='Prince', axis = 0)\n",
    "pws_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ci_df = df_final.filter(like='Cook', axis = 0)\n",
    "# ci_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "                                 cat_ID_txt            cat_ID        region  \\\ncat_ID_con                                                                    \nCopper_River_75019800007852  75019800007852 75019800007852.00  Copper_River   \nCopper_River_75019800005498  75019800005498 75019800005498.00  Copper_River   \nCopper_River_75019800019853  75019800019853 75019800019853.00  Copper_River   \nCopper_River_75019800002596  75019800002596 75019800002596.00  Copper_River   \nCopper_River_75019800019678  75019800019678 75019800019678.00  Copper_River   \n...                                     ...               ...           ...   \nCopper_River_75003900029086  75003900029086 75003900029086.00  Copper_River   \nCopper_River_75003900044552  75003900044552 75003900044552.00  Copper_River   \nCopper_River_75003900054944  75003900054944 75003900054944.00  Copper_River   \nCopper_River_75003900029096  75003900029096 75003900029096.00  Copper_River   \nCopper_River_75003900047600  75003900047600 75003900047600.00  Copper_River   \n\n                             AwcHuc12_cat_slope_COUNT  \\\ncat_ID_con                                              \nCopper_River_75019800007852                   7179.00   \nCopper_River_75019800005498                   2783.00   \nCopper_River_75019800019853                    630.00   \nCopper_River_75019800002596                   3851.00   \nCopper_River_75019800019678                  39848.00   \n...                                               ...   \nCopper_River_75003900029086                   1469.00   \nCopper_River_75003900044552                  11111.00   \nCopper_River_75003900054944                    121.00   \nCopper_River_75003900029096                      3.00   \nCopper_River_75003900047600                   1022.00   \n\n                             AwcHuc12_cat_slope_AREA  AwcHuc12_cat_slope_MIN  \\\ncat_ID_con                                                                     \nCopper_River_75019800007852                717900.00                    0.00   \nCopper_River_75019800005498                278300.00                    0.00   \nCopper_River_75019800019853                 63000.00                    0.00   \nCopper_River_75019800002596                385100.00                    0.00   \nCopper_River_75019800019678               3984800.00                    0.00   \n...                                              ...                     ...   \nCopper_River_75003900029086                146900.00                    0.00   \nCopper_River_75003900044552               1111100.00                    0.00   \nCopper_River_75003900054944                 12100.00                    0.00   \nCopper_River_75003900029096                   300.00                    3.38   \nCopper_River_75003900047600                102200.00                    0.00   \n\n                             AwcHuc12_cat_slope_MAX  AwcHuc12_cat_slope_RANGE  \\\ncat_ID_con                                                                      \nCopper_River_75019800007852                   37.96                     37.96   \nCopper_River_75019800005498                   24.06                     24.06   \nCopper_River_75019800019853                   42.57                     42.57   \nCopper_River_75019800002596                   21.85                     21.85   \nCopper_River_75019800019678                   39.38                     39.38   \n...                                             ...                       ...   \nCopper_River_75003900029086                    6.71                      6.71   \nCopper_River_75003900044552                   37.33                     37.33   \nCopper_River_75003900054944                    3.44                      3.44   \nCopper_River_75003900029096                    7.62                      4.23   \nCopper_River_75003900047600                   37.44                     37.44   \n\n                             AwcHuc12_cat_slope_MEAN  AwcHuc12_cat_slope_STD  \\\ncat_ID_con                                                                     \nCopper_River_75019800007852                    10.23                    9.44   \nCopper_River_75019800005498                     1.35                    2.62   \nCopper_River_75019800019853                    13.76                   11.73   \nCopper_River_75019800002596                     7.42                    4.91   \nCopper_River_75019800019678                     3.39                    5.35   \n...                                              ...                     ...   \nCopper_River_75003900029086                     0.93                    1.49   \nCopper_River_75003900044552                    10.44                    8.06   \nCopper_River_75003900054944                     0.97                    1.32   \nCopper_River_75003900029096                     5.79                    1.78   \nCopper_River_75003900047600                    10.84                    6.88   \n\n                             ...  AwcHuc12_non_north_area  \\\ncat_ID_con                   ...                            \nCopper_River_75019800007852  ...              55997900.00   \nCopper_River_75019800005498  ...             218281700.00   \nCopper_River_75019800019853  ...             231029100.00   \nCopper_River_75019800002596  ...              66925300.00   \nCopper_River_75019800019678  ...             101165100.00   \n...                          ...                      ...   \nCopper_River_75003900029086  ...              17465000.00   \nCopper_River_75003900044552  ...              10002100.00   \nCopper_River_75003900054944  ...               7381300.00   \nCopper_River_75003900029096  ...              14284800.00   \nCopper_River_75003900047600  ...              42358100.00   \n\n                             AwcHuc12_north_area  AwcHuc12_wtd_north_per  \\\ncat_ID_con                                                                 \nCopper_River_75019800007852          15343900.00                     NaN   \nCopper_River_75019800005498          26206700.00                     NaN   \nCopper_River_75019800019853          56257700.00                     NaN   \nCopper_River_75019800002596          27116100.00                     NaN   \nCopper_River_75019800019678          24739500.00                     NaN   \n...                                          ...                     ...   \nCopper_River_75003900029086           1929700.00                     NaN   \nCopper_River_75003900044552           2113300.00                     NaN   \nCopper_River_75003900054944           1345600.00                     NaN   \nCopper_River_75003900029096           3542200.00                     NaN   \nCopper_River_75003900047600          12046500.00                     NaN   \n\n                             non_wetland_area  AwcHuc12_wetland_area  \\\ncat_ID_con                                                             \nCopper_River_75019800007852               NaN              372900.00   \nCopper_River_75019800005498               NaN             1212500.00   \nCopper_River_75019800019853               NaN             3357300.00   \nCopper_River_75019800002596               NaN             1196300.00   \nCopper_River_75019800019678               NaN             5800300.00   \n...                                       ...                    ...   \nCopper_River_75003900029086               NaN            19076100.00   \nCopper_River_75003900044552               NaN             1742100.00   \nCopper_River_75003900054944               NaN             3113100.00   \nCopper_River_75003900029096               NaN              778800.00   \nCopper_River_75003900047600               NaN              159300.00   \n\n                             AwcHuc12_wtd_wet_per  AwcHuc12_wtd_lake_area_sqm  \\\ncat_ID_con                                                                      \nCopper_River_75019800007852                   NaN                         NaN   \nCopper_River_75019800005498                   NaN                         NaN   \nCopper_River_75019800019853                   NaN                         NaN   \nCopper_River_75019800002596                   NaN                         NaN   \nCopper_River_75019800019678                   NaN                         NaN   \n...                                           ...                         ...   \nCopper_River_75003900029086                   NaN                         NaN   \nCopper_River_75003900044552                   NaN                         NaN   \nCopper_River_75003900054944                   NaN                         NaN   \nCopper_River_75003900029096                   NaN                         NaN   \nCopper_River_75003900047600                   NaN                         NaN   \n\n                             AwcHuc12_wtd_lake_per  \\\ncat_ID_con                                           \nCopper_River_75019800007852                    NaN   \nCopper_River_75019800005498                    NaN   \nCopper_River_75019800019853                    NaN   \nCopper_River_75019800002596                    NaN   \nCopper_River_75019800019678                    NaN   \n...                                            ...   \nCopper_River_75003900029086                    NaN   \nCopper_River_75003900044552                    NaN   \nCopper_River_75003900054944                    NaN   \nCopper_River_75003900029096                    NaN   \nCopper_River_75003900047600                    NaN   \n\n                             AwcHuc12_wtd_glacier_area_sqm  \\\ncat_ID_con                                                   \nCopper_River_75019800007852                            NaN   \nCopper_River_75019800005498                            NaN   \nCopper_River_75019800019853                            NaN   \nCopper_River_75019800002596                            NaN   \nCopper_River_75019800019678                            NaN   \n...                                                    ...   \nCopper_River_75003900029086                            NaN   \nCopper_River_75003900044552                            NaN   \nCopper_River_75003900054944                            NaN   \nCopper_River_75003900029096                            NaN   \nCopper_River_75003900047600                            NaN   \n\n                             AwcHuc12_wtd_glacier_per  \ncat_ID_con                                             \nCopper_River_75019800007852                       NaN  \nCopper_River_75019800005498                       NaN  \nCopper_River_75019800019853                       NaN  \nCopper_River_75019800002596                       NaN  \nCopper_River_75019800019678                       NaN  \n...                                               ...  \nCopper_River_75003900029086                       NaN  \nCopper_River_75003900044552                       NaN  \nCopper_River_75003900054944                       NaN  \nCopper_River_75003900029096                       NaN  \nCopper_River_75003900047600                       NaN  \n\n[245 rows x 44 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat_ID_txt</th>\n      <th>cat_ID</th>\n      <th>region</th>\n      <th>AwcHuc12_cat_slope_COUNT</th>\n      <th>AwcHuc12_cat_slope_AREA</th>\n      <th>AwcHuc12_cat_slope_MIN</th>\n      <th>AwcHuc12_cat_slope_MAX</th>\n      <th>AwcHuc12_cat_slope_RANGE</th>\n      <th>AwcHuc12_cat_slope_MEAN</th>\n      <th>AwcHuc12_cat_slope_STD</th>\n      <th>...</th>\n      <th>AwcHuc12_non_north_area</th>\n      <th>AwcHuc12_north_area</th>\n      <th>AwcHuc12_wtd_north_per</th>\n      <th>non_wetland_area</th>\n      <th>AwcHuc12_wetland_area</th>\n      <th>AwcHuc12_wtd_wet_per</th>\n      <th>AwcHuc12_wtd_lake_area_sqm</th>\n      <th>AwcHuc12_wtd_lake_per</th>\n      <th>AwcHuc12_wtd_glacier_area_sqm</th>\n      <th>AwcHuc12_wtd_glacier_per</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Copper_River_75019800007852</th>\n      <td>75019800007852</td>\n      <td>75019800007852.00</td>\n      <td>Copper_River</td>\n      <td>7179.00</td>\n      <td>717900.00</td>\n      <td>0.00</td>\n      <td>37.96</td>\n      <td>37.96</td>\n      <td>10.23</td>\n      <td>9.44</td>\n      <td>...</td>\n      <td>55997900.00</td>\n      <td>15343900.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>372900.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75019800005498</th>\n      <td>75019800005498</td>\n      <td>75019800005498.00</td>\n      <td>Copper_River</td>\n      <td>2783.00</td>\n      <td>278300.00</td>\n      <td>0.00</td>\n      <td>24.06</td>\n      <td>24.06</td>\n      <td>1.35</td>\n      <td>2.62</td>\n      <td>...</td>\n      <td>218281700.00</td>\n      <td>26206700.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1212500.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75019800019853</th>\n      <td>75019800019853</td>\n      <td>75019800019853.00</td>\n      <td>Copper_River</td>\n      <td>630.00</td>\n      <td>63000.00</td>\n      <td>0.00</td>\n      <td>42.57</td>\n      <td>42.57</td>\n      <td>13.76</td>\n      <td>11.73</td>\n      <td>...</td>\n      <td>231029100.00</td>\n      <td>56257700.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3357300.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75019800002596</th>\n      <td>75019800002596</td>\n      <td>75019800002596.00</td>\n      <td>Copper_River</td>\n      <td>3851.00</td>\n      <td>385100.00</td>\n      <td>0.00</td>\n      <td>21.85</td>\n      <td>21.85</td>\n      <td>7.42</td>\n      <td>4.91</td>\n      <td>...</td>\n      <td>66925300.00</td>\n      <td>27116100.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1196300.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75019800019678</th>\n      <td>75019800019678</td>\n      <td>75019800019678.00</td>\n      <td>Copper_River</td>\n      <td>39848.00</td>\n      <td>3984800.00</td>\n      <td>0.00</td>\n      <td>39.38</td>\n      <td>39.38</td>\n      <td>3.39</td>\n      <td>5.35</td>\n      <td>...</td>\n      <td>101165100.00</td>\n      <td>24739500.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5800300.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029086</th>\n      <td>75003900029086</td>\n      <td>75003900029086.00</td>\n      <td>Copper_River</td>\n      <td>1469.00</td>\n      <td>146900.00</td>\n      <td>0.00</td>\n      <td>6.71</td>\n      <td>6.71</td>\n      <td>0.93</td>\n      <td>1.49</td>\n      <td>...</td>\n      <td>17465000.00</td>\n      <td>1929700.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>19076100.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900044552</th>\n      <td>75003900044552</td>\n      <td>75003900044552.00</td>\n      <td>Copper_River</td>\n      <td>11111.00</td>\n      <td>1111100.00</td>\n      <td>0.00</td>\n      <td>37.33</td>\n      <td>37.33</td>\n      <td>10.44</td>\n      <td>8.06</td>\n      <td>...</td>\n      <td>10002100.00</td>\n      <td>2113300.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1742100.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900054944</th>\n      <td>75003900054944</td>\n      <td>75003900054944.00</td>\n      <td>Copper_River</td>\n      <td>121.00</td>\n      <td>12100.00</td>\n      <td>0.00</td>\n      <td>3.44</td>\n      <td>3.44</td>\n      <td>0.97</td>\n      <td>1.32</td>\n      <td>...</td>\n      <td>7381300.00</td>\n      <td>1345600.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3113100.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900029096</th>\n      <td>75003900029096</td>\n      <td>75003900029096.00</td>\n      <td>Copper_River</td>\n      <td>3.00</td>\n      <td>300.00</td>\n      <td>3.38</td>\n      <td>7.62</td>\n      <td>4.23</td>\n      <td>5.79</td>\n      <td>1.78</td>\n      <td>...</td>\n      <td>14284800.00</td>\n      <td>3542200.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>778800.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Copper_River_75003900047600</th>\n      <td>75003900047600</td>\n      <td>75003900047600.00</td>\n      <td>Copper_River</td>\n      <td>1022.00</td>\n      <td>102200.00</td>\n      <td>0.00</td>\n      <td>37.44</td>\n      <td>37.44</td>\n      <td>10.84</td>\n      <td>6.88</td>\n      <td>...</td>\n      <td>42358100.00</td>\n      <td>12046500.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>159300.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>245 rows  44 columns</p>\n</div>"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cop_df = df_final.filter(like='Copper', axis = 0)\n",
    "cop_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "                               cat_ID_txt            cat_ID      region  \\\ncat_ID_con                                                                \nCook_Inlet_75004200000901  75004200000901 75004200000901.00  Cook_Inlet   \nCook_Inlet_75004200001724  75004200001724 75004200001724.00  Cook_Inlet   \nCook_Inlet_75004200001726  75004200001726 75004200001726.00  Cook_Inlet   \nCook_Inlet_75004200001493  75004200001493 75004200001493.00  Cook_Inlet   \nCook_Inlet_75004200004105  75004200004105 75004200004105.00  Cook_Inlet   \n...                                   ...               ...         ...   \nCook_Inlet_75005400000004  75005400000004 75005400000004.00  Cook_Inlet   \nCook_Inlet_75005400001431  75005400001431 75005400001431.00  Cook_Inlet   \nCook_Inlet_75005400031008  75005400031008 75005400031008.00  Cook_Inlet   \nCook_Inlet_75005400024975  75005400024975 75005400024975.00  Cook_Inlet   \nCook_Inlet_75004500000122  75004500000122 75004500000122.00  Cook_Inlet   \n\n                           AwcHuc12_cat_slope_COUNT  AwcHuc12_cat_slope_AREA  \\\ncat_ID_con                                                                     \nCook_Inlet_75004200000901                   3516.00                351600.00   \nCook_Inlet_75004200001724                   1410.00                141000.00   \nCook_Inlet_75004200001726                    196.00                 19600.00   \nCook_Inlet_75004200001493                    525.00                 52500.00   \nCook_Inlet_75004200004105                    458.00                 45800.00   \n...                                             ...                      ...   \nCook_Inlet_75005400000004                  34837.00               3483700.00   \nCook_Inlet_75005400001431                   4333.00                433300.00   \nCook_Inlet_75005400031008                  17011.00               1701100.00   \nCook_Inlet_75005400024975                  13365.00               1336500.00   \nCook_Inlet_75004500000122                   3544.00                354400.00   \n\n                           AwcHuc12_cat_slope_MIN  AwcHuc12_cat_slope_MAX  \\\ncat_ID_con                                                                  \nCook_Inlet_75004200000901                    0.00                   46.44   \nCook_Inlet_75004200001724                    0.00                   20.08   \nCook_Inlet_75004200001726                    0.00                    3.44   \nCook_Inlet_75004200001493                    0.00                   30.78   \nCook_Inlet_75004200004105                    0.00                   16.35   \n...                                           ...                     ...   \nCook_Inlet_75005400000004                    0.00                    6.03   \nCook_Inlet_75005400001431                    0.00                   39.12   \nCook_Inlet_75005400031008                    0.00                   46.25   \nCook_Inlet_75005400024975                    0.00                   58.60   \nCook_Inlet_75004500000122                    0.00                   22.51   \n\n                           AwcHuc12_cat_slope_RANGE  AwcHuc12_cat_slope_MEAN  \\\ncat_ID_con                                                                     \nCook_Inlet_75004200000901                     46.44                    12.45   \nCook_Inlet_75004200001724                     20.08                     4.58   \nCook_Inlet_75004200001726                      3.44                     0.82   \nCook_Inlet_75004200001493                     30.78                    10.86   \nCook_Inlet_75004200004105                     16.35                     4.50   \n...                                             ...                      ...   \nCook_Inlet_75005400000004                      6.03                     0.66   \nCook_Inlet_75005400001431                     39.12                     7.94   \nCook_Inlet_75005400031008                     46.25                     5.63   \nCook_Inlet_75005400024975                     58.60                    11.14   \nCook_Inlet_75004500000122                     22.51                     5.04   \n\n                           AwcHuc12_cat_slope_STD  ...  \\\ncat_ID_con                                         ...   \nCook_Inlet_75004200000901                    9.31  ...   \nCook_Inlet_75004200001724                    2.78  ...   \nCook_Inlet_75004200001726                    1.17  ...   \nCook_Inlet_75004200001493                    6.82  ...   \nCook_Inlet_75004200004105                    3.00  ...   \n...                                           ...  ...   \nCook_Inlet_75005400000004                    1.20  ...   \nCook_Inlet_75005400001431                    4.69  ...   \nCook_Inlet_75005400031008                    6.79  ...   \nCook_Inlet_75005400024975                   12.32  ...   \nCook_Inlet_75004500000122                    3.58  ...   \n\n                           AwcHuc12_non_north_area  AwcHuc12_north_area  \\\ncat_ID_con                                                                \nCook_Inlet_75004200000901              31878600.00           5081600.00   \nCook_Inlet_75004200001724             126608700.00          44202600.00   \nCook_Inlet_75004200001726             439802800.00         130311400.00   \nCook_Inlet_75004200001493               8601100.00           1039700.00   \nCook_Inlet_75004200004105              12141000.00           1882800.00   \n...                                            ...                  ...   \nCook_Inlet_75005400000004              84065900.00          13340300.00   \nCook_Inlet_75005400001431             236668000.00          62550200.00   \nCook_Inlet_75005400031008             189522100.00          60275000.00   \nCook_Inlet_75005400024975             296172200.00          82432300.00   \nCook_Inlet_75004500000122              26921000.00           5184100.00   \n\n                           AwcHuc12_wtd_north_per  non_wetland_area  \\\ncat_ID_con                                                            \nCook_Inlet_75004200000901                     NaN               NaN   \nCook_Inlet_75004200001724                     NaN               NaN   \nCook_Inlet_75004200001726                     NaN               NaN   \nCook_Inlet_75004200001493                     NaN               NaN   \nCook_Inlet_75004200004105                     NaN               NaN   \n...                                           ...               ...   \nCook_Inlet_75005400000004                     NaN               NaN   \nCook_Inlet_75005400001431                     NaN               NaN   \nCook_Inlet_75005400031008                     NaN               NaN   \nCook_Inlet_75005400024975                     NaN               NaN   \nCook_Inlet_75004500000122                     NaN               NaN   \n\n                           AwcHuc12_wetland_area  AwcHuc12_wtd_wet_per  \\\ncat_ID_con                                                               \nCook_Inlet_75004200000901              186700.00                   NaN   \nCook_Inlet_75004200001724             2768600.00                   NaN   \nCook_Inlet_75004200001726             8772300.00                   NaN   \nCook_Inlet_75004200001493                 800.00                   NaN   \nCook_Inlet_75004200004105               86600.00                   NaN   \n...                                          ...                   ...   \nCook_Inlet_75005400000004              580700.00                   NaN   \nCook_Inlet_75005400001431                   0.00                   NaN   \nCook_Inlet_75005400031008                   0.00                   NaN   \nCook_Inlet_75005400024975                   0.00                   NaN   \nCook_Inlet_75004500000122            14539000.00                   NaN   \n\n                           AwcHuc12_wtd_lake_area_sqm  AwcHuc12_wtd_lake_per  \\\ncat_ID_con                                                                     \nCook_Inlet_75004200000901                         NaN                    NaN   \nCook_Inlet_75004200001724                         NaN                    NaN   \nCook_Inlet_75004200001726                         NaN                    NaN   \nCook_Inlet_75004200001493                         NaN                    NaN   \nCook_Inlet_75004200004105                         NaN                    NaN   \n...                                               ...                    ...   \nCook_Inlet_75005400000004                         NaN                    NaN   \nCook_Inlet_75005400001431                         NaN                    NaN   \nCook_Inlet_75005400031008                         NaN                    NaN   \nCook_Inlet_75005400024975                         NaN                    NaN   \nCook_Inlet_75004500000122                         NaN                    NaN   \n\n                           AwcHuc12_wtd_glacier_area_sqm  \\\ncat_ID_con                                                 \nCook_Inlet_75004200000901                            NaN   \nCook_Inlet_75004200001724                            NaN   \nCook_Inlet_75004200001726                            NaN   \nCook_Inlet_75004200001493                            NaN   \nCook_Inlet_75004200004105                            NaN   \n...                                                  ...   \nCook_Inlet_75005400000004                            NaN   \nCook_Inlet_75005400001431                            NaN   \nCook_Inlet_75005400031008                            NaN   \nCook_Inlet_75005400024975                            NaN   \nCook_Inlet_75004500000122                            NaN   \n\n                           AwcHuc12_wtd_glacier_per  \ncat_ID_con                                           \nCook_Inlet_75004200000901                       NaN  \nCook_Inlet_75004200001724                       NaN  \nCook_Inlet_75004200001726                       NaN  \nCook_Inlet_75004200001493                       NaN  \nCook_Inlet_75004200004105                       NaN  \n...                                             ...  \nCook_Inlet_75005400000004                       NaN  \nCook_Inlet_75005400001431                       NaN  \nCook_Inlet_75005400031008                       NaN  \nCook_Inlet_75005400024975                       NaN  \nCook_Inlet_75004500000122                       NaN  \n\n[661 rows x 44 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat_ID_txt</th>\n      <th>cat_ID</th>\n      <th>region</th>\n      <th>AwcHuc12_cat_slope_COUNT</th>\n      <th>AwcHuc12_cat_slope_AREA</th>\n      <th>AwcHuc12_cat_slope_MIN</th>\n      <th>AwcHuc12_cat_slope_MAX</th>\n      <th>AwcHuc12_cat_slope_RANGE</th>\n      <th>AwcHuc12_cat_slope_MEAN</th>\n      <th>AwcHuc12_cat_slope_STD</th>\n      <th>...</th>\n      <th>AwcHuc12_non_north_area</th>\n      <th>AwcHuc12_north_area</th>\n      <th>AwcHuc12_wtd_north_per</th>\n      <th>non_wetland_area</th>\n      <th>AwcHuc12_wetland_area</th>\n      <th>AwcHuc12_wtd_wet_per</th>\n      <th>AwcHuc12_wtd_lake_area_sqm</th>\n      <th>AwcHuc12_wtd_lake_per</th>\n      <th>AwcHuc12_wtd_glacier_area_sqm</th>\n      <th>AwcHuc12_wtd_glacier_per</th>\n    </tr>\n    <tr>\n      <th>cat_ID_con</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Cook_Inlet_75004200000901</th>\n      <td>75004200000901</td>\n      <td>75004200000901.00</td>\n      <td>Cook_Inlet</td>\n      <td>3516.00</td>\n      <td>351600.00</td>\n      <td>0.00</td>\n      <td>46.44</td>\n      <td>46.44</td>\n      <td>12.45</td>\n      <td>9.31</td>\n      <td>...</td>\n      <td>31878600.00</td>\n      <td>5081600.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>186700.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004200001724</th>\n      <td>75004200001724</td>\n      <td>75004200001724.00</td>\n      <td>Cook_Inlet</td>\n      <td>1410.00</td>\n      <td>141000.00</td>\n      <td>0.00</td>\n      <td>20.08</td>\n      <td>20.08</td>\n      <td>4.58</td>\n      <td>2.78</td>\n      <td>...</td>\n      <td>126608700.00</td>\n      <td>44202600.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2768600.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004200001726</th>\n      <td>75004200001726</td>\n      <td>75004200001726.00</td>\n      <td>Cook_Inlet</td>\n      <td>196.00</td>\n      <td>19600.00</td>\n      <td>0.00</td>\n      <td>3.44</td>\n      <td>3.44</td>\n      <td>0.82</td>\n      <td>1.17</td>\n      <td>...</td>\n      <td>439802800.00</td>\n      <td>130311400.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8772300.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004200001493</th>\n      <td>75004200001493</td>\n      <td>75004200001493.00</td>\n      <td>Cook_Inlet</td>\n      <td>525.00</td>\n      <td>52500.00</td>\n      <td>0.00</td>\n      <td>30.78</td>\n      <td>30.78</td>\n      <td>10.86</td>\n      <td>6.82</td>\n      <td>...</td>\n      <td>8601100.00</td>\n      <td>1039700.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>800.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004200004105</th>\n      <td>75004200004105</td>\n      <td>75004200004105.00</td>\n      <td>Cook_Inlet</td>\n      <td>458.00</td>\n      <td>45800.00</td>\n      <td>0.00</td>\n      <td>16.35</td>\n      <td>16.35</td>\n      <td>4.50</td>\n      <td>3.00</td>\n      <td>...</td>\n      <td>12141000.00</td>\n      <td>1882800.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>86600.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75005400000004</th>\n      <td>75005400000004</td>\n      <td>75005400000004.00</td>\n      <td>Cook_Inlet</td>\n      <td>34837.00</td>\n      <td>3483700.00</td>\n      <td>0.00</td>\n      <td>6.03</td>\n      <td>6.03</td>\n      <td>0.66</td>\n      <td>1.20</td>\n      <td>...</td>\n      <td>84065900.00</td>\n      <td>13340300.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>580700.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75005400001431</th>\n      <td>75005400001431</td>\n      <td>75005400001431.00</td>\n      <td>Cook_Inlet</td>\n      <td>4333.00</td>\n      <td>433300.00</td>\n      <td>0.00</td>\n      <td>39.12</td>\n      <td>39.12</td>\n      <td>7.94</td>\n      <td>4.69</td>\n      <td>...</td>\n      <td>236668000.00</td>\n      <td>62550200.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75005400031008</th>\n      <td>75005400031008</td>\n      <td>75005400031008.00</td>\n      <td>Cook_Inlet</td>\n      <td>17011.00</td>\n      <td>1701100.00</td>\n      <td>0.00</td>\n      <td>46.25</td>\n      <td>46.25</td>\n      <td>5.63</td>\n      <td>6.79</td>\n      <td>...</td>\n      <td>189522100.00</td>\n      <td>60275000.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75005400024975</th>\n      <td>75005400024975</td>\n      <td>75005400024975.00</td>\n      <td>Cook_Inlet</td>\n      <td>13365.00</td>\n      <td>1336500.00</td>\n      <td>0.00</td>\n      <td>58.60</td>\n      <td>58.60</td>\n      <td>11.14</td>\n      <td>12.32</td>\n      <td>...</td>\n      <td>296172200.00</td>\n      <td>82432300.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Cook_Inlet_75004500000122</th>\n      <td>75004500000122</td>\n      <td>75004500000122.00</td>\n      <td>Cook_Inlet</td>\n      <td>3544.00</td>\n      <td>354400.00</td>\n      <td>0.00</td>\n      <td>22.51</td>\n      <td>22.51</td>\n      <td>5.04</td>\n      <td>3.58</td>\n      <td>...</td>\n      <td>26921000.00</td>\n      <td>5184100.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>14539000.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>661 rows  44 columns</p>\n</div>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ci_df = df_final.filter(like='Cook', axis = 0)\n",
    "ci_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8caab41e",
   "language": "python",
   "display_name": "PyCharm (AKSSF)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}