{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a id='top'></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Watershed and Catchment Landcover Metrics\n",
    "\n",
    "## Aspect and Percent North Covariates\n",
    "Calculate aspect grid with the DEM used to create the flow network for each processing area (e.g. HUC8 in NHDPlus or\n",
    " region for BB, PWS, or Kodiak). We need the DEMs used for each flow direction grid, or we can't calculate covariates at\n",
    " the watershed scale.\n",
    " * **~~aspect_rch = calculate mean aspect for stream reach (zonal statistics)~~**\n",
    " * **~~aspect_cat = calculate mean aspect over catchments (zonal statistics)~~**\n",
    " * **north_wtd = create 1/0 grid of north facing cells from aspect grid (north = aspects from 315-45 degrees), ~~~use\n",
    "  weighted flow accumulation to sum north facing cells, divide by flow accumulation grid to get % of north facing\n",
    "  cells in each watershed~~~ Use tabulate area to quantify area of North cells (VALUE_1) and non-North (VALUE_0) cells\n",
    "  for each watershed and calculate percent north as north_wtd = row[VALUE_1]/(row[VALUE_1]+row[VALUE_0])*100 .**\n",
    "## Elevation Metrics\n",
    "Calculate elevation metrics for catchment/watershed with temperature data using zonal statistics as table.\n",
    "* <b> Running \"ALL\" zonal statistics as it does not allow you to choose two types of statistics\n",
    "(ex statistics_type = [\"MIN\",\"MAX\"]) instead set statistics_type=\"ALL\"</b>\n",
    "### Catchment Elevation Metrics\n",
    "* **cat_elev_mn = mean elevation for catchment**\n",
    "* **cat_elev_min = minimum elevation for catchment**\n",
    "* **cat_elev_max = max elevation for catchment**\n",
    "* **cat_elev_std = standard deviation of elevation for catchment**\n",
    "### Watershed Elevation Metrics\n",
    "* **wtd_elev_mn = mean watershed elevation**\n",
    "* **wtd_elev_min = min watershed elevation**\n",
    "* **wtd_elev_max = max watershed elevation**\n",
    "* **wtd_elev_sd (or cv) = standard deviation of watershed elevation**\n",
    "## Slope Metrics\n",
    "Calculate slope metrics for catchment/watershed with temperature data using zonal statistics as table and\n",
    "statistics_type = \"ALL\".\n",
    "### Catchment Slope Metrics\n",
    "* **cat_slope_mn = mean slope for catchment**\n",
    "* **cat_slope_min = minimum slope for catchment**\n",
    "* **cat_slope_max = max slope for catchment**\n",
    "* **cat_slope_std = standard deviation of slope for catchment**\n",
    "### Watershed Elevation Metrics\n",
    "* **wtd_slope_mn = mean watershed slope**\n",
    "* **wtd_slope_min = min watershed slope**\n",
    "* **wtd_slope_max = max watershed slope**\n",
    "* **wtd_slope_sd (or cv) = standard deviation of watershed slope**\n",
    "## Lake, Wetland and Glacier Cover\n",
    "Lake/Pond type waterbodies from NHDPLus hydrography for those regions with NHDPlus derived datasets and NHD waterbodies\n",
    "for those regions with TauDEM derived waterbodies.  Merge all waterbodies together (FTYPE = 390) and use tabulate area\n",
    "calculate percent cover of lakes in catchments/watersheds.\n",
    " * **Created local copies of NHDPlus and NHD waterbodies and exported to T driver here <>  **\n",
    "Use NLCD grid (wetlands.tif) and tabulate area on wetlands grid with watersheds (sum) / divide by number of cells in\n",
    "watershed from fac grid, wetlands from NLCD\n",
    "## Distance from coast\n",
    "DO NOT WORK ON THIS\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import modules"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26102021\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\landcover\n",
      "C:\\Users\\dwmerrigan\\AppData\\Local\\Programs\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\n"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "arcpy.env.overwriteOutput = True\n",
    "today = datetime.datetime.now()\n",
    "# Make the time stamp.\n",
    "time_stamp = '{:%d%m%Y}'.format(today)\n",
    "print(time_stamp)\n",
    "\n",
    "path = os.getcwd()\n",
    "print (path)\n",
    "print (sys.base_exec_prefix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create working output location to store intermediate data\n",
    "Create folder and gdb to store output data.\n",
    "Set data_dir to folder containing all AKSSF regional subfolders/geoadatabases\n",
    "* RS data folder: data_dir = r\"W:\\GIS\\AKSSF\"\n",
    "* DM data folder: data_dir = r\"D:\\GIS_Temp\\AKSSF_BeckyCopy\\AKSSF\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\GIS_temp\\\\AKSSF\\\\Bristol_Bay', 'D:\\\\GIS_temp\\\\AKSSF\\\\Cook_Inlet', 'D:\\\\GIS_temp\\\\AKSSF\\\\Copper_River', 'D:\\\\GIS_temp\\\\AKSSF\\\\Kodiak', 'D:\\\\GIS_temp\\\\AKSSF\\\\Prince_William_Sound']\n",
      "Working Folder already created... D:\\GIS_temp\\AKSSF_land_met\n",
      "Output location already exists D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\n"
     ]
    }
   ],
   "source": [
    "# Set AKSSF Data directory\n",
    "# data_dir = r\"W:\\GIS\\AKSSF\"\n",
    "\n",
    "data_dir = r\"D:\\GIS_Temp\\AKSSF\"\n",
    "arcpy.env.workspace = data_dir\n",
    "regions = arcpy.ListWorkspaces(workspace_type=\"Folder\")\n",
    "rois= []\n",
    "print (regions)\n",
    "\n",
    "# Path to create output folder/gdb\n",
    "temppath = r\"D:\\GIS_temp\" # Output folder\n",
    "dirname = 'AKSSF_land_met'\n",
    "tempgdbname = 'AKSSF_land_met.gdb'\n",
    "temp_dir = os.path.join(temppath, dirname)\n",
    "\n",
    "# Create temporary working gdb\n",
    "if not arcpy.Exists(temp_dir):\n",
    "    os.makedirs(temp_dir)\n",
    "else:\n",
    "    print('Working Folder already created...', temp_dir)\n",
    "\n",
    "outcheck = os.path.join(temp_dir, tempgdbname)\n",
    "\n",
    "if arcpy.Exists(outcheck):\n",
    "    print ('Output location already exists', outcheck)\n",
    "    outgdb = outcheck\n",
    "if not arcpy.Exists(outcheck):\n",
    "    print('Creating output GDB')\n",
    "    tempgdb = arcpy.CreateFileGDB_management(temp_dir,tempgdbname)\n",
    "    print ('Output geodatabase created at', outcheck)\n",
    "    outgdb = tempgdb.getOutput(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['D:\\\\GIS_temp\\\\AKSSF\\\\Bristol_Bay',\n 'D:\\\\GIS_temp\\\\AKSSF\\\\Cook_Inlet',\n 'D:\\\\GIS_temp\\\\AKSSF\\\\Copper_River',\n 'D:\\\\GIS_temp\\\\AKSSF\\\\Kodiak',\n 'D:\\\\GIS_temp\\\\AKSSF\\\\Prince_William_Sound']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set regional workspaces from AKSSF data folder and store in list\n",
    "arcpy.env.workspace = data_dir\n",
    "# Use All of the cores on the machine\n",
    "arcpy.env.parallelProcessingFactor = \"100%\"\n",
    "\n",
    "regions  = arcpy.ListWorkspaces(workspace_type=\"Folder\")\n",
    "regions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create aspect and north grids if they do not already exists\n",
    "### NHDPlus"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Code to create merged elevation grid, aspect and north aspect grids for entire AKSSF region with NHDPlus elev data\n",
    "\n",
    "# elrasters = []\n",
    "# nhd_dat = r\"C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\AKSSF\\\\hydrography\\\\AKSSF_NHDPlus\\\\extracts\"\n",
    "# for dirpath, dirname, filenames in arcpy.da.Walk(nhd_dat, 'RasterDataset'):\n",
    "#     for filename in filenames:\n",
    "#         if filename == \"elev_cm.tif\":\n",
    "#             elras = os.path.join(dirpath, filename)\n",
    "#             elrasters.append(elras)\n",
    "#             print (f'Appending {elras} to list')\n",
    "#\n",
    "# spatial_ref = arcpy.Describe(elrasters[0]).spatialReference\n",
    "# print (spatial_ref.name)\n",
    "# # Merge all nhdplus elevation rasters together\n",
    "# elevname = 'AKSSF_NHDPlus_elev_cm.tif'\n",
    "# AKSSF_elev_cm = arcpy.MosaicToNewRaster_management(elrasters,temp_dir,elevname, spatial_ref, \"32_BIT_SIGNED\", \"5\", \"1\", \"LAST\",\"FIRST\")\n",
    "#\n",
    "# #make aspect raster for all of akssf from merged nhdplus\n",
    "# from arcpy.sa import *\n",
    "# aspname = 'AKSSF_NHDPlus_aspect.tif'\n",
    "# asp_rast = Aspect(in_raster= AKSSF_elev_cm, method='Planar')\n",
    "# asp_rast.save(os.path.join(temp_dir, aspname))\n",
    "#\n",
    "# # make north raster from aspect raster\n",
    "# norname = 'AKSSF_NHDPlus_north_aspect.tif'\n",
    "# aspect_in = Raster(asp_rast)\n",
    "# north_raster = Con((aspect_in>=0)&(aspect_in<=45),1,Con((aspect_in<=360)&(aspect_in>=315),1,0))\n",
    "# north_raster.save(os.path.join(temp_dir, norname))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TauDEM - Create grids using Timms Composite DEM for entire TauDEM processed areas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Code to create merged elevation grid, aspect and north aspect grids for entire AKSSF region with TauDEM elev data\n",
    "# compDEM = r\"C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\data\\topography\\AKSSF_Elevation_Composite_10m.tif\"\n",
    "# clip to study area\n",
    "# AKSSF_elev_10m = r\"D:\\\\GIS_temp\\\\AKSSF_Composite_10m_extract.tif\"\n",
    "#\n",
    "# #make aspect raster for all of akssf from merged nhdplus\n",
    "# from arcpy.sa import *\n",
    "# aspname = 'AKSSF_Composite_10m_aspect.tif'\n",
    "# asp_rast = Aspect(in_raster= AKSSF_elev_10m, method='Planar')\n",
    "# asp_rast.save(os.path.join(temp_dir, aspname))\n",
    "#\n",
    "# # make north raster from aspect raster\n",
    "# norname = 'AKSSF_Composite_10m_north_aspect.tif'\n",
    "# aspect_in = Raster(asp_rast)\n",
    "# north_raster = Con((aspect_in>=0)&(aspect_in<=45),1,Con((aspect_in<=360)&(aspect_in>=315),1,0))\n",
    "# north_raster.save(os.path.join(temp_dir, norname))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Begin GIS portion\n",
    "- May be faster and save more space to create aspect rasters here using extract by mask?\n",
    "- May be able to use aspect raster with tabulate intersection to calculate percent North (aspects from 315-45 degrees)\n",
    "\n",
    "### <b>UPDATE - 2021-10-12 Do not run aspect metrics at this time. Only need to run percent North for watersheds</b>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cook_Inlet using data from D:\\GIS_temp\\AKSSF\\Cook_Inlet folder\n",
      "Cook_Inlet in ['Cook_Inlet', 'Copper_River'] AKSSF list, using cat_fields ['cat_ID_txt', 'NHDPlusID', 'cat_ID_con'] and watershed fields ['cat_ID_txt', 'cat_ID', 'cat_ID_con']\n",
      "----------\n",
      "cat_ID_txt field already in dataset D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Cook_Inlet_cats_intersect\n",
      "----------\n",
      "cat_ID_con field already in dataset D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Cook_Inlet_cats_intersect\n",
      "----------\n",
      "Merged watershed dataset wtds_merge found\n",
      "----------\n",
      "cat_ID_txt field already in dataset\n",
      "----------\n",
      "cat_ID_con field already in dataset D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Cook_Inlet_wtds_merge\n",
      "----------\n",
      "Calculating topographic metrics for catchments & watersheds of interest in Cook_Inlet region\n",
      "----------\n",
      "Geodatabase: ['D:\\\\GIS_temp\\\\AKSSF\\\\Cook_Inlet\\\\Cook_Inlet.gdb']\n",
      "----------\n",
      "Watershed Merge: D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Cook_Inlet_wtds_merge\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Catchment Intersect: D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Cook_Inlet_cats_intersect\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Elevation Raster: D:\\GIS_temp\\AKSSF\\Cook_Inlet\\elev.tif\n",
      "  Projection: NAD_1983_Albers\n",
      "----------\n",
      "North Aspect Raster: D:\\GIS_temp\\AKSSF\\Cook_Inlet\\north.tif\n",
      "  Projection: NAD_1983_Albers\n",
      "----------\n",
      "Wetlands Raster: D:\\GIS_temp\\AKSSF\\Cook_Inlet\\wetlands.tif\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Slope Raster: D:\\GIS_temp\\AKSSF\\Cook_Inlet\\slope.tif\n",
      "  Projection NAD_1983_Albers\n",
      "----------\n",
      "Lakes Ponds fc: D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\AKSSF_NHDPlus_LakePond_alb\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Glaciers fc: D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Cook_Inlet_glaciers \n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "241 Watersheds to process\n",
      "----------\n",
      "Catchment intersect D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Cook_Inlet_cats_intersect selected\n",
      "----------\n",
      "Begin Elevation zonal statistics min/mean/max std dev for watersheds and catchments in Cook_Inlet region\n",
      "Calculating Cook_Inlet watershed elevation zonal stats...\n",
      "Calculating Cook_Inlet catchment elevation zonal stats...\n",
      "Calculating Cook_Inlet catchment slope zonal stats...\n",
      "Begin Slope zonal statistics min/mean/max std dev for watersheds and catchments in Cook_Inlet region\n",
      "Calculating Cook_Inlet watershed slope zonal stats...\n",
      "Zonal Stats for Cook_Inlet Elapsed time: (1:11:55)\n",
      "----------\n",
      "Begin tabulate area of north facing cells for watersheds and catchments in Cook_Inlet region\n",
      "----------\n",
      "['OBJECTID', 'CAT_ID_TXT_DEL', 'VALUE_0', 'VALUE_1', 'region', 'wtd_north_per', 'cat_ID_txt', 'cat_ID_con']\n",
      "Begin tabulate intersection between D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\AKSSF_NHDPlus_LakePond_alb and watersheds in Cook_Inlet region\n",
      "----------\n",
      "['OBJECTID', 'cat_ID_txt', 'FType', 'wtd_lake_area_sqm', 'wtd_lake_per', 'region', 'cat_ID', 'cat_ID_con']\n",
      "Begin tabulate intersection between D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Cook_Inlet_glaciers and watersheds in Cook_Inlet region\n",
      "----------\n",
      "['OBJECTID', 'cat_ID_txt', 'O1Region', 'wtd_glacier_area_sqm', 'wtd_glacier_per', 'region', 'cat_ID', 'cat_ID_con']\n",
      "Begin tabulate intersection between D:\\GIS_temp\\AKSSF\\Cook_Inlet\\wetlands.tif and watersheds in Cook_Inlet region\n",
      "----------\n",
      "['OBJECTID', 'CAT_ID_TXT_DEL', 'VALUE_0', 'VALUE_1', 'region', 'wtd_wet_per', 'cat_ID_txt', 'cat_ID_con']\n",
      "Tabulate area/intersections for Cook_Inlet Elapsed time: (0:18:24)\n",
      "----------\n",
      "All Covariates for Cook_Inlet completed. Elapsed time: (1:30:24)\n",
      "----------\n",
      "Region Cook_Inlet not found in D:\\GIS_temp\\AKSSF\\Prince_William_Sound\n",
      "Copper_River using data from D:\\GIS_temp\\AKSSF\\Copper_River folder\n",
      "Copper_River in ['Cook_Inlet', 'Copper_River'] AKSSF list, using cat_fields ['cat_ID_txt', 'NHDPlusID', 'cat_ID_con'] and watershed fields ['cat_ID_txt', 'cat_ID', 'cat_ID_con']\n",
      "----------\n",
      "cat_ID_txt field already in dataset D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Copper_River_cats_intersect\n",
      "----------\n",
      "cat_ID_con field already in dataset D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Copper_River_cats_intersect\n",
      "----------\n",
      "Merged watershed dataset wtds_merge found\n",
      "----------\n",
      "cat_ID_txt field already in dataset\n",
      "----------\n",
      "cat_ID_con field already in dataset D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Copper_River_wtds_merge\n",
      "----------\n",
      "Calculating topographic metrics for catchments & watersheds of interest in Copper_River region\n",
      "----------\n",
      "Geodatabase: ['D:\\\\GIS_temp\\\\AKSSF\\\\Copper_River\\\\Copper_River.gdb']\n",
      "----------\n",
      "Watershed Merge: D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Copper_River_wtds_merge\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Catchment Intersect: D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Copper_River_cats_intersect\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Elevation Raster: D:\\GIS_temp\\AKSSF\\Copper_River\\elev.tif\n",
      "  Projection: NAD_1983_Alaska_Albers\n",
      "----------\n",
      "North Aspect Raster: D:\\GIS_temp\\AKSSF\\Copper_River\\north.tif\n",
      "  Projection: NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Wetlands Raster: D:\\GIS_temp\\AKSSF\\Copper_River\\wetlands.tif\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Slope Raster: D:\\GIS_temp\\AKSSF\\Copper_River\\slope.tif\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Lakes Ponds fc: D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\AKSSF_NHDPlus_LakePond_alb\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Glaciers fc: D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Copper_River_glaciers \n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "28 Watersheds to process\n",
      "----------\n",
      "Catchment intersect D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Copper_River_cats_intersect selected\n",
      "----------\n",
      "Begin Elevation zonal statistics min/mean/max std dev for watersheds and catchments in Copper_River region\n",
      "Calculating Copper_River watershed elevation zonal stats...\n",
      "Calculating Copper_River catchment elevation zonal stats...\n",
      "Calculating Copper_River catchment slope zonal stats...\n",
      "Begin Slope zonal statistics min/mean/max std dev for watersheds and catchments in Copper_River region\n",
      "Calculating Copper_River watershed slope zonal stats...\n",
      "Zonal Stats for Copper_River Elapsed time: (0:06:48)\n",
      "----------\n",
      "Begin tabulate area of north facing cells for watersheds and catchments in Copper_River region\n",
      "----------\n",
      "['OBJECTID', 'CAT_ID_TXT_DEL', 'VALUE_0', 'VALUE_1', 'region', 'wtd_north_per', 'cat_ID_txt', 'cat_ID_con']\n",
      "Begin tabulate intersection between D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\AKSSF_NHDPlus_LakePond_alb and watersheds in Copper_River region\n",
      "----------\n",
      "['OBJECTID', 'cat_ID_txt', 'FType', 'wtd_lake_area_sqm', 'wtd_lake_per', 'region', 'cat_ID', 'cat_ID_con']\n",
      "Begin tabulate intersection between D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Copper_River_glaciers and watersheds in Copper_River region\n",
      "----------\n",
      "['OBJECTID', 'cat_ID_txt', 'O1Region', 'wtd_glacier_area_sqm', 'wtd_glacier_per', 'region', 'cat_ID', 'cat_ID_con']\n",
      "Begin tabulate intersection between D:\\GIS_temp\\AKSSF\\Copper_River\\wetlands.tif and watersheds in Copper_River region\n",
      "----------\n",
      "['OBJECTID', 'CAT_ID_TXT_DEL', 'VALUE_0', 'VALUE_1', 'region', 'wtd_wet_per', 'cat_ID_txt', 'cat_ID_con']\n",
      "Tabulate area/intersections for Copper_River Elapsed time: (0:05:39)\n",
      "----------\n",
      "All Covariates for Copper_River completed. Elapsed time: (0:12:33)\n",
      "----------\n",
      "Region Copper_River not found in D:\\GIS_temp\\AKSSF\\Prince_William_Sound\n",
      "Bristol_Bay using data from D:\\GIS_temp\\AKSSF\\Bristol_Bay folder\n",
      "Bristol_Bay in ['Bristol_Bay', 'Kodiak', 'Prince_William_Sound'] TauDEM list, using cat_fields ['cat_ID_txt', 'gridcode', 'cat_ID_con'] and watershed fields ['cat_ID_txt', 'cat_ID', 'cat_ID_con']\n",
      "----------\n",
      "cat_ID_txt field already in dataset D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Bristol_Bay_cats_intersect\n",
      "----------\n",
      "cat_ID_con field already in dataset D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Bristol_Bay_cats_intersect\n",
      "----------\n",
      "Merged watershed dataset wtds_merge found\n",
      "----------\n",
      "cat_ID_txt field already in dataset\n",
      "----------\n",
      "cat_ID_con field already in dataset D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Bristol_Bay_wtds_merge\n",
      "----------\n",
      "Calculating topographic metrics for catchments & watersheds of interest in Bristol_Bay region\n",
      "----------\n",
      "Geodatabase: ['D:\\\\GIS_temp\\\\AKSSF\\\\Bristol_Bay\\\\Bristol_Bay.gdb']\n",
      "----------\n",
      "Watershed Merge: D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Bristol_Bay_wtds_merge\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Catchment Intersect: D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Bristol_Bay_cats_intersect\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Elevation Raster: D:\\GIS_temp\\AKSSF\\Bristol_Bay\\elev.tif\n",
      "  Projection: NAD_1983_Alaska_Albers\n",
      "----------\n",
      "North Aspect Raster: D:\\GIS_temp\\AKSSF\\Bristol_Bay\\north.tif\n",
      "  Projection: NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Wetlands Raster: D:\\GIS_temp\\AKSSF\\Bristol_Bay\\wetlands.tif\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Slope Raster: D:\\GIS_temp\\AKSSF\\Bristol_Bay\\slope.tif\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Lakes Ponds fc: D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\AKSSF_NHD_LakesPonds_alb\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Glaciers fc: D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Bristol_Bay_glaciers \n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "114 Watersheds to process\n",
      "----------\n",
      "Catchment intersect D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Bristol_Bay_cats_intersect selected\n",
      "----------\n",
      "Begin Elevation zonal statistics min/mean/max std dev for watersheds and catchments in Bristol_Bay region\n",
      "Calculating Bristol_Bay watershed elevation zonal stats...\n",
      "Calculating Bristol_Bay catchment elevation zonal stats...\n",
      "Calculating Bristol_Bay catchment slope zonal stats...\n",
      "Begin Slope zonal statistics min/mean/max std dev for watersheds and catchments in Bristol_Bay region\n",
      "Calculating Bristol_Bay watershed slope zonal stats...\n",
      "Zonal Stats for Bristol_Bay Elapsed time: (0:02:38)\n",
      "----------\n",
      "Begin tabulate area of north facing cells for watersheds and catchments in Bristol_Bay region\n",
      "----------\n",
      "['OBJECTID', 'CAT_ID_TXT_DEL', 'VALUE_0', 'VALUE_1', 'region', 'wtd_north_per', 'cat_ID_txt', 'cat_ID_con']\n",
      "Begin tabulate intersection between D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\AKSSF_NHD_LakesPonds_alb and watersheds in Bristol_Bay region\n",
      "----------\n",
      "['OBJECTID', 'cat_ID_txt', 'FType', 'wtd_lake_area_sqm', 'wtd_lake_per', 'region', 'cat_ID', 'cat_ID_con']\n",
      "Begin tabulate intersection between D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Bristol_Bay_glaciers and watersheds in Bristol_Bay region\n",
      "----------\n",
      "['OBJECTID', 'cat_ID_txt', 'O1Region', 'wtd_glacier_area_sqm', 'wtd_glacier_per', 'region', 'cat_ID', 'cat_ID_con']\n",
      "Begin tabulate intersection between D:\\GIS_temp\\AKSSF\\Bristol_Bay\\wetlands.tif and watersheds in Bristol_Bay region\n",
      "----------\n",
      "['OBJECTID', 'CAT_ID_TXT_DEL', 'VALUE_0', 'VALUE_1', 'region', 'wtd_wet_per', 'cat_ID_txt', 'cat_ID_con']\n",
      "Tabulate area/intersections for Bristol_Bay Elapsed time: (0:02:08)\n",
      "----------\n",
      "All Covariates for Bristol_Bay completed. Elapsed time: (0:04:50)\n",
      "----------\n",
      "Region Bristol_Bay not found in D:\\GIS_temp\\AKSSF\\Prince_William_Sound\n",
      "Kodiak using data from D:\\GIS_temp\\AKSSF\\Kodiak folder\n",
      "Kodiak in ['Bristol_Bay', 'Kodiak', 'Prince_William_Sound'] TauDEM list, using cat_fields ['cat_ID_txt', 'gridcode', 'cat_ID_con'] and watershed fields ['cat_ID_txt', 'cat_ID', 'cat_ID_con']\n",
      "----------\n",
      "cat_ID_txt field already in dataset D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Kodiak_cats_intersect\n",
      "----------\n",
      "cat_ID_con field already in dataset D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Kodiak_cats_intersect\n",
      "----------\n",
      "Merged watershed dataset wtds_merge found\n",
      "----------\n",
      "cat_ID_txt field already in dataset\n",
      "----------\n",
      "cat_ID_con field already in dataset D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Kodiak_wtds_merge\n",
      "----------\n",
      "Calculating topographic metrics for catchments & watersheds of interest in Kodiak region\n",
      "----------\n",
      "Geodatabase: ['D:\\\\GIS_temp\\\\AKSSF\\\\Kodiak\\\\Kodiak.gdb']\n",
      "----------\n",
      "Watershed Merge: D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Kodiak_wtds_merge\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Catchment Intersect: D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Kodiak_cats_intersect\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Elevation Raster: D:\\GIS_temp\\AKSSF\\Kodiak\\elev.tif\n",
      "  Projection: NAD_1983_Alaska_Albers\n",
      "----------\n",
      "North Aspect Raster: D:\\GIS_temp\\AKSSF\\Kodiak\\north.tif\n",
      "  Projection: NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Wetlands Raster: D:\\GIS_temp\\AKSSF\\Kodiak\\wetlands.tif\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Slope Raster: D:\\GIS_temp\\AKSSF\\Kodiak\\slope.tif\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Lakes Ponds fc: D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\AKSSF_NHD_LakesPonds_alb\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Glaciers fc: D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Kodiak_glaciers \n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "28 Watersheds to process\n",
      "----------\n",
      "Catchment intersect D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Kodiak_cats_intersect selected\n",
      "----------\n",
      "Begin Elevation zonal statistics min/mean/max std dev for watersheds and catchments in Kodiak region\n",
      "Calculating Kodiak watershed elevation zonal stats...\n",
      "Calculating Kodiak catchment elevation zonal stats...\n",
      "Calculating Kodiak catchment slope zonal stats...\n",
      "Begin Slope zonal statistics min/mean/max std dev for watersheds and catchments in Kodiak region\n",
      "Calculating Kodiak watershed slope zonal stats...\n",
      "Zonal Stats for Kodiak Elapsed time: (0:00:31)\n",
      "----------\n",
      "Begin tabulate area of north facing cells for watersheds and catchments in Kodiak region\n",
      "----------\n",
      "['OBJECTID', 'CAT_ID_TXT_DEL', 'VALUE_0', 'VALUE_1', 'region', 'wtd_north_per', 'cat_ID_txt', 'cat_ID_con']\n",
      "Begin tabulate intersection between D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\AKSSF_NHD_LakesPonds_alb and watersheds in Kodiak region\n",
      "----------\n",
      "['OBJECTID', 'cat_ID_txt', 'FType', 'wtd_lake_area_sqm', 'wtd_lake_per', 'region', 'cat_ID', 'cat_ID_con']\n",
      "Begin tabulate intersection between D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Kodiak_glaciers and watersheds in Kodiak region\n",
      "----------\n",
      "['OBJECTID', 'cat_ID_txt', 'O1Region', 'wtd_glacier_area_sqm', 'wtd_glacier_per', 'region', 'cat_ID', 'cat_ID_con']\n",
      "Begin tabulate intersection between D:\\GIS_temp\\AKSSF\\Kodiak\\wetlands.tif and watersheds in Kodiak region\n",
      "----------\n",
      "['OBJECTID', 'CAT_ID_TXT_DEL', 'VALUE_0', 'VALUE_1', 'region', 'wtd_wet_per', 'cat_ID_txt', 'cat_ID_con']\n",
      "Tabulate area/intersections for Kodiak Elapsed time: (0:00:23)\n",
      "----------\n",
      "All Covariates for Kodiak completed. Elapsed time: (0:00:58)\n",
      "----------\n",
      "Region Kodiak not found in D:\\GIS_temp\\AKSSF\\Prince_William_Sound\n",
      "Prince_William_Sound using data from D:\\GIS_temp\\AKSSF\\Prince_William_Sound folder\n",
      "Prince_William_Sound in ['Bristol_Bay', 'Kodiak', 'Prince_William_Sound'] TauDEM list, using cat_fields ['cat_ID_txt', 'gridcode', 'cat_ID_con'] and watershed fields ['cat_ID_txt', 'cat_ID', 'cat_ID_con']\n",
      "----------\n",
      "cat_ID_txt field already in dataset D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Prince_William_Sound_cats_intersect\n",
      "----------\n",
      "cat_ID_con field already in dataset D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Prince_William_Sound_cats_intersect\n",
      "----------\n",
      "Merged watershed dataset wtds_merge found\n",
      "----------\n",
      "cat_ID_txt field already in dataset\n",
      "----------\n",
      "cat_ID_con field already in dataset D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Prince_William_Sound_wtds_merge\n",
      "----------\n",
      "Calculating topographic metrics for catchments & watersheds of interest in Prince_William_Sound region\n",
      "----------\n",
      "Geodatabase: ['D:\\\\GIS_temp\\\\AKSSF\\\\Prince_William_Sound\\\\Prince_William_Sound.gdb']\n",
      "----------\n",
      "Watershed Merge: D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Prince_William_Sound_wtds_merge\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Catchment Intersect: D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Prince_William_Sound_cats_intersect\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Elevation Raster: D:\\GIS_temp\\AKSSF\\Prince_William_Sound\\elev.tif\n",
      "  Projection: NAD_1983_Alaska_Albers\n",
      "----------\n",
      "North Aspect Raster: D:\\GIS_temp\\AKSSF\\Prince_William_Sound\\north.tif\n",
      "  Projection: NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Wetlands Raster: D:\\GIS_temp\\AKSSF\\Prince_William_Sound\\wetlands.tif\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Slope Raster: D:\\GIS_temp\\AKSSF\\Prince_William_Sound\\slope.tif\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Lakes Ponds fc: D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\AKSSF_NHD_LakesPonds_alb\n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "Glaciers fc: D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Prince_William_Sound_glaciers \n",
      "  Projection NAD_1983_Alaska_Albers\n",
      "----------\n",
      "19 Watersheds to process\n",
      "----------\n",
      "Catchment intersect D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Prince_William_Sound_cats_intersect selected\n",
      "----------\n",
      "Begin Elevation zonal statistics min/mean/max std dev for watersheds and catchments in Prince_William_Sound region\n",
      "Calculating Prince_William_Sound watershed elevation zonal stats...\n",
      "Calculating Prince_William_Sound catchment elevation zonal stats...\n",
      "Calculating Prince_William_Sound catchment slope zonal stats...\n",
      "Begin Slope zonal statistics min/mean/max std dev for watersheds and catchments in Prince_William_Sound region\n",
      "Calculating Prince_William_Sound watershed slope zonal stats...\n",
      "Zonal Stats for Prince_William_Sound Elapsed time: (0:00:29)\n",
      "----------\n",
      "Begin tabulate area of north facing cells for watersheds and catchments in Prince_William_Sound region\n",
      "----------\n",
      "['OBJECTID', 'CAT_ID_TXT_DEL', 'VALUE_0', 'VALUE_1', 'region', 'wtd_north_per', 'cat_ID_txt', 'cat_ID_con']\n",
      "Begin tabulate intersection between D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\AKSSF_NHD_LakesPonds_alb and watersheds in Prince_William_Sound region\n",
      "----------\n",
      "['OBJECTID', 'cat_ID_txt', 'FType', 'wtd_lake_area_sqm', 'wtd_lake_per', 'region', 'cat_ID', 'cat_ID_con']\n",
      "Begin tabulate intersection between D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\\Prince_William_Sound_glaciers and watersheds in Prince_William_Sound region\n",
      "----------\n",
      "['OBJECTID', 'cat_ID_txt', 'O1Region', 'wtd_glacier_area_sqm', 'wtd_glacier_per', 'region', 'cat_ID', 'cat_ID_con']\n",
      "Begin tabulate intersection between D:\\GIS_temp\\AKSSF\\Prince_William_Sound\\wetlands.tif and watersheds in Prince_William_Sound region\n",
      "----------\n",
      "['OBJECTID', 'CAT_ID_TXT_DEL', 'VALUE_0', 'VALUE_1', 'region', 'wtd_wet_per', 'cat_ID_txt', 'cat_ID_con']\n",
      "Tabulate area/intersections for Prince_William_Sound Elapsed time: (0:00:23)\n",
      "----------\n",
      "All Covariates for Prince_William_Sound completed. Elapsed time: (0:00:57)\n",
      "----------\n",
      "Region Prince_William_Sound not found in D:\\GIS_temp\\AKSSF\\Prince_William_Sound\n",
      "Process completed at 2021-10-27 00:59 (Elapsed time: 1:49:44)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "from arcpy.sa import *\n",
    "import re\n",
    "\n",
    "# Set data_dir equal to folder containing AKSSF regional subfolders containing GDBs and raster datasets\n",
    "arcpy.env.workspace = data_dir\n",
    "arcpy.env.overwriteOutput = True\n",
    "sr = arcpy.SpatialReference(3338) #'NAD_1983_Alaska_Albers'\n",
    "arcpy.env.outputCoordinateSystem = sr\n",
    "regions  = arcpy.ListWorkspaces(workspace_type=\"Folder\")\n",
    "\n",
    "# Lists for variables not needed at present time\n",
    "#cat_asp_ztables = []\n",
    "#wtd_asp_ztables = []\n",
    "#cat_pernorth_taba_tables=[]\n",
    "\n",
    "# Lists to store output tables\n",
    "wtd_pernorth_taba_tables=[]\n",
    "wtd_lp_tabint_tables = []\n",
    "wtd_glac_tabint_tables = []\n",
    "wtd_wet_taba_tables = []\n",
    "cat_elev_ztables = []\n",
    "wtd_elev_ztables = []\n",
    "cat_slope_ztables = []\n",
    "wtd_slope_ztables = []\n",
    "\n",
    "\n",
    "# Clear lists\n",
    "cat_cur_fields = []\n",
    "wtd_cur_fields = []\n",
    "\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "\n",
    "# Seperate data by\n",
    "nhdplus_dat = ['Cook_Inlet','Copper_River']\n",
    "tauDem_dat = ['Bristol_Bay', 'Kodiak', 'Prince_William_Sound']\n",
    "\n",
    "# Loop through all processing areas\n",
    "rois = nhdplus_dat + tauDem_dat\n",
    "#rois = ['Cook_Inlet']\n",
    "# Uncomment and change list accordingly below to test individual roi/rois\n",
    "# rois = ['Kodiak']\n",
    "for roi in rois:\n",
    "    # Loop through regional folders\n",
    "    for region in regions:\n",
    "        if roi in str(region):\n",
    "            print(f'{roi} using data from {region} folder')\n",
    "            # Set data and variables unique to regions with NHDPlus Data\n",
    "            if roi in nhdplus_dat:\n",
    "                # # NHDPLus raster data for DM pc, variables will be overwritten below if they exist in source folder.\n",
    "                # asp_rast = r\"D:\\Basedata\\AKSSF_Basedata\\AKSSF_NHDPlus_aspect.tif\"\n",
    "                # elev_rast = r\"D:\\Basedata\\AKSSF_Basedata\\AKSSF_NHDPlus_elev_cm.ti\n",
    "                # f\"\n",
    "                # nor_rast = r\"D:\\Basedata\\AKSSF_Basedata\\AKSSF_NHDPlus_north_aspect.tif\"\n",
    "                lakes_fc = r\"D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\AKSSF_NHDPlus_LakePond_alb\"\n",
    "                # Fields for update cursor\n",
    "                cat_cur_fields = ['cat_ID_txt', 'NHDPlusID',\"cat_ID_con\"]\n",
    "                wtd_cur_fields = ['cat_ID_txt', 'cat_ID',\"cat_ID_con\"]\n",
    "                print (f'{roi} in {nhdplus_dat} AKSSF list, using cat_fields {cat_cur_fields} and watershed fields {wtd_cur_fields}')\n",
    "                # print(f'NHD data: north raster - {nor_rast}')\n",
    "                # print(f'         aspect raster - {asp_rast}')\n",
    "                # print(f'      elevation raster - {elev_rast}')\n",
    "                print('----------')\n",
    "            # Set data and variables unique to regions with TauDEM Data\n",
    "            elif roi in tauDem_dat:\n",
    "                # # TauDEM raster data for DM pc, variables will be overwritten below if they exist in source folder.\n",
    "                # nor_rast = r\"D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_north_aspect.tif\"\n",
    "                # asp_rast = r\"D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_aspect.tif\"\n",
    "                # elev_rast = r\"D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_extract.tif\"\n",
    "\n",
    "                lakes_fc = r\"D:\\\\Basedata\\\\AKSSF_Basedata\\\\AKSSF_Basedata.gdb\\\\AKSSF_NHD_LakesPonds_alb\"\n",
    "                # Fields for update cursor\n",
    "                cat_cur_fields = ['cat_ID_txt', 'gridcode',\"cat_ID_con\"]\n",
    "                wtd_cur_fields = ['cat_ID_txt', 'cat_ID',\"cat_ID_con\"]\n",
    "\n",
    "                print (f'{roi} in {tauDem_dat} TauDEM list, using cat_fields {cat_cur_fields} and watershed fields {wtd_cur_fields}')\n",
    "                # print(f'TauDem data: north raster - {nor_rast}')\n",
    "                # print(f'         aspect raster - {asp_rast}')\n",
    "                # print(f'      elevation raster - {elev_rast}')\n",
    "                print('----------')\n",
    "\n",
    "            wtds = []\n",
    "            cats = []\n",
    "            # Start iter timing function\n",
    "            iteration_start = time.time()\n",
    "            # Set workspace to region folder\n",
    "            arcpy.env.workspace = region\n",
    "            gdb = arcpy.ListWorkspaces(workspace_type='FileGDB')\n",
    "            walk = arcpy.da.Walk(region, datatype = ['FeatureClass','RasterDataset'])\n",
    "            for dirpath, dirnames, filenames in walk:\n",
    "                for filename in filenames:\n",
    "                    # Create list of watersheds\n",
    "                    if ((\"wtd\" in filename) and (\"merge\" not in filename)):\n",
    "                        #print(f\" {filename} watershed identified\")\n",
    "                        wtds.append(os.path.join(dirpath, filename))\n",
    "                    # Set merged watersheds dataset\n",
    "                    elif 'wtds_merge'in filename:\n",
    "                        wtdpath = os.path.join(dirpath,filename)\n",
    "                        wtdname = roi +'_'+filename\n",
    "                        # Make local copy projected in AKAlbers\n",
    "                        wtd_merge = arcpy.FeatureClassToFeatureClass_conversion(wtdpath,outgdb,wtdname)\n",
    "                        print(f'Merged watershed dataset {filename} found')\n",
    "                        print('----------')\n",
    "                        wtdfieldnames = []\n",
    "                        wtdlstFields = arcpy.ListFields(wtd_merge)\n",
    "                        for field in wtdlstFields:\n",
    "                            wtdfieldnames.append(field.name)\n",
    "                        if str(wtd_cur_fields[0]) in wtdfieldnames:\n",
    "                            print (f'{wtd_cur_fields[0]} field already in dataset')\n",
    "                            print('----------')\n",
    "                        else:\n",
    "                            print (f'Adding {wtd_cur_fields[0]} field to watershed dataset {wtd_merge}')\n",
    "                            print('----------')\n",
    "                            # add cat_ID_txt field and concat cat_ID + region\n",
    "                            arcpy.AddField_management(wtd_merge, str(wtd_cur_fields[0]),field_type='TEXT')\n",
    "                            # populate cat_ID_txt\n",
    "                            with arcpy.da.UpdateCursor(wtd_merge, wtd_cur_fields[0:2]) as cur:\n",
    "                                for row in cur:\n",
    "                                    int_val = int(row[1])\n",
    "                                    row[0] = str(int_val)\n",
    "                                    # Update rows\n",
    "                                    cur.updateRow(row)\n",
    "                                del(row)\n",
    "                            del(cur)\n",
    "                        if str(wtd_cur_fields[2]) in wtdfieldnames:\n",
    "                            print (f'{wtd_cur_fields[2]} field already in dataset {wtd_merge}')\n",
    "                            print('----------')\n",
    "                        else:\n",
    "                            print (f'Adding {wtd_cur_fields[2]} field to watershed dataset {wtd_merge}')\n",
    "                            print('----------')\n",
    "                            # add cat_ID_con field and concat cat_ID + region\n",
    "                            arcpy.AddField_management(wtd_merge, str(wtd_cur_fields[2]),field_type='TEXT')\n",
    "                            # populate cat_ID_txt\n",
    "                            with arcpy.da.UpdateCursor(wtd_merge, wtd_cur_fields) as cur:\n",
    "                                for row in cur:\n",
    "                                    int_val = int(row[1])\n",
    "                                    row[2] = str(roi) +'_'+ str(int_val)\n",
    "                                    # Update rows\n",
    "                                    cur.updateRow(row)\n",
    "                                del(row)\n",
    "                            del(cur)\n",
    "\n",
    "                    # Select glaciers fc\n",
    "                    elif 'glaciers' in filename:\n",
    "                        # Make local copy projected in AKAlbers\n",
    "                        glacpath = os.path.join(dirpath, filename)\n",
    "                        glacname = roi+'_'+filename\n",
    "                        glac_fc = arcpy.FeatureClassToFeatureClass_conversion(glacpath,outgdb,glacname)\n",
    "\n",
    "                    # Select elevation raster\n",
    "                    elif 'elev.tif' == filename:\n",
    "                        elev_rast = os.path.join(dirpath, filename)\n",
    "\n",
    "                    # # Select aspect raster\n",
    "                    # elif 'aspect' in filename:\n",
    "                    #     asp_rast = os.path.join(dirpath, filename)\n",
    "\n",
    "                    # Select north raster\n",
    "                    elif 'north.tif' == filename:\n",
    "                        nor_rast = os.path.join(dirpath, filename)\n",
    "\n",
    "                    # Select slope raster\n",
    "                    elif 'slope.tif' == filename:\n",
    "                        slope_rast = os.path.join(dirpath, filename)\n",
    "\n",
    "                    # Select wetland raster\n",
    "                    elif 'wetlands.tif' == filename:\n",
    "                        wet_rast = os.path.join(dirpath, filename)\n",
    "\n",
    "                    # Select catch_int fc (catchments of interest for region) and make a copy\n",
    "                    elif 'cats_intersect' in filename:\n",
    "                        # Make local copy projected in AKAlbers\n",
    "                        catspath = os.path.join(dirpath,filename)\n",
    "                        catsname = roi+\"_\"+filename\n",
    "                        cats = arcpy.FeatureClassToFeatureClass_conversion(catspath, outgdb,catsname)\n",
    "                        catlstfields = arcpy.ListFields(cats)\n",
    "                        catfieldnames = []\n",
    "                        for field in catlstfields:\n",
    "                            catfieldnames.append(field.name)\n",
    "                        if str(cat_cur_fields[0]) in catfieldnames:\n",
    "                            print (f'{cat_cur_fields[0]} field already in dataset {cats}')\n",
    "                            print('----------')\n",
    "                        else:\n",
    "                            print (f'Adding {cat_cur_fields[0]} field to catchment dataset {cats}')\n",
    "                            print('----------')\n",
    "                            # add cat_ID_txt field\n",
    "                            arcpy.AddField_management(cats, str(cat_cur_fields[0]), field_type='TEXT')\n",
    "                            # populate cat_ID_txt\n",
    "                            with arcpy.da.UpdateCursor(cats, cat_cur_fields[0:2]) as cur:\n",
    "                                for row in cur:\n",
    "                                    int_val = int(row[1])\n",
    "                                    row[0] = str(int_val)\n",
    "                                    # Update rows\n",
    "                                    cur.updateRow(row)\n",
    "                                del(row)\n",
    "                            del(cur)\n",
    "                        if str(cat_cur_fields[2]) in catfieldnames:\n",
    "                            print (f'{cat_cur_fields[2]} field already in dataset {cats}')\n",
    "                            print('----------')\n",
    "                        else:\n",
    "                            print (f'Adding {cat_cur_fields[2]} field to catchment dataset {cats}')\n",
    "                            print('----------')\n",
    "                            # add cat_ID_txt field & cat_ID + region concat field\n",
    "                            arcpy.AddField_management(cats,str(cat_cur_fields[2]),field_type='TEXT')\n",
    "                            # populate cat_ID_con\n",
    "                            with arcpy.da.UpdateCursor(cats, cat_cur_fields) as cur:\n",
    "                                for row in cur:\n",
    "                                    int_val = int(row[1])\n",
    "                                    row[2] = str(roi) +'_'+ str(int_val)\n",
    "                                    # Update rows\n",
    "                                    cur.updateRow(row)\n",
    "                                del(row)\n",
    "                            del(cur)\n",
    "\n",
    "            print (f'Calculating topographic metrics for catchments & watersheds of interest in {roi}'\n",
    "                   f' region')\n",
    "            print ('----------')\n",
    "            print(f'Geodatabase: {gdb}')\n",
    "            print ('----------')\n",
    "            print (f'Watershed Merge: {wtd_merge}')\n",
    "            print (f'  Projection {arcpy.Describe(wtd_merge).spatialReference.name}')\n",
    "            print ('----------')\n",
    "            print (f'Catchment Intersect: {cats}')\n",
    "            print (f'  Projection {arcpy.Describe(cats).spatialReference.name}')\n",
    "            print ('----------')\n",
    "            print (f'Elevation Raster: {elev_rast}')\n",
    "            print (f'  Projection: {arcpy.Describe(elev_rast).spatialReference.name}')\n",
    "            print ('----------')\n",
    "            print (f'North Aspect Raster: {nor_rast}')\n",
    "            print (f'  Projection: {arcpy.Describe(nor_rast).spatialReference.name}')\n",
    "            print ('----------')\n",
    "            print (f'Wetlands Raster: {wet_rast}')\n",
    "            print (f'  Projection {arcpy.Describe(wet_rast).spatialReference.name}')\n",
    "            print ('----------')\n",
    "            print (f'Slope Raster: {slope_rast}')\n",
    "            print (f'  Projection {arcpy.Describe(slope_rast).spatialReference.name}')\n",
    "            print ('----------')        \n",
    "            print (f'Lakes Ponds fc: {lakes_fc}')\n",
    "            print (f'  Projection {arcpy.Describe(lakes_fc).spatialReference.name}')\n",
    "            print ('----------')\n",
    "            print (f'Glaciers fc: {glac_fc} ')\n",
    "            print (f'  Projection {arcpy.Describe(glac_fc).spatialReference.name}')\n",
    "            print ('----------')\n",
    "            print (f'{len(wtds)} Watersheds to process')\n",
    "            print ('----------')\n",
    "            print (f'Catchment intersect {cats} selected')\n",
    "            print ('----------')\n",
    "\n",
    "            try:\n",
    "                # Set output names/paths for watershed and catchment tables\n",
    "                wtd_merge_name = roi + \"_Watersheds_Merge\"\n",
    "                wtd_merge_path = os.path.join(outgdb,wtd_merge_name)\n",
    "\n",
    "                # # Aspect variables\n",
    "                # wtd_merge_asp_table_name = roi + \"_Watersheds_Merge_AspectZstats\"\n",
    "                # wtd_merge_asp_table_path = os.path.join(outgdb, wtd_merge_asp_table_name)\n",
    "                # cat_asp_table_name = roi + \"_Catchments_AspectZstats\"\n",
    "                # cat_asp_table_path = os.path.join(outgdb, cat_asp_table_name)\n",
    "\n",
    "                # Percent North variables\n",
    "                wtd_merge_pernorth_table_name = roi + \"_Watersheds_Merge_PercentNorth\"\n",
    "                wtd_merge_pernorth_table_path = os.path.join(outgdb, wtd_merge_pernorth_table_name)\n",
    "                # cat_pernorth_table_name = roi + \"_Catchments_PercentNorth\"\n",
    "                # cat_pernorth_table_path = os.path.join(outgdb, cat_pernorth_table_name)\n",
    "\n",
    "                # Elevation variables\n",
    "                wtd_merge_elev_table_name = roi + \"_Watersheds_Merge_ElevZstats\"\n",
    "                wtd_merge_elev_table_path = os.path.join(outgdb, wtd_merge_elev_table_name)\n",
    "                cat_elev_table_name = roi + \"_Catchments_ElevZstats\"\n",
    "                cat_elev_table_path = os.path.join(outgdb, cat_elev_table_name)\n",
    "                \n",
    "                # Slope variables\n",
    "                wtd_merge_slope_table_name = roi + \"_Watershed_Merge_SlopeZstats\"\n",
    "                wtd_merge_slope_table_path = os.path.join(outgdb, wtd_merge_slope_table_name)\n",
    "                cat_slope_table_name = roi + \"_Catchments_SlopeZstats\"\n",
    "                cat_slope_table_path = os.path.join(outgdb, cat_slope_table_name)\n",
    "\n",
    "                # Lakes Ponds variables\n",
    "                wtd_merge_lp_table_name = roi + \"_Watershed_Merge_LakesPonds\"\n",
    "                wtd_merge_lp_table_path = os.path.join(outgdb, wtd_merge_lp_table_name)\n",
    "                cat_lp_table_name = roi + \"_Catchments_LakesPonds\"\n",
    "                cat_lp_path = os.path.join(outgdb, cat_lp_table_name)\n",
    "\n",
    "                # Wetlands variables\n",
    "                wtd_merge_wetlands_table_name = roi + \"_Watershed_Merge_Wetlands\"\n",
    "                wtd_merge_wetlands_table_path = os.path.join(outgdb, wtd_merge_wetlands_table_name)\n",
    "                cat_wetlands_table_name = roi + \"_Catchments_Wetlands\"\n",
    "                cat_wetlands_table_path = os.path.join(outgdb, cat_wetlands_table_name)\n",
    "\n",
    "                # Glaciers\n",
    "                wtd_merge_glac_table_name = roi + \"_Watershed_Merge_Glaciers\"\n",
    "                wtd_merge_glac_table_path = os.path.join(outgdb, wtd_merge_glac_table_name)\n",
    "                cat_glac_table_name = roi + \"_Catchments_Glaciers\"\n",
    "                cat_glac_table_path = os.path.join(outgdb, cat_glac_table_name)\n",
    "\n",
    "                # # Watersheds already merged so no need to run at this time\n",
    "                # if not arcpy.Exists(wtd_merge):\n",
    "                #     mergestart = time.time()\n",
    "                #     # Merge watersheds\n",
    "                #     wtd_merge = arcpy.Merge_management( wtds, wtd_merge_path ,add_source='ADD_SOURCE_INFO')\n",
    "                #     # Add wtd_id field\n",
    "                #     arcpy.AddField_management(wtd_merge,'cat_ID_txt',field_type='TEXT')\n",
    "                #     arcpy.AddField_management(wtd_merge,\"cat_ID_con\",field_type='TEXT')\n",
    "                #     # Add region field\n",
    "                #     arcpy.AddField_management(wtd_merge,'region',field_type='TEXT')\n",
    "                #     # Populate watershed id and region information using update cursor - faster than field calc\n",
    "                #     with arcpy.da.UpdateCursor(wtd_merge,['MERGE_SRC','cat_ID_txt','region','cat_ID_con']) as cur:\n",
    "                #         for row in cur:\n",
    "                #             row[1] = re.findall('\\d+', row[0])[0]\n",
    "                #             row[2] = roi\n",
    "                #             row[3] = + str(roi) + '_'+ str(re.findall('\\d+', row[0])[0])\n",
    "                #             # Update\n",
    "                #             cur.updateRow(row)\n",
    "                #         del(row)\n",
    "                #     del(cur)\n",
    "                #     mergestop = time.time()\n",
    "                #     mergetime = int (mergestop - mergestart)\n",
    "                #     print(f'Watershed Merge for {roi} Elapsed time: ({datetime.timedelta(seconds=mergetime)})')\n",
    "                #     print('----------')\n",
    "                # else:\n",
    "                #     print (f'Merged watershed dataset {wtd_merge} already created')\n",
    "                #     print('----------')\n",
    "\n",
    "                # Begin Zonal Stats\n",
    "                zstat_start = time.time()\n",
    "                print(f'Begin Elevation zonal statistics min/mean/max std dev for watersheds and catchments in {roi}'\n",
    "                      f' region')\n",
    "\n",
    "                # Elevation Zonal statistics  for watersheds\n",
    "                print(f'Calculating {roi} watershed elevation zonal stats...')\n",
    "                arcpy.env.snapRaster = elev_rast\n",
    "                arcpy.env.cellSize = elev_rast\n",
    "                wtd_elev_metrics_table = ZonalStatisticsAsTable(in_zone_data = wtd_merge,\n",
    "                                                                zone_field = wtd_cur_fields[0],\n",
    "                                                                in_value_raster = elev_rast,\n",
    "                                                                out_table = wtd_merge_elev_table_path,\n",
    "                                                                statistics_type='ALL'\n",
    "                                                                )\n",
    "                # Add region identifier field for watershed tables                                                )\n",
    "                arcpy.AddField_management(wtd_elev_metrics_table,'region',field_type='TEXT')\n",
    "                # Add cat_ID_Con field\n",
    "                arcpy.AddField_management(wtd_elev_metrics_table,'cat_ID_con',field_type='TEXT')\n",
    "                # Update region field\n",
    "                with arcpy.da.UpdateCursor(wtd_elev_metrics_table,['region','cat_ID_txt','cat_ID_con']) as cur:\n",
    "                    for row in cur:\n",
    "                        row[0] = roi\n",
    "                        row[2] = roi+\"_\"+row[1]\n",
    "                        # Update\n",
    "                        cur.updateRow(row)\n",
    "                    del(row)\n",
    "                del(cur)\n",
    "                # Append watershed elev table to list\n",
    "                wtd_elev_ztables.append(wtd_elev_metrics_table)\n",
    "\n",
    "                # Elevation zonal statistics for catchments\n",
    "                print(f'Calculating {roi} catchment elevation zonal stats...')\n",
    "                arcpy.env.snapRaster = elev_rast\n",
    "                arcpy.env.cellSize = elev_rast\n",
    "                cat_elev_metrics_table = ZonalStatisticsAsTable(in_zone_data = cats ,\n",
    "                                                                zone_field = cat_cur_fields[0],\n",
    "                                                                in_value_raster = elev_rast,\n",
    "                                                                out_table = cat_elev_table_path,\n",
    "                                                                statistics_type='ALL'\n",
    "                                                                )\n",
    "                # Add region identifier field for catchment table\n",
    "                arcpy.AddField_management(cat_elev_metrics_table,'region',field_type='TEXT')\n",
    "                # Add cat_ID_Con field\n",
    "                arcpy.AddField_management(cat_elev_metrics_table,'cat_ID_con',field_type='TEXT')\n",
    "\n",
    "                # Update fields\n",
    "                with arcpy.da.UpdateCursor(cat_elev_metrics_table,['region','cat_ID_txt','cat_ID_con']) as cur:\n",
    "                    for row in cur:\n",
    "                        row[0] = roi\n",
    "                        row[2] = roi+\"_\"+row[1]\n",
    "                        # Update\n",
    "                        cur.updateRow(row)\n",
    "                    del(row)\n",
    "                del(cur)\n",
    "                # Append catchment elev table to list\n",
    "                cat_elev_ztables.append(cat_elev_metrics_table)\n",
    "\n",
    "                # Slope zonal statistics for catchments\n",
    "                print(f'Calculating {roi} catchment slope zonal stats...')\n",
    "                arcpy.env.snapRaster = slope_rast\n",
    "                arcpy.env.cellSize = slope_rast\n",
    "                cat_slope_metrics_table = ZonalStatisticsAsTable(in_zone_data = cats ,\n",
    "                                                                zone_field = cat_cur_fields[0],\n",
    "                                                                in_value_raster = slope_rast,\n",
    "                                                                out_table = cat_slope_table_path,\n",
    "                                                                statistics_type='ALL'\n",
    "                                                                )\n",
    "                # Add region identifier field for catchment table\n",
    "                arcpy.AddField_management(cat_slope_metrics_table,'region',field_type='TEXT')\n",
    "                # Add cat_ID_Con field\n",
    "                arcpy.AddField_management(cat_slope_metrics_table,'cat_ID_con',field_type='TEXT')\n",
    "\n",
    "                # Update region field\n",
    "                with arcpy.da.UpdateCursor(cat_slope_metrics_table,['region','cat_ID_txt','cat_ID_con']) as cur:\n",
    "                    for row in cur:\n",
    "                        row[0] = roi\n",
    "                        row[2] = roi+\"_\"+row[1]\n",
    "                        # Update\n",
    "                        cur.updateRow(row)\n",
    "                    del(row)\n",
    "                del(cur)\n",
    "                # Append catchment slope table to list\n",
    "\n",
    "                cat_slope_ztables.append(cat_slope_metrics_table)\n",
    "                # Watershed slope Zonal Statistics\n",
    "                print(f'Begin Slope zonal statistics min/mean/max std dev for watersheds and catchments in {roi}'\n",
    "                      f' region')\n",
    "\n",
    "                # Elevation Zonal statistics  for watersheds\n",
    "                print(f'Calculating {roi} watershed slope zonal stats...')\n",
    "                arcpy.env.snapRaster = slope_rast\n",
    "                arcpy.env.cellSize = slope_rast\n",
    "                wtd_slope_metrics_table = ZonalStatisticsAsTable(in_zone_data = wtd_merge,\n",
    "                                                                zone_field = wtd_cur_fields[0],\n",
    "                                                                in_value_raster = slope_rast,\n",
    "                                                                out_table = wtd_merge_slope_table_path,\n",
    "                                                                statistics_type='ALL'\n",
    "                                                                )\n",
    "                # Add region identifier field for watershed tables                                                )\n",
    "                arcpy.AddField_management(wtd_slope_metrics_table,'region',field_type='TEXT')\n",
    "                # Add cat_ID_Con field\n",
    "                arcpy.AddField_management(wtd_slope_metrics_table,'cat_ID_con',field_type='TEXT')\n",
    "\n",
    "                # Update region field\n",
    "                with arcpy.da.UpdateCursor(wtd_slope_metrics_table,['region','cat_ID_txt','cat_ID_con']) as cur:\n",
    "                    for row in cur:\n",
    "                        row[0] = roi\n",
    "                        row[2] = roi+\"_\"+row[1]\n",
    "                        # Update\n",
    "                        cur.updateRow(row)\n",
    "                    del(row)\n",
    "                del(cur)\n",
    "                # Append watershed slope table to list\n",
    "                wtd_slope_ztables.append(wtd_slope_metrics_table)\n",
    "\n",
    "                # # Aspect Zonal statistics  for watersheds\n",
    "                # print(f'Calculating {roi} watershed aspect zonal stats...')\n",
    "                # wtd_asp_metrics_table = ZonalStatisticsAsTable(in_zone_data = wtd_merge, zone_field =\"cat_ID_txt\",\n",
    "                #                                                in_value_raster = asp_rast, out_table = wtd_merge_asp_table_path,\n",
    "                #                                                statistics_type='ALL')\n",
    "                # arcpy.AddField_management(wtd_asp_metrics_table, 'region', field_type='TEXT')\n",
    "                # Add cat_ID_Con field\n",
    "                # arcpy.AddField_management(wtd_asp_metrics_table,'cat_ID_con',field_type='TEXT')\n",
    "                # arcpy.CalculateField_management(wtd_asp_metrics_table, 'region', 'roi')\n",
    "                # Update region field\n",
    "                # with arcpy.da.UpdateCursor(wtd_asp_metrics_table,['region','cat_ID_txt','cat_ID_con']) as cur:\n",
    "                #     for row in cur:\n",
    "                #         row[0] = roi\n",
    "                #         row[2] = roi+\"_\"+row[1]\n",
    "                #         # Update\n",
    "                #         cur.updateRow(row)\n",
    "                #     del(row)\n",
    "                # del(cur)\n",
    "                # wtd_asp_ztables.append(wtd_asp_metrics_table)\n",
    "\n",
    "                # # Aspect Zonal statistics for catchments\n",
    "                # print(f'Calculating {roi} catchment aspect zonal stats...')\n",
    "                # cat_asp_metrics_table = ZonalStatisticsAsTable(in_zone_data = cats, zone_field =\"cat_ID_txt\",\n",
    "                #                                                in_value_raster = asp_rast, out_table = cat_asp_table_path,\n",
    "                #                                                statistics_type='ALL')\n",
    "                # arcpy.AddField_management(cat_asp_metrics_table, 'region', field_type='TEXT')\n",
    "                # Add cat_ID_Con field\n",
    "                # arcpy.AddField_management(cat_asp_metrics_table,'cat_ID_con',field_type='TEXT')\n",
    "                # arcpy.CalculateField_management(cat_asp_metrics_table, 'region', 'roi')\n",
    "                # Update region field\n",
    "                # with arcpy.da.UpdateCursor(cat_asp_metrics_table,['region','cat_ID_txt','cat_ID_con']) as cur:\n",
    "                #     for row in cur:\n",
    "                #         row[0] = roi\n",
    "                #         row[2] = roi+\"_\"+row[1]\n",
    "                #         # Update\n",
    "                #         cur.updateRow(row)\n",
    "                #     del(row)\n",
    "                # del(cur)\n",
    "                # cat_asp_ztables.append(cat_asp_metrics_table)\n",
    "\n",
    "                zstat_stop = time.time()\n",
    "                zstat_time = int (zstat_stop - zstat_start)\n",
    "                print(f'Zonal Stats for {roi} Elapsed time: ({datetime.timedelta(seconds=zstat_time)})')\n",
    "                print('----------')\n",
    "\n",
    "                # Tabulate Area with north grid and watersheds\n",
    "                tabarea_start = time.time()\n",
    "                print(f'Begin tabulate area of north facing cells for watersheds and catchments in {roi} region')\n",
    "                print('----------')\n",
    "                # Percent North Tabulate area for watersheds\n",
    "                wtd_per_north_tabarea = arcpy.sa.TabulateArea(in_zone_data= wtd_merge,\n",
    "                                                              zone_field= wtd_cur_fields[0],\n",
    "                                                              in_class_data=nor_rast,\n",
    "                                                              class_field=\"Value\",\n",
    "                                                              out_table=wtd_merge_pernorth_table_path\n",
    "                                                              )\n",
    "                # Add region and percent north fields\n",
    "                arcpy.AlterField_management(wtd_per_north_tabarea,'CAT_ID_TXT','CAT_ID_TXT_DEL','CAT_ID_TXT_DEL')\n",
    "                arcpy.AddField_management(wtd_per_north_tabarea, 'region', field_type='TEXT')\n",
    "                arcpy.AddField_management(wtd_per_north_tabarea, 'wtd_north_per', field_type='Float')\n",
    "                arcpy.AddField_management(wtd_per_north_tabarea, wtd_cur_fields[0], field_type='TEXT')\n",
    "                arcpy.AddField_management(wtd_per_north_tabarea, wtd_cur_fields[2], field_type='TEXT')\n",
    "                wtdnorfields = [f.name for f in arcpy.ListFields(wtd_per_north_tabarea)]\n",
    "                print (wtdnorfields)\n",
    "                with arcpy.da.UpdateCursor(wtd_per_north_tabarea, wtdnorfields) as cur:\n",
    "                    for row in cur:\n",
    "                        row[4] = roi\n",
    "                        row[5] = row[3]/(row[3]+row[2])*100\n",
    "                        row[6] = row[1]\n",
    "                        row[7] = roi +'_'+ row[1]\n",
    "                        # Update\n",
    "                        cur.updateRow(row)\n",
    "                    del(row)\n",
    "                del(cur)\n",
    "                # Drop UPPERCASE field form tab area\n",
    "                arcpy.DeleteField_management(wtd_per_north_tabarea,'CAT_ID_TXT_DEL')\n",
    "                # Append watershed percent north table to list\n",
    "                wtd_pernorth_taba_tables.append(wtd_per_north_tabarea)\n",
    "\n",
    "                # Percent Lakes Ponds using Tabulate Intersection for watersheds\n",
    "                print(f'Begin tabulate intersection between {lakes_fc} and watersheds in {roi} region')\n",
    "                print('----------')\n",
    "                wtd_lp_tabint = arcpy.TabulateIntersection_analysis(wtd_merge,\n",
    "                                                                    zone_fields=wtd_cur_fields[0],\n",
    "                                                                    in_class_features=lakes_fc,\n",
    "                                                                    out_table=wtd_merge_lp_table_path,\n",
    "                                                                    class_fields='Ftype',\n",
    "                                                                    out_units=\"SQUARE_METERS\"\n",
    "                                                                    )\n",
    "                # Add region and cat id fields\n",
    "                arcpy.AlterField_management(wtd_lp_tabint,'PERCENTAGE','wtd_lake_per','wtd_lake_per')\n",
    "                arcpy.AlterField_management(wtd_lp_tabint,'AREA','wtd_lake_area_sqm','wtd_lake_area_sqm')\n",
    "                arcpy.AddField_management(wtd_lp_tabint, 'region', field_type='TEXT')\n",
    "                arcpy.AddField_management(wtd_lp_tabint, wtd_cur_fields[1], field_type='TEXT')\n",
    "                arcpy.AddField_management(wtd_lp_tabint, wtd_cur_fields[2], field_type='TEXT')\n",
    "                wtdlpfields = [f.name for f in arcpy.ListFields(wtd_lp_tabint)]\n",
    "                print (wtdlpfields)\n",
    "                with arcpy.da.UpdateCursor(wtd_lp_tabint, wtdlpfields) as cur:\n",
    "                    for row in cur:\n",
    "                        row[5] = roi\n",
    "                        row[6] = row[1]\n",
    "                        row[7] = roi +'_'+ row[1]\n",
    "                        # Update\n",
    "                        cur.updateRow(row)\n",
    "                    del(row)\n",
    "                del(cur)\n",
    "\n",
    "                # Append watershed lakes ponds table to list\n",
    "                wtd_lp_tabint_tables.append(wtd_lp_tabint)\n",
    "\n",
    "                # Percent glaciers using Tabulate Intersection for watersheds\n",
    "                print(f'Begin tabulate intersection between {glac_fc} and watersheds in {roi} region')\n",
    "                print('----------')\n",
    "                wtd_glac_tabint = arcpy.TabulateIntersection_analysis(wtd_merge,\n",
    "                                                                    zone_fields=wtd_cur_fields[0],\n",
    "                                                                    in_class_features=glac_fc,\n",
    "                                                                    out_table=wtd_merge_glac_table_path,\n",
    "                                                                    class_fields='O1Region',\n",
    "                                                                    out_units=\"SQUARE_METERS\"\n",
    "                                                                    )\n",
    "                # Add region and cat id fields\n",
    "                arcpy.AlterField_management(wtd_glac_tabint,'PERCENTAGE','wtd_glacier_per','wtd_glacier_per')\n",
    "                arcpy.AlterField_management(wtd_glac_tabint,'AREA','wtd_glacier_area_sqm','wtd_glacier_area_sqm')\n",
    "                arcpy.AddField_management(wtd_glac_tabint, 'region', field_type='TEXT')\n",
    "                arcpy.AddField_management(wtd_glac_tabint, wtd_cur_fields[1], field_type='TEXT')\n",
    "                arcpy.AddField_management(wtd_glac_tabint, wtd_cur_fields[2], field_type='TEXT')\n",
    "                wtdglacfields = [f.name for f in arcpy.ListFields(wtd_glac_tabint)]\n",
    "                print (wtdglacfields)\n",
    "                with arcpy.da.UpdateCursor(wtd_glac_tabint, wtdglacfields) as cur:\n",
    "                    for row in cur:\n",
    "                        row[5] = roi\n",
    "                        row[6] = row[1]\n",
    "                        row[7] = roi +'_'+ row[1]\n",
    "                        # Update\n",
    "                        cur.updateRow(row)\n",
    "                    del(row)\n",
    "                del(cur)\n",
    "                # Append watershed percent north table to list\n",
    "                wtd_glac_tabint_tables.append(wtd_glac_tabint)\n",
    "\n",
    "                # Tabulate Area with wetlands grid and watersheds\n",
    "                print(f'Begin tabulate intersection between {wet_rast} and watersheds in {roi} region')\n",
    "                print('----------')\n",
    "                # Percent North Tabulate area for watersheds\n",
    "                wtd_per_wet_tabarea = arcpy.sa.TabulateArea(in_zone_data= wtd_merge,\n",
    "                                                              zone_field= wtd_cur_fields[0],\n",
    "                                                              in_class_data=wet_rast,\n",
    "                                                              class_field=\"Value\",\n",
    "                                                              out_table=wtd_merge_wetlands_table_path\n",
    "                                                              )\n",
    "                # Add region and percent wet fields\n",
    "                arcpy.AlterField_management(wtd_per_wet_tabarea,'CAT_ID_TXT','CAT_ID_TXT_DEL','CAT_ID_TXT_DEL')\n",
    "                arcpy.AddField_management(wtd_per_wet_tabarea, 'region', field_type='TEXT')\n",
    "                arcpy.AddField_management(wtd_per_wet_tabarea, 'wtd_wet_per', field_type='Float')\n",
    "                arcpy.AddField_management(wtd_per_wet_tabarea, wtd_cur_fields[0], field_type='TEXT')\n",
    "                arcpy.AddField_management(wtd_per_wet_tabarea, wtd_cur_fields[2], field_type='TEXT')\n",
    "                wtdwetfields = [f.name for f in arcpy.ListFields(wtd_per_wet_tabarea)]\n",
    "                print (wtdwetfields)\n",
    "                with arcpy.da.UpdateCursor(wtd_per_wet_tabarea, wtdwetfields) as cur:\n",
    "                    for row in cur:\n",
    "                        row[4] = roi\n",
    "                        row[5] = row[3]/(row[3]+row[2])*100\n",
    "                        row[6] = row[1]\n",
    "                        row[7] = roi +'_'+ row[1]\n",
    "                        # Update\n",
    "                        cur.updateRow(row)\n",
    "                    del(row)\n",
    "                del(cur)\n",
    "                # Drop UPPERCASE field form tab area\n",
    "                arcpy.DeleteField_management(wtd_per_wet_tabarea,'CAT_ID_TXT_DEL')\n",
    "                # Append watershed percent north table to list\n",
    "                wtd_wet_taba_tables.append(wtd_per_wet_tabarea)\n",
    "\n",
    "                # # Percent North Tabulate Area for catchments\n",
    "                # cat_per_north_tabarea = arcpy.sa.TabulateArea(in_zone_data= cats, zone_field='cat_ID_con',\n",
    "                #                                             in_class_data=nor_rast,\"Value\",\n",
    "                #                                             out_table=cat_pernorth_table_path)\n",
    "\n",
    "                # # Add and calculate region identifier field for catchment table\n",
    "                # arcpy.AlterField_management(cat_per_north_tabarea,'CAT_ID_TXT','CAT_ID_TXT_DEL','CAT_ID_TXT_DEL')\n",
    "                # arcpy.AddField_management(cat_per_north_tabarea, 'region', field_type='TEXT')\n",
    "                # arcpy.AddField_management(cat_per_north_tabarea, 'cat_north_per', field_type='Float')\n",
    "                # arcpy.AddField_management(cat_per_north_tabarea, cat_cur_fields[0], field_type='TEXT')\n",
    "                # arcpy.AddField_management(cat_per_north_tabarea, cat_cur_fields[2], field_type='TEXT')\n",
    "                # catnorfields = [f.name for f in arcpy.ListFields(cat_per_north_tabarea)]\n",
    "                # print (catnorfields)\n",
    "                # with arcpy.da.UpdateCursor(cat_per_north_tabarea,catnorfields) as cur:\n",
    "                #     for row in cur:\n",
    "                #         row[4] = roi\n",
    "                #         row[5] = row[3]/(row[3]+row[2])*100\n",
    "                #         row[6] = row[1]\n",
    "                #         row[7] = roi +'_'+ row[1]\n",
    "                #         # Update\n",
    "                #         cur.updateRow(row)\n",
    "                #     del(row)\n",
    "                # del(cur)\n",
    "                # Drop UPPERCASE field form tab area\n",
    "                # arcpy.DeleteField_management(cat_per_north_tabarea,'CAT_ID_TXT_DEL')\n",
    "                # # Append catchment percent north table to list\n",
    "                # cat_pernorth_taba_tables.append(cat_per_north_tabarea)\n",
    "\n",
    "                tabarea_stop = time.time()\n",
    "                tabarea_time = int (tabarea_stop - tabarea_start)\n",
    "                print(f'Tabulate area/intersections for {roi} Elapsed time: ({datetime.timedelta(seconds=tabarea_time)})')\n",
    "                print('----------')\n",
    "\n",
    "            except:\n",
    "                e = sys.exc_info()[1]\n",
    "                print(e.args[0])\n",
    "                arcpy.AddError(e.args[0])\n",
    "\n",
    "            iter_stop = time.time()\n",
    "            iter_time = int(iter_stop - iteration_start)\n",
    "            print(f'All Covariates for {roi} completed. Elapsed time: ({datetime.timedelta(seconds=iter_time)})')\n",
    "            print('----------')\n",
    "\n",
    "    else:\n",
    "        print(f'Region {str(roi)} not found in {region}')\n",
    "\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "\n",
    "# Report success\n",
    "print(f'Process completed at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "      f'(Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print('----------')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Drop unnecessary fields and rename as needed from merged tables.\n",
    "- Create Key value dictionary and use update cursor to rename fields."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables merged\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Lists to store output tables\n",
    "# wtd_pernorth_taba_tables=[]\n",
    "# wtd_lp_tabint_tables = []\n",
    "# wtd_glac_tabint_tables = []\n",
    "# wtd_wet_taba_tables = []\n",
    "# cat_elev_ztables = []\n",
    "# wtd_elev_ztables = []\n",
    "# cat_slope_ztables = []\n",
    "# wtd_slope_ztables = []\n",
    "\n",
    "# Table names/paths\n",
    "wtd_per_north_table_out = os.path.join(outgdb, 'AKSSF_wtd_north_per')\n",
    "cat_elev_table_out = os.path.join(outgdb,'AKSSF_cat_elev')\n",
    "cat_slope_table_out = os.path.join(outgdb,'AKSSF_cat_slope')\n",
    "wtd_elev_table_out = os.path.join(outgdb, 'AKSSF_wtd_elev')\n",
    "wtd_per_glac_table_out = os.path.join(outgdb, 'AKSSF_wtd_glacier_per')\n",
    "wtd_per_lp_table_out = os.path.join(outgdb, 'AKSSF_wtd_lakepond_per')\n",
    "wtd_slope_table_out = os.path.join(outgdb, 'AKSSF_wtd_slope')\n",
    "wtd_wet_table_out = os.path.join(outgdb, 'AKSSF_wtd_wetland_per')\n",
    "\n",
    "# Merge all regional tables together\n",
    "outtables = []\n",
    "wtd_per_north = arcpy.Merge_management(wtd_pernorth_taba_tables, wtd_per_north_table_out)\n",
    "arcpy.AlterField_management(wtd_per_north,\"VALUE_0\",\"non_north_area\",\"non_north_area\")\n",
    "arcpy.AlterField_management(wtd_per_north,\"VALUE_1\",\"north_area\",\"north_area\")\n",
    "outtables.append(wtd_per_north)\n",
    "cat_elev = arcpy.Merge_management(cat_elev_ztables, cat_elev_table_out)\n",
    "outtables.append(cat_elev)\n",
    "wtd_elev = arcpy.Merge_management(wtd_elev_ztables, wtd_elev_table_out)\n",
    "outtables.append(wtd_elev)\n",
    "wtd_slope = arcpy.Merge_management(wtd_slope_ztables, wtd_slope_table_out)\n",
    "outtables.append(wtd_slope)\n",
    "cat_slope = arcpy.Merge_management(cat_slope_ztables, cat_slope_table_out)\n",
    "outtables.append(cat_slope)\n",
    "wtd_wet = arcpy.Merge_management(wtd_wet_taba_tables, wtd_wet_table_out)\n",
    "arcpy.AlterField_management(wtd_wet,\"VALUE_0\",\"non_wetland_area\",\"non_wetland_area\")\n",
    "arcpy.AlterField_management(wtd_wet,\"VALUE_1\",\"wetland_area\",\"wetland_area\")\n",
    "outtables.append(wtd_wet)\n",
    "wtd_glac = arcpy.Merge_management(wtd_glac_tabint_tables, wtd_per_glac_table_out)\n",
    "outtables.append(wtd_glac)\n",
    "wtd_lp = arcpy.Merge_management(wtd_lp_tabint_tables, wtd_per_lp_table_out)\n",
    "outtables.append(wtd_lp)\n",
    "print ('Tables merged')\n",
    "print('----------')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZONE_CODE wtd_elev_ZONE_CODE\n",
      "COUNT wtd_elev_COUNT\n",
      "AREA wtd_elev_AREA\n",
      "MIN wtd_elev_MIN\n",
      "MAX wtd_elev_MAX\n",
      "RANGE wtd_elev_RANGE\n",
      "MEAN wtd_elev_MEAN\n",
      "STD wtd_elev_STD\n",
      "SUM wtd_elev_SUM\n",
      "VARIETY wtd_elev_VARIETY\n",
      "MAJORITY wtd_elev_MAJORITY\n",
      "MINORITY wtd_elev_MINORITY\n",
      "MEDIAN wtd_elev_MEDIAN\n",
      "PCT90 wtd_elev_PCT90\n",
      "ZONE_CODE cat_elev_ZONE_CODE\n",
      "COUNT cat_elev_COUNT\n",
      "AREA cat_elev_AREA\n",
      "MIN cat_elev_MIN\n",
      "MAX cat_elev_MAX\n",
      "RANGE cat_elev_RANGE\n",
      "MEAN cat_elev_MEAN\n",
      "STD cat_elev_STD\n",
      "SUM cat_elev_SUM\n",
      "VARIETY cat_elev_VARIETY\n",
      "MAJORITY cat_elev_MAJORITY\n",
      "MINORITY cat_elev_MINORITY\n",
      "MEDIAN cat_elev_MEDIAN\n",
      "PCT90 cat_elev_PCT90\n",
      "ZONE_CODE wtd_slope_ZONE_CODE\n",
      "COUNT wtd_slope_COUNT\n",
      "AREA wtd_slope_AREA\n",
      "MIN wtd_slope_MIN\n",
      "MAX wtd_slope_MAX\n",
      "RANGE wtd_slope_RANGE\n",
      "MEAN wtd_slope_MEAN\n",
      "STD wtd_slope_STD\n",
      "SUM wtd_slope_SUM\n",
      "MEDIAN wtd_slope_MEDIAN\n",
      "PCT90 wtd_slope_PCT90\n",
      "ZONE_CODE cat_slope_ZONE_CODE\n",
      "COUNT cat_slope_COUNT\n",
      "AREA cat_slope_AREA\n",
      "MIN cat_slope_MIN\n",
      "MAX cat_slope_MAX\n",
      "RANGE cat_slope_RANGE\n",
      "MEAN cat_slope_MEAN\n",
      "STD cat_slope_STD\n",
      "SUM cat_slope_SUM\n",
      "MEDIAN cat_slope_MEDIAN\n",
      "PCT90 cat_slope_PCT90\n"
     ]
    }
   ],
   "source": [
    "#Set up field dictionary\n",
    "elevDict = { 'ZONE_CODE': ('cat_elev_ZONE_CODE', 'wtd_elev_ZONE_CODE'),\n",
    "         'COUNT': ('cat_elev_COUNT', 'wtd_elev_COUNT'),\n",
    "          'AREA': ('cat_elev_AREA', 'wtd_elev_AREA'),\n",
    "          'MIN': ('cat_elev_MIN', 'wtd_elev_MIN'),\n",
    "          'MAX': ('cat_elev_MAX', 'wtd_elev_MAX'),\n",
    "          'RANGE': ('cat_elev_RANGE', 'wtd_elev_RANGE'),\n",
    "          'MEAN': ('cat_elev_MEAN', 'wtd_elev_MEAN'),\n",
    "          'STD': ('cat_elev_STD', 'wtd_elev_STD'),\n",
    "          'SUM': ('cat_elev_SUM', 'wtd_elev_SUM'),\n",
    "          'VARIETY': ('cat_elev_VARIETY', 'wtd_elev_VARIETY'),\n",
    "          'MAJORITY': ('cat_elev_MAJORITY', 'wtd_elev_MAJORITY'),\n",
    "          'MINORITY': ('cat_elev_MINORITY', 'wtd_elev_MINORITY'),\n",
    "          'MEDIAN': ('cat_elev_MEDIAN', 'wtd_elev_MEDIAN'),\n",
    "          'PCT90': ('cat_elev_PCT90', 'wtd_elev_PCT90')\n",
    "         }\n",
    "\n",
    "slopeDict = { 'ZONE_CODE': ('cat_slope_ZONE_CODE', 'wtd_slope_ZONE_CODE'),\n",
    "         'COUNT': ('cat_slope_COUNT', 'wtd_slope_COUNT'),\n",
    "          'AREA': ('cat_slope_AREA', 'wtd_slope_AREA'),\n",
    "          'MIN': ('cat_slope_MIN', 'wtd_slope_MIN'),\n",
    "          'MAX': ('cat_slope_MAX', 'wtd_slope_MAX'),\n",
    "          'RANGE': ('cat_slope_RANGE', 'wtd_slope_RANGE'),\n",
    "          'MEAN': ('cat_slope_MEAN', 'wtd_slope_MEAN'),\n",
    "          'STD': ('cat_slope_STD', 'wtd_slope_STD'),\n",
    "          'SUM': ('cat_slope_SUM', 'wtd_slope_SUM'),\n",
    "          'VARIETY': ('cat_slope_VARIETY', 'wtd_slope_VARIETY'),\n",
    "          'MAJORITY': ('cat_slope_MAJORITY', 'wtd_slope_MAJORITY'),\n",
    "          'MINORITY': ('cat_slope_MINORITY', 'wtd_slope_MINORITY'),\n",
    "          'MEDIAN': ('cat_slope_MEDIAN', 'wtd_slope_MEDIAN'),\n",
    "          'PCT90': ('cat_slope_PCT90', 'wtd_slope_PCT90')\n",
    "         }\n",
    "\n",
    "# Rename fields for elevation tables\n",
    "for field in arcpy.ListFields(wtd_elev):\n",
    "    keyval = field.name\n",
    "    if keyval in elevDict:\n",
    "        newname = elevDict[keyval][1]\n",
    "        newalias = elevDict[keyval][1]\n",
    "        print (keyval, newname)\n",
    "        arcpy.AlterField_management(wtd_elev, keyval, newname, newalias)\n",
    "\n",
    "for field in arcpy.ListFields(cat_elev):\n",
    "    keyval = field.name\n",
    "    if keyval in elevDict:\n",
    "        newname = elevDict[keyval][0]\n",
    "        newalias = elevDict[keyval][0]\n",
    "        print (keyval, newname)\n",
    "        arcpy.AlterField_management(cat_elev, keyval, newname, newalias)\n",
    "\n",
    "# Rename fields for slope tables\n",
    "for field in arcpy.ListFields(wtd_slope):\n",
    "    keyval = field.name\n",
    "    if keyval in slopeDict:\n",
    "        newname = slopeDict[keyval][1]\n",
    "        newalias = slopeDict[keyval][1]\n",
    "        print (keyval, newname)\n",
    "        arcpy.AlterField_management(wtd_slope, keyval, newname, newalias)\n",
    "\n",
    "for field in arcpy.ListFields(cat_slope):\n",
    "    keyval = field.name\n",
    "    if keyval in slopeDict:\n",
    "        newname = slopeDict[keyval][0]\n",
    "        newalias = slopeDict[keyval][0]\n",
    "        print (keyval, newname)\n",
    "        arcpy.AlterField_management(cat_slope, keyval, newname, newalias)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AKSSF_wtd_north_per\n",
      "AKSSF_cat_elev\n",
      "AKSSF_wtd_elev\n",
      "AKSSF_wtd_slope\n",
      "AKSSF_cat_slope\n",
      "AKSSF_wtd_wetland_per\n",
      "AKSSF_wtd_glacier_per\n",
      "AKSSF_wtd_lakepond_per\n"
     ]
    }
   ],
   "source": [
    "for table in outtables:\n",
    "    print (arcpy.Describe(table).basename)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_wtd_north_per.csv\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_cat_elev.csv\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_wtd_elev.csv\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_wtd_slope.csv\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_cat_slope.csv\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_wtd_wetland_per.csv\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_wtd_glacier_per.csv\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_wtd_lakepond_per.csv\n"
     ]
    }
   ],
   "source": [
    "# Export copies of dbf tables as csv\n",
    "outdir = r\"C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\"\n",
    "for table in outtables:\n",
    "    tablename = arcpy.Describe(table).basename + \".csv\"\n",
    "    tablepath = os.path.join(outdir,tablename)\n",
    "    print( tablepath)\n",
    "    arcpy.conversion.TableToTable(table, outdir, tablename)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "<Result 'C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\AKSSF\\\\data_preparation\\\\sensitivity_drivers\\\\AKSSF_Covariates.csv'>",
      "text/html": "<h2>Output</h2>C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\AKSSF_Covariates.csv<h2>Messages</h2>Start Time: Wednesday, October 27, 2021 02:23:14<br/>Succeeded at Wednesday, October 27, 2021 02:23:15 (Elapsed Time: 0.34 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge all\n",
    "alltables = os.path.join(outgdb, \"AKSSF_Covariates\")\n",
    "alltablesname = 'AKSSF_Covariates.csv'\n",
    "akssf_cov_tables_merge = arcpy.Merge_management(outtables, alltables)\n",
    "arcpy.conversion.TableToTable(akssf_cov_tables_merge, outdir, alltablesname)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert tables to pandas df and explore results\n",
    "* **Merge tables and export to csv**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.2f}'.format # only display 2 decimal places\n",
    "# list to store covariate data frames\n",
    "dfs = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "                  cat_elev_COUNT  cat_elev_AREA  cat_elev_MIN  cat_elev_MAX  \\\ncat_ID_txt                                                                    \n75004200007057.0        38470.00      961750.00             0           908   \n75004300006312.0        57563.00     1439075.00            59            98   \n75004300001906.0        12127.00      303175.00             3           146   \n75004300000100.0        78759.00     1968975.00            33            78   \n75004300004983.0       113568.00     2839200.00            21           479   \n...                          ...            ...           ...           ...   \n43933                    3776.00      377600.00             0           512   \n43973                    2363.00      236300.00             1           362   \n44553                    3888.00      388800.00             0            35   \n44623                    4300.00      430000.00             0            13   \n46055                    1455.00      145500.00             2            70   \n\n                  cat_elev_RANGE  cat_elev_MEAN  cat_elev_STD  cat_elev_SUM  \\\ncat_ID_txt                                                                    \n75004200007057.0             908         346.00        251.07   13310762.00   \n75004300006312.0              39          76.31          9.37    4392462.00   \n75004300001906.0             143          27.85         21.37     337746.00   \n75004300000100.0              45          58.67          8.23    4620998.00   \n75004300004983.0             458         265.10        100.44   30107239.00   \n...                          ...            ...           ...           ...   \n43933                        512         222.92        164.12     841739.00   \n43973                        361          52.16         67.87     123252.00   \n44553                         35           4.44          3.49      17249.00   \n44623                         13           5.56          2.99      23918.00   \n46055                         68          17.64         13.27      25660.00   \n\n                  cat_elev_VARIETY  cat_elev_MAJORITY  cat_elev_MINORITY  \\\ncat_ID_txt                                                                 \n75004200007057.0               909                  4                908   \n75004300006312.0                40                 69                 59   \n75004300001906.0               142                  9                132   \n75004300000100.0                46                 65                 33   \n75004300004983.0               459                336                 24   \n...                            ...                ...                ...   \n43933                          512                  4                 32   \n43973                          258                  4                141   \n44553                           34                  5                 17   \n44623                           14                  6                 13   \n46055                           68                  3                 59   \n\n                  cat_elev_MEDIAN  \ncat_ID_txt                         \n75004200007057.0              333  \n75004300006312.0               74  \n75004300001906.0               21  \n75004300000100.0               59  \n75004300004983.0              282  \n...                           ...  \n43933                         222  \n43973                          20  \n44553                           4  \n44623                           6  \n46055                          16  \n\n[428 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat_elev_COUNT</th>\n      <th>cat_elev_AREA</th>\n      <th>cat_elev_MIN</th>\n      <th>cat_elev_MAX</th>\n      <th>cat_elev_RANGE</th>\n      <th>cat_elev_MEAN</th>\n      <th>cat_elev_STD</th>\n      <th>cat_elev_SUM</th>\n      <th>cat_elev_VARIETY</th>\n      <th>cat_elev_MAJORITY</th>\n      <th>cat_elev_MINORITY</th>\n      <th>cat_elev_MEDIAN</th>\n    </tr>\n    <tr>\n      <th>cat_ID_txt</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>75004200007057.0</th>\n      <td>38470.00</td>\n      <td>961750.00</td>\n      <td>0</td>\n      <td>908</td>\n      <td>908</td>\n      <td>346.00</td>\n      <td>251.07</td>\n      <td>13310762.00</td>\n      <td>909</td>\n      <td>4</td>\n      <td>908</td>\n      <td>333</td>\n    </tr>\n    <tr>\n      <th>75004300006312.0</th>\n      <td>57563.00</td>\n      <td>1439075.00</td>\n      <td>59</td>\n      <td>98</td>\n      <td>39</td>\n      <td>76.31</td>\n      <td>9.37</td>\n      <td>4392462.00</td>\n      <td>40</td>\n      <td>69</td>\n      <td>59</td>\n      <td>74</td>\n    </tr>\n    <tr>\n      <th>75004300001906.0</th>\n      <td>12127.00</td>\n      <td>303175.00</td>\n      <td>3</td>\n      <td>146</td>\n      <td>143</td>\n      <td>27.85</td>\n      <td>21.37</td>\n      <td>337746.00</td>\n      <td>142</td>\n      <td>9</td>\n      <td>132</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>75004300000100.0</th>\n      <td>78759.00</td>\n      <td>1968975.00</td>\n      <td>33</td>\n      <td>78</td>\n      <td>45</td>\n      <td>58.67</td>\n      <td>8.23</td>\n      <td>4620998.00</td>\n      <td>46</td>\n      <td>65</td>\n      <td>33</td>\n      <td>59</td>\n    </tr>\n    <tr>\n      <th>75004300004983.0</th>\n      <td>113568.00</td>\n      <td>2839200.00</td>\n      <td>21</td>\n      <td>479</td>\n      <td>458</td>\n      <td>265.10</td>\n      <td>100.44</td>\n      <td>30107239.00</td>\n      <td>459</td>\n      <td>336</td>\n      <td>24</td>\n      <td>282</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43933</th>\n      <td>3776.00</td>\n      <td>377600.00</td>\n      <td>0</td>\n      <td>512</td>\n      <td>512</td>\n      <td>222.92</td>\n      <td>164.12</td>\n      <td>841739.00</td>\n      <td>512</td>\n      <td>4</td>\n      <td>32</td>\n      <td>222</td>\n    </tr>\n    <tr>\n      <th>43973</th>\n      <td>2363.00</td>\n      <td>236300.00</td>\n      <td>1</td>\n      <td>362</td>\n      <td>361</td>\n      <td>52.16</td>\n      <td>67.87</td>\n      <td>123252.00</td>\n      <td>258</td>\n      <td>4</td>\n      <td>141</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>44553</th>\n      <td>3888.00</td>\n      <td>388800.00</td>\n      <td>0</td>\n      <td>35</td>\n      <td>35</td>\n      <td>4.44</td>\n      <td>3.49</td>\n      <td>17249.00</td>\n      <td>34</td>\n      <td>5</td>\n      <td>17</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>44623</th>\n      <td>4300.00</td>\n      <td>430000.00</td>\n      <td>0</td>\n      <td>13</td>\n      <td>13</td>\n      <td>5.56</td>\n      <td>2.99</td>\n      <td>23918.00</td>\n      <td>14</td>\n      <td>6</td>\n      <td>13</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>46055</th>\n      <td>1455.00</td>\n      <td>145500.00</td>\n      <td>2</td>\n      <td>70</td>\n      <td>68</td>\n      <td>17.64</td>\n      <td>13.27</td>\n      <td>25660.00</td>\n      <td>68</td>\n      <td>3</td>\n      <td>59</td>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n<p>428 rows  12 columns</p>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make catchment elev df\n",
    "cat_df = pd.DataFrame()\n",
    "cat_field_list = []\n",
    "for field in arcpy.ListFields(cat_elev):\n",
    "    cat_field_list.append(field.name)\n",
    "cat_elev_arr = arcpy.da.TableToNumPyArray(cat_elev,cat_field_list)\n",
    "cat_df = pd.DataFrame(cat_elev_arr)\n",
    "cat_df = cat_df.drop([\"OBJECTID\",\"cat_elev_ZONE_CODE\"],axis=1)\n",
    "cat_df = cat_df.set_index('cat_ID_txt')\n",
    "dfs.append(cat_df)\n",
    "cat_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJECTID OBJECTID\n",
      "cat_ID_txt cat_ID_txt\n",
      "cat_slope_ZONE_CODE cat_slope_ZONE_CODE\n",
      "cat_slope_COUNT cat_slope_COUNT\n",
      "cat_slope_AREA cat_slope_AREA\n",
      "cat_slope_MIN cat_slope_MIN\n",
      "cat_slope_MAX cat_slope_MAX\n",
      "cat_slope_RANGE cat_slope_RANGE\n",
      "cat_slope_MEAN cat_slope_MEAN\n",
      "cat_slope_STD cat_slope_STD\n",
      "cat_slope_SUM cat_slope_SUM\n",
      "cat_slope_MEDIAN cat_slope_MEDIAN\n",
      "cat_slope_PCT90 cat_slope_PCT90\n",
      "region region\n",
      "cat_ID_con cat_ID_con\n"
     ]
    },
    {
     "data": {
      "text/plain": "                  cat_slope_COUNT  cat_slope_AREA  cat_slope_MIN  \\\ncat_ID_txt                                                         \n75004200007057.0         38470.00       961750.00           0.00   \n75004300006312.0         57563.00      1439075.00           0.00   \n75004300001906.0         12127.00       303175.00           0.00   \n75004300000100.0         78759.00      1968975.00           0.00   \n75004300004983.0        113568.00      2839200.00           0.00   \n...                           ...             ...            ...   \n43933                     3776.00       377600.00           0.00   \n43973                     2363.00       236300.00           0.00   \n44553                     3888.00       388800.00           0.00   \n44623                     4300.00       430000.00           0.00   \n46055                     1455.00       145500.00           0.00   \n\n                  cat_slope_MAX  cat_slope_RANGE  cat_slope_MEAN  \\\ncat_ID_txt                                                         \n75004200007057.0          51.53            51.53           24.00   \n75004300006312.0          25.87            25.87            3.99   \n75004300001906.0          42.81            42.81            9.36   \n75004300000100.0          51.12            51.12            4.12   \n75004300004983.0          58.81            58.81           17.92   \n...                         ...              ...             ...   \n43933                      1.05             1.05            0.35   \n43973                      0.89             0.89            0.16   \n44553                      0.23             0.23            0.04   \n44623                      0.29             0.29            0.04   \n46055                      0.21             0.21            0.06   \n\n                  cat_slope_STD  cat_slope_SUM  cat_slope_MEDIAN  \\\ncat_ID_txt                                                         \n75004200007057.0          11.34      923424.18             26.77   \n75004300006312.0           3.30      229592.37              3.91   \n75004300001906.0           8.12      113559.70              6.35   \n75004300000100.0           4.13      324142.71              3.79   \n75004300004983.0          10.56     2035012.13             16.38   \n...                         ...            ...               ...   \n43933                      0.19        1323.08              0.39   \n43973                      0.16         372.47              0.11   \n44553                      0.04         161.89              0.03   \n44623                      0.05         182.51              0.03   \n46055                      0.04          92.81              0.06   \n\n                  cat_slope_PCT90                region  \\\ncat_ID_txt                                                \n75004200007057.0            36.20            Cook_Inlet   \n75004300006312.0             8.12            Cook_Inlet   \n75004300001906.0            22.22            Cook_Inlet   \n75004300000100.0             8.95            Cook_Inlet   \n75004300004983.0            32.59            Cook_Inlet   \n...                           ...                   ...   \n43933                        0.56  Prince_William_Sound   \n43973                        0.34  Prince_William_Sound   \n44553                        0.09  Prince_William_Sound   \n44623                        0.11  Prince_William_Sound   \n46055                        0.13  Prince_William_Sound   \n\n                                   cat_ID_con  \ncat_ID_txt                                     \n75004200007057.0  Cook_Inlet_75004200007057.0  \n75004300006312.0  Cook_Inlet_75004300006312.0  \n75004300001906.0  Cook_Inlet_75004300001906.0  \n75004300000100.0  Cook_Inlet_75004300000100.0  \n75004300004983.0  Cook_Inlet_75004300004983.0  \n...                                       ...  \n43933              Prince_William_Sound_43933  \n43973              Prince_William_Sound_43973  \n44553              Prince_William_Sound_44553  \n44623              Prince_William_Sound_44623  \n46055              Prince_William_Sound_46055  \n\n[428 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat_slope_COUNT</th>\n      <th>cat_slope_AREA</th>\n      <th>cat_slope_MIN</th>\n      <th>cat_slope_MAX</th>\n      <th>cat_slope_RANGE</th>\n      <th>cat_slope_MEAN</th>\n      <th>cat_slope_STD</th>\n      <th>cat_slope_SUM</th>\n      <th>cat_slope_MEDIAN</th>\n      <th>cat_slope_PCT90</th>\n      <th>region</th>\n      <th>cat_ID_con</th>\n    </tr>\n    <tr>\n      <th>cat_ID_txt</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>75004200007057.0</th>\n      <td>38470.00</td>\n      <td>961750.00</td>\n      <td>0.00</td>\n      <td>51.53</td>\n      <td>51.53</td>\n      <td>24.00</td>\n      <td>11.34</td>\n      <td>923424.18</td>\n      <td>26.77</td>\n      <td>36.20</td>\n      <td>Cook_Inlet</td>\n      <td>Cook_Inlet_75004200007057.0</td>\n    </tr>\n    <tr>\n      <th>75004300006312.0</th>\n      <td>57563.00</td>\n      <td>1439075.00</td>\n      <td>0.00</td>\n      <td>25.87</td>\n      <td>25.87</td>\n      <td>3.99</td>\n      <td>3.30</td>\n      <td>229592.37</td>\n      <td>3.91</td>\n      <td>8.12</td>\n      <td>Cook_Inlet</td>\n      <td>Cook_Inlet_75004300006312.0</td>\n    </tr>\n    <tr>\n      <th>75004300001906.0</th>\n      <td>12127.00</td>\n      <td>303175.00</td>\n      <td>0.00</td>\n      <td>42.81</td>\n      <td>42.81</td>\n      <td>9.36</td>\n      <td>8.12</td>\n      <td>113559.70</td>\n      <td>6.35</td>\n      <td>22.22</td>\n      <td>Cook_Inlet</td>\n      <td>Cook_Inlet_75004300001906.0</td>\n    </tr>\n    <tr>\n      <th>75004300000100.0</th>\n      <td>78759.00</td>\n      <td>1968975.00</td>\n      <td>0.00</td>\n      <td>51.12</td>\n      <td>51.12</td>\n      <td>4.12</td>\n      <td>4.13</td>\n      <td>324142.71</td>\n      <td>3.79</td>\n      <td>8.95</td>\n      <td>Cook_Inlet</td>\n      <td>Cook_Inlet_75004300000100.0</td>\n    </tr>\n    <tr>\n      <th>75004300004983.0</th>\n      <td>113568.00</td>\n      <td>2839200.00</td>\n      <td>0.00</td>\n      <td>58.81</td>\n      <td>58.81</td>\n      <td>17.92</td>\n      <td>10.56</td>\n      <td>2035012.13</td>\n      <td>16.38</td>\n      <td>32.59</td>\n      <td>Cook_Inlet</td>\n      <td>Cook_Inlet_75004300004983.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43933</th>\n      <td>3776.00</td>\n      <td>377600.00</td>\n      <td>0.00</td>\n      <td>1.05</td>\n      <td>1.05</td>\n      <td>0.35</td>\n      <td>0.19</td>\n      <td>1323.08</td>\n      <td>0.39</td>\n      <td>0.56</td>\n      <td>Prince_William_Sound</td>\n      <td>Prince_William_Sound_43933</td>\n    </tr>\n    <tr>\n      <th>43973</th>\n      <td>2363.00</td>\n      <td>236300.00</td>\n      <td>0.00</td>\n      <td>0.89</td>\n      <td>0.89</td>\n      <td>0.16</td>\n      <td>0.16</td>\n      <td>372.47</td>\n      <td>0.11</td>\n      <td>0.34</td>\n      <td>Prince_William_Sound</td>\n      <td>Prince_William_Sound_43973</td>\n    </tr>\n    <tr>\n      <th>44553</th>\n      <td>3888.00</td>\n      <td>388800.00</td>\n      <td>0.00</td>\n      <td>0.23</td>\n      <td>0.23</td>\n      <td>0.04</td>\n      <td>0.04</td>\n      <td>161.89</td>\n      <td>0.03</td>\n      <td>0.09</td>\n      <td>Prince_William_Sound</td>\n      <td>Prince_William_Sound_44553</td>\n    </tr>\n    <tr>\n      <th>44623</th>\n      <td>4300.00</td>\n      <td>430000.00</td>\n      <td>0.00</td>\n      <td>0.29</td>\n      <td>0.29</td>\n      <td>0.04</td>\n      <td>0.05</td>\n      <td>182.51</td>\n      <td>0.03</td>\n      <td>0.11</td>\n      <td>Prince_William_Sound</td>\n      <td>Prince_William_Sound_44623</td>\n    </tr>\n    <tr>\n      <th>46055</th>\n      <td>1455.00</td>\n      <td>145500.00</td>\n      <td>0.00</td>\n      <td>0.21</td>\n      <td>0.21</td>\n      <td>0.06</td>\n      <td>0.04</td>\n      <td>92.81</td>\n      <td>0.06</td>\n      <td>0.13</td>\n      <td>Prince_William_Sound</td>\n      <td>Prince_William_Sound_46055</td>\n    </tr>\n  </tbody>\n</table>\n<p>428 rows  12 columns</p>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make catchment slope df\n",
    "cat_sl_df = pd.DataFrame()\n",
    "cat_sl_field_list = []\n",
    "for field in arcpy.ListFields(cat_slope):\n",
    "    cat_sl_field_list.append(field.name)\n",
    "    print (field.name, field.aliasName)\n",
    "cat_sl_arr = arcpy.da.TableToNumPyArray(cat_slope, cat_sl_field_list)\n",
    "cat_sl_df = pd.DataFrame(cat_sl_arr)\n",
    "cat_sl_df = cat_sl_df.drop([\"OBJECTID\", \"cat_slope_ZONE_CODE\"],axis=1)\n",
    "cat_sl_df = cat_sl_df.set_index('cat_ID_txt')\n",
    "dfs.append(cat_sl_df)\n",
    "cat_sl_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "                  wtd_elev_COUNT  wtd_elev_AREA  wtd_elev_MIN  wtd_elev_MAX  \\\ncat_ID_txt                                                                    \n75004200007057.0       258675.00     6466875.00             0          1443   \n75004300006312.0      6167928.00   154198200.00            59           569   \n75004300001906.0      3674802.00    91870050.00             3           767   \n75004300000100.0      1158019.00    28950475.00            34           415   \n75004300004983.0       609413.00    15235325.00            21          1468   \n...                          ...            ...           ...           ...   \n43933.0                328912.00    32891200.00             0          3324   \n43973.0                172326.00    17232600.00             1          3324   \n44553.0                508260.00    50826000.00             0          3324   \n44623.0                354677.00    35467700.00             0          3324   \n46055.0                 32971.00     3297100.00             2          3324   \n\n                  wtd_elev_RANGE  wtd_elev_MEAN  wtd_elev_STD  wtd_elev_SUM  \\\ncat_ID_txt                                                                    \n75004200007057.0            1443         430.06        372.54  111247003.00   \n75004300006312.0             510         250.99        117.77 1548112719.00   \n75004300001906.0             764         401.48        119.92 1475371075.00   \n75004300000100.0             381         156.26         85.69  180956824.00   \n75004300004983.0            1447         672.58        333.96  409876549.00   \n...                          ...            ...           ...           ...   \n43933.0                     3324         659.88        420.19  217042673.00   \n43973.0                     3323         487.63        501.77   84030647.00   \n44553.0                     3324         617.58        428.77  313889063.00   \n44623.0                     3324         451.24        473.36  160046103.00   \n46055.0                     3322         542.06       1061.32   17872287.00   \n\n                  wtd_elev_VARIETY  wtd_elev_MAJORITY  wtd_elev_MINORITY  \\\ncat_ID_txt                                                                 \n75004200007057.0              1444                  5               1422   \n75004300006312.0               511                126                569   \n75004300001906.0               765                377                  3   \n75004300000100.0               382                 91                415   \n75004300004983.0              1448                336               1467   \n...                            ...                ...                ...   \n43933.0                       2275                200               1355   \n43973.0                       2021                254               1164   \n44553.0                       2515                 45               1493   \n44623.0                       2099                 19               1248   \n46055.0                        977                115                148   \n\n                  wtd_elev_MEDIAN  \ncat_ID_txt                         \n75004200007057.0              343  \n75004300006312.0              227  \n75004300001906.0              402  \n75004300000100.0              128  \n75004300004983.0              651  \n...                           ...  \n43933.0                       654  \n43973.0                       394  \n44553.0                       592  \n44623.0                       376  \n46055.0                        95  \n\n[430 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>wtd_elev_COUNT</th>\n      <th>wtd_elev_AREA</th>\n      <th>wtd_elev_MIN</th>\n      <th>wtd_elev_MAX</th>\n      <th>wtd_elev_RANGE</th>\n      <th>wtd_elev_MEAN</th>\n      <th>wtd_elev_STD</th>\n      <th>wtd_elev_SUM</th>\n      <th>wtd_elev_VARIETY</th>\n      <th>wtd_elev_MAJORITY</th>\n      <th>wtd_elev_MINORITY</th>\n      <th>wtd_elev_MEDIAN</th>\n    </tr>\n    <tr>\n      <th>cat_ID_txt</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>75004200007057.0</th>\n      <td>258675.00</td>\n      <td>6466875.00</td>\n      <td>0</td>\n      <td>1443</td>\n      <td>1443</td>\n      <td>430.06</td>\n      <td>372.54</td>\n      <td>111247003.00</td>\n      <td>1444</td>\n      <td>5</td>\n      <td>1422</td>\n      <td>343</td>\n    </tr>\n    <tr>\n      <th>75004300006312.0</th>\n      <td>6167928.00</td>\n      <td>154198200.00</td>\n      <td>59</td>\n      <td>569</td>\n      <td>510</td>\n      <td>250.99</td>\n      <td>117.77</td>\n      <td>1548112719.00</td>\n      <td>511</td>\n      <td>126</td>\n      <td>569</td>\n      <td>227</td>\n    </tr>\n    <tr>\n      <th>75004300001906.0</th>\n      <td>3674802.00</td>\n      <td>91870050.00</td>\n      <td>3</td>\n      <td>767</td>\n      <td>764</td>\n      <td>401.48</td>\n      <td>119.92</td>\n      <td>1475371075.00</td>\n      <td>765</td>\n      <td>377</td>\n      <td>3</td>\n      <td>402</td>\n    </tr>\n    <tr>\n      <th>75004300000100.0</th>\n      <td>1158019.00</td>\n      <td>28950475.00</td>\n      <td>34</td>\n      <td>415</td>\n      <td>381</td>\n      <td>156.26</td>\n      <td>85.69</td>\n      <td>180956824.00</td>\n      <td>382</td>\n      <td>91</td>\n      <td>415</td>\n      <td>128</td>\n    </tr>\n    <tr>\n      <th>75004300004983.0</th>\n      <td>609413.00</td>\n      <td>15235325.00</td>\n      <td>21</td>\n      <td>1468</td>\n      <td>1447</td>\n      <td>672.58</td>\n      <td>333.96</td>\n      <td>409876549.00</td>\n      <td>1448</td>\n      <td>336</td>\n      <td>1467</td>\n      <td>651</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43933.0</th>\n      <td>328912.00</td>\n      <td>32891200.00</td>\n      <td>0</td>\n      <td>3324</td>\n      <td>3324</td>\n      <td>659.88</td>\n      <td>420.19</td>\n      <td>217042673.00</td>\n      <td>2275</td>\n      <td>200</td>\n      <td>1355</td>\n      <td>654</td>\n    </tr>\n    <tr>\n      <th>43973.0</th>\n      <td>172326.00</td>\n      <td>17232600.00</td>\n      <td>1</td>\n      <td>3324</td>\n      <td>3323</td>\n      <td>487.63</td>\n      <td>501.77</td>\n      <td>84030647.00</td>\n      <td>2021</td>\n      <td>254</td>\n      <td>1164</td>\n      <td>394</td>\n    </tr>\n    <tr>\n      <th>44553.0</th>\n      <td>508260.00</td>\n      <td>50826000.00</td>\n      <td>0</td>\n      <td>3324</td>\n      <td>3324</td>\n      <td>617.58</td>\n      <td>428.77</td>\n      <td>313889063.00</td>\n      <td>2515</td>\n      <td>45</td>\n      <td>1493</td>\n      <td>592</td>\n    </tr>\n    <tr>\n      <th>44623.0</th>\n      <td>354677.00</td>\n      <td>35467700.00</td>\n      <td>0</td>\n      <td>3324</td>\n      <td>3324</td>\n      <td>451.24</td>\n      <td>473.36</td>\n      <td>160046103.00</td>\n      <td>2099</td>\n      <td>19</td>\n      <td>1248</td>\n      <td>376</td>\n    </tr>\n    <tr>\n      <th>46055.0</th>\n      <td>32971.00</td>\n      <td>3297100.00</td>\n      <td>2</td>\n      <td>3324</td>\n      <td>3322</td>\n      <td>542.06</td>\n      <td>1061.32</td>\n      <td>17872287.00</td>\n      <td>977</td>\n      <td>115</td>\n      <td>148</td>\n      <td>95</td>\n    </tr>\n  </tbody>\n</table>\n<p>430 rows  12 columns</p>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make watershed elev df\n",
    "wtd_df = pd.DataFrame()\n",
    "wtd_field_list = []\n",
    "for field in arcpy.ListFields(wtd_elev):\n",
    "    wtd_field_list.append(field.name)\n",
    "\n",
    "wtd_elev_arr = arcpy.da.TableToNumPyArray(wtd_elev,wtd_field_list)\n",
    "wtd_df = pd.DataFrame(wtd_elev_arr)\n",
    "wtd_df = wtd_df.drop([\"OBJECTID\",\"wtd_elev_ZONE_CODE\"],axis=1)\n",
    "wtd_df = wtd_df.set_index('cat_ID_txt')\n",
    "dfs.append(wtd_df)\n",
    "wtd_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "                  wtd_slope_COUNT  wtd_slope_AREA  wtd_slope_MIN  \\\ncat_ID_txt                                                         \n75004200007057.0        258675.00      6466875.00           0.00   \n75004300006312.0       6167928.00    154198200.00           0.00   \n75004300001906.0       3674802.00     91870050.00           0.00   \n75004300000100.0       1158019.00     28950475.00           0.00   \n75004300004983.0        609413.00     15235325.00           0.00   \n...                           ...             ...            ...   \n43933.0                 328912.00     32891200.00           0.00   \n43973.0                 172326.00     17232600.00           0.00   \n44553.0                 508260.00     50826000.00           0.00   \n44623.0                 354677.00     35467700.00           0.00   \n46055.0                  32971.00      3297100.00           0.00   \n\n                  wtd_slope_MAX  wtd_slope_RANGE  wtd_slope_MEAN  \\\ncat_ID_txt                                                         \n75004200007057.0          68.24            68.24           22.42   \n75004300006312.0          46.85            46.85            5.60   \n75004300001906.0          67.73            67.73            8.74   \n75004300000100.0          51.12            51.12            4.20   \n75004300004983.0          67.44            67.44           20.99   \n...                         ...              ...             ...   \n43933.0                    2.49             2.49            0.37   \n43973.0                    1.51             1.51            0.34   \n44553.0                    2.01             2.01            0.28   \n44623.0                    2.79             2.79            0.28   \n46055.0                    0.88             0.88            0.13   \n\n                  wtd_slope_STD  wtd_slope_SUM  wtd_slope_MEDIAN  \\\ncat_ID_txt                                                         \n75004200007057.0          13.44     5800405.06             22.49   \n75004300006312.0           4.54    34538223.06              5.11   \n75004300001906.0          10.37    32127520.68              5.30   \n75004300000100.0           3.95     4860942.85              3.93   \n75004300004983.0          12.28    12793041.78             19.11   \n...                         ...            ...               ...   \n43933.0                    0.20      123130.07              0.35   \n43973.0                    0.18       58079.41              0.33   \n44553.0                    0.19      144425.55              0.26   \n44623.0                    0.23       98311.50              0.26   \n46055.0                    0.13        4182.97              0.09   \n\n                  wtd_slope_PCT90                region  \\\ncat_ID_txt                                                \n75004200007057.0            40.33            Cook_Inlet   \n75004300006312.0            11.48            Cook_Inlet   \n75004300001906.0            26.62            Cook_Inlet   \n75004300000100.0             8.80            Cook_Inlet   \n75004300004983.0            38.72            Cook_Inlet   \n...                           ...                   ...   \n43933.0                      0.63  Prince_William_Sound   \n43973.0                      0.56  Prince_William_Sound   \n44553.0                      0.53  Prince_William_Sound   \n44623.0                      0.57  Prince_William_Sound   \n46055.0                      0.25  Prince_William_Sound   \n\n                                    cat_ID_con  \ncat_ID_txt                                      \n75004200007057.0   Cook_Inlet_75004200007057.0  \n75004300006312.0   Cook_Inlet_75004300006312.0  \n75004300001906.0   Cook_Inlet_75004300001906.0  \n75004300000100.0   Cook_Inlet_75004300000100.0  \n75004300004983.0   Cook_Inlet_75004300004983.0  \n...                                        ...  \n43933.0           Prince_William_Sound_43933.0  \n43973.0           Prince_William_Sound_43973.0  \n44553.0           Prince_William_Sound_44553.0  \n44623.0           Prince_William_Sound_44623.0  \n46055.0           Prince_William_Sound_46055.0  \n\n[430 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>wtd_slope_COUNT</th>\n      <th>wtd_slope_AREA</th>\n      <th>wtd_slope_MIN</th>\n      <th>wtd_slope_MAX</th>\n      <th>wtd_slope_RANGE</th>\n      <th>wtd_slope_MEAN</th>\n      <th>wtd_slope_STD</th>\n      <th>wtd_slope_SUM</th>\n      <th>wtd_slope_MEDIAN</th>\n      <th>wtd_slope_PCT90</th>\n      <th>region</th>\n      <th>cat_ID_con</th>\n    </tr>\n    <tr>\n      <th>cat_ID_txt</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>75004200007057.0</th>\n      <td>258675.00</td>\n      <td>6466875.00</td>\n      <td>0.00</td>\n      <td>68.24</td>\n      <td>68.24</td>\n      <td>22.42</td>\n      <td>13.44</td>\n      <td>5800405.06</td>\n      <td>22.49</td>\n      <td>40.33</td>\n      <td>Cook_Inlet</td>\n      <td>Cook_Inlet_75004200007057.0</td>\n    </tr>\n    <tr>\n      <th>75004300006312.0</th>\n      <td>6167928.00</td>\n      <td>154198200.00</td>\n      <td>0.00</td>\n      <td>46.85</td>\n      <td>46.85</td>\n      <td>5.60</td>\n      <td>4.54</td>\n      <td>34538223.06</td>\n      <td>5.11</td>\n      <td>11.48</td>\n      <td>Cook_Inlet</td>\n      <td>Cook_Inlet_75004300006312.0</td>\n    </tr>\n    <tr>\n      <th>75004300001906.0</th>\n      <td>3674802.00</td>\n      <td>91870050.00</td>\n      <td>0.00</td>\n      <td>67.73</td>\n      <td>67.73</td>\n      <td>8.74</td>\n      <td>10.37</td>\n      <td>32127520.68</td>\n      <td>5.30</td>\n      <td>26.62</td>\n      <td>Cook_Inlet</td>\n      <td>Cook_Inlet_75004300001906.0</td>\n    </tr>\n    <tr>\n      <th>75004300000100.0</th>\n      <td>1158019.00</td>\n      <td>28950475.00</td>\n      <td>0.00</td>\n      <td>51.12</td>\n      <td>51.12</td>\n      <td>4.20</td>\n      <td>3.95</td>\n      <td>4860942.85</td>\n      <td>3.93</td>\n      <td>8.80</td>\n      <td>Cook_Inlet</td>\n      <td>Cook_Inlet_75004300000100.0</td>\n    </tr>\n    <tr>\n      <th>75004300004983.0</th>\n      <td>609413.00</td>\n      <td>15235325.00</td>\n      <td>0.00</td>\n      <td>67.44</td>\n      <td>67.44</td>\n      <td>20.99</td>\n      <td>12.28</td>\n      <td>12793041.78</td>\n      <td>19.11</td>\n      <td>38.72</td>\n      <td>Cook_Inlet</td>\n      <td>Cook_Inlet_75004300004983.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43933.0</th>\n      <td>328912.00</td>\n      <td>32891200.00</td>\n      <td>0.00</td>\n      <td>2.49</td>\n      <td>2.49</td>\n      <td>0.37</td>\n      <td>0.20</td>\n      <td>123130.07</td>\n      <td>0.35</td>\n      <td>0.63</td>\n      <td>Prince_William_Sound</td>\n      <td>Prince_William_Sound_43933.0</td>\n    </tr>\n    <tr>\n      <th>43973.0</th>\n      <td>172326.00</td>\n      <td>17232600.00</td>\n      <td>0.00</td>\n      <td>1.51</td>\n      <td>1.51</td>\n      <td>0.34</td>\n      <td>0.18</td>\n      <td>58079.41</td>\n      <td>0.33</td>\n      <td>0.56</td>\n      <td>Prince_William_Sound</td>\n      <td>Prince_William_Sound_43973.0</td>\n    </tr>\n    <tr>\n      <th>44553.0</th>\n      <td>508260.00</td>\n      <td>50826000.00</td>\n      <td>0.00</td>\n      <td>2.01</td>\n      <td>2.01</td>\n      <td>0.28</td>\n      <td>0.19</td>\n      <td>144425.55</td>\n      <td>0.26</td>\n      <td>0.53</td>\n      <td>Prince_William_Sound</td>\n      <td>Prince_William_Sound_44553.0</td>\n    </tr>\n    <tr>\n      <th>44623.0</th>\n      <td>354677.00</td>\n      <td>35467700.00</td>\n      <td>0.00</td>\n      <td>2.79</td>\n      <td>2.79</td>\n      <td>0.28</td>\n      <td>0.23</td>\n      <td>98311.50</td>\n      <td>0.26</td>\n      <td>0.57</td>\n      <td>Prince_William_Sound</td>\n      <td>Prince_William_Sound_44623.0</td>\n    </tr>\n    <tr>\n      <th>46055.0</th>\n      <td>32971.00</td>\n      <td>3297100.00</td>\n      <td>0.00</td>\n      <td>0.88</td>\n      <td>0.88</td>\n      <td>0.13</td>\n      <td>0.13</td>\n      <td>4182.97</td>\n      <td>0.09</td>\n      <td>0.25</td>\n      <td>Prince_William_Sound</td>\n      <td>Prince_William_Sound_46055.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>430 rows  12 columns</p>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make watershed slope df\n",
    "wtd_sl_df = pd.DataFrame()\n",
    "wtd_sl_field_list = []\n",
    "for field in arcpy.ListFields(wtd_slope):\n",
    "    wtd_sl_field_list.append(field.name)\n",
    "wtd_sl_arr = arcpy.da.TableToNumPyArray(wtd_slope, wtd_sl_field_list)\n",
    "wtd_sl_df = pd.DataFrame(wtd_sl_arr)\n",
    "wtd_sl_df = wtd_sl_df.drop([\"OBJECTID\", \"wtd_slope_ZONE_CODE\"],axis=1)\n",
    "wtd_sl_df = wtd_sl_df.set_index('cat_ID_txt')\n",
    "dfs.append(wtd_sl_df)\n",
    "wtd_sl_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "                  non_north_area  north_area                region  \\\ncat_ID_txt                                                           \n75004200007057.0      5612475.00   854400.00            Cook_Inlet   \n75004300006312.0     99444100.00 54754100.00            Cook_Inlet   \n75004300001906.0     77036175.00 14833875.00            Cook_Inlet   \n75004300000100.0     17989525.00 10960950.00            Cook_Inlet   \n75004300004983.0     10671675.00  4563650.00            Cook_Inlet   \n...                          ...         ...                   ...   \n43933.0              28684300.00  4206900.00  Prince_William_Sound   \n43973.0              13954700.00  3277900.00  Prince_William_Sound   \n44553.0              42757600.00  8068400.00  Prince_William_Sound   \n44623.0              22243000.00 13224700.00  Prince_William_Sound   \n46055.0               2785100.00   512000.00  Prince_William_Sound   \n\n                  wtd_north_per                    cat_ID_con  \ncat_ID_txt                                                     \n75004200007057.0          13.21   Cook_Inlet_75004200007057.0  \n75004300006312.0          35.51   Cook_Inlet_75004300006312.0  \n75004300001906.0          16.15   Cook_Inlet_75004300001906.0  \n75004300000100.0          37.86   Cook_Inlet_75004300000100.0  \n75004300004983.0          29.95   Cook_Inlet_75004300004983.0  \n...                         ...                           ...  \n43933.0                   12.79  Prince_William_Sound_43933.0  \n43973.0                   19.02  Prince_William_Sound_43973.0  \n44553.0                   15.87  Prince_William_Sound_44553.0  \n44623.0                   37.29  Prince_William_Sound_44623.0  \n46055.0                   15.53  Prince_William_Sound_46055.0  \n\n[430 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>non_north_area</th>\n      <th>north_area</th>\n      <th>region</th>\n      <th>wtd_north_per</th>\n      <th>cat_ID_con</th>\n    </tr>\n    <tr>\n      <th>cat_ID_txt</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>75004200007057.0</th>\n      <td>5612475.00</td>\n      <td>854400.00</td>\n      <td>Cook_Inlet</td>\n      <td>13.21</td>\n      <td>Cook_Inlet_75004200007057.0</td>\n    </tr>\n    <tr>\n      <th>75004300006312.0</th>\n      <td>99444100.00</td>\n      <td>54754100.00</td>\n      <td>Cook_Inlet</td>\n      <td>35.51</td>\n      <td>Cook_Inlet_75004300006312.0</td>\n    </tr>\n    <tr>\n      <th>75004300001906.0</th>\n      <td>77036175.00</td>\n      <td>14833875.00</td>\n      <td>Cook_Inlet</td>\n      <td>16.15</td>\n      <td>Cook_Inlet_75004300001906.0</td>\n    </tr>\n    <tr>\n      <th>75004300000100.0</th>\n      <td>17989525.00</td>\n      <td>10960950.00</td>\n      <td>Cook_Inlet</td>\n      <td>37.86</td>\n      <td>Cook_Inlet_75004300000100.0</td>\n    </tr>\n    <tr>\n      <th>75004300004983.0</th>\n      <td>10671675.00</td>\n      <td>4563650.00</td>\n      <td>Cook_Inlet</td>\n      <td>29.95</td>\n      <td>Cook_Inlet_75004300004983.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43933.0</th>\n      <td>28684300.00</td>\n      <td>4206900.00</td>\n      <td>Prince_William_Sound</td>\n      <td>12.79</td>\n      <td>Prince_William_Sound_43933.0</td>\n    </tr>\n    <tr>\n      <th>43973.0</th>\n      <td>13954700.00</td>\n      <td>3277900.00</td>\n      <td>Prince_William_Sound</td>\n      <td>19.02</td>\n      <td>Prince_William_Sound_43973.0</td>\n    </tr>\n    <tr>\n      <th>44553.0</th>\n      <td>42757600.00</td>\n      <td>8068400.00</td>\n      <td>Prince_William_Sound</td>\n      <td>15.87</td>\n      <td>Prince_William_Sound_44553.0</td>\n    </tr>\n    <tr>\n      <th>44623.0</th>\n      <td>22243000.00</td>\n      <td>13224700.00</td>\n      <td>Prince_William_Sound</td>\n      <td>37.29</td>\n      <td>Prince_William_Sound_44623.0</td>\n    </tr>\n    <tr>\n      <th>46055.0</th>\n      <td>2785100.00</td>\n      <td>512000.00</td>\n      <td>Prince_William_Sound</td>\n      <td>15.53</td>\n      <td>Prince_William_Sound_46055.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>430 rows  5 columns</p>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make watershed north df\n",
    "wtd_n_df = pd.DataFrame()\n",
    "wtd_n_field_list = []\n",
    "for field in arcpy.ListFields(wtd_per_north):\n",
    "    wtd_n_field_list.append(field.name)\n",
    "wtd_n_arr = arcpy.da.TableToNumPyArray(wtd_per_north,wtd_n_field_list)\n",
    "wtd_n_df = pd.DataFrame(wtd_n_arr)\n",
    "wtd_n_df = wtd_n_df.drop(\"OBJECTID\",axis=1)\n",
    "wtd_n_df = wtd_n_df.set_index('cat_ID_txt')\n",
    "dfs.append(wtd_n_df)\n",
    "wtd_n_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "                  non_wetland_area  wetland_area                region  \\\ncat_ID_txt                                                               \n75004200007057.0        6461475.00       5400.00            Cook_Inlet   \n75004300006312.0      130671950.00   23526250.00            Cook_Inlet   \n75004300001906.0       73786825.00   18083225.00            Cook_Inlet   \n75004300000100.0       18462700.00   10487775.00            Cook_Inlet   \n75004300004983.0       15124625.00     110700.00            Cook_Inlet   \n...                            ...           ...                   ...   \n43933.0                32833700.00      57500.00  Prince_William_Sound   \n43973.0                17164500.00      68100.00  Prince_William_Sound   \n44553.0                50420300.00     405700.00  Prince_William_Sound   \n44623.0                32350300.00    3117400.00  Prince_William_Sound   \n46055.0                 2521100.00     776000.00  Prince_William_Sound   \n\n                  wtd_wet_per                    cat_ID_con  \ncat_ID_txt                                                   \n75004200007057.0         0.08   Cook_Inlet_75004200007057.0  \n75004300006312.0        15.26   Cook_Inlet_75004300006312.0  \n75004300001906.0        19.68   Cook_Inlet_75004300001906.0  \n75004300000100.0        36.23   Cook_Inlet_75004300000100.0  \n75004300004983.0         0.73   Cook_Inlet_75004300004983.0  \n...                       ...                           ...  \n43933.0                  0.17  Prince_William_Sound_43933.0  \n43973.0                  0.40  Prince_William_Sound_43973.0  \n44553.0                  0.80  Prince_William_Sound_44553.0  \n44623.0                  8.79  Prince_William_Sound_44623.0  \n46055.0                 23.54  Prince_William_Sound_46055.0  \n\n[430 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>non_wetland_area</th>\n      <th>wetland_area</th>\n      <th>region</th>\n      <th>wtd_wet_per</th>\n      <th>cat_ID_con</th>\n    </tr>\n    <tr>\n      <th>cat_ID_txt</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>75004200007057.0</th>\n      <td>6461475.00</td>\n      <td>5400.00</td>\n      <td>Cook_Inlet</td>\n      <td>0.08</td>\n      <td>Cook_Inlet_75004200007057.0</td>\n    </tr>\n    <tr>\n      <th>75004300006312.0</th>\n      <td>130671950.00</td>\n      <td>23526250.00</td>\n      <td>Cook_Inlet</td>\n      <td>15.26</td>\n      <td>Cook_Inlet_75004300006312.0</td>\n    </tr>\n    <tr>\n      <th>75004300001906.0</th>\n      <td>73786825.00</td>\n      <td>18083225.00</td>\n      <td>Cook_Inlet</td>\n      <td>19.68</td>\n      <td>Cook_Inlet_75004300001906.0</td>\n    </tr>\n    <tr>\n      <th>75004300000100.0</th>\n      <td>18462700.00</td>\n      <td>10487775.00</td>\n      <td>Cook_Inlet</td>\n      <td>36.23</td>\n      <td>Cook_Inlet_75004300000100.0</td>\n    </tr>\n    <tr>\n      <th>75004300004983.0</th>\n      <td>15124625.00</td>\n      <td>110700.00</td>\n      <td>Cook_Inlet</td>\n      <td>0.73</td>\n      <td>Cook_Inlet_75004300004983.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43933.0</th>\n      <td>32833700.00</td>\n      <td>57500.00</td>\n      <td>Prince_William_Sound</td>\n      <td>0.17</td>\n      <td>Prince_William_Sound_43933.0</td>\n    </tr>\n    <tr>\n      <th>43973.0</th>\n      <td>17164500.00</td>\n      <td>68100.00</td>\n      <td>Prince_William_Sound</td>\n      <td>0.40</td>\n      <td>Prince_William_Sound_43973.0</td>\n    </tr>\n    <tr>\n      <th>44553.0</th>\n      <td>50420300.00</td>\n      <td>405700.00</td>\n      <td>Prince_William_Sound</td>\n      <td>0.80</td>\n      <td>Prince_William_Sound_44553.0</td>\n    </tr>\n    <tr>\n      <th>44623.0</th>\n      <td>32350300.00</td>\n      <td>3117400.00</td>\n      <td>Prince_William_Sound</td>\n      <td>8.79</td>\n      <td>Prince_William_Sound_44623.0</td>\n    </tr>\n    <tr>\n      <th>46055.0</th>\n      <td>2521100.00</td>\n      <td>776000.00</td>\n      <td>Prince_William_Sound</td>\n      <td>23.54</td>\n      <td>Prince_William_Sound_46055.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>430 rows  5 columns</p>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make watershed wetland df\n",
    "wtd_wet_df = pd.DataFrame()\n",
    "wtd_wet_field_list = []\n",
    "for field in arcpy.ListFields(wtd_wet):\n",
    "    wtd_wet_field_list.append(field.name)\n",
    "wtd_wet_arr = arcpy.da.TableToNumPyArray(wtd_wet,wtd_wet_field_list)\n",
    "wtd_wet_df = pd.DataFrame(wtd_wet_arr)\n",
    "wtd_wet_df = wtd_wet_df.drop(\"OBJECTID\",axis=1)\n",
    "wtd_wet_df = wtd_wet_df.set_index('cat_ID_txt')\n",
    "dfs.append(wtd_wet_df)\n",
    "wtd_wet_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "                  FType  wtd_lake_area_sqm  wtd_lake_per  \\\ncat_ID_txt                                                 \n75000100000004.0    390          922030.93          0.54   \n75000100000059.0    390          314031.76          0.87   \n75000100000652.0    390        32224328.96          9.98   \n75000100000981.0    390          753288.15          0.69   \n75000100001919.0    390          391083.09          0.54   \n...                 ...                ...           ...   \n43185.0             390           51132.56          0.21   \n43933.0             390          484188.75          1.47   \n43973.0             390           12804.67          0.07   \n44553.0             390            1216.19          0.00   \n46055.0             390           15697.81          0.48   \n\n                                region            cat_ID  \\\ncat_ID_txt                                                 \n75000100000004.0            Cook_Inlet  75000100000004.0   \n75000100000059.0            Cook_Inlet  75000100000059.0   \n75000100000652.0            Cook_Inlet  75000100000652.0   \n75000100000981.0            Cook_Inlet  75000100000981.0   \n75000100001919.0            Cook_Inlet  75000100001919.0   \n...                                ...               ...   \n43185.0           Prince_William_Sound           43185.0   \n43933.0           Prince_William_Sound           43933.0   \n43973.0           Prince_William_Sound           43973.0   \n44553.0           Prince_William_Sound           44553.0   \n46055.0           Prince_William_Sound           46055.0   \n\n                                    cat_ID_con  \ncat_ID_txt                                      \n75000100000004.0   Cook_Inlet_75000100000004.0  \n75000100000059.0   Cook_Inlet_75000100000059.0  \n75000100000652.0   Cook_Inlet_75000100000652.0  \n75000100000981.0   Cook_Inlet_75000100000981.0  \n75000100001919.0   Cook_Inlet_75000100001919.0  \n...                                        ...  \n43185.0           Prince_William_Sound_43185.0  \n43933.0           Prince_William_Sound_43933.0  \n43973.0           Prince_William_Sound_43973.0  \n44553.0           Prince_William_Sound_44553.0  \n46055.0           Prince_William_Sound_46055.0  \n\n[400 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FType</th>\n      <th>wtd_lake_area_sqm</th>\n      <th>wtd_lake_per</th>\n      <th>region</th>\n      <th>cat_ID</th>\n      <th>cat_ID_con</th>\n    </tr>\n    <tr>\n      <th>cat_ID_txt</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>75000100000004.0</th>\n      <td>390</td>\n      <td>922030.93</td>\n      <td>0.54</td>\n      <td>Cook_Inlet</td>\n      <td>75000100000004.0</td>\n      <td>Cook_Inlet_75000100000004.0</td>\n    </tr>\n    <tr>\n      <th>75000100000059.0</th>\n      <td>390</td>\n      <td>314031.76</td>\n      <td>0.87</td>\n      <td>Cook_Inlet</td>\n      <td>75000100000059.0</td>\n      <td>Cook_Inlet_75000100000059.0</td>\n    </tr>\n    <tr>\n      <th>75000100000652.0</th>\n      <td>390</td>\n      <td>32224328.96</td>\n      <td>9.98</td>\n      <td>Cook_Inlet</td>\n      <td>75000100000652.0</td>\n      <td>Cook_Inlet_75000100000652.0</td>\n    </tr>\n    <tr>\n      <th>75000100000981.0</th>\n      <td>390</td>\n      <td>753288.15</td>\n      <td>0.69</td>\n      <td>Cook_Inlet</td>\n      <td>75000100000981.0</td>\n      <td>Cook_Inlet_75000100000981.0</td>\n    </tr>\n    <tr>\n      <th>75000100001919.0</th>\n      <td>390</td>\n      <td>391083.09</td>\n      <td>0.54</td>\n      <td>Cook_Inlet</td>\n      <td>75000100001919.0</td>\n      <td>Cook_Inlet_75000100001919.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43185.0</th>\n      <td>390</td>\n      <td>51132.56</td>\n      <td>0.21</td>\n      <td>Prince_William_Sound</td>\n      <td>43185.0</td>\n      <td>Prince_William_Sound_43185.0</td>\n    </tr>\n    <tr>\n      <th>43933.0</th>\n      <td>390</td>\n      <td>484188.75</td>\n      <td>1.47</td>\n      <td>Prince_William_Sound</td>\n      <td>43933.0</td>\n      <td>Prince_William_Sound_43933.0</td>\n    </tr>\n    <tr>\n      <th>43973.0</th>\n      <td>390</td>\n      <td>12804.67</td>\n      <td>0.07</td>\n      <td>Prince_William_Sound</td>\n      <td>43973.0</td>\n      <td>Prince_William_Sound_43973.0</td>\n    </tr>\n    <tr>\n      <th>44553.0</th>\n      <td>390</td>\n      <td>1216.19</td>\n      <td>0.00</td>\n      <td>Prince_William_Sound</td>\n      <td>44553.0</td>\n      <td>Prince_William_Sound_44553.0</td>\n    </tr>\n    <tr>\n      <th>46055.0</th>\n      <td>390</td>\n      <td>15697.81</td>\n      <td>0.48</td>\n      <td>Prince_William_Sound</td>\n      <td>46055.0</td>\n      <td>Prince_William_Sound_46055.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>400 rows  6 columns</p>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make watershed lakes df\n",
    "wtd_lp_df = pd.DataFrame()\n",
    "wtd_lp_field_list = []\n",
    "for field in arcpy.ListFields(wtd_lp):\n",
    "    wtd_lp_field_list.append(field.name)\n",
    "wtd_lp_arr = arcpy.da.TableToNumPyArray(wtd_lp, wtd_lp_field_list)\n",
    "wtd_lp_df = pd.DataFrame(wtd_lp_arr)\n",
    "wtd_lp_df = wtd_lp_df.drop(\"OBJECTID\",axis=1)\n",
    "wtd_lp_df = wtd_lp_df.set_index('cat_ID_txt')\n",
    "dfs.append(wtd_lp_df)\n",
    "wtd_lp_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "                 O1Region  wtd_glacier_area_sqm  wtd_glacier_per  \\\ncat_ID_txt                                                         \n75000100002463.0        1             170415.67             0.05   \n75000100003094.0        1             170853.46             0.07   \n75000200000021.0        1            1730403.02             0.22   \n75000200000745.0        1         2245823873.64             7.02   \n75000200002162.0        1            1728702.43             1.60   \n...                   ...                   ...              ...   \n43933.0                 1            1452068.36             4.41   \n43973.0                 1             533700.00             3.10   \n44553.0                 1           24056095.14            47.33   \n44623.0                 1            3131176.02             8.83   \n46055.0                 1             533700.00            16.19   \n\n                                region            cat_ID  \\\ncat_ID_txt                                                 \n75000100002463.0            Cook_Inlet  75000100002463.0   \n75000100003094.0            Cook_Inlet  75000100003094.0   \n75000200000021.0            Cook_Inlet  75000200000021.0   \n75000200000745.0            Cook_Inlet  75000200000745.0   \n75000200002162.0            Cook_Inlet  75000200002162.0   \n...                                ...               ...   \n43933.0           Prince_William_Sound           43933.0   \n43973.0           Prince_William_Sound           43973.0   \n44553.0           Prince_William_Sound           44553.0   \n44623.0           Prince_William_Sound           44623.0   \n46055.0           Prince_William_Sound           46055.0   \n\n                                    cat_ID_con  \ncat_ID_txt                                      \n75000100002463.0   Cook_Inlet_75000100002463.0  \n75000100003094.0   Cook_Inlet_75000100003094.0  \n75000200000021.0   Cook_Inlet_75000200000021.0  \n75000200000745.0   Cook_Inlet_75000200000745.0  \n75000200002162.0   Cook_Inlet_75000200002162.0  \n...                                        ...  \n43933.0           Prince_William_Sound_43933.0  \n43973.0           Prince_William_Sound_43973.0  \n44553.0           Prince_William_Sound_44553.0  \n44623.0           Prince_William_Sound_44623.0  \n46055.0           Prince_William_Sound_46055.0  \n\n[108 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>O1Region</th>\n      <th>wtd_glacier_area_sqm</th>\n      <th>wtd_glacier_per</th>\n      <th>region</th>\n      <th>cat_ID</th>\n      <th>cat_ID_con</th>\n    </tr>\n    <tr>\n      <th>cat_ID_txt</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>75000100002463.0</th>\n      <td>1</td>\n      <td>170415.67</td>\n      <td>0.05</td>\n      <td>Cook_Inlet</td>\n      <td>75000100002463.0</td>\n      <td>Cook_Inlet_75000100002463.0</td>\n    </tr>\n    <tr>\n      <th>75000100003094.0</th>\n      <td>1</td>\n      <td>170853.46</td>\n      <td>0.07</td>\n      <td>Cook_Inlet</td>\n      <td>75000100003094.0</td>\n      <td>Cook_Inlet_75000100003094.0</td>\n    </tr>\n    <tr>\n      <th>75000200000021.0</th>\n      <td>1</td>\n      <td>1730403.02</td>\n      <td>0.22</td>\n      <td>Cook_Inlet</td>\n      <td>75000200000021.0</td>\n      <td>Cook_Inlet_75000200000021.0</td>\n    </tr>\n    <tr>\n      <th>75000200000745.0</th>\n      <td>1</td>\n      <td>2245823873.64</td>\n      <td>7.02</td>\n      <td>Cook_Inlet</td>\n      <td>75000200000745.0</td>\n      <td>Cook_Inlet_75000200000745.0</td>\n    </tr>\n    <tr>\n      <th>75000200002162.0</th>\n      <td>1</td>\n      <td>1728702.43</td>\n      <td>1.60</td>\n      <td>Cook_Inlet</td>\n      <td>75000200002162.0</td>\n      <td>Cook_Inlet_75000200002162.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43933.0</th>\n      <td>1</td>\n      <td>1452068.36</td>\n      <td>4.41</td>\n      <td>Prince_William_Sound</td>\n      <td>43933.0</td>\n      <td>Prince_William_Sound_43933.0</td>\n    </tr>\n    <tr>\n      <th>43973.0</th>\n      <td>1</td>\n      <td>533700.00</td>\n      <td>3.10</td>\n      <td>Prince_William_Sound</td>\n      <td>43973.0</td>\n      <td>Prince_William_Sound_43973.0</td>\n    </tr>\n    <tr>\n      <th>44553.0</th>\n      <td>1</td>\n      <td>24056095.14</td>\n      <td>47.33</td>\n      <td>Prince_William_Sound</td>\n      <td>44553.0</td>\n      <td>Prince_William_Sound_44553.0</td>\n    </tr>\n    <tr>\n      <th>44623.0</th>\n      <td>1</td>\n      <td>3131176.02</td>\n      <td>8.83</td>\n      <td>Prince_William_Sound</td>\n      <td>44623.0</td>\n      <td>Prince_William_Sound_44623.0</td>\n    </tr>\n    <tr>\n      <th>46055.0</th>\n      <td>1</td>\n      <td>533700.00</td>\n      <td>16.19</td>\n      <td>Prince_William_Sound</td>\n      <td>46055.0</td>\n      <td>Prince_William_Sound_46055.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>108 rows  6 columns</p>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make watershed glacier df\n",
    "wtd_glac_df = pd.DataFrame()\n",
    "wtd_glac_field_list = []\n",
    "for field in arcpy.ListFields(wtd_glac):\n",
    "    wtd_glac_field_list.append(field.name)\n",
    "wtd_glac_arr = arcpy.da.TableToNumPyArray(wtd_glac, wtd_glac_field_list)\n",
    "wtd_glac_df = pd.DataFrame(wtd_glac_arr)\n",
    "wtd_glac_df = wtd_glac_df.drop(\"OBJECTID\",axis=1)\n",
    "wtd_glac_df = wtd_glac_df.set_index('cat_ID_txt')\n",
    "dfs.append(wtd_glac_df)\n",
    "wtd_glac_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "                  cat_elev_COUNT  cat_elev_AREA  cat_elev_MIN  cat_elev_MAX  \\\ncat_ID_txt                                                                    \n75004200007057.0        38470.00      961750.00          0.00        908.00   \n75004300006312.0        57563.00     1439075.00         59.00         98.00   \n75004300001906.0        12127.00      303175.00          3.00        146.00   \n75004300000100.0        78759.00     1968975.00         33.00         78.00   \n75004300004983.0       113568.00     2839200.00         21.00        479.00   \n...                          ...            ...           ...           ...   \n43933.0                      NaN            NaN           NaN           NaN   \n43973.0                      NaN            NaN           NaN           NaN   \n44553.0                      NaN            NaN           NaN           NaN   \n44623.0                      NaN            NaN           NaN           NaN   \n46055.0                      NaN            NaN           NaN           NaN   \n\n                  cat_elev_RANGE  cat_elev_MEAN  cat_elev_STD  cat_elev_SUM  \\\ncat_ID_txt                                                                    \n75004200007057.0          908.00         346.00        251.07   13310762.00   \n75004300006312.0           39.00          76.31          9.37    4392462.00   \n75004300001906.0          143.00          27.85         21.37     337746.00   \n75004300000100.0           45.00          58.67          8.23    4620998.00   \n75004300004983.0          458.00         265.10        100.44   30107239.00   \n...                          ...            ...           ...           ...   \n43933.0                      NaN            NaN           NaN           NaN   \n43973.0                      NaN            NaN           NaN           NaN   \n44553.0                      NaN            NaN           NaN           NaN   \n44623.0                      NaN            NaN           NaN           NaN   \n46055.0                      NaN            NaN           NaN           NaN   \n\n                  cat_elev_VARIETY  cat_elev_MAJORITY  ...  wtd_lake_per  \\\ncat_ID_txt                                             ...                 \n75004200007057.0            909.00               4.00  ...          0.68   \n75004300006312.0             40.00              69.00  ...          0.02   \n75004300001906.0            142.00               9.00  ...          3.43   \n75004300000100.0             46.00              65.00  ...          0.13   \n75004300004983.0            459.00             336.00  ...          0.95   \n...                            ...                ...  ...           ...   \n43933.0                        NaN                NaN  ...          1.47   \n43973.0                        NaN                NaN  ...          0.07   \n44553.0                        NaN                NaN  ...          0.00   \n44623.0                        NaN                NaN  ...           NaN   \n46055.0                        NaN                NaN  ...          0.48   \n\n                              region_x          cat_ID_x  \\\ncat_ID_txt                                                 \n75004200007057.0            Cook_Inlet  75004200007057.0   \n75004300006312.0            Cook_Inlet  75004300006312.0   \n75004300001906.0            Cook_Inlet  75004300001906.0   \n75004300000100.0            Cook_Inlet  75004300000100.0   \n75004300004983.0            Cook_Inlet  75004300004983.0   \n...                                ...               ...   \n43933.0           Prince_William_Sound           43933.0   \n43973.0           Prince_William_Sound           43973.0   \n44553.0           Prince_William_Sound           44553.0   \n44623.0                            NaN               NaN   \n46055.0           Prince_William_Sound           46055.0   \n\n                                  cat_ID_con_x  O1Region  \\\ncat_ID_txt                                                 \n75004200007057.0   Cook_Inlet_75004200007057.0         1   \n75004300006312.0   Cook_Inlet_75004300006312.0       NaN   \n75004300001906.0   Cook_Inlet_75004300001906.0       NaN   \n75004300000100.0   Cook_Inlet_75004300000100.0       NaN   \n75004300004983.0   Cook_Inlet_75004300004983.0         1   \n...                                        ...       ...   \n43933.0           Prince_William_Sound_43933.0         1   \n43973.0           Prince_William_Sound_43973.0         1   \n44553.0           Prince_William_Sound_44553.0         1   \n44623.0                                    NaN         1   \n46055.0           Prince_William_Sound_46055.0         1   \n\n                  wtd_glacier_area_sqm  wtd_glacier_per              region_y  \\\ncat_ID_txt                                                                      \n75004200007057.0             245412.94             3.79            Cook_Inlet   \n75004300006312.0                   NaN              NaN                   NaN   \n75004300001906.0                   NaN              NaN                   NaN   \n75004300000100.0                   NaN              NaN                   NaN   \n75004300004983.0             448126.38             2.94            Cook_Inlet   \n...                                ...              ...                   ...   \n43933.0                     1452068.36             4.41  Prince_William_Sound   \n43973.0                      533700.00             3.10  Prince_William_Sound   \n44553.0                    24056095.14            47.33  Prince_William_Sound   \n44623.0                     3131176.02             8.83  Prince_William_Sound   \n46055.0                      533700.00            16.19  Prince_William_Sound   \n\n                          cat_ID_y                  cat_ID_con_y  \ncat_ID_txt                                                        \n75004200007057.0  75004200007057.0   Cook_Inlet_75004200007057.0  \n75004300006312.0               NaN                           NaN  \n75004300001906.0               NaN                           NaN  \n75004300000100.0               NaN                           NaN  \n75004300004983.0  75004300004983.0   Cook_Inlet_75004300004983.0  \n...                            ...                           ...  \n43933.0                    43933.0  Prince_William_Sound_43933.0  \n43973.0                    43973.0  Prince_William_Sound_43973.0  \n44553.0                    44553.0  Prince_William_Sound_44553.0  \n44623.0                    44623.0  Prince_William_Sound_44623.0  \n46055.0                    46055.0  Prince_William_Sound_46055.0  \n\n[561 rows x 70 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat_elev_COUNT</th>\n      <th>cat_elev_AREA</th>\n      <th>cat_elev_MIN</th>\n      <th>cat_elev_MAX</th>\n      <th>cat_elev_RANGE</th>\n      <th>cat_elev_MEAN</th>\n      <th>cat_elev_STD</th>\n      <th>cat_elev_SUM</th>\n      <th>cat_elev_VARIETY</th>\n      <th>cat_elev_MAJORITY</th>\n      <th>...</th>\n      <th>wtd_lake_per</th>\n      <th>region_x</th>\n      <th>cat_ID_x</th>\n      <th>cat_ID_con_x</th>\n      <th>O1Region</th>\n      <th>wtd_glacier_area_sqm</th>\n      <th>wtd_glacier_per</th>\n      <th>region_y</th>\n      <th>cat_ID_y</th>\n      <th>cat_ID_con_y</th>\n    </tr>\n    <tr>\n      <th>cat_ID_txt</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>75004200007057.0</th>\n      <td>38470.00</td>\n      <td>961750.00</td>\n      <td>0.00</td>\n      <td>908.00</td>\n      <td>908.00</td>\n      <td>346.00</td>\n      <td>251.07</td>\n      <td>13310762.00</td>\n      <td>909.00</td>\n      <td>4.00</td>\n      <td>...</td>\n      <td>0.68</td>\n      <td>Cook_Inlet</td>\n      <td>75004200007057.0</td>\n      <td>Cook_Inlet_75004200007057.0</td>\n      <td>1</td>\n      <td>245412.94</td>\n      <td>3.79</td>\n      <td>Cook_Inlet</td>\n      <td>75004200007057.0</td>\n      <td>Cook_Inlet_75004200007057.0</td>\n    </tr>\n    <tr>\n      <th>75004300006312.0</th>\n      <td>57563.00</td>\n      <td>1439075.00</td>\n      <td>59.00</td>\n      <td>98.00</td>\n      <td>39.00</td>\n      <td>76.31</td>\n      <td>9.37</td>\n      <td>4392462.00</td>\n      <td>40.00</td>\n      <td>69.00</td>\n      <td>...</td>\n      <td>0.02</td>\n      <td>Cook_Inlet</td>\n      <td>75004300006312.0</td>\n      <td>Cook_Inlet_75004300006312.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75004300001906.0</th>\n      <td>12127.00</td>\n      <td>303175.00</td>\n      <td>3.00</td>\n      <td>146.00</td>\n      <td>143.00</td>\n      <td>27.85</td>\n      <td>21.37</td>\n      <td>337746.00</td>\n      <td>142.00</td>\n      <td>9.00</td>\n      <td>...</td>\n      <td>3.43</td>\n      <td>Cook_Inlet</td>\n      <td>75004300001906.0</td>\n      <td>Cook_Inlet_75004300001906.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75004300000100.0</th>\n      <td>78759.00</td>\n      <td>1968975.00</td>\n      <td>33.00</td>\n      <td>78.00</td>\n      <td>45.00</td>\n      <td>58.67</td>\n      <td>8.23</td>\n      <td>4620998.00</td>\n      <td>46.00</td>\n      <td>65.00</td>\n      <td>...</td>\n      <td>0.13</td>\n      <td>Cook_Inlet</td>\n      <td>75004300000100.0</td>\n      <td>Cook_Inlet_75004300000100.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75004300004983.0</th>\n      <td>113568.00</td>\n      <td>2839200.00</td>\n      <td>21.00</td>\n      <td>479.00</td>\n      <td>458.00</td>\n      <td>265.10</td>\n      <td>100.44</td>\n      <td>30107239.00</td>\n      <td>459.00</td>\n      <td>336.00</td>\n      <td>...</td>\n      <td>0.95</td>\n      <td>Cook_Inlet</td>\n      <td>75004300004983.0</td>\n      <td>Cook_Inlet_75004300004983.0</td>\n      <td>1</td>\n      <td>448126.38</td>\n      <td>2.94</td>\n      <td>Cook_Inlet</td>\n      <td>75004300004983.0</td>\n      <td>Cook_Inlet_75004300004983.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43933.0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.47</td>\n      <td>Prince_William_Sound</td>\n      <td>43933.0</td>\n      <td>Prince_William_Sound_43933.0</td>\n      <td>1</td>\n      <td>1452068.36</td>\n      <td>4.41</td>\n      <td>Prince_William_Sound</td>\n      <td>43933.0</td>\n      <td>Prince_William_Sound_43933.0</td>\n    </tr>\n    <tr>\n      <th>43973.0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.07</td>\n      <td>Prince_William_Sound</td>\n      <td>43973.0</td>\n      <td>Prince_William_Sound_43973.0</td>\n      <td>1</td>\n      <td>533700.00</td>\n      <td>3.10</td>\n      <td>Prince_William_Sound</td>\n      <td>43973.0</td>\n      <td>Prince_William_Sound_43973.0</td>\n    </tr>\n    <tr>\n      <th>44553.0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>Prince_William_Sound</td>\n      <td>44553.0</td>\n      <td>Prince_William_Sound_44553.0</td>\n      <td>1</td>\n      <td>24056095.14</td>\n      <td>47.33</td>\n      <td>Prince_William_Sound</td>\n      <td>44553.0</td>\n      <td>Prince_William_Sound_44553.0</td>\n    </tr>\n    <tr>\n      <th>44623.0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>3131176.02</td>\n      <td>8.83</td>\n      <td>Prince_William_Sound</td>\n      <td>44623.0</td>\n      <td>Prince_William_Sound_44623.0</td>\n    </tr>\n    <tr>\n      <th>46055.0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.48</td>\n      <td>Prince_William_Sound</td>\n      <td>46055.0</td>\n      <td>Prince_William_Sound_46055.0</td>\n      <td>1</td>\n      <td>533700.00</td>\n      <td>16.19</td>\n      <td>Prince_William_Sound</td>\n      <td>46055.0</td>\n      <td>Prince_William_Sound_46055.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>561 rows  70 columns</p>\n</div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge all data frames together\n",
    "from functools import reduce\n",
    "df_final = reduce(lambda left,right: pd.merge(left,right,on='cat_ID_txt',how=\"outer\"), dfs)\n",
    "#df_final = pd.concat(dfs)\n",
    "df_final\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8caab41e",
   "language": "python",
   "display_name": "PyCharm (AKSSF)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}