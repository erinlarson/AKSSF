{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a id='top'></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Aspect and Percent North Covariates\n",
    "Calculate aspect grid with the DEM used to create the flow network for each processing area (e.g. HUC8 in NHDPlus or\n",
    " region for BB, PWS, or Kodiak). We need the DEMs used for each flow direction grid, or we can't calculate covariates at\n",
    " the watershed scale.\n",
    " * **~~aspect_rch = calculate mean aspect for stream reach (zonal statistics)~~**\n",
    " * **~~aspect_cat = calculate mean aspect over catchments (zonal statistics)~~**\n",
    " * **north_wtd = create 1/0 grid of north facing cells from aspect grid (north = aspects from 315-45 degrees), ~~~use\n",
    "  weighted flow accumulation to sum north facing cells, divide by flow accumulation grid to get % of north facing\n",
    "  cells in each watershed~~~ Use tabulate area to quantify area of North cells (VALUE_1) and non-North (VALUE_0) cells\n",
    "  for each watershed and calculate percent north as north_wtd = row[VALUE_1]/(row[VALUE_1]+row[VALUE_0])*100 .**\n",
    "\n",
    "## Import modules"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13102021\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\landcover\n",
      "C:\\Users\\dwmerrigan\\AppData\\Local\\Programs\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\n"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "arcpy.env.overwriteOutput = True\n",
    "today = datetime.datetime.now()\n",
    "# Make the time stamp.\n",
    "time_stamp = '{:%d%m%Y}'.format(today)\n",
    "print(time_stamp)\n",
    "\n",
    "path = os.getcwd()\n",
    "print (path)\n",
    "print (sys.base_exec_prefix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Collect data and set working output locations\n",
    "Set data_dir to folder containing all AKSSF regional subfolders/geoadatabases\n",
    "* RS data folder: data_dir = r\"W:\\GIS\\AKSSF\"\n",
    "* DM data folder: data_dir = r\"D:\\GIS_Temp\\AKSSF_BeckyCopy\\AKSSF\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\GIS_temp\\\\AKSSF_BeckyCopy\\\\AKSSF\\\\Bristol_Bay', 'D:\\\\GIS_temp\\\\AKSSF_BeckyCopy\\\\AKSSF\\\\Cook_Inlet', 'D:\\\\GIS_temp\\\\AKSSF_BeckyCopy\\\\AKSSF\\\\Copper_River', 'D:\\\\GIS_temp\\\\AKSSF_BeckyCopy\\\\AKSSF\\\\Kodiak', 'D:\\\\GIS_temp\\\\AKSSF_BeckyCopy\\\\AKSSF\\\\Prince_William_Sound']\n",
      "Working Folder already created... D:\\GIS_temp\\AKSSF_asp_met\n",
      "Output location already exists D:\\GIS_temp\\AKSSF_asp_met\\AKSSF_asp_met.gdb\n"
     ]
    }
   ],
   "source": [
    "# Set AKSSF Data directory\n",
    "# data_dir = r\"W:\\GIS\\AKSSF\"\n",
    "\n",
    "# dm local\n",
    "data_dir = r\"D:\\GIS_Temp\\AKSSF_BeckyCopy\\AKSSF\"\n",
    "\n",
    "arcpy.env.workspace = data_dir\n",
    "regions = arcpy.ListWorkspaces(workspace_type=\"Folder\")\n",
    "rois= []\n",
    "print (regions)\n",
    "\n",
    "# Path to create output folder/gdb\n",
    "temppath = r\"D:\\GIS_temp\" # Output folder\n",
    "dirname = 'AKSSF_asp_met'\n",
    "tempgdbname = 'AKSSF_asp_met.gdb'\n",
    "temp_dir = os.path.join(temppath, dirname)\n",
    "\n",
    "# Create temporary working gdb\n",
    "if not arcpy.Exists(temp_dir):\n",
    "    os.makedirs(temp_dir)\n",
    "else:\n",
    "    print('Working Folder already created...', temp_dir)\n",
    "\n",
    "outcheck = os.path.join(temp_dir, tempgdbname)\n",
    "\n",
    "if arcpy.Exists(outcheck):\n",
    "    print ('Output location already exists', outcheck)\n",
    "    outgdb = outcheck\n",
    "if not arcpy.Exists(outcheck):\n",
    "    print('Creating output GDB')\n",
    "    tempgdb = arcpy.CreateFileGDB_management(temp_dir,tempgdbname)\n",
    "    print ('Output geodatabase created at', outcheck)\n",
    "    outgdb = tempgdb.getOutput(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "['D:\\\\GIS_temp\\\\AKSSF_BeckyCopy\\\\AKSSF\\\\Bristol_Bay',\n 'D:\\\\GIS_temp\\\\AKSSF_BeckyCopy\\\\AKSSF\\\\Cook_Inlet',\n 'D:\\\\GIS_temp\\\\AKSSF_BeckyCopy\\\\AKSSF\\\\Copper_River',\n 'D:\\\\GIS_temp\\\\AKSSF_BeckyCopy\\\\AKSSF\\\\Kodiak',\n 'D:\\\\GIS_temp\\\\AKSSF_BeckyCopy\\\\AKSSF\\\\Prince_William_Sound']"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set regional workspaces from AKSSF data folder and store in list\n",
    "arcpy.env.workspace = data_dir\n",
    "regions  = arcpy.ListWorkspaces(workspace_type=\"Folder\")\n",
    "regions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create aspect and north grids if they do not already exists\n",
    "### NHDPlus"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020202\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020301\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020302\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020401\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020402\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020501\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020502\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020503\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020504\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020505\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020601\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020602\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020800\\elev_cm.tif to list\n"
     ]
    }
   ],
   "source": [
    "# Code to create merged elevation grid, aspect and north aspect grids for entire AKSSF region with NHDPlus elev data\n",
    "\n",
    "# elrasters = []\n",
    "# nhd_dat = r\"C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\AKSSF\\\\hydrography\\\\AKSSF_NHDPlus\\\\extracts\"\n",
    "# for dirpath, dirname, filenames in arcpy.da.Walk(nhd_dat, 'RasterDataset'):\n",
    "#     for filename in filenames:\n",
    "#         if filename == \"elev_cm.tif\":\n",
    "#             elras = os.path.join(dirpath, filename)\n",
    "#             elrasters.append(elras)\n",
    "#             print (f'Appending {elras} to list')\n",
    "#\n",
    "# spatial_ref = arcpy.Describe(elrasters[0]).spatialReference\n",
    "# print (spatial_ref.name)\n",
    "# # Merge all nhdplus elevation rasters together\n",
    "# elevname = 'AKSSF_NHDPlus_elev_cm.tif'\n",
    "# AKSSF_elev_cm = arcpy.MosaicToNewRaster_management(elrasters,temp_dir,elevname, spatial_ref, \"32_BIT_SIGNED\", \"5\", \"1\", \"LAST\",\"FIRST\")\n",
    "#\n",
    "# #make aspect raster for all of akssf from merged nhdplus\n",
    "# from arcpy.sa import *\n",
    "# aspname = 'AKSSF_NHDPlus_aspect.tif'\n",
    "# asp_rast = Aspect(in_raster= AKSSF_elev_cm, method='Planar')\n",
    "# asp_rast.save(os.path.join(temp_dir, aspname))\n",
    "#\n",
    "# # make north raster from aspect raster\n",
    "# norname = 'AKSSF_NHDPlus_north_aspect.tif'\n",
    "# aspect_in = Raster(asp_rast)\n",
    "# north_raster = Con((aspect_in>=0)&(aspect_in<=45),1,Con((aspect_in<=360)&(aspect_in>=315),1,0))\n",
    "# north_raster.save(os.path.join(temp_dir, norname))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TauDEM - Create grids using Timms Composite DEM for entire TauDEM processed areas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# Code to create merged elevation grid, aspect and north aspect grids for entire AKSSF region with TauDEM elev data\n",
    "# compDEM = r\"C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\data\\topography\\AKSSF_Elevation_Composite_10m.tif\"\n",
    "# clip to study area\n",
    "# AKSSF_elev_10m = r\"D:\\\\GIS_temp\\\\AKSSF_Composite_10m_extract.tif\"\n",
    "#\n",
    "# #make aspect raster for all of akssf from merged nhdplus\n",
    "# from arcpy.sa import *\n",
    "# aspname = 'AKSSF_Composite_10m_aspect.tif'\n",
    "# asp_rast = Aspect(in_raster= AKSSF_elev_10m, method='Planar')\n",
    "# asp_rast.save(os.path.join(temp_dir, aspname))\n",
    "#\n",
    "# # make north raster from aspect raster\n",
    "# norname = 'AKSSF_Composite_10m_north_aspect.tif'\n",
    "# aspect_in = Raster(asp_rast)\n",
    "# north_raster = Con((aspect_in>=0)&(aspect_in<=45),1,Con((aspect_in<=360)&(aspect_in>=315),1,0))\n",
    "# north_raster.save(os.path.join(temp_dir, norname))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Begin GIS portion\n",
    "- May be faster and save more space to create aspect rasters here using extract by mask?\n",
    "- May be able to use aspect raster with tabulate intersection to calculate percent North (aspects from 315-45 degrees)\n",
    "\n",
    "### <b>UPDATE - 2021-10-12 Do not run aspect metrics at this time. Only need to run percent North for watersheds</b>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\GIS_temp\\AKSSF_BeckyCopy\\AKSSF\\Bristol_Bay\n",
      "D:\\GIS_temp\\AKSSF_BeckyCopy\\AKSSF\\Cook_Inlet\n",
      "D:\\GIS_temp\\AKSSF_BeckyCopy\\AKSSF\\Cook_Inlet found for Cook_Inlet\n",
      "NHD data: north raster - D:\\GIS_temp\\AKSSF_asp_met\\AKSSF_NHDPlus_north_aspect.tif\n",
      "         aspect raster - D:\\GIS_temp\\AKSSF_asp_met\\AKSSF_NHDPlus_aspect.tif\n",
      "      elevation raster - D:\\GIS_temp\\AKSSF_asp_met\\AKSSF_NHDPlus_elev_cm.tif\n",
      "----------\n",
      "Calculating aspect metrics and percent north for catchments & watersheds of interest in Cook_Inlet region\n",
      "----------\n",
      "Geodatabase: ['D:\\\\GIS_temp\\\\AKSSF_BeckyCopy\\\\AKSSF\\\\Cook_Inlet\\\\Cook_Inlet.gdb']\n",
      "----------\n",
      "Elevation Raster: AKSSF_NHDPlus_aspect\n",
      "----------\n",
      "114 Watersheds to process\n",
      "----------\n",
      "Watershed Merge for Cook_Inlet Elapsed time: (0:00:22)\n",
      "----------\n",
      "Begin zonal statistics min/mean/max std dev for watersheds and catchments in Cook_Inlet region\n",
      "Zonal Stats for Cook_Inlet Elapsed time: (0:00:00)\n",
      "----------\n",
      "Begin tabulate area of north facing cells for watersheds and catchments in Cook_Inlet region\n",
      "Tabulate area for Cook_Inlet Elapsed time: (0:04:39)\n",
      "----------\n",
      "D:\\GIS_temp\\AKSSF_BeckyCopy\\AKSSF\\Copper_River\n",
      "D:\\GIS_temp\\AKSSF_BeckyCopy\\AKSSF\\Kodiak\n",
      "D:\\GIS_temp\\AKSSF_BeckyCopy\\AKSSF\\Prince_William_Sound\n",
      "Region Cook_Inlet not found in D:\\GIS_temp\\AKSSF_BeckyCopy\\AKSSF\\Prince_William_Sound\n",
      "D:\\GIS_temp\\AKSSF_BeckyCopy\\AKSSF\\Bristol_Bay\n",
      "D:\\GIS_temp\\AKSSF_BeckyCopy\\AKSSF\\Bristol_Bay found for Bristol_Bay\n",
      "TauDem data: north raster - D:\\\\GIS_temp\\\\AKSSF_asp_met\\\\AKSSF_Composite_10m_north_aspect.tif\n",
      "         aspect raster - D:\\\\GIS_temp\\\\AKSSF_asp_met\\\\AKSSF_Composite_10m_aspect.tif\n",
      "      elevation raster - C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\data\\topography\\AKSSF_Elevation_Composite_10m.tif\n",
      "----------\n",
      "Calculating aspect metrics and percent north for catchments & watersheds of interest in Bristol_Bay region\n",
      "----------\n",
      "Geodatabase: ['D:\\\\GIS_temp\\\\AKSSF_BeckyCopy\\\\AKSSF\\\\Bristol_Bay\\\\Bristol_Bay.gdb']\n",
      "----------\n",
      "Elevation Raster: AKSSF_Composite_10m_aspect\n",
      "----------\n",
      "114 Watersheds to process\n",
      "----------\n",
      "Watershed Merge for Bristol_Bay Elapsed time: (0:00:13)\n",
      "----------\n",
      "Begin zonal statistics min/mean/max std dev for watersheds and catchments in Bristol_Bay region\n",
      "Zonal Stats for Bristol_Bay Elapsed time: (0:00:00)\n",
      "----------\n",
      "Begin tabulate area of north facing cells for watersheds and catchments in Bristol_Bay region\n",
      "Tabulate area for Bristol_Bay Elapsed time: (0:00:57)\n",
      "----------\n",
      "D:\\GIS_temp\\AKSSF_BeckyCopy\\AKSSF\\Cook_Inlet\n",
      "D:\\GIS_temp\\AKSSF_BeckyCopy\\AKSSF\\Copper_River\n",
      "D:\\GIS_temp\\AKSSF_BeckyCopy\\AKSSF\\Kodiak\n",
      "D:\\GIS_temp\\AKSSF_BeckyCopy\\AKSSF\\Prince_William_Sound\n",
      "Region Bristol_Bay not found in D:\\GIS_temp\\AKSSF_BeckyCopy\\AKSSF\\Prince_William_Sound\n",
      "Process completed at 2021-10-13 16:21 (Elapsed time: 0:06:14)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "from arcpy.sa import *\n",
    "import re\n",
    "\n",
    "# Set data_dir equal to folder containing AKSSF regional subfolders containing GDBs and raster datasets\n",
    "arcpy.env.workspace = data_dir\n",
    "arcpy.env.overwriteOutput = True\n",
    "regions  = arcpy.ListWorkspaces(workspace_type=\"Folder\")\n",
    "regions\n",
    "\n",
    "# Lists to store output tables\n",
    "cat_asp_ztables = []\n",
    "wtd_asp_ztables = []\n",
    "cat_pernorth_taba_tables=[]\n",
    "wtd_pernorth_taba_tables=[]\n",
    "\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "\n",
    "# Seperate data by\n",
    "nhdplus_dat = ['Cook_Inlet','Copper_River']\n",
    "tauDem_dat = ['Bristol_Bay', 'Kodiak', 'Prince_William_Sound']\n",
    "\n",
    "# Limit to cook inlet and bbay for testing\n",
    "rois = ['Cook_Inlet', 'Bristol_Bay']\n",
    "for roi in rois:\n",
    "# Loop through regional folders\n",
    "    for region in regions:\n",
    "        print (region)\n",
    "        if roi in str(region):\n",
    "            print(f'{region} found for {roi}')\n",
    "            if roi in nhdplus_dat:\n",
    "                # NHDPLus raster data for DM pc, variables will be overwritten below if they exist in source folder.\n",
    "                asp_rast = r\"D:\\GIS_temp\\AKSSF_asp_met\\AKSSF_NHDPlus_aspect.tif\"\n",
    "                elev_rast = r\"D:\\GIS_temp\\AKSSF_asp_met\\AKSSF_NHDPlus_elev_cm.tif\"\n",
    "                nor_rast = r\"D:\\GIS_temp\\AKSSF_asp_met\\AKSSF_NHDPlus_north_aspect.tif\"\n",
    "                print(f'NHD data: north raster - {nor_rast}')\n",
    "                print(f'         aspect raster - {asp_rast}')\n",
    "                print(f'      elevation raster - {elev_rast}')\n",
    "                print('----------')\n",
    "\n",
    "            elif roi in tauDem_dat:\n",
    "                # TauDEM raster data for DM pc, variables will be overwritten below if they exist in source folder.\n",
    "                nor_rast = r\"D:\\\\GIS_temp\\\\AKSSF_asp_met\\\\AKSSF_Composite_10m_north_aspect.tif\"\n",
    "                asp_rast = r\"D:\\\\GIS_temp\\\\AKSSF_asp_met\\\\AKSSF_Composite_10m_aspect.tif\"\n",
    "                elev_rast = r\"C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\data\\topography\\AKSSF_Elevation_Composite_10m.tif\"\n",
    "                print(f'TauDem data: north raster - {nor_rast}')\n",
    "                print(f'         aspect raster - {asp_rast}')\n",
    "                print(f'      elevation raster - {elev_rast}')\n",
    "                print('----------')\n",
    "\n",
    "            stats_fields = ['MEAN','MAX','MIN','STD']\n",
    "            wtds = []\n",
    "            cats = []\n",
    "            # Start iter timing function\n",
    "            iteration_start = time.time()\n",
    "            # Set workspace to region folder\n",
    "            arcpy.env.workspace = region\n",
    "            gdb = arcpy.ListWorkspaces(workspace_type='FileGDB')\n",
    "            walk = arcpy.da.Walk(region, datatype = ['FeatureClass','RasterDataset'])\n",
    "            for dirpath, dirnames, filenames in walk:\n",
    "                for filename in filenames:\n",
    "                    # Create list of watersheds\n",
    "                    if \"wtd\" in filename:\n",
    "                        wtds.append(os.path.join(dirpath, filename))\n",
    "                        outgdb = gdb\n",
    "\n",
    "                    # # Select aspect raster\n",
    "                    # elif 'aspect' in filename:\n",
    "                    #     asp_rast = os.path.join(dirpath, filename)\n",
    "\n",
    "                    # Select north raster\n",
    "                    elif 'north_asp' in filename:\n",
    "                        nor_rast = os.path.join(dirpath, filename)\n",
    "\n",
    "                    # Select catch_int fc (catchments of interest for region) and make a copy\n",
    "                    elif 'cats_intersect' in filename:\n",
    "                        cats = arcpy.FeatureClassToFeatureClass_conversion(os.path.join(dirpath,filename),\n",
    "                                                                           'memory\\\\','cat_copy')\n",
    "                        arcpy.AddField_management(cats,\"NHDPlusID_txt\",field_type='TEXT')\n",
    "                        # Copy NHDPlusID as text field for use in zonal stats\n",
    "                        with arcpy.da.UpdateCursor(cats, ['NHDPlusID','NHDPlusID_txt']) as cur:\n",
    "                            for row in cur:\n",
    "                                row[1] = roi + \"_\" + str(row[0])\n",
    "                                # Update rows\n",
    "                                cur.updateRow(row)\n",
    "                            del(row)\n",
    "                        del(cur)\n",
    "\n",
    "            print (f'Calculating aspect metrics and percent north for catchments & watersheds of interest in {roi}'\n",
    "                   f' region')\n",
    "            print ('----------')\n",
    "            print(f'Geodatabase: {gdb}')\n",
    "            print ('----------')\n",
    "            print (f'Elevation Raster: {arcpy.Describe(asp_rast).baseName}')\n",
    "            print ('----------')\n",
    "            print (f'{len(wtds)} Watersheds to process')\n",
    "            print ('----------')\n",
    "            print (f'Catchment intersect {cats} selected')\n",
    "\n",
    "            try:\n",
    "                mergestart = time.time()\n",
    "                # Set output names/paths for watershed and catchment tables\n",
    "                wtd_merge_name = roi + \"_Watersheds_Merge\"\n",
    "                wtd_merge_path = os.path.join(outgdb,wtd_merge_name)\n",
    "                # # Aspect variables\n",
    "                # wtd_merge_asp_table_name = roi + \"_Watersheds_Merge_AspectZstats\"\n",
    "                # wtd_merge_asp_table_path = os.path.join(outgdb, wtd_merge_asp_table_name)\n",
    "                # cat_asp_table_name = roi + \"_Catchments_AspectZstats\"\n",
    "                # cat_asp_table_path = os.path.join(outgdb, cat_asp_table_name)\n",
    "                # Percent North variables\n",
    "                wtd_merge_pernorth_table_name = roi + \"_Watersheds_Merge_PercentNorth\"\n",
    "                wtd_merge_pernorth_table_path = os.path.join(outgdb, wtd_merge_pernorth_table_name)\n",
    "                # cat_pernorth_table_name = roi + \"_Catchments_PercentNorth\"\n",
    "                # cat_pernorth_table_path = os.path.join(outgdb, cat_pernorth_table_name)\n",
    "\n",
    "                # Merge watersheds\n",
    "                wtd_merge = arcpy.Merge_management( wtds, wtd_merge_path ,add_source='ADD_SOURCE_INFO')\n",
    "                # Add wtd_id field\n",
    "                arcpy.AddField_management(wtd_merge,'wtd_id',field_type='TEXT')\n",
    "                # Add region field\n",
    "                arcpy.AddField_management(wtd_merge,'region',field_type='TEXT')\n",
    "                # Populate watershed id and region information using update cursor - faster than field calc\n",
    "                with arcpy.da.UpdateCursor(wtd_merge,['MERGE_SRC','wtd_id','region']) as cur:\n",
    "                    for row in cur:\n",
    "                        row[1] = re.findall('\\d+', row[0])[0]\n",
    "                        row[2] = roi\n",
    "                        # Update\n",
    "                        cur.updateRow(row)\n",
    "                    del(row)\n",
    "                del(cur)\n",
    "                mergestop = time.time()\n",
    "                mergetime = int (mergestop - mergestart)\n",
    "                print(f'Watershed Merge for {roi} Elapsed time: ({datetime.timedelta(seconds=mergetime)})')\n",
    "                print('----------')\n",
    "\n",
    "                # Begin Zonal Stats/Tabulate Area\n",
    "                zstat_start = time.time()\n",
    "                print(f'Begin zonal statistics min/mean/max std dev for watersheds and catchments in {roi} region')\n",
    "\n",
    "                # # Aspect Zonal statistics  for watersheds\n",
    "                # wtd_asp_metrics_table = ZonalStatisticsAsTable(in_zone_data = wtd_merge, zone_field =\"wtd_id\",\n",
    "                #                                                in_value_raster = asp_rast, out_table = wtd_merge_asp_table_path,\n",
    "                #                                                statistics_type='ALL')\n",
    "                # arcpy.AddField_management(wtd_asp_metrics_table, 'region', field_type='TEXT')\n",
    "                # arcpy.CalculateField_management(wtd_asp_metrics_table, 'region', 'roi')\n",
    "                # wtd_asp_ztables.append(wtd_asp_metrics_table)\n",
    "\n",
    "                # # Aspect Zonal statistics for catchments\n",
    "                # cat_asp_metrics_table = ZonalStatisticsAsTable(in_zone_data = cats, zone_field =\"NHDPlusID_txt\",\n",
    "                #                                                in_value_raster = asp_rast, out_table = cat_asp_table_path,\n",
    "                #                                                statistics_type='ALL')\n",
    "                # cat_asp_ztables.append(cat_asp_metrics_table)\n",
    "                zstat_stop = time.time()\n",
    "                zstat_time = int (zstat_stop - zstat_start)\n",
    "                print(f'Zonal Stats for {roi} Elapsed time: ({datetime.timedelta(seconds=zstat_time)})')\n",
    "                print('----------')\n",
    "\n",
    "                # Tabulate Area with north grid and catchments/watersheds\n",
    "                tabarea_start = time.time()\n",
    "                print(f'Begin tabulate area of north facing cells for watersheds and catchments in {roi} region')\n",
    "                # Percent North Tabulate area for watersheds\n",
    "                wtd_per_north_tabarea = arcpy.sa.TabulateArea(in_zone_data= wtd_merge, zone_field='wtd_id',\n",
    "                                                            in_class_data=nor_rast, class_field=\"Value\",\n",
    "                                                            out_table=wtd_merge_pernorth_table_path)\n",
    "\n",
    "                arcpy.AddField_management(wtd_per_north_tabarea, 'region', field_type='TEXT')\n",
    "                arcpy.AddField_management(wtd_per_north_tabarea, 'north_wtd', field_type='Float')\n",
    "\n",
    "                with arcpy.da.UpdateCursor(wtd_per_north_tabarea,['wtd_id','region', 'VALUE_0',\n",
    "                                                                        'VALUE_1', 'north_wtd']) as cur:\n",
    "                    for row in cur:\n",
    "                        row[1] = roi\n",
    "                        row[4] = row[3]/(row[3]+row[2])*100\n",
    "                        # Update\n",
    "                        cur.updateRow(row)\n",
    "                    del(row)\n",
    "                del(cur)\n",
    "\n",
    "                wtd_pernorth_taba_tables.append(wtd_per_north_tabarea)\n",
    "\n",
    "                # # Percent North Tabulate Area for catchments\n",
    "                # cat_per_north_tabarea = arcpy.sa.TabulateArea(in_zone_data= cats, zone_field='NHDPlusID',\n",
    "                #                                             in_class_data=nor_rast,\"Value\",\n",
    "                #                                             out_table=cat_pernorth_table_path)\n",
    "\n",
    "                # # Add and calculate region identifier field for catchment table\n",
    "                # arcpy.AddField_management(cat_per_north_tabarea, 'wtd_id', field_type='Float')\n",
    "                # arcpy.AddField_management(cat_per_north_tabarea, 'region', field_type='TEXT')\n",
    "                # arcpy.AddField_management(cat_per_north_tabarea, 'north_cat', field_type='Float')\n",
    "                #\n",
    "                # with arcpy.da.UpdateCursor(cat_per_north_tabarea,['NHDPlusID','region', 'VALUE_0',\n",
    "                #                                                         'VALUE_1', 'north_cat']) as cur:\n",
    "                #     for row in cur:\n",
    "                #         row[1] = roi\n",
    "                #         row[4] = row[3]/(row[3]+row[2])*100\n",
    "                #         # Update\n",
    "                #         cur.updateRow(row)\n",
    "                #     del(row)\n",
    "                # del(cur)\n",
    "                # cat_pernorth_taba_tables.append(cat_per_north_tabarea)\n",
    "                tabarea_stop = time.time()\n",
    "                tabarea_time = int (tabarea_stop - tabarea_start)\n",
    "                print(f'Tabulate area for {roi} Elapsed time: ({datetime.timedelta(seconds=tabarea_time)})')\n",
    "                print('----------')\n",
    "\n",
    "            except:\n",
    "                e = sys.exc_info()[1]\n",
    "                print(e.args[0])\n",
    "                arcpy.AddError(e.args[0])\n",
    "\n",
    "    else:\n",
    "        print(f'Region {str(roi)} not found in {region}')\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "\n",
    "# Report success\n",
    "print(f'Process completed at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "      f'(Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print('----------')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Drop unnecessary fields and rename as needed from merged tables.\n",
    "- Create Key value dictionary and use update cursor to rename fields."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Merge tables together\n",
    "        # wtd_per_north = arcpy.Merge_management(wtd_elev_ztables, wtd_per_north_table_out)\n",
    "        # cat_per_north = arcpy.Merge_management(cat_asp_ztables, cat_per_north_table_out)\n",
    "        # Use update cursor to calculate percent North\n",
    "                        # with arcpy.da.UpdateCursor(wtd_per_north,['VALUE_0','VALUE_1','wtd_aspect_mn']) as cur:\n",
    "                        #     for row in cur:\n",
    "                        #         row[2] = row[1]/(row[0] + row[1]) *100\n",
    "                        #         cur.updateRow(row)\n",
    "                        #     del(row)\n",
    "                        # del(cur)\n",
    "\n",
    "# Select tables and rename fields\n",
    "\n",
    "# Export to csv\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8caab41e",
   "language": "python",
   "display_name": "PyCharm (AKSSF)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}