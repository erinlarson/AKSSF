{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a id='top'></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Watershed and Catchment elevation statistics and percent north facing landcover.\n",
    "\n",
    "## Aspect and Percent North Covariates\n",
    "Calculate aspect grid with the DEM used to create the flow network for each processing area (e.g. HUC8 in NHDPlus or\n",
    " region for BB, PWS, or Kodiak). We need the DEMs used for each flow direction grid, or we can't calculate covariates at\n",
    " the watershed scale.\n",
    " * **~~aspect_rch = calculate mean aspect for stream reach (zonal statistics)~~**\n",
    " * **~~aspect_cat = calculate mean aspect over catchments (zonal statistics)~~**\n",
    " * **north_wtd = create 1/0 grid of north facing cells from aspect grid (north = aspects from 315-45 degrees), ~~~use\n",
    "  weighted flow accumulation to sum north facing cells, divide by flow accumulation grid to get % of north facing\n",
    "  cells in each watershed~~~ Use tabulate area to quantify area of North cells (VALUE_1) and non-North (VALUE_0) cells\n",
    "  for each watershed and calculate percent north as north_wtd = row[VALUE_1]/(row[VALUE_1]+row[VALUE_0])*100 .**\n",
    "\n",
    "## AKSSF Watershed and Catchment Elevation Metrics\n",
    "Calculate elevation metrics for catchment/watershed with temperature data using zonal statistics as table.\n",
    "\n",
    "### Catchment Elevation Metrics\n",
    "* **cat_elev_mn = mean elevation for catchment**\n",
    "* **cat_elev_min = minimum elevation for catchment**\n",
    "* **cat_elev_max = max elevation for catchment**\n",
    "* **cat_elev_std = standard deviation of elevation for catchment**\n",
    "\n",
    "### Watershed Elevation Metrics\n",
    "* **wtd_elev_mn = mean watershed elevation**\n",
    "* **wtd_elev_min = min watershed elevation**\n",
    "* **wtd_elev_max = max watershed elevation**\n",
    "* **wtd_elev_sd (or cv) = standard deviation of watershed elevation**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import modules"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18102021\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\landcover\n",
      "C:\\Users\\dwmerrigan\\AppData\\Local\\Programs\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\n"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "arcpy.env.overwriteOutput = True\n",
    "today = datetime.datetime.now()\n",
    "# Make the time stamp.\n",
    "time_stamp = '{:%d%m%Y}'.format(today)\n",
    "print(time_stamp)\n",
    "\n",
    "path = os.getcwd()\n",
    "print (path)\n",
    "print (sys.base_exec_prefix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Collect data and set working output locations\n",
    "Set data_dir to folder containing all AKSSF regional subfolders/geoadatabases\n",
    "* RS data folder: data_dir = r\"W:\\GIS\\AKSSF\"\n",
    "* DM data folder: data_dir = r\"D:\\GIS_Temp\\AKSSF_BeckyCopy\\AKSSF\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\GIS_temp\\\\AKSSF\\\\Bristol_Bay', 'D:\\\\GIS_temp\\\\AKSSF\\\\Cook_Inlet', 'D:\\\\GIS_temp\\\\AKSSF\\\\Copper_River', 'D:\\\\GIS_temp\\\\AKSSF\\\\Kodiak', 'D:\\\\GIS_temp\\\\AKSSF\\\\Prince_William_Sound']\n",
      "Working Folder already created... D:\\GIS_temp\\AKSSF_land_met\n",
      "Output location already exists D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\n"
     ]
    }
   ],
   "source": [
    "# Set AKSSF Data directory\n",
    "# data_dir = r\"W:\\GIS\\AKSSF\"\n",
    "\n",
    "# dm local\n",
    "data_dir = r\"D:\\GIS_Temp\\AKSSF\"\n",
    "\n",
    "arcpy.env.workspace = data_dir\n",
    "regions = arcpy.ListWorkspaces(workspace_type=\"Folder\")\n",
    "rois= []\n",
    "print (regions)\n",
    "\n",
    "# Path to create output folder/gdb\n",
    "temppath = r\"D:\\GIS_temp\" # Output folder\n",
    "dirname = 'AKSSF_land_met'\n",
    "tempgdbname = 'AKSSF_land_met.gdb'\n",
    "temp_dir = os.path.join(temppath, dirname)\n",
    "\n",
    "# Create temporary working gdb\n",
    "if not arcpy.Exists(temp_dir):\n",
    "    os.makedirs(temp_dir)\n",
    "else:\n",
    "    print('Working Folder already created...', temp_dir)\n",
    "\n",
    "outcheck = os.path.join(temp_dir, tempgdbname)\n",
    "\n",
    "if arcpy.Exists(outcheck):\n",
    "    print ('Output location already exists', outcheck)\n",
    "    outgdb = outcheck\n",
    "if not arcpy.Exists(outcheck):\n",
    "    print('Creating output GDB')\n",
    "    tempgdb = arcpy.CreateFileGDB_management(temp_dir,tempgdbname)\n",
    "    print ('Output geodatabase created at', outcheck)\n",
    "    outgdb = tempgdb.getOutput(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "['D:\\\\GIS_temp\\\\AKSSF\\\\Bristol_Bay',\n 'D:\\\\GIS_temp\\\\AKSSF\\\\Cook_Inlet',\n 'D:\\\\GIS_temp\\\\AKSSF\\\\Copper_River',\n 'D:\\\\GIS_temp\\\\AKSSF\\\\Kodiak',\n 'D:\\\\GIS_temp\\\\AKSSF\\\\Prince_William_Sound']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set regional workspaces from AKSSF data folder and store in list\n",
    "arcpy.env.workspace = data_dir\n",
    "regions  = arcpy.ListWorkspaces(workspace_type=\"Folder\")\n",
    "regions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create aspect and north grids if they do not already exists\n",
    "### NHDPlus"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020202\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020301\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020302\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020401\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020402\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020501\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020502\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020503\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020504\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020505\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020601\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020602\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020800\\elev_cm.tif to list\n"
     ]
    }
   ],
   "source": [
    "# Code to create merged elevation grid, aspect and north aspect grids for entire AKSSF region with NHDPlus elev data\n",
    "\n",
    "# elrasters = []\n",
    "# nhd_dat = r\"C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\AKSSF\\\\hydrography\\\\AKSSF_NHDPlus\\\\extracts\"\n",
    "# for dirpath, dirname, filenames in arcpy.da.Walk(nhd_dat, 'RasterDataset'):\n",
    "#     for filename in filenames:\n",
    "#         if filename == \"elev_cm.tif\":\n",
    "#             elras = os.path.join(dirpath, filename)\n",
    "#             elrasters.append(elras)\n",
    "#             print (f'Appending {elras} to list')\n",
    "#\n",
    "# spatial_ref = arcpy.Describe(elrasters[0]).spatialReference\n",
    "# print (spatial_ref.name)\n",
    "# # Merge all nhdplus elevation rasters together\n",
    "# elevname = 'AKSSF_NHDPlus_elev_cm.tif'\n",
    "# AKSSF_elev_cm = arcpy.MosaicToNewRaster_management(elrasters,temp_dir,elevname, spatial_ref, \"32_BIT_SIGNED\", \"5\", \"1\", \"LAST\",\"FIRST\")\n",
    "#\n",
    "# #make aspect raster for all of akssf from merged nhdplus\n",
    "# from arcpy.sa import *\n",
    "# aspname = 'AKSSF_NHDPlus_aspect.tif'\n",
    "# asp_rast = Aspect(in_raster= AKSSF_elev_cm, method='Planar')\n",
    "# asp_rast.save(os.path.join(temp_dir, aspname))\n",
    "#\n",
    "# # make north raster from aspect raster\n",
    "# norname = 'AKSSF_NHDPlus_north_aspect.tif'\n",
    "# aspect_in = Raster(asp_rast)\n",
    "# north_raster = Con((aspect_in>=0)&(aspect_in<=45),1,Con((aspect_in<=360)&(aspect_in>=315),1,0))\n",
    "# north_raster.save(os.path.join(temp_dir, norname))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TauDEM - Create grids using Timms Composite DEM for entire TauDEM processed areas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# Code to create merged elevation grid, aspect and north aspect grids for entire AKSSF region with TauDEM elev data\n",
    "# compDEM = r\"C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\data\\topography\\AKSSF_Elevation_Composite_10m.tif\"\n",
    "# clip to study area\n",
    "# AKSSF_elev_10m = r\"D:\\\\GIS_temp\\\\AKSSF_Composite_10m_extract.tif\"\n",
    "#\n",
    "# #make aspect raster for all of akssf from merged nhdplus\n",
    "# from arcpy.sa import *\n",
    "# aspname = 'AKSSF_Composite_10m_aspect.tif'\n",
    "# asp_rast = Aspect(in_raster= AKSSF_elev_10m, method='Planar')\n",
    "# asp_rast.save(os.path.join(temp_dir, aspname))\n",
    "#\n",
    "# # make north raster from aspect raster\n",
    "# norname = 'AKSSF_Composite_10m_north_aspect.tif'\n",
    "# aspect_in = Raster(asp_rast)\n",
    "# north_raster = Con((aspect_in>=0)&(aspect_in<=45),1,Con((aspect_in<=360)&(aspect_in>=315),1,0))\n",
    "# north_raster.save(os.path.join(temp_dir, norname))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Begin GIS portion\n",
    "- May be faster and save more space to create aspect rasters here using extract by mask?\n",
    "- May be able to use aspect raster with tabulate intersection to calculate percent North (aspects from 315-45 degrees)\n",
    "\n",
    "### <b>UPDATE - 2021-10-12 Do not run aspect metrics at this time. Only need to run percent North for watersheds</b>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\GIS_temp\\AKSSF\\Bristol_Bay\n",
      "D:\\GIS_temp\\AKSSF\\Cook_Inlet\n",
      "D:\\GIS_temp\\AKSSF\\Cook_Inlet found for Cook_Inlet\n",
      "NHD data: north raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_NHDPlus_north_aspect.tif\n",
      "         aspect raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_NHDPlus_aspect.tif\n",
      "      elevation raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_NHDPlus_elev_cm.tif\n",
      "----------\n",
      "Adding cat_ID_txt field to catchment dataset D:\\GIS_temp\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb\\cats_intersect\n",
      "----------\n",
      "Adding cat_ID_txt field to watershed dataset D:\\GIS_temp\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb\\wtds_merge\n",
      "----------\n",
      "Calculating aspect metrics and percent north for catchments & watersheds of interest in Cook_Inlet region\n",
      "----------\n",
      "Geodatabase: ['D:\\\\GIS_temp\\\\AKSSF\\\\Cook_Inlet\\\\Cook_Inlet.gdb']\n",
      "----------\n",
      "Elevation Raster: D:\\GIS_temp\\AKSSF\\Cook_Inlet\\elev.tif\n",
      "----------\n",
      "North Aspect Raster: D:\\Basedata\\AKSSF_Basedata\\AKSSF_NHDPlus_north_aspect.tif\n",
      "----------\n",
      "241 Watersheds to process\n",
      "----------\n",
      "Catchment intersect D:\\GIS_temp\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb\\cats_intersect selected\n",
      "----------\n",
      "Merged watershed dataset D:\\GIS_temp\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb\\wtds_merge already created\n",
      "----------\n",
      "Begin zonal statistics min/mean/max std dev for watersheds and catchments in Cook_Inlet region\n",
      "Zonal Stats for Cook_Inlet Elapsed time: (0:11:02)\n",
      "----------\n",
      "Begin tabulate area of north facing cells for watersheds and catchments in Cook_Inlet region\n",
      "Tabulate area for Cook_Inlet Elapsed time: (0:06:28)\n",
      "----------\n",
      "D:\\GIS_temp\\AKSSF\\Copper_River\n",
      "D:\\GIS_temp\\AKSSF\\Kodiak\n",
      "D:\\GIS_temp\\AKSSF\\Prince_William_Sound\n",
      "Region Cook_Inlet not found in D:\\GIS_temp\\AKSSF\\Prince_William_Sound\n",
      "D:\\GIS_temp\\AKSSF\\Bristol_Bay\n",
      "D:\\GIS_temp\\AKSSF\\Cook_Inlet\n",
      "D:\\GIS_temp\\AKSSF\\Copper_River\n",
      "D:\\GIS_temp\\AKSSF\\Copper_River found for Copper_River\n",
      "NHD data: north raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_NHDPlus_north_aspect.tif\n",
      "         aspect raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_NHDPlus_aspect.tif\n",
      "      elevation raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_NHDPlus_elev_cm.tif\n",
      "----------\n",
      "Adding cat_ID_txt field to catchment dataset D:\\GIS_temp\\AKSSF\\Copper_River\\Copper_River.gdb\\cats_intersect\n",
      "----------\n",
      "Adding cat_ID_txt field to watershed dataset D:\\GIS_temp\\AKSSF\\Copper_River\\Copper_River.gdb\\wtds_merge\n",
      "----------\n",
      "Calculating aspect metrics and percent north for catchments & watersheds of interest in Copper_River region\n",
      "----------\n",
      "Geodatabase: ['D:\\\\GIS_temp\\\\AKSSF\\\\Copper_River\\\\Copper_River.gdb']\n",
      "----------\n",
      "Elevation Raster: D:\\GIS_temp\\AKSSF\\Copper_River\\elev.tif\n",
      "----------\n",
      "North Aspect Raster: D:\\GIS_temp\\AKSSF\\Copper_River\\north.tif\n",
      "----------\n",
      "28 Watersheds to process\n",
      "----------\n",
      "Catchment intersect D:\\GIS_temp\\AKSSF\\Copper_River\\Copper_River.gdb\\cats_intersect selected\n",
      "----------\n",
      "Merged watershed dataset D:\\GIS_temp\\AKSSF\\Copper_River\\Copper_River.gdb\\wtds_merge already created\n",
      "----------\n",
      "Begin zonal statistics min/mean/max std dev for watersheds and catchments in Copper_River region\n",
      "Zonal Stats for Copper_River Elapsed time: (0:05:45)\n",
      "----------\n",
      "Begin tabulate area of north facing cells for watersheds and catchments in Copper_River region\n",
      "Tabulate area for Copper_River Elapsed time: (0:03:23)\n",
      "----------\n",
      "D:\\GIS_temp\\AKSSF\\Kodiak\n",
      "D:\\GIS_temp\\AKSSF\\Prince_William_Sound\n",
      "Region Copper_River not found in D:\\GIS_temp\\AKSSF\\Prince_William_Sound\n",
      "D:\\GIS_temp\\AKSSF\\Bristol_Bay\n",
      "D:\\GIS_temp\\AKSSF\\Bristol_Bay found for Bristol_Bay\n",
      "TauDem data: north raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_north_aspect.tif\n",
      "         aspect raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_aspect.tif\n",
      "      elevation raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_extract.tif\n",
      "----------\n",
      "Id field already in dataset\n",
      "Id field already in dataset\n",
      "----------\n",
      "Calculating aspect metrics and percent north for catchments & watersheds of interest in Bristol_Bay region\n",
      "----------\n",
      "Geodatabase: ['D:\\\\GIS_temp\\\\AKSSF\\\\Bristol_Bay\\\\Bristol_Bay.gdb']\n",
      "----------\n",
      "Elevation Raster: D:\\GIS_temp\\AKSSF\\Bristol_Bay\\elev.tif\n",
      "----------\n",
      "North Aspect Raster: D:\\GIS_temp\\AKSSF\\Bristol_Bay\\north.tif\n",
      "----------\n",
      "114 Watersheds to process\n",
      "----------\n",
      "Catchment intersect D:\\GIS_temp\\AKSSF\\Bristol_Bay\\Bristol_Bay.gdb\\cats_intersect selected\n",
      "----------\n",
      "Merged watershed dataset D:\\GIS_temp\\AKSSF\\Bristol_Bay\\Bristol_Bay.gdb\\wtds_merge already created\n",
      "----------\n",
      "Begin zonal statistics min/mean/max std dev for watersheds and catchments in Bristol_Bay region\n",
      "Zonal Stats for Bristol_Bay Elapsed time: (0:00:56)\n",
      "----------\n",
      "Begin tabulate area of north facing cells for watersheds and catchments in Bristol_Bay region\n",
      "Tabulate area for Bristol_Bay Elapsed time: (0:00:59)\n",
      "----------\n",
      "D:\\GIS_temp\\AKSSF\\Cook_Inlet\n",
      "D:\\GIS_temp\\AKSSF\\Copper_River\n",
      "D:\\GIS_temp\\AKSSF\\Kodiak\n",
      "D:\\GIS_temp\\AKSSF\\Prince_William_Sound\n",
      "Region Bristol_Bay not found in D:\\GIS_temp\\AKSSF\\Prince_William_Sound\n",
      "D:\\GIS_temp\\AKSSF\\Bristol_Bay\n",
      "D:\\GIS_temp\\AKSSF\\Cook_Inlet\n",
      "D:\\GIS_temp\\AKSSF\\Copper_River\n",
      "D:\\GIS_temp\\AKSSF\\Kodiak\n",
      "D:\\GIS_temp\\AKSSF\\Kodiak found for Kodiak\n",
      "TauDem data: north raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_north_aspect.tif\n",
      "         aspect raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_aspect.tif\n",
      "      elevation raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_extract.tif\n",
      "----------\n",
      "Adding cat_ID_txt field to catchment dataset D:\\GIS_temp\\AKSSF\\Kodiak\\Kodiak.gdb\\cats_intersect\n",
      "----------\n",
      "Adding cat_ID_txt field to watershed dataset D:\\GIS_temp\\AKSSF\\Kodiak\\Kodiak.gdb\\wtds_merge\n",
      "----------\n",
      "Calculating aspect metrics and percent north for catchments & watersheds of interest in Kodiak region\n",
      "----------\n",
      "Geodatabase: ['D:\\\\GIS_temp\\\\AKSSF\\\\Kodiak\\\\Kodiak.gdb']\n",
      "----------\n",
      "Elevation Raster: D:\\GIS_temp\\AKSSF\\Kodiak\\elev.tif\n",
      "----------\n",
      "North Aspect Raster: D:\\GIS_temp\\AKSSF\\Kodiak\\north.tif\n",
      "----------\n",
      "28 Watersheds to process\n",
      "----------\n",
      "Catchment intersect D:\\GIS_temp\\AKSSF\\Kodiak\\Kodiak.gdb\\cats_intersect selected\n",
      "----------\n",
      "Merged watershed dataset D:\\GIS_temp\\AKSSF\\Kodiak\\Kodiak.gdb\\wtds_merge already created\n",
      "----------\n",
      "Begin zonal statistics min/mean/max std dev for watersheds and catchments in Kodiak region\n",
      "Zonal Stats for Kodiak Elapsed time: (0:00:10)\n",
      "----------\n",
      "Begin tabulate area of north facing cells for watersheds and catchments in Kodiak region\n",
      "Tabulate area for Kodiak Elapsed time: (0:00:08)\n",
      "----------\n",
      "D:\\GIS_temp\\AKSSF\\Prince_William_Sound\n",
      "Region Kodiak not found in D:\\GIS_temp\\AKSSF\\Prince_William_Sound\n",
      "D:\\GIS_temp\\AKSSF\\Bristol_Bay\n",
      "D:\\GIS_temp\\AKSSF\\Cook_Inlet\n",
      "D:\\GIS_temp\\AKSSF\\Copper_River\n",
      "D:\\GIS_temp\\AKSSF\\Kodiak\n",
      "D:\\GIS_temp\\AKSSF\\Prince_William_Sound\n",
      "D:\\GIS_temp\\AKSSF\\Prince_William_Sound found for Prince_William_Sound\n",
      "TauDem data: north raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_north_aspect.tif\n",
      "         aspect raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_aspect.tif\n",
      "      elevation raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_extract.tif\n",
      "----------\n",
      "Adding cat_ID_txt field to catchment dataset D:\\GIS_temp\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\\cats_intersect\n",
      "----------\n",
      "Adding cat_ID_txt field to watershed dataset D:\\GIS_temp\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\\wtds_merge\n",
      "----------\n",
      "Calculating aspect metrics and percent north for catchments & watersheds of interest in Prince_William_Sound region\n",
      "----------\n",
      "Geodatabase: ['D:\\\\GIS_temp\\\\AKSSF\\\\Prince_William_Sound\\\\Prince_William_Sound.gdb']\n",
      "----------\n",
      "Elevation Raster: D:\\GIS_temp\\AKSSF\\Prince_William_Sound\\elev.tif\n",
      "----------\n",
      "North Aspect Raster: D:\\GIS_temp\\AKSSF\\Prince_William_Sound\\north.tif\n",
      "----------\n",
      "19 Watersheds to process\n",
      "----------\n",
      "Catchment intersect D:\\GIS_temp\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\\cats_intersect selected\n",
      "----------\n",
      "Merged watershed dataset D:\\GIS_temp\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\\wtds_merge already created\n",
      "----------\n",
      "Begin zonal statistics min/mean/max std dev for watersheds and catchments in Prince_William_Sound region\n",
      "Zonal Stats for Prince_William_Sound Elapsed time: (0:00:09)\n",
      "----------\n",
      "Begin tabulate area of north facing cells for watersheds and catchments in Prince_William_Sound region\n",
      "Tabulate area for Prince_William_Sound Elapsed time: (0:00:08)\n",
      "----------\n",
      "Region Prince_William_Sound not found in D:\\GIS_temp\\AKSSF\\Prince_William_Sound\n",
      "Process completed at 2021-10-18 11:45 (Elapsed time: 0:29:19)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "from arcpy.sa import *\n",
    "import re\n",
    "\n",
    "# Set data_dir equal to folder containing AKSSF regional subfolders containing GDBs and raster datasets\n",
    "arcpy.env.workspace = data_dir\n",
    "arcpy.env.overwriteOutput = True\n",
    "regions  = arcpy.ListWorkspaces(workspace_type=\"Folder\")\n",
    "\n",
    "# Lists for variables not needed at present time\n",
    "#cat_asp_ztables = []\n",
    "#wtd_asp_ztables = []\n",
    "#cat_pernorth_taba_tables=[]\n",
    "\n",
    "# Lists to store output tables\n",
    "wtd_pernorth_taba_tables=[]\n",
    "cat_elev_ztables = []\n",
    "wtd_elev_ztables = []\n",
    "\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "\n",
    "# Seperate data by\n",
    "nhdplus_dat = ['Cook_Inlet','Copper_River']\n",
    "tauDem_dat = ['Bristol_Bay', 'Kodiak', 'Prince_William_Sound']\n",
    "\n",
    "# Loop through all processing areas\n",
    "rois = nhdplus_dat + tauDem_dat\n",
    "#xrois = ['Bristol_Bay']\n",
    "for roi in rois:\n",
    "# Loop through regional folders\n",
    "    for region in regions:\n",
    "        print (region)\n",
    "        if roi in str(region):\n",
    "            print(f'{region} found for {roi}')\n",
    "            if roi in nhdplus_dat:\n",
    "                # NHDPLus raster data for DM pc, variables will be overwritten below if they exist in source folder.\n",
    "                asp_rast = r\"D:\\Basedata\\AKSSF_Basedata\\AKSSF_NHDPlus_aspect.tif\"\n",
    "                elev_rast = r\"D:\\Basedata\\AKSSF_Basedata\\AKSSF_NHDPlus_elev_cm.tif\"\n",
    "                nor_rast = r\"D:\\Basedata\\AKSSF_Basedata\\AKSSF_NHDPlus_north_aspect.tif\"\n",
    "                cat_cur_fields = ['cat_ID_txt', 'NHDPlusID']\n",
    "                wtd_cur_fields = ['cat_ID_txt', 'cat_ID']\n",
    "\n",
    "                print(f'NHD data: north raster - {nor_rast}')\n",
    "                print(f'         aspect raster - {asp_rast}')\n",
    "                print(f'      elevation raster - {elev_rast}')\n",
    "                print('----------')\n",
    "\n",
    "            elif roi in tauDem_dat:\n",
    "                # TauDEM raster data for DM pc, variables will be overwritten below if they exist in source folder.\n",
    "                nor_rast = r\"D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_north_aspect.tif\"\n",
    "                asp_rast = r\"D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_aspect.tif\"\n",
    "                elev_rast = r\"D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_extract.tif\"\n",
    "                cat_cur_fields = ['cat_ID_txt', 'gridcode']\n",
    "                wtd_cur_fields = ['cat_ID_txt', 'cat_ID']\n",
    "                print(f'TauDem data: north raster - {nor_rast}')\n",
    "                print(f'         aspect raster - {asp_rast}')\n",
    "                print(f'      elevation raster - {elev_rast}')\n",
    "                print('----------')\n",
    "\n",
    "            stats_fields = ['MEAN','MAX','MIN','STD']\n",
    "            wtds = []\n",
    "            cats = []\n",
    "            # Start iter timing function\n",
    "            iteration_start = time.time()\n",
    "            # Set workspace to region folder\n",
    "            arcpy.env.workspace = region\n",
    "            gdb = arcpy.ListWorkspaces(workspace_type='FileGDB')\n",
    "            walk = arcpy.da.Walk(region, datatype = ['FeatureClass','RasterDataset'])\n",
    "            for dirpath, dirnames, filenames in walk:\n",
    "                for filename in filenames:\n",
    "                    # Create list of watersheds\n",
    "                    if ((\"wtd\" in filename) and (\"merge\" not in filename)):\n",
    "                        wtds.append(os.path.join(dirpath, filename))\n",
    "\n",
    "                    # Set watershed merged watersheds dataset\n",
    "                    elif 'wtds_merge'in filename:\n",
    "                        wtd_merge = os.path.join(dirpath, filename)\n",
    "                        wtdfieldnames = []\n",
    "                        wtdlstFields = arcpy.ListFields(wtd_merge)\n",
    "                        for field in wtdlstFields:\n",
    "                            wtdfieldnames.append(field.name)\n",
    "                        if 'cat_ID_txt' in wtdfieldnames:\n",
    "                            print ('Id field already in dataset')\n",
    "                            print('----------')\n",
    "                        else:\n",
    "                            print (f'Adding cat_ID_txt field to watershed dataset {wtd_merge}')\n",
    "                            print('----------')\n",
    "                            # add cat_ID_txt field\n",
    "                            arcpy.AddField_management(wtd_merge,\"cat_ID_txt\",field_type='TEXT')\n",
    "                            # populate cat_ID_txt\n",
    "                            with arcpy.da.UpdateCursor(wtd_merge, wtd_cur_fields) as cur:\n",
    "                                for row in cur:\n",
    "                                    row[0] = str(row[1])\n",
    "                                    # Update rows\n",
    "                                    cur.updateRow(row)\n",
    "                                del(row)\n",
    "                            del(cur)\n",
    "\n",
    "                    # Select elevation raster\n",
    "                    elif 'elev.tif' == filename:\n",
    "                        elev_rast = os.path.join(dirpath, filename)\n",
    "\n",
    "                    # # Select aspect raster\n",
    "                    # elif 'aspect' in filename:\n",
    "                    #     asp_rast = os.path.join(dirpath, filename)\n",
    "\n",
    "                    # Select north raster\n",
    "                    elif 'north.tif' == filename:\n",
    "                        nor_rast = os.path.join(dirpath, filename)\n",
    "\n",
    "                    # Select catch_int fc (catchments of interest for region) and make a copy\n",
    "                    elif 'cats_intersect' in filename:\n",
    "                        cats = os.path.join(dirpath,filename)\n",
    "                        catlstfields = arcpy.ListFields(cats)\n",
    "                        catfieldnames = []\n",
    "                        catlstfields = arcpy.ListFields(cats)\n",
    "                        for field in catlstfields:\n",
    "                            catfieldnames.append(field.name)\n",
    "                        if 'cat_ID_txt' in catfieldnames:\n",
    "                            print ('Id field already in dataset')\n",
    "                        else:\n",
    "                            print (f'Adding cat_ID_txt field to catchment dataset {cats}')\n",
    "                            print('----------')\n",
    "                            # add cat_ID_txt field\n",
    "                            arcpy.AddField_management(cats,\"cat_ID_txt\",field_type='TEXT')\n",
    "                            # populate cat_ID_txt\n",
    "                            with arcpy.da.UpdateCursor(cats, cat_cur_fields) as cur:\n",
    "                                for row in cur:\n",
    "                                    row[0] = str(row[1])\n",
    "                                    # Update rows\n",
    "                                    cur.updateRow(row)\n",
    "                                del(row)\n",
    "                            del(cur)\n",
    "\n",
    "            print (f'Calculating aspect metrics and percent north for catchments & watersheds of interest in {roi}'\n",
    "                   f' region')\n",
    "            print ('----------')\n",
    "            print(f'Geodatabase: {gdb}')\n",
    "            print ('----------')\n",
    "            print (f'Elevation Raster: {elev_rast}')\n",
    "            print ('----------')\n",
    "            print (f'North Aspect Raster: {nor_rast}')\n",
    "            print ('----------')\n",
    "            print (f'{len(wtds)} Watersheds to process')\n",
    "            print ('----------')\n",
    "            print (f'Catchment intersect {cats} selected')\n",
    "            print ('----------')\n",
    "\n",
    "            try:\n",
    "                # Set output names/paths for watershed and catchment tables\n",
    "                wtd_merge_name = roi + \"_Watersheds_Merge\"\n",
    "                wtd_merge_path = os.path.join(outgdb,wtd_merge_name)\n",
    "\n",
    "                # # Aspect variables\n",
    "                # wtd_merge_asp_table_name = roi + \"_Watersheds_Merge_AspectZstats\"\n",
    "                # wtd_merge_asp_table_path = os.path.join(outgdb, wtd_merge_asp_table_name)\n",
    "                # cat_asp_table_name = roi + \"_Catchments_AspectZstats\"\n",
    "                # cat_asp_table_path = os.path.join(outgdb, cat_asp_table_name)\n",
    "\n",
    "                # Percent North variables\n",
    "                wtd_merge_pernorth_table_name = roi + \"_Watersheds_Merge_PercentNorth\"\n",
    "                wtd_merge_pernorth_table_path = os.path.join(outgdb, wtd_merge_pernorth_table_name)\n",
    "                # cat_pernorth_table_name = roi + \"_Catchments_PercentNorth\"\n",
    "                # cat_pernorth_table_path = os.path.join(outgdb, cat_pernorth_table_name)\n",
    "\n",
    "                # Elevation variables\n",
    "                wtd_merge_elev_table_name = roi + \"_Watersheds_Merge_ElevZstats\"\n",
    "                wtd_merge_elev_table_path = os.path.join(outgdb, wtd_merge_elev_table_name)\n",
    "                cat_elev_table_name = roi + \"_Catchments_ElevZstats\"\n",
    "                cat_elev_table_path = os.path.join(outgdb, cat_elev_table_name)\n",
    "\n",
    "                if not arcpy.Exists(wtd_merge):\n",
    "                    mergestart = time.time()\n",
    "                    # Merge watersheds\n",
    "                    wtd_merge = arcpy.Merge_management( wtds, wtd_merge_path ,add_source='ADD_SOURCE_INFO')\n",
    "                    # Add wtd_id field\n",
    "                    arcpy.AddField_management(wtd_merge,'cat_ID_txt',field_type='TEXT')\n",
    "                    # Add region field\n",
    "                    arcpy.AddField_management(wtd_merge,'region',field_type='TEXT')\n",
    "                    # Populate watershed id and region information using update cursor - faster than field calc\n",
    "                    with arcpy.da.UpdateCursor(wtd_merge,['MERGE_SRC','cat_ID_txt','region']) as cur:\n",
    "                        for row in cur:\n",
    "                            row[1] = re.findall('\\d+', row[0])[0]\n",
    "                            row[2] = roi\n",
    "                            # Update\n",
    "                            cur.updateRow(row)\n",
    "                        del(row)\n",
    "                    del(cur)\n",
    "                    mergestop = time.time()\n",
    "                    mergetime = int (mergestop - mergestart)\n",
    "                    print(f'Watershed Merge for {roi} Elapsed time: ({datetime.timedelta(seconds=mergetime)})')\n",
    "                    print('----------')\n",
    "                else:\n",
    "                    print (f'Merged watershed dataset {wtd_merge} already created')\n",
    "                    print('----------')\n",
    "                    \n",
    "                # Begin Zonal Stats\n",
    "                zstat_start = time.time()\n",
    "                print(f'Begin zonal statistics min/mean/max std dev for watersheds and catchments in {roi} region')\n",
    "\n",
    "                # Elevation Zonal statistics  for watersheds\n",
    "                wtd_elev_metrics_table = ZonalStatisticsAsTable(in_zone_data = wtd_merge,\n",
    "                                                                zone_field = \"cat_ID_txt\",\n",
    "                                                                in_value_raster = elev_rast,\n",
    "                                                                out_table = wtd_merge_elev_table_path,\n",
    "                                                                statistics_type='ALL'\n",
    "                                                                )\n",
    "                # Add region identifier field for watershed tables                                                )\n",
    "                arcpy.AddField_management(wtd_elev_metrics_table,'region',field_type='TEXT')\n",
    "                # Update region field\n",
    "                with arcpy.da.UpdateCursor(wtd_elev_metrics_table,'region') as cur:\n",
    "                    for row in cur:\n",
    "                        row[0] = roi\n",
    "                        # Update\n",
    "                        cur.updateRow(row)\n",
    "                    del(row)\n",
    "                del(cur)\n",
    "                # Append watershed elev table to list\n",
    "                wtd_elev_ztables.append(wtd_elev_metrics_table)\n",
    "\n",
    "                # Elevation zonal statistics for catchments\n",
    "                cat_elev_metrics_table = ZonalStatisticsAsTable(in_zone_data = cats ,\n",
    "                                                                zone_field = \"cat_ID_txt\",\n",
    "                                                                in_value_raster = elev_rast,\n",
    "                                                                out_table = cat_elev_table_path,\n",
    "                                                                statistics_type='ALL'\n",
    "                                                                )\n",
    "                # Add region identifier field for catchment table\n",
    "                arcpy.AddField_management(cat_elev_metrics_table,'region',field_type='TEXT')\n",
    "\n",
    "                # Update region field\n",
    "                with arcpy.da.UpdateCursor(cat_elev_metrics_table,'region') as cur:\n",
    "                    for row in cur:\n",
    "                        row[0] = roi\n",
    "                        # Update\n",
    "                        cur.updateRow(row)\n",
    "                    del(row)\n",
    "                del(cur)\n",
    "                # Append catchment elev table to list\n",
    "                cat_elev_ztables.append(cat_elev_metrics_table)\n",
    "\n",
    "                # # Aspect Zonal statistics  for watersheds\n",
    "                # wtd_asp_metrics_table = ZonalStatisticsAsTable(in_zone_data = wtd_merge, zone_field =\"cat_ID_txt\",\n",
    "                #                                                in_value_raster = asp_rast, out_table = wtd_merge_asp_table_path,\n",
    "                #                                                statistics_type='ALL')\n",
    "                # arcpy.AddField_management(wtd_asp_metrics_table, 'region', field_type='TEXT')\n",
    "                # arcpy.CalculateField_management(wtd_asp_metrics_table, 'region', 'roi')\n",
    "                # wtd_asp_ztables.append(wtd_asp_metrics_table)\n",
    "\n",
    "                # # Aspect Zonal statistics for catchments\n",
    "                # cat_asp_metrics_table = ZonalStatisticsAsTable(in_zone_data = cats, zone_field =\"cat_ID_txt\",\n",
    "                #                                                in_value_raster = asp_rast, out_table = cat_asp_table_path,\n",
    "                #                                                statistics_type='ALL')\n",
    "                # cat_asp_ztables.append(cat_asp_metrics_table)\n",
    "\n",
    "                zstat_stop = time.time()\n",
    "                zstat_time = int (zstat_stop - zstat_start)\n",
    "                print(f'Zonal Stats for {roi} Elapsed time: ({datetime.timedelta(seconds=zstat_time)})')\n",
    "                print('----------')\n",
    "\n",
    "                # Tabulate Area with north grid and catchments/watersheds\n",
    "                tabarea_start = time.time()\n",
    "                print(f'Begin tabulate area of north facing cells for watersheds and catchments in {roi} region')\n",
    "                # Percent North Tabulate area for watersheds\n",
    "                wtd_per_north_tabarea = arcpy.sa.TabulateArea(in_zone_data= wtd_merge,\n",
    "                                                              zone_field='cat_ID_txt',\n",
    "                                                              in_class_data=nor_rast,\n",
    "                                                              class_field=\"Value\",\n",
    "                                                              out_table=wtd_merge_pernorth_table_path\n",
    "                                                              )\n",
    "                # Add region and percent north fields\n",
    "                arcpy.AddField_management(wtd_per_north_tabarea, 'region', field_type='TEXT')\n",
    "                arcpy.AddField_management(wtd_per_north_tabarea, 'wtd_north_per', field_type='Float')\n",
    "\n",
    "                with arcpy.da.UpdateCursor(wtd_per_north_tabarea,['cat_ID_txt','region', 'VALUE_0',\n",
    "                                                                        'VALUE_1', 'north_wtd']) as cur:\n",
    "                    for row in cur:\n",
    "                        row[1] = roi\n",
    "                        row[4] = row[3]/(row[3]+row[2])*100\n",
    "                        # Update\n",
    "                        cur.updateRow(row)\n",
    "                    del(row)\n",
    "                del(cur)\n",
    "                # Append watershed percent north table to list\n",
    "                wtd_pernorth_taba_tables.append(wtd_per_north_tabarea)\n",
    "\n",
    "                # # Percent North Tabulate Area for catchments\n",
    "                # cat_per_north_tabarea = arcpy.sa.TabulateArea(in_zone_data= cats, zone_field='cat_ID_txt',\n",
    "                #                                             in_class_data=nor_rast,\"Value\",\n",
    "                #                                             out_table=cat_pernorth_table_path)\n",
    "\n",
    "                # # Add and calculate region identifier field for catchment table\n",
    "                # arcpy.AddField_management(cat_per_north_tabarea, 'cat_ID_txt', field_type='Float')\n",
    "                # arcpy.AddField_management(cat_per_north_tabarea, 'region', field_type='TEXT')\n",
    "                # arcpy.AddField_management(cat_per_north_tabarea, 'north_cat', field_type='Float')\n",
    "                #\n",
    "                # with arcpy.da.UpdateCursor(cat_per_north_tabarea,['cat_ID_txt','region', 'VALUE_0',\n",
    "                #                                                         'VALUE_1', 'north_cat']) as cur:\n",
    "                #     for row in cur:\n",
    "                #         row[1] = roi\n",
    "                #         row[4] = row[3]/(row[3]+row[2])*100\n",
    "                #         # Update\n",
    "                #         cur.updateRow(row)\n",
    "                #     del(row)\n",
    "                # del(cur)\n",
    "                # cat_pernorth_taba_tables.append(cat_per_north_tabarea)\n",
    "                tabarea_stop = time.time()\n",
    "                tabarea_time = int (tabarea_stop - tabarea_start)\n",
    "                print(f'Tabulate area for {roi} Elapsed time: ({datetime.timedelta(seconds=tabarea_time)})')\n",
    "                print('----------')\n",
    "\n",
    "            except:\n",
    "                e = sys.exc_info()[1]\n",
    "                print(e.args[0])\n",
    "                arcpy.AddError(e.args[0])\n",
    "\n",
    "    else:\n",
    "        print(f'Region {str(roi)} not found in {region}')\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "\n",
    "# Report success\n",
    "print(f'Process completed at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "      f'(Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print('----------')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Drop unnecessary fields and rename as needed from merged tables.\n",
    "- Create Key value dictionary and use update cursor to rename fields."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "wtd_pernorth_taba_tables\n",
    "cat_elev_ztables\n",
    "wtd_elev_ztables\n",
    "\n",
    "# Table names/paths\n",
    "wtd_per_north_table_out = os.path.join(outgdb, 'AKSSF_wtd_north_per')\n",
    "cat_elev_table_out = os.path.join(outgdb,'AKSSF_cat_elev')\n",
    "wtd_elev_table_out = os.path.join(outgdb, 'AKSSF_wtd_elev')\n",
    "\n",
    "# Merge tables together\n",
    "wtd_per_north = arcpy.Merge_management(wtd_pernorth_taba_tables, wtd_per_north_table_out)\n",
    "cat_elev = arcpy.Merge_management(cat_elev_ztables, cat_elev_table_out)\n",
    "wtd_elev = arcpy.Merge_management(wtd_elev_ztables, wtd_elev_table_out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "#Set up field dictionary\n",
    "dict = { 'ZONE_CODE': ('cat_elev_ZONE_CODE', 'wtd_elev_ZONE_CODE'),\n",
    " 'COUNT': ('cat_elev_COUNT', 'wtd_elev_COUNT'),\n",
    " 'AREA': ('cat_elev_AREA', 'wtd_elev_AREA'),\n",
    " 'MIN': ('cat_elev_MIN', 'wtd_elev_MIN'),\n",
    " 'MAX': ('cat_elev_MAX', 'wtd_elev_MAX'),\n",
    " 'RANGE': ('cat_elev_RANGE', 'wtd_elev_RANGE'),\n",
    " 'MEAN': ('cat_elev_MEAN', 'wtd_elev_MEAN'),\n",
    " 'STD': ('cat_elev_STD', 'wtd_elev_STD'),\n",
    " 'SUM': ('cat_elev_SUM', 'wtd_elev_SUM'),\n",
    " 'VARIETY': ('cat_elev_VARIETY', 'wtd_elev_VARIETY'),\n",
    " 'MAJORITY': ('cat_elev_MAJORITY', 'wtd_elev_MAJORITY'),\n",
    " 'MINORITY': ('cat_elev_MINORITY', 'wtd_elev_MINORITY'),\n",
    " 'MEDIAN': ('cat_elev_MEDIAN', 'wtd_elev_MEDIAN'),\n",
    " 'PCT90': ('cat_elev_PCT90', 'wtd_elev_PCT90')}\n",
    "\n",
    "catz = []\n",
    "catzup = []\n",
    "wtdz = []\n",
    "wtdzup = []\n",
    "\n",
    "# Field lists\n",
    "wtd_pernoth_fields = arcpy.ListFields(wtd_per_north)\n",
    "cat_elev_zfields = arcpy.ListFields(cat_elev)\n",
    "wtd_elev_zfields = arcpy.ListFields(wtd_elev)\n",
    "\n",
    "# for field in cat_elev_zfields:\n",
    "#     fnam = field.name\n",
    "#     print (fnam)\n",
    "#     catznew = 'cat_elev_' + str(fnam)\n",
    "#     catz.append(fnam)\n",
    "#     catzup.append(catznew)\n",
    "#\n",
    "# for field in wtd_elev_zfields:\n",
    "#     fnam = field.name\n",
    "#     print (fnam)\n",
    "#     wtdznew = 'wtd_elev_' + str(fnam)\n",
    "#     wtdz.append(fnam)\n",
    "#     wtdzup.append(wtdznew)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# Rename fields\n",
    "for field in arcpy.ListFields(wtd_elev):\n",
    "    keyval = field.name\n",
    "    if keyval in dict:\n",
    "        newname = dict[keyval][1]\n",
    "        newalias = dict[keyval][1]\n",
    "        print (keyval, newname)\n",
    "        arcpy.AlterField_management(wtd_elev, keyval, newname, newalias)\n",
    "\n",
    "for field in arcpy.ListFields(cat_elev):\n",
    "    keyval = field.name\n",
    "    if keyval in dict:\n",
    "        newname = dict[keyval][0]\n",
    "        newalias = dict[keyval][0]\n",
    "        print (keyval, newname)\n",
    "        arcpy.AlterField_management(cat_elev, keyval, newname, newalias)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJECTID OBJECTID\n",
      "cat_ID_txt cat_ID_txt\n",
      "cat_elev_ZONE_CODE cat_elev_ZONE_CODE\n",
      "cat_elev_COUNT cat_elev_COUNT\n",
      "cat_elev_AREA cat_elev_AREA\n",
      "cat_elev_MIN cat_elev_MIN\n",
      "cat_elev_MAX cat_elev_MAX\n",
      "cat_elev_RANGE cat_elev_RANGE\n",
      "cat_elev_MEAN cat_elev_MEAN\n",
      "cat_elev_STD cat_elev_STD\n",
      "cat_elev_SUM cat_elev_SUM\n",
      "cat_elev_VARIETY cat_elev_VARIETY\n",
      "cat_elev_MAJORITY cat_elev_MAJORITY\n",
      "cat_elev_MINORITY cat_elev_MINORITY\n",
      "cat_elev_MEDIAN cat_elev_MEDIAN\n",
      "cat_elev_PCT90 cat_elev_PCT90\n",
      "region region\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of ['cat_ID_txt'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-114-43cef69e5f96>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     33\u001B[0m \u001B[0mwtd_n_df\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mwtd_n_arr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     34\u001B[0m \u001B[0mwtd_n_df\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mwtd_n_df\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdrop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"OBJECTID\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 35\u001B[1;33m \u001B[0mwtd_n_df\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mwtd_n_df\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mset_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'cat_ID_txt'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     36\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     37\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36mset_index\u001B[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001B[0m\n\u001B[0;32m   4725\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4726\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mmissing\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 4727\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"None of {missing} are in the columns\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   4728\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4729\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0minplace\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: \"None of ['cat_ID_txt'] are in the columns\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.2f}'.format # only display 2 decimal places\n",
    "#create empty dataframes\n",
    "cat_df = pd.DataFrame()\n",
    "wtd_df = pd.DataFrame()\n",
    "wtd_n_df = pd.DataFrame()\n",
    "#create empty field lists\n",
    "cat_field_list = []\n",
    "wtd_field_list = []\n",
    "wtd_n_field_list = []\n",
    "\n",
    "# Make catchment elev df\n",
    "for field in arcpy.ListFields(cat_elev):\n",
    "    cat_field_list.append(field.name)\n",
    "    print (field.name, field.aliasName)\n",
    "cat_elev_arr = arcpy.da.TableToNumPyArray(cat_elev,cat_field_list)\n",
    "cat_df = pd.DataFrame(cat_elev_arr)\n",
    "cat_df = cat_df.drop([\"OBJECTID\",\"cat_elev_ZONE_CODE\"],axis=1)\n",
    "cat_df = cat_df.set_index('cat_ID_txt')\n",
    "\n",
    "# Make watershed elev df\n",
    "for field in arcpy.ListFields(wtd_elev):\n",
    "    wtd_field_list.append(field.name)\n",
    "wtd_elev_arr = arcpy.da.TableToNumPyArray(wtd_elev,wtd_field_list)\n",
    "wtd_df = pd.DataFrame(wtd_elev_arr)\n",
    "wtd_df = wtd_df.drop([\"OBJECTID\",\"wtd_elev_ZONE_CODE\"],axis=1)\n",
    "wtd_df = wtd_df.set_index('cat_ID_txt')\n",
    "\n",
    "# Make watershed north df\n",
    "for field in arcpy.ListFields(wtd_per_north):\n",
    "    wtd_n_field_list.append(field.name)\n",
    "wtd_n_arr = arcpy.da.TableToNumPyArray(wtd_per_north,wtd_n_field_list)\n",
    "wtd_n_df = pd.DataFrame(wtd_n_arr)\n",
    "wtd_n_df = wtd_n_df.drop(\"OBJECTID\",axis=1)\n",
    "wtd_n_df = wtd_n_df.set_index('cat_ID_txt')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "data": {
      "text/plain": "            cat_elev_COUNT  cat_elev_AREA  cat_elev_MIN  cat_elev_MAX  \\\ncat_ID_txt                                                              \n88586             15636.00     1563600.00             5            30   \n34126             34571.00     3457100.00            15            66   \n885                4034.00      403400.00            16            49   \n20194             12085.00     1208500.00           212           479   \n21055             10874.00     1087400.00             5            39   \n...                    ...            ...           ...           ...   \n26464             10795.00     1079500.00            10           263   \n18457              2358.00      235800.00             3            70   \n44623              4300.00      430000.00             0            13   \n38993              4342.00      434200.00             1            52   \n46055              1455.00      145500.00             2            70   \n\n            cat_elev_RANGE  cat_elev_MEAN  cat_elev_STD  cat_elev_SUM  \\\ncat_ID_txt                                                              \n88586                   25          15.32          7.09     239565.00   \n34126                   51          21.51          9.36     743750.00   \n885                     33          29.53          8.05     119119.00   \n20194                  267         256.92         46.73    3104820.00   \n21055                   34          13.99          9.24     152167.00   \n...                    ...            ...           ...           ...   \n26464                  253          90.13         42.61     972986.00   \n18457                   67          19.23         14.74      45342.00   \n44623                   13           5.56          2.99      23918.00   \n38993                   51          19.61          7.31      85141.00   \n46055                   68          17.64         13.27      25660.00   \n\n            cat_elev_VARIETY  cat_elev_MAJORITY  cat_elev_MINORITY  \\\ncat_ID_txt                                                           \n88586                     26                  6                 28   \n34126                     52                 19                 65   \n885                       34                 16                 47   \n20194                    267                215                437   \n21055                     35                  8                 17   \n...                      ...                ...                ...   \n26464                    244                108                222   \n18457                     68                  8                 70   \n44623                     14                  6                 13   \n38993                     52                 18                  1   \n46055                     68                  3                 59   \n\n            cat_elev_MEDIAN  cat_elev_PCT90                region  \ncat_ID_txt                                                         \n88586                    17              24           Bristol_Bay  \n34126                    19              25           Bristol_Bay  \n885                      29              40           Bristol_Bay  \n20194                   238             317           Bristol_Bay  \n21055                    10              31           Bristol_Bay  \n...                     ...             ...                   ...  \n26464                    93             136  Prince_William_Sound  \n18457                    13              42  Prince_William_Sound  \n44623                     6               9  Prince_William_Sound  \n38993                    18              27  Prince_William_Sound  \n46055                    16              37  Prince_William_Sound  \n\n[428 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat_elev_COUNT</th>\n      <th>cat_elev_AREA</th>\n      <th>cat_elev_MIN</th>\n      <th>cat_elev_MAX</th>\n      <th>cat_elev_RANGE</th>\n      <th>cat_elev_MEAN</th>\n      <th>cat_elev_STD</th>\n      <th>cat_elev_SUM</th>\n      <th>cat_elev_VARIETY</th>\n      <th>cat_elev_MAJORITY</th>\n      <th>cat_elev_MINORITY</th>\n      <th>cat_elev_MEDIAN</th>\n      <th>cat_elev_PCT90</th>\n      <th>region</th>\n    </tr>\n    <tr>\n      <th>cat_ID_txt</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>88586</th>\n      <td>15636.00</td>\n      <td>1563600.00</td>\n      <td>5</td>\n      <td>30</td>\n      <td>25</td>\n      <td>15.32</td>\n      <td>7.09</td>\n      <td>239565.00</td>\n      <td>26</td>\n      <td>6</td>\n      <td>28</td>\n      <td>17</td>\n      <td>24</td>\n      <td>Bristol_Bay</td>\n    </tr>\n    <tr>\n      <th>34126</th>\n      <td>34571.00</td>\n      <td>3457100.00</td>\n      <td>15</td>\n      <td>66</td>\n      <td>51</td>\n      <td>21.51</td>\n      <td>9.36</td>\n      <td>743750.00</td>\n      <td>52</td>\n      <td>19</td>\n      <td>65</td>\n      <td>19</td>\n      <td>25</td>\n      <td>Bristol_Bay</td>\n    </tr>\n    <tr>\n      <th>885</th>\n      <td>4034.00</td>\n      <td>403400.00</td>\n      <td>16</td>\n      <td>49</td>\n      <td>33</td>\n      <td>29.53</td>\n      <td>8.05</td>\n      <td>119119.00</td>\n      <td>34</td>\n      <td>16</td>\n      <td>47</td>\n      <td>29</td>\n      <td>40</td>\n      <td>Bristol_Bay</td>\n    </tr>\n    <tr>\n      <th>20194</th>\n      <td>12085.00</td>\n      <td>1208500.00</td>\n      <td>212</td>\n      <td>479</td>\n      <td>267</td>\n      <td>256.92</td>\n      <td>46.73</td>\n      <td>3104820.00</td>\n      <td>267</td>\n      <td>215</td>\n      <td>437</td>\n      <td>238</td>\n      <td>317</td>\n      <td>Bristol_Bay</td>\n    </tr>\n    <tr>\n      <th>21055</th>\n      <td>10874.00</td>\n      <td>1087400.00</td>\n      <td>5</td>\n      <td>39</td>\n      <td>34</td>\n      <td>13.99</td>\n      <td>9.24</td>\n      <td>152167.00</td>\n      <td>35</td>\n      <td>8</td>\n      <td>17</td>\n      <td>10</td>\n      <td>31</td>\n      <td>Bristol_Bay</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>26464</th>\n      <td>10795.00</td>\n      <td>1079500.00</td>\n      <td>10</td>\n      <td>263</td>\n      <td>253</td>\n      <td>90.13</td>\n      <td>42.61</td>\n      <td>972986.00</td>\n      <td>244</td>\n      <td>108</td>\n      <td>222</td>\n      <td>93</td>\n      <td>136</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n    <tr>\n      <th>18457</th>\n      <td>2358.00</td>\n      <td>235800.00</td>\n      <td>3</td>\n      <td>70</td>\n      <td>67</td>\n      <td>19.23</td>\n      <td>14.74</td>\n      <td>45342.00</td>\n      <td>68</td>\n      <td>8</td>\n      <td>70</td>\n      <td>13</td>\n      <td>42</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n    <tr>\n      <th>44623</th>\n      <td>4300.00</td>\n      <td>430000.00</td>\n      <td>0</td>\n      <td>13</td>\n      <td>13</td>\n      <td>5.56</td>\n      <td>2.99</td>\n      <td>23918.00</td>\n      <td>14</td>\n      <td>6</td>\n      <td>13</td>\n      <td>6</td>\n      <td>9</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n    <tr>\n      <th>38993</th>\n      <td>4342.00</td>\n      <td>434200.00</td>\n      <td>1</td>\n      <td>52</td>\n      <td>51</td>\n      <td>19.61</td>\n      <td>7.31</td>\n      <td>85141.00</td>\n      <td>52</td>\n      <td>18</td>\n      <td>1</td>\n      <td>18</td>\n      <td>27</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n    <tr>\n      <th>46055</th>\n      <td>1455.00</td>\n      <td>145500.00</td>\n      <td>2</td>\n      <td>70</td>\n      <td>68</td>\n      <td>17.64</td>\n      <td>13.27</td>\n      <td>25660.00</td>\n      <td>68</td>\n      <td>3</td>\n      <td>59</td>\n      <td>16</td>\n      <td>37</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n  </tbody>\n</table>\n<p>428 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_df.sort_values(by='region')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "data": {
      "text/plain": "            wtd_elev_COUNT  wtd_elev_AREA  wtd_elev_MIN  wtd_elev_MAX  \\\ncat_ID_txt                                                              \n3023044.0       1487091.00   148709100.00            13           819   \n3033956.0       2731076.00   273107600.00            13          1455   \n3034126.0        792503.00    79250300.00            15           805   \n4000885.0          4034.00      403400.00            16            49   \n4020194.0         12085.00     1208500.00           212           479   \n...                    ...            ...           ...           ...   \n26464.0           50434.00     5043400.00            10          3324   \n18457.0          131871.00    13187100.00             1          3324   \n44623.0          354677.00    35467700.00             0          3324   \n38993.0           37023.00     3702300.00             1          3324   \n46055.0           32971.00     3297100.00             2          3324   \n\n            wtd_elev_RANGE  wtd_elev_MEAN  wtd_elev_STD  wtd_elev_SUM  \\\ncat_ID_txt                                                              \n3023044.0              806         272.79        142.84  405658810.00   \n3033956.0             1442         517.22        293.48 1412562475.00   \n3034126.0              790         108.76        139.12   86193506.00   \n4000885.0               33          29.53          8.05     119119.00   \n4020194.0              267         256.92         46.73    3104820.00   \n...                    ...            ...           ...           ...   \n26464.0               3314         600.64        831.39   30292661.00   \n18457.0               3323         193.96        569.45   25578255.00   \n44623.0               3324         451.24        473.36  160046103.00   \n38993.0               3323         512.48       1009.66   18973709.00   \n46055.0               3322         542.06       1061.32   17872287.00   \n\n            wtd_elev_VARIETY  wtd_elev_MAJORITY  wtd_elev_MINORITY  \\\ncat_ID_txt                                                           \n3023044.0                806                226                 16   \n3033956.0               1443                 13               1455   \n3034126.0                791                 21                770   \n4000885.0                 34                 16                 47   \n4020194.0                267                215                437   \n...                      ...                ...                ...   \n26464.0                 1766                108                865   \n18457.0                 1077                  1               2478   \n44623.0                 2099                 19               1248   \n38993.0                 1365                 29                  1   \n46055.0                  977                115                148   \n\n            wtd_elev_MEDIAN  wtd_elev_PCT90                region  \ncat_ID_txt                                                         \n3023044.0               242             481           Bristol_Bay  \n3033956.0               477             937           Bristol_Bay  \n3034126.0                38             316           Bristol_Bay  \n4000885.0                29              40           Bristol_Bay  \n4020194.0               238             317           Bristol_Bay  \n...                     ...             ...                   ...  \n26464.0                 353            2568  Prince_William_Sound  \n18457.0                  72             157  Prince_William_Sound  \n44623.0                 376             960  Prince_William_Sound  \n38993.0                  48            2786  Prince_William_Sound  \n46055.0                  95            2903  Prince_William_Sound  \n\n[430 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>wtd_elev_COUNT</th>\n      <th>wtd_elev_AREA</th>\n      <th>wtd_elev_MIN</th>\n      <th>wtd_elev_MAX</th>\n      <th>wtd_elev_RANGE</th>\n      <th>wtd_elev_MEAN</th>\n      <th>wtd_elev_STD</th>\n      <th>wtd_elev_SUM</th>\n      <th>wtd_elev_VARIETY</th>\n      <th>wtd_elev_MAJORITY</th>\n      <th>wtd_elev_MINORITY</th>\n      <th>wtd_elev_MEDIAN</th>\n      <th>wtd_elev_PCT90</th>\n      <th>region</th>\n    </tr>\n    <tr>\n      <th>cat_ID_txt</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3023044.0</th>\n      <td>1487091.00</td>\n      <td>148709100.00</td>\n      <td>13</td>\n      <td>819</td>\n      <td>806</td>\n      <td>272.79</td>\n      <td>142.84</td>\n      <td>405658810.00</td>\n      <td>806</td>\n      <td>226</td>\n      <td>16</td>\n      <td>242</td>\n      <td>481</td>\n      <td>Bristol_Bay</td>\n    </tr>\n    <tr>\n      <th>3033956.0</th>\n      <td>2731076.00</td>\n      <td>273107600.00</td>\n      <td>13</td>\n      <td>1455</td>\n      <td>1442</td>\n      <td>517.22</td>\n      <td>293.48</td>\n      <td>1412562475.00</td>\n      <td>1443</td>\n      <td>13</td>\n      <td>1455</td>\n      <td>477</td>\n      <td>937</td>\n      <td>Bristol_Bay</td>\n    </tr>\n    <tr>\n      <th>3034126.0</th>\n      <td>792503.00</td>\n      <td>79250300.00</td>\n      <td>15</td>\n      <td>805</td>\n      <td>790</td>\n      <td>108.76</td>\n      <td>139.12</td>\n      <td>86193506.00</td>\n      <td>791</td>\n      <td>21</td>\n      <td>770</td>\n      <td>38</td>\n      <td>316</td>\n      <td>Bristol_Bay</td>\n    </tr>\n    <tr>\n      <th>4000885.0</th>\n      <td>4034.00</td>\n      <td>403400.00</td>\n      <td>16</td>\n      <td>49</td>\n      <td>33</td>\n      <td>29.53</td>\n      <td>8.05</td>\n      <td>119119.00</td>\n      <td>34</td>\n      <td>16</td>\n      <td>47</td>\n      <td>29</td>\n      <td>40</td>\n      <td>Bristol_Bay</td>\n    </tr>\n    <tr>\n      <th>4020194.0</th>\n      <td>12085.00</td>\n      <td>1208500.00</td>\n      <td>212</td>\n      <td>479</td>\n      <td>267</td>\n      <td>256.92</td>\n      <td>46.73</td>\n      <td>3104820.00</td>\n      <td>267</td>\n      <td>215</td>\n      <td>437</td>\n      <td>238</td>\n      <td>317</td>\n      <td>Bristol_Bay</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>26464.0</th>\n      <td>50434.00</td>\n      <td>5043400.00</td>\n      <td>10</td>\n      <td>3324</td>\n      <td>3314</td>\n      <td>600.64</td>\n      <td>831.39</td>\n      <td>30292661.00</td>\n      <td>1766</td>\n      <td>108</td>\n      <td>865</td>\n      <td>353</td>\n      <td>2568</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n    <tr>\n      <th>18457.0</th>\n      <td>131871.00</td>\n      <td>13187100.00</td>\n      <td>1</td>\n      <td>3324</td>\n      <td>3323</td>\n      <td>193.96</td>\n      <td>569.45</td>\n      <td>25578255.00</td>\n      <td>1077</td>\n      <td>1</td>\n      <td>2478</td>\n      <td>72</td>\n      <td>157</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n    <tr>\n      <th>44623.0</th>\n      <td>354677.00</td>\n      <td>35467700.00</td>\n      <td>0</td>\n      <td>3324</td>\n      <td>3324</td>\n      <td>451.24</td>\n      <td>473.36</td>\n      <td>160046103.00</td>\n      <td>2099</td>\n      <td>19</td>\n      <td>1248</td>\n      <td>376</td>\n      <td>960</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n    <tr>\n      <th>38993.0</th>\n      <td>37023.00</td>\n      <td>3702300.00</td>\n      <td>1</td>\n      <td>3324</td>\n      <td>3323</td>\n      <td>512.48</td>\n      <td>1009.66</td>\n      <td>18973709.00</td>\n      <td>1365</td>\n      <td>29</td>\n      <td>1</td>\n      <td>48</td>\n      <td>2786</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n    <tr>\n      <th>46055.0</th>\n      <td>32971.00</td>\n      <td>3297100.00</td>\n      <td>2</td>\n      <td>3324</td>\n      <td>3322</td>\n      <td>542.06</td>\n      <td>1061.32</td>\n      <td>17872287.00</td>\n      <td>977</td>\n      <td>115</td>\n      <td>148</td>\n      <td>95</td>\n      <td>2903</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n  </tbody>\n</table>\n<p>430 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wtd_df.sort_values(by='region')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "data": {
      "text/plain": "    CAT_ID_TXT      VALUE_0     VALUE_1                region  north_wtd\n295  3023044.0 116279900.00 32429200.00           Bristol_Bay      21.81\n299  3033956.0 189873600.00 83234000.00           Bristol_Bay      30.48\n300  3034126.0  52052800.00 27197500.00           Bristol_Bay      34.32\n301  4000885.0    357100.00    46300.00           Bristol_Bay      11.48\n302  4020194.0   1151200.00    57300.00           Bristol_Bay       4.74\n..         ...          ...         ...                   ...        ...\n412    26464.0   3100800.00  1942600.00  Prince_William_Sound      38.52\n411    18457.0  10389600.00  2797500.00  Prince_William_Sound      21.21\n428    44623.0  22243000.00 13224700.00  Prince_William_Sound      37.29\n419    38993.0   3407700.00   294600.00  Prince_William_Sound       7.96\n429    46055.0   2785100.00   512000.00  Prince_William_Sound      15.53\n\n[430 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CAT_ID_TXT</th>\n      <th>VALUE_0</th>\n      <th>VALUE_1</th>\n      <th>region</th>\n      <th>north_wtd</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>295</th>\n      <td>3023044.0</td>\n      <td>116279900.00</td>\n      <td>32429200.00</td>\n      <td>Bristol_Bay</td>\n      <td>21.81</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>3033956.0</td>\n      <td>189873600.00</td>\n      <td>83234000.00</td>\n      <td>Bristol_Bay</td>\n      <td>30.48</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>3034126.0</td>\n      <td>52052800.00</td>\n      <td>27197500.00</td>\n      <td>Bristol_Bay</td>\n      <td>34.32</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>4000885.0</td>\n      <td>357100.00</td>\n      <td>46300.00</td>\n      <td>Bristol_Bay</td>\n      <td>11.48</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>4020194.0</td>\n      <td>1151200.00</td>\n      <td>57300.00</td>\n      <td>Bristol_Bay</td>\n      <td>4.74</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>412</th>\n      <td>26464.0</td>\n      <td>3100800.00</td>\n      <td>1942600.00</td>\n      <td>Prince_William_Sound</td>\n      <td>38.52</td>\n    </tr>\n    <tr>\n      <th>411</th>\n      <td>18457.0</td>\n      <td>10389600.00</td>\n      <td>2797500.00</td>\n      <td>Prince_William_Sound</td>\n      <td>21.21</td>\n    </tr>\n    <tr>\n      <th>428</th>\n      <td>44623.0</td>\n      <td>22243000.00</td>\n      <td>13224700.00</td>\n      <td>Prince_William_Sound</td>\n      <td>37.29</td>\n    </tr>\n    <tr>\n      <th>419</th>\n      <td>38993.0</td>\n      <td>3407700.00</td>\n      <td>294600.00</td>\n      <td>Prince_William_Sound</td>\n      <td>7.96</td>\n    </tr>\n    <tr>\n      <th>429</th>\n      <td>46055.0</td>\n      <td>2785100.00</td>\n      <td>512000.00</td>\n      <td>Prince_William_Sound</td>\n      <td>15.53</td>\n    </tr>\n  </tbody>\n</table>\n<p>430 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wtd_n_df.sort_values(by='region')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "                  wtd_elev_COUNT  wtd_elev_AREA  wtd_elev_MIN  wtd_elev_MAX  \\\ncat_ID_txt                                                                    \n75004200007057.0       258728.00     6468200.00             0        144500   \n75000200010547.0      5613443.00   140336075.00         13141         45160   \n75000200005606.0       333424.00     8335600.00         14141         20215   \n75000200002554.0        94100.00     2352500.00         14175         17227   \n75000200017518.0      1790105.00    44752625.00         55716        197502   \n...                          ...            ...           ...           ...   \n75019800010313.0     22480838.00   562020950.00         72462        280991   \n75019800000406.0       294229.00     7355725.00         66017         72493   \n75003900039073.0       230415.00     5760375.00           489          9943   \n75003900033524.0      2162086.00    54052150.00          1613        146599   \n75003900027771.0        64405.00     1610125.00           560         10928   \n\n                  wtd_elev_RANGE  wtd_elev_MEAN  wtd_elev_STD  \\\ncat_ID_txt                                                      \n75004200007057.0          144500       43255.27      37427.70   \n75000200010547.0           32019       24260.98       6157.49   \n75000200005606.0            6074       16940.60       1153.71   \n75000200002554.0            3052       15846.43        575.76   \n75000200017518.0          141786      119840.65      26050.70   \n...                          ...            ...           ...   \n75019800010313.0          208529      122419.95      37416.27   \n75019800000406.0            6476       69062.47       1480.28   \n75003900039073.0            9454        3060.51       1557.69   \n75003900033524.0          144986       62382.77      31303.20   \n75003900027771.0           10368        4223.11       1479.12   \n\n                     wtd_elev_SUM  wtd_elev_VARIETY  wtd_elev_MAJORITY  ...  \\\ncat_ID_txt                                                              ...   \n75004200007057.0   11191350026.00             99715                500  ...   \n75000200010547.0  136187609252.00             31673              21432  ...   \n75000200005606.0    5648402724.00              5996              17421  ...   \n75000200002554.0    1491148775.00              2825              16230  ...   \n75000200017518.0  214527347400.00            122471             128903  ...   \n...                           ...               ...                ...  ...   \n75019800010313.0 2752102974453.00            193923              88700  ...   \n75019800000406.0   20320182865.00              6474              70062  ...   \n75003900039073.0     705188333.00              8339               2632  ...   \n75003900033524.0  134876923340.00            134789              13298  ...   \n75003900027771.0     271989608.00              7691               3060  ...   \n\n                  cat_elev_RANGE  cat_elev_MEAN  cat_elev_STD   cat_elev_SUM  \\\ncat_ID_txt                                                                     \n75004200007057.0           90800       34649.43      25122.14  1333483286.00   \n75000200010547.0             586       13395.05        125.80    35255769.00   \n75000200005606.0            2003       15215.23        522.56   435277309.00   \n75000200002554.0            2641       15593.10        521.04   980322504.00   \n75000200017518.0            8103       58948.07       2148.32   279531767.00   \n...                          ...            ...           ...            ...   \n75019800010313.0            1257       73133.74        268.65   864733310.00   \n75019800000406.0            6476       69062.47       1480.28 20320182865.00   \n75003900039073.0            1902        1140.87        479.45     1955444.00   \n75003900033524.0           11480        5407.86       3280.50    19273616.00   \n75003900027771.0            4806        3274.08       1101.73    26100941.00   \n\n                  cat_elev_VARIETY  cat_elev_MAJORITY  cat_elev_MINORITY  \\\ncat_ID_txt                                                                 \n75004200007057.0             27216                400                 36   \n75000200010547.0               510              13294              13141   \n75000200005606.0              1903              15864              14141   \n75000200002554.0              2566              15508              14178   \n75000200017518.0              3032              61427              55716   \n...                            ...                ...                ...   \n75019800010313.0              1165              73346              72462   \n75019800000406.0              6474              70062              66220   \n75003900039073.0               938                624                529   \n75003900033524.0              2805               2053               1613   \n75003900027771.0              3424               4316                560   \n\n                  cat_elev_MEDIAN  cat_elev_PCT90      region_y  \ncat_ID_txt                                                       \n75004200007057.0            33377           70627    Cook_Inlet  \n75000200010547.0            13388           13565    Cook_Inlet  \n75000200005606.0            15294           15853    Cook_Inlet  \n75000200002554.0            15626           16209    Cook_Inlet  \n75000200017518.0            58486           62625    Cook_Inlet  \n...                           ...             ...           ...  \n75019800010313.0            73171           73466  Copper_River  \n75019800000406.0            69057           71091  Copper_River  \n75003900039073.0             1092            1773  Copper_River  \n75003900033524.0             4049           10623  Copper_River  \n75003900027771.0             3413            4562  Copper_River  \n\n[269 rows x 28 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>wtd_elev_COUNT</th>\n      <th>wtd_elev_AREA</th>\n      <th>wtd_elev_MIN</th>\n      <th>wtd_elev_MAX</th>\n      <th>wtd_elev_RANGE</th>\n      <th>wtd_elev_MEAN</th>\n      <th>wtd_elev_STD</th>\n      <th>wtd_elev_SUM</th>\n      <th>wtd_elev_VARIETY</th>\n      <th>wtd_elev_MAJORITY</th>\n      <th>...</th>\n      <th>cat_elev_RANGE</th>\n      <th>cat_elev_MEAN</th>\n      <th>cat_elev_STD</th>\n      <th>cat_elev_SUM</th>\n      <th>cat_elev_VARIETY</th>\n      <th>cat_elev_MAJORITY</th>\n      <th>cat_elev_MINORITY</th>\n      <th>cat_elev_MEDIAN</th>\n      <th>cat_elev_PCT90</th>\n      <th>region_y</th>\n    </tr>\n    <tr>\n      <th>cat_ID_txt</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>75004200007057.0</th>\n      <td>258728.00</td>\n      <td>6468200.00</td>\n      <td>0</td>\n      <td>144500</td>\n      <td>144500</td>\n      <td>43255.27</td>\n      <td>37427.70</td>\n      <td>11191350026.00</td>\n      <td>99715</td>\n      <td>500</td>\n      <td>...</td>\n      <td>90800</td>\n      <td>34649.43</td>\n      <td>25122.14</td>\n      <td>1333483286.00</td>\n      <td>27216</td>\n      <td>400</td>\n      <td>36</td>\n      <td>33377</td>\n      <td>70627</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>75000200010547.0</th>\n      <td>5613443.00</td>\n      <td>140336075.00</td>\n      <td>13141</td>\n      <td>45160</td>\n      <td>32019</td>\n      <td>24260.98</td>\n      <td>6157.49</td>\n      <td>136187609252.00</td>\n      <td>31673</td>\n      <td>21432</td>\n      <td>...</td>\n      <td>586</td>\n      <td>13395.05</td>\n      <td>125.80</td>\n      <td>35255769.00</td>\n      <td>510</td>\n      <td>13294</td>\n      <td>13141</td>\n      <td>13388</td>\n      <td>13565</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>75000200005606.0</th>\n      <td>333424.00</td>\n      <td>8335600.00</td>\n      <td>14141</td>\n      <td>20215</td>\n      <td>6074</td>\n      <td>16940.60</td>\n      <td>1153.71</td>\n      <td>5648402724.00</td>\n      <td>5996</td>\n      <td>17421</td>\n      <td>...</td>\n      <td>2003</td>\n      <td>15215.23</td>\n      <td>522.56</td>\n      <td>435277309.00</td>\n      <td>1903</td>\n      <td>15864</td>\n      <td>14141</td>\n      <td>15294</td>\n      <td>15853</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>75000200002554.0</th>\n      <td>94100.00</td>\n      <td>2352500.00</td>\n      <td>14175</td>\n      <td>17227</td>\n      <td>3052</td>\n      <td>15846.43</td>\n      <td>575.76</td>\n      <td>1491148775.00</td>\n      <td>2825</td>\n      <td>16230</td>\n      <td>...</td>\n      <td>2641</td>\n      <td>15593.10</td>\n      <td>521.04</td>\n      <td>980322504.00</td>\n      <td>2566</td>\n      <td>15508</td>\n      <td>14178</td>\n      <td>15626</td>\n      <td>16209</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>75000200017518.0</th>\n      <td>1790105.00</td>\n      <td>44752625.00</td>\n      <td>55716</td>\n      <td>197502</td>\n      <td>141786</td>\n      <td>119840.65</td>\n      <td>26050.70</td>\n      <td>214527347400.00</td>\n      <td>122471</td>\n      <td>128903</td>\n      <td>...</td>\n      <td>8103</td>\n      <td>58948.07</td>\n      <td>2148.32</td>\n      <td>279531767.00</td>\n      <td>3032</td>\n      <td>61427</td>\n      <td>55716</td>\n      <td>58486</td>\n      <td>62625</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>75019800010313.0</th>\n      <td>22480838.00</td>\n      <td>562020950.00</td>\n      <td>72462</td>\n      <td>280991</td>\n      <td>208529</td>\n      <td>122419.95</td>\n      <td>37416.27</td>\n      <td>2752102974453.00</td>\n      <td>193923</td>\n      <td>88700</td>\n      <td>...</td>\n      <td>1257</td>\n      <td>73133.74</td>\n      <td>268.65</td>\n      <td>864733310.00</td>\n      <td>1165</td>\n      <td>73346</td>\n      <td>72462</td>\n      <td>73171</td>\n      <td>73466</td>\n      <td>Copper_River</td>\n    </tr>\n    <tr>\n      <th>75019800000406.0</th>\n      <td>294229.00</td>\n      <td>7355725.00</td>\n      <td>66017</td>\n      <td>72493</td>\n      <td>6476</td>\n      <td>69062.47</td>\n      <td>1480.28</td>\n      <td>20320182865.00</td>\n      <td>6474</td>\n      <td>70062</td>\n      <td>...</td>\n      <td>6476</td>\n      <td>69062.47</td>\n      <td>1480.28</td>\n      <td>20320182865.00</td>\n      <td>6474</td>\n      <td>70062</td>\n      <td>66220</td>\n      <td>69057</td>\n      <td>71091</td>\n      <td>Copper_River</td>\n    </tr>\n    <tr>\n      <th>75003900039073.0</th>\n      <td>230415.00</td>\n      <td>5760375.00</td>\n      <td>489</td>\n      <td>9943</td>\n      <td>9454</td>\n      <td>3060.51</td>\n      <td>1557.69</td>\n      <td>705188333.00</td>\n      <td>8339</td>\n      <td>2632</td>\n      <td>...</td>\n      <td>1902</td>\n      <td>1140.87</td>\n      <td>479.45</td>\n      <td>1955444.00</td>\n      <td>938</td>\n      <td>624</td>\n      <td>529</td>\n      <td>1092</td>\n      <td>1773</td>\n      <td>Copper_River</td>\n    </tr>\n    <tr>\n      <th>75003900033524.0</th>\n      <td>2162086.00</td>\n      <td>54052150.00</td>\n      <td>1613</td>\n      <td>146599</td>\n      <td>144986</td>\n      <td>62382.77</td>\n      <td>31303.20</td>\n      <td>134876923340.00</td>\n      <td>134789</td>\n      <td>13298</td>\n      <td>...</td>\n      <td>11480</td>\n      <td>5407.86</td>\n      <td>3280.50</td>\n      <td>19273616.00</td>\n      <td>2805</td>\n      <td>2053</td>\n      <td>1613</td>\n      <td>4049</td>\n      <td>10623</td>\n      <td>Copper_River</td>\n    </tr>\n    <tr>\n      <th>75003900027771.0</th>\n      <td>64405.00</td>\n      <td>1610125.00</td>\n      <td>560</td>\n      <td>10928</td>\n      <td>10368</td>\n      <td>4223.11</td>\n      <td>1479.12</td>\n      <td>271989608.00</td>\n      <td>7691</td>\n      <td>3060</td>\n      <td>...</td>\n      <td>4806</td>\n      <td>3274.08</td>\n      <td>1101.73</td>\n      <td>26100941.00</td>\n      <td>3424</td>\n      <td>4316</td>\n      <td>560</td>\n      <td>3413</td>\n      <td>4562</td>\n      <td>Copper_River</td>\n    </tr>\n  </tbody>\n</table>\n<p>269 rows × 28 columns</p>\n</div>"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmet_merge_df = pd.merge(wtd_df,cat_df,on='cat_ID_txt', how='outer')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "dfs = [wtd_df,cat_df]\n",
    "df_final = reduce(lambda left,right: pd.merge(left,right,on='cat_ID_txt'), dfs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "data": {
      "text/plain": "                  wtd_elev_COUNT  wtd_elev_AREA  wtd_elev_MIN  wtd_elev_MAX  \\\ncat_ID_txt                                                                    \n75004200007057.0       258728.00     6468200.00             0        144500   \n75004300006312.0      6172261.00   154306525.00          5900         56900   \n75004300001906.0      3674807.00    91870175.00           300         77174   \n75004300000100.0      1158453.00    28961325.00          3305         41700   \n75004300004983.0       610455.00    15261375.00          2100        147384   \n...                          ...            ...           ...           ...   \n75003900023674.0       155526.00     3888150.00          1357         67537   \n75003900062264.0       886085.00    22152125.00          2182         54687   \n75003900055316.0       293348.00     7333700.00          2943         57672   \n75003900039073.0       230415.00     5760375.00           489          9943   \n75003900027771.0        64405.00     1610125.00           560         10928   \n\n                  wtd_elev_RANGE  wtd_elev_MEAN  wtd_elev_STD    wtd_elev_SUM  \\\ncat_ID_txt                                                                      \n75004200007057.0          144500       43255.27      37427.70  11191350026.00   \n75004300006312.0           51000       25127.05      11779.40 155090722985.00   \n75004300001906.0           76874       40142.44      11984.06 147515731019.00   \n75004300000100.0           38395       15654.17       8590.35  18134625884.00   \n75004300004983.0          145284       67339.95      33460.53  41108006739.00   \n...                          ...            ...           ...             ...   \n75003900023674.0           66180       16985.47      16387.75   2641682563.00   \n75003900062264.0           52505       15531.18      13899.79  13761946382.00   \n75003900055316.0           54729       21011.88      14481.52   6163794155.00   \n75003900039073.0            9454        3060.51       1557.69    705188333.00   \n75003900027771.0           10368        4223.11       1479.12    271989608.00   \n\n                  wtd_elev_VARIETY  wtd_elev_MAJORITY  ...  cat_elev_RANGE  \\\ncat_ID_txt                                             ...                   \n75004200007057.0             99715                500  ...           90800   \n75004300006312.0             50691              12600  ...            3900   \n75004300001906.0             75573              37700  ...           14321   \n75004300000100.0             36389               9100  ...            4495   \n75004300004983.0            126942              33600  ...           45843   \n...                            ...                ...  ...             ...   \n75003900023674.0             43720               4726  ...             165   \n75003900062264.0             51028               3513  ...            1180   \n75003900055316.0             51198               3082  ...            3971   \n75003900039073.0              8339               2632  ...            1902   \n75003900027771.0              7691               3060  ...            4806   \n\n                  cat_elev_MEAN  cat_elev_STD  cat_elev_SUM  cat_elev_VARIETY  \\\ncat_ID_txt                                                                      \n75004200007057.0       34649.43      25122.14 1333483286.00             27216   \n75004300006312.0        7654.30        935.80  440704003.00              3605   \n75004300001906.0        2818.64       2135.86   34164787.00              4573   \n75004300000100.0        5889.18        819.43  463731919.00              3963   \n75004300004983.0       26556.24      10043.37 3015646404.00             35402   \n...                         ...           ...           ...               ...   \n75003900023674.0        1585.92         40.31     269606.00               105   \n75003900062264.0        3139.22        110.48   21054744.00               614   \n75003900055316.0        3256.86        626.21   30822898.00              1344   \n75003900039073.0        1140.87        479.45    1955444.00               938   \n75003900027771.0        3274.08       1101.73   26100941.00              3424   \n\n                  cat_elev_MAJORITY  cat_elev_MINORITY  cat_elev_MEDIAN  \\\ncat_ID_txt                                                                \n75004200007057.0                400                 36            33377   \n75004300006312.0               6900               5909             7400   \n75004300001906.0               1000                301             2126   \n75004300000100.0               6500               3305             5933   \n75004300004983.0              33600               2103            28233   \n...                             ...                ...              ...   \n75003900023674.0               1583               1508             1583   \n75003900062264.0               3175               2182             3161   \n75003900055316.0               3069               2943             3062   \n75003900039073.0                624                529             1092   \n75003900027771.0               4316                560             3413   \n\n                  cat_elev_PCT90      region_y  \ncat_ID_txt                                      \n75004200007057.0           70627    Cook_Inlet  \n75004300006312.0            9002    Cook_Inlet  \n75004300001906.0            5218    Cook_Inlet  \n75004300000100.0            6800    Cook_Inlet  \n75004300004983.0           38776    Cook_Inlet  \n...                          ...           ...  \n75003900023674.0            1642  Copper_River  \n75003900062264.0            3244  Copper_River  \n75003900055316.0            3621  Copper_River  \n75003900039073.0            1773  Copper_River  \n75003900027771.0            4562  Copper_River  \n\n[269 rows x 28 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>wtd_elev_COUNT</th>\n      <th>wtd_elev_AREA</th>\n      <th>wtd_elev_MIN</th>\n      <th>wtd_elev_MAX</th>\n      <th>wtd_elev_RANGE</th>\n      <th>wtd_elev_MEAN</th>\n      <th>wtd_elev_STD</th>\n      <th>wtd_elev_SUM</th>\n      <th>wtd_elev_VARIETY</th>\n      <th>wtd_elev_MAJORITY</th>\n      <th>...</th>\n      <th>cat_elev_RANGE</th>\n      <th>cat_elev_MEAN</th>\n      <th>cat_elev_STD</th>\n      <th>cat_elev_SUM</th>\n      <th>cat_elev_VARIETY</th>\n      <th>cat_elev_MAJORITY</th>\n      <th>cat_elev_MINORITY</th>\n      <th>cat_elev_MEDIAN</th>\n      <th>cat_elev_PCT90</th>\n      <th>region_y</th>\n    </tr>\n    <tr>\n      <th>cat_ID_txt</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>75004200007057.0</th>\n      <td>258728.00</td>\n      <td>6468200.00</td>\n      <td>0</td>\n      <td>144500</td>\n      <td>144500</td>\n      <td>43255.27</td>\n      <td>37427.70</td>\n      <td>11191350026.00</td>\n      <td>99715</td>\n      <td>500</td>\n      <td>...</td>\n      <td>90800</td>\n      <td>34649.43</td>\n      <td>25122.14</td>\n      <td>1333483286.00</td>\n      <td>27216</td>\n      <td>400</td>\n      <td>36</td>\n      <td>33377</td>\n      <td>70627</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>75004300006312.0</th>\n      <td>6172261.00</td>\n      <td>154306525.00</td>\n      <td>5900</td>\n      <td>56900</td>\n      <td>51000</td>\n      <td>25127.05</td>\n      <td>11779.40</td>\n      <td>155090722985.00</td>\n      <td>50691</td>\n      <td>12600</td>\n      <td>...</td>\n      <td>3900</td>\n      <td>7654.30</td>\n      <td>935.80</td>\n      <td>440704003.00</td>\n      <td>3605</td>\n      <td>6900</td>\n      <td>5909</td>\n      <td>7400</td>\n      <td>9002</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>75004300001906.0</th>\n      <td>3674807.00</td>\n      <td>91870175.00</td>\n      <td>300</td>\n      <td>77174</td>\n      <td>76874</td>\n      <td>40142.44</td>\n      <td>11984.06</td>\n      <td>147515731019.00</td>\n      <td>75573</td>\n      <td>37700</td>\n      <td>...</td>\n      <td>14321</td>\n      <td>2818.64</td>\n      <td>2135.86</td>\n      <td>34164787.00</td>\n      <td>4573</td>\n      <td>1000</td>\n      <td>301</td>\n      <td>2126</td>\n      <td>5218</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>75004300000100.0</th>\n      <td>1158453.00</td>\n      <td>28961325.00</td>\n      <td>3305</td>\n      <td>41700</td>\n      <td>38395</td>\n      <td>15654.17</td>\n      <td>8590.35</td>\n      <td>18134625884.00</td>\n      <td>36389</td>\n      <td>9100</td>\n      <td>...</td>\n      <td>4495</td>\n      <td>5889.18</td>\n      <td>819.43</td>\n      <td>463731919.00</td>\n      <td>3963</td>\n      <td>6500</td>\n      <td>3305</td>\n      <td>5933</td>\n      <td>6800</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>75004300004983.0</th>\n      <td>610455.00</td>\n      <td>15261375.00</td>\n      <td>2100</td>\n      <td>147384</td>\n      <td>145284</td>\n      <td>67339.95</td>\n      <td>33460.53</td>\n      <td>41108006739.00</td>\n      <td>126942</td>\n      <td>33600</td>\n      <td>...</td>\n      <td>45843</td>\n      <td>26556.24</td>\n      <td>10043.37</td>\n      <td>3015646404.00</td>\n      <td>35402</td>\n      <td>33600</td>\n      <td>2103</td>\n      <td>28233</td>\n      <td>38776</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>75003900023674.0</th>\n      <td>155526.00</td>\n      <td>3888150.00</td>\n      <td>1357</td>\n      <td>67537</td>\n      <td>66180</td>\n      <td>16985.47</td>\n      <td>16387.75</td>\n      <td>2641682563.00</td>\n      <td>43720</td>\n      <td>4726</td>\n      <td>...</td>\n      <td>165</td>\n      <td>1585.92</td>\n      <td>40.31</td>\n      <td>269606.00</td>\n      <td>105</td>\n      <td>1583</td>\n      <td>1508</td>\n      <td>1583</td>\n      <td>1642</td>\n      <td>Copper_River</td>\n    </tr>\n    <tr>\n      <th>75003900062264.0</th>\n      <td>886085.00</td>\n      <td>22152125.00</td>\n      <td>2182</td>\n      <td>54687</td>\n      <td>52505</td>\n      <td>15531.18</td>\n      <td>13899.79</td>\n      <td>13761946382.00</td>\n      <td>51028</td>\n      <td>3513</td>\n      <td>...</td>\n      <td>1180</td>\n      <td>3139.22</td>\n      <td>110.48</td>\n      <td>21054744.00</td>\n      <td>614</td>\n      <td>3175</td>\n      <td>2182</td>\n      <td>3161</td>\n      <td>3244</td>\n      <td>Copper_River</td>\n    </tr>\n    <tr>\n      <th>75003900055316.0</th>\n      <td>293348.00</td>\n      <td>7333700.00</td>\n      <td>2943</td>\n      <td>57672</td>\n      <td>54729</td>\n      <td>21011.88</td>\n      <td>14481.52</td>\n      <td>6163794155.00</td>\n      <td>51198</td>\n      <td>3082</td>\n      <td>...</td>\n      <td>3971</td>\n      <td>3256.86</td>\n      <td>626.21</td>\n      <td>30822898.00</td>\n      <td>1344</td>\n      <td>3069</td>\n      <td>2943</td>\n      <td>3062</td>\n      <td>3621</td>\n      <td>Copper_River</td>\n    </tr>\n    <tr>\n      <th>75003900039073.0</th>\n      <td>230415.00</td>\n      <td>5760375.00</td>\n      <td>489</td>\n      <td>9943</td>\n      <td>9454</td>\n      <td>3060.51</td>\n      <td>1557.69</td>\n      <td>705188333.00</td>\n      <td>8339</td>\n      <td>2632</td>\n      <td>...</td>\n      <td>1902</td>\n      <td>1140.87</td>\n      <td>479.45</td>\n      <td>1955444.00</td>\n      <td>938</td>\n      <td>624</td>\n      <td>529</td>\n      <td>1092</td>\n      <td>1773</td>\n      <td>Copper_River</td>\n    </tr>\n    <tr>\n      <th>75003900027771.0</th>\n      <td>64405.00</td>\n      <td>1610125.00</td>\n      <td>560</td>\n      <td>10928</td>\n      <td>10368</td>\n      <td>4223.11</td>\n      <td>1479.12</td>\n      <td>271989608.00</td>\n      <td>7691</td>\n      <td>3060</td>\n      <td>...</td>\n      <td>4806</td>\n      <td>3274.08</td>\n      <td>1101.73</td>\n      <td>26100941.00</td>\n      <td>3424</td>\n      <td>4316</td>\n      <td>560</td>\n      <td>3413</td>\n      <td>4562</td>\n      <td>Copper_River</td>\n    </tr>\n  </tbody>\n</table>\n<p>269 rows × 28 columns</p>\n</div>"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8caab41e",
   "language": "python",
   "display_name": "PyCharm (AKSSF)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}