{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a id='top'></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Watershed and Catchment elevation statistics and percent north facing landcover.\n",
    "\n",
    "## Aspect and Percent North Covariates\n",
    "Calculate aspect grid with the DEM used to create the flow network for each processing area (e.g. HUC8 in NHDPlus or\n",
    " region for BB, PWS, or Kodiak). We need the DEMs used for each flow direction grid, or we can't calculate covariates at\n",
    " the watershed scale.\n",
    " * **~~aspect_rch = calculate mean aspect for stream reach (zonal statistics)~~**\n",
    " * **~~aspect_cat = calculate mean aspect over catchments (zonal statistics)~~**\n",
    " * **north_wtd = create 1/0 grid of north facing cells from aspect grid (north = aspects from 315-45 degrees), ~~~use\n",
    "  weighted flow accumulation to sum north facing cells, divide by flow accumulation grid to get % of north facing\n",
    "  cells in each watershed~~~ Use tabulate area to quantify area of North cells (VALUE_1) and non-North (VALUE_0) cells\n",
    "  for each watershed and calculate percent north as north_wtd = row[VALUE_1]/(row[VALUE_1]+row[VALUE_0])*100 .**\n",
    "\n",
    "## AKSSF Watershed and Catchment Elevation Metrics\n",
    "Calculate elevation metrics for catchment/watershed with temperature data using zonal statistics as table.\n",
    "MHDPLus\n",
    "\n",
    "### Catchment Elevation Metrics\n",
    "* **cat_elev_mn = mean elevation for catchment**\n",
    "* **cat_elev_min = minimum elevation for catchment**\n",
    "* **cat_elev_max = max elevation for catchment**\n",
    "* **cat_elev_std = standard deviation of elevation for catchment**\n",
    "\n",
    "### Watershed Elevation Metrics\n",
    "* **wtd_elev_mn = mean watershed elevation**\n",
    "* **wtd_elev_min = min watershed elevation**\n",
    "* **wtd_elev_max = max watershed elevation**\n",
    "* **wtd_elev_sd (or cv) = standard deviation of watershed elevation**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import modules"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18102021\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\data_preparation\\sensitivity_drivers\\landcover\n",
      "C:\\Users\\dwmerrigan\\AppData\\Local\\Programs\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\n"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "arcpy.env.overwriteOutput = True\n",
    "today = datetime.datetime.now()\n",
    "# Make the time stamp.\n",
    "time_stamp = '{:%d%m%Y}'.format(today)\n",
    "print(time_stamp)\n",
    "\n",
    "path = os.getcwd()\n",
    "print (path)\n",
    "print (sys.base_exec_prefix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Collect data and set working output locations\n",
    "Set data_dir to folder containing all AKSSF regional subfolders/geoadatabases\n",
    "* RS data folder: data_dir = r\"W:\\GIS\\AKSSF\"\n",
    "* DM data folder: data_dir = r\"D:\\GIS_Temp\\AKSSF_BeckyCopy\\AKSSF\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\GIS_temp\\\\AKSSF\\\\Bristol_Bay', 'D:\\\\GIS_temp\\\\AKSSF\\\\Cook_Inlet', 'D:\\\\GIS_temp\\\\AKSSF\\\\Copper_River', 'D:\\\\GIS_temp\\\\AKSSF\\\\Kodiak', 'D:\\\\GIS_temp\\\\AKSSF\\\\Prince_William_Sound']\n",
      "Working Folder already created... D:\\GIS_temp\\AKSSF_land_met\n",
      "Output location already exists D:\\GIS_temp\\AKSSF_land_met\\AKSSF_land_met.gdb\n"
     ]
    }
   ],
   "source": [
    "# Set AKSSF Data directory\n",
    "# data_dir = r\"W:\\GIS\\AKSSF\"\n",
    "\n",
    "# dm local\n",
    "data_dir = r\"D:\\GIS_Temp\\AKSSF\"\n",
    "\n",
    "arcpy.env.workspace = data_dir\n",
    "regions = arcpy.ListWorkspaces(workspace_type=\"Folder\")\n",
    "rois= []\n",
    "print (regions)\n",
    "\n",
    "# Path to create output folder/gdb\n",
    "temppath = r\"D:\\GIS_temp\" # Output folder\n",
    "dirname = 'AKSSF_land_met'\n",
    "tempgdbname = 'AKSSF_land_met.gdb'\n",
    "temp_dir = os.path.join(temppath, dirname)\n",
    "\n",
    "# Create temporary working gdb\n",
    "if not arcpy.Exists(temp_dir):\n",
    "    os.makedirs(temp_dir)\n",
    "else:\n",
    "    print('Working Folder already created...', temp_dir)\n",
    "\n",
    "outcheck = os.path.join(temp_dir, tempgdbname)\n",
    "\n",
    "if arcpy.Exists(outcheck):\n",
    "    print ('Output location already exists', outcheck)\n",
    "    outgdb = outcheck\n",
    "if not arcpy.Exists(outcheck):\n",
    "    print('Creating output GDB')\n",
    "    tempgdb = arcpy.CreateFileGDB_management(temp_dir,tempgdbname)\n",
    "    print ('Output geodatabase created at', outcheck)\n",
    "    outgdb = tempgdb.getOutput(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "['D:\\\\GIS_temp\\\\AKSSF\\\\Bristol_Bay',\n 'D:\\\\GIS_temp\\\\AKSSF\\\\Cook_Inlet',\n 'D:\\\\GIS_temp\\\\AKSSF\\\\Copper_River',\n 'D:\\\\GIS_temp\\\\AKSSF\\\\Kodiak',\n 'D:\\\\GIS_temp\\\\AKSSF\\\\Prince_William_Sound']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set regional workspaces from AKSSF data folder and store in list\n",
    "arcpy.env.workspace = data_dir\n",
    "regions  = arcpy.ListWorkspaces(workspace_type=\"Folder\")\n",
    "regions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create aspect and north grids if they do not already exists\n",
    "### NHDPlus"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020202\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020301\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020302\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020401\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020402\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020501\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020502\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020503\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020504\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020505\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020601\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020602\\elev_cm.tif to list\n",
      "Appending C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\AKSSF_NHDPlus\\extracts\\HRNHDPlusRasters19020800\\elev_cm.tif to list\n"
     ]
    }
   ],
   "source": [
    "# Code to create merged elevation grid, aspect and north aspect grids for entire AKSSF region with NHDPlus elev data\n",
    "\n",
    "# elrasters = []\n",
    "# nhd_dat = r\"C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\AKSSF\\\\hydrography\\\\AKSSF_NHDPlus\\\\extracts\"\n",
    "# for dirpath, dirname, filenames in arcpy.da.Walk(nhd_dat, 'RasterDataset'):\n",
    "#     for filename in filenames:\n",
    "#         if filename == \"elev_cm.tif\":\n",
    "#             elras = os.path.join(dirpath, filename)\n",
    "#             elrasters.append(elras)\n",
    "#             print (f'Appending {elras} to list')\n",
    "#\n",
    "# spatial_ref = arcpy.Describe(elrasters[0]).spatialReference\n",
    "# print (spatial_ref.name)\n",
    "# # Merge all nhdplus elevation rasters together\n",
    "# elevname = 'AKSSF_NHDPlus_elev_cm.tif'\n",
    "# AKSSF_elev_cm = arcpy.MosaicToNewRaster_management(elrasters,temp_dir,elevname, spatial_ref, \"32_BIT_SIGNED\", \"5\", \"1\", \"LAST\",\"FIRST\")\n",
    "#\n",
    "# #make aspect raster for all of akssf from merged nhdplus\n",
    "# from arcpy.sa import *\n",
    "# aspname = 'AKSSF_NHDPlus_aspect.tif'\n",
    "# asp_rast = Aspect(in_raster= AKSSF_elev_cm, method='Planar')\n",
    "# asp_rast.save(os.path.join(temp_dir, aspname))\n",
    "#\n",
    "# # make north raster from aspect raster\n",
    "# norname = 'AKSSF_NHDPlus_north_aspect.tif'\n",
    "# aspect_in = Raster(asp_rast)\n",
    "# north_raster = Con((aspect_in>=0)&(aspect_in<=45),1,Con((aspect_in<=360)&(aspect_in>=315),1,0))\n",
    "# north_raster.save(os.path.join(temp_dir, norname))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TauDEM - Create grids using Timms Composite DEM for entire TauDEM processed areas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# Code to create merged elevation grid, aspect and north aspect grids for entire AKSSF region with TauDEM elev data\n",
    "# compDEM = r\"C:\\Users\\dwmerrigan\\Documents\\GitHub\\AKSSF\\hydrography\\data\\topography\\AKSSF_Elevation_Composite_10m.tif\"\n",
    "# clip to study area\n",
    "# AKSSF_elev_10m = r\"D:\\\\GIS_temp\\\\AKSSF_Composite_10m_extract.tif\"\n",
    "#\n",
    "# #make aspect raster for all of akssf from merged nhdplus\n",
    "# from arcpy.sa import *\n",
    "# aspname = 'AKSSF_Composite_10m_aspect.tif'\n",
    "# asp_rast = Aspect(in_raster= AKSSF_elev_10m, method='Planar')\n",
    "# asp_rast.save(os.path.join(temp_dir, aspname))\n",
    "#\n",
    "# # make north raster from aspect raster\n",
    "# norname = 'AKSSF_Composite_10m_north_aspect.tif'\n",
    "# aspect_in = Raster(asp_rast)\n",
    "# north_raster = Con((aspect_in>=0)&(aspect_in<=45),1,Con((aspect_in<=360)&(aspect_in>=315),1,0))\n",
    "# north_raster.save(os.path.join(temp_dir, norname))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Begin GIS portion\n",
    "- May be faster and save more space to create aspect rasters here using extract by mask?\n",
    "- May be able to use aspect raster with tabulate intersection to calculate percent North (aspects from 315-45 degrees)\n",
    "\n",
    "### <b>UPDATE - 2021-10-12 Do not run aspect metrics at this time. Only need to run percent North for watersheds</b>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\GIS_temp\\AKSSF\\Bristol_Bay\n",
      "D:\\GIS_temp\\AKSSF\\Cook_Inlet\n",
      "D:\\GIS_temp\\AKSSF\\Cook_Inlet found for Cook_Inlet\n",
      "NHD data: north raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_NHDPlus_north_aspect.tif\n",
      "         aspect raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_NHDPlus_aspect.tif\n",
      "      elevation raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_NHDPlus_elev_cm.tif\n",
      "----------\n",
      "Adding cat_ID_txt field to catchment dataset D:\\GIS_temp\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb\\cats_intersect\n",
      "----------\n",
      "Adding cat_ID_txt field to watershed dataset D:\\GIS_temp\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb\\wtds_merge\n",
      "----------\n",
      "Calculating aspect metrics and percent north for catchments & watersheds of interest in Cook_Inlet region\n",
      "----------\n",
      "Geodatabase: ['D:\\\\GIS_temp\\\\AKSSF\\\\Cook_Inlet\\\\Cook_Inlet.gdb']\n",
      "----------\n",
      "Elevation Raster: D:\\GIS_temp\\AKSSF\\Cook_Inlet\\elev.tif\n",
      "----------\n",
      "North Aspect Raster: D:\\Basedata\\AKSSF_Basedata\\AKSSF_NHDPlus_north_aspect.tif\n",
      "----------\n",
      "241 Watersheds to process\n",
      "----------\n",
      "Catchment intersect D:\\GIS_temp\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb\\cats_intersect selected\n",
      "----------\n",
      "Merged watershed dataset D:\\GIS_temp\\AKSSF\\Cook_Inlet\\Cook_Inlet.gdb\\wtds_merge already created\n",
      "----------\n",
      "Begin zonal statistics min/mean/max std dev for watersheds and catchments in Cook_Inlet region\n",
      "Zonal Stats for Cook_Inlet Elapsed time: (0:11:02)\n",
      "----------\n",
      "Begin tabulate area of north facing cells for watersheds and catchments in Cook_Inlet region\n",
      "Tabulate area for Cook_Inlet Elapsed time: (0:06:28)\n",
      "----------\n",
      "D:\\GIS_temp\\AKSSF\\Copper_River\n",
      "D:\\GIS_temp\\AKSSF\\Kodiak\n",
      "D:\\GIS_temp\\AKSSF\\Prince_William_Sound\n",
      "Region Cook_Inlet not found in D:\\GIS_temp\\AKSSF\\Prince_William_Sound\n",
      "D:\\GIS_temp\\AKSSF\\Bristol_Bay\n",
      "D:\\GIS_temp\\AKSSF\\Cook_Inlet\n",
      "D:\\GIS_temp\\AKSSF\\Copper_River\n",
      "D:\\GIS_temp\\AKSSF\\Copper_River found for Copper_River\n",
      "NHD data: north raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_NHDPlus_north_aspect.tif\n",
      "         aspect raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_NHDPlus_aspect.tif\n",
      "      elevation raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_NHDPlus_elev_cm.tif\n",
      "----------\n",
      "Adding cat_ID_txt field to catchment dataset D:\\GIS_temp\\AKSSF\\Copper_River\\Copper_River.gdb\\cats_intersect\n",
      "----------\n",
      "Adding cat_ID_txt field to watershed dataset D:\\GIS_temp\\AKSSF\\Copper_River\\Copper_River.gdb\\wtds_merge\n",
      "----------\n",
      "Calculating aspect metrics and percent north for catchments & watersheds of interest in Copper_River region\n",
      "----------\n",
      "Geodatabase: ['D:\\\\GIS_temp\\\\AKSSF\\\\Copper_River\\\\Copper_River.gdb']\n",
      "----------\n",
      "Elevation Raster: D:\\GIS_temp\\AKSSF\\Copper_River\\elev.tif\n",
      "----------\n",
      "North Aspect Raster: D:\\GIS_temp\\AKSSF\\Copper_River\\north.tif\n",
      "----------\n",
      "28 Watersheds to process\n",
      "----------\n",
      "Catchment intersect D:\\GIS_temp\\AKSSF\\Copper_River\\Copper_River.gdb\\cats_intersect selected\n",
      "----------\n",
      "Merged watershed dataset D:\\GIS_temp\\AKSSF\\Copper_River\\Copper_River.gdb\\wtds_merge already created\n",
      "----------\n",
      "Begin zonal statistics min/mean/max std dev for watersheds and catchments in Copper_River region\n",
      "Zonal Stats for Copper_River Elapsed time: (0:05:45)\n",
      "----------\n",
      "Begin tabulate area of north facing cells for watersheds and catchments in Copper_River region\n",
      "Tabulate area for Copper_River Elapsed time: (0:03:23)\n",
      "----------\n",
      "D:\\GIS_temp\\AKSSF\\Kodiak\n",
      "D:\\GIS_temp\\AKSSF\\Prince_William_Sound\n",
      "Region Copper_River not found in D:\\GIS_temp\\AKSSF\\Prince_William_Sound\n",
      "D:\\GIS_temp\\AKSSF\\Bristol_Bay\n",
      "D:\\GIS_temp\\AKSSF\\Bristol_Bay found for Bristol_Bay\n",
      "TauDem data: north raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_north_aspect.tif\n",
      "         aspect raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_aspect.tif\n",
      "      elevation raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_extract.tif\n",
      "----------\n",
      "Id field already in dataset\n",
      "Id field already in dataset\n",
      "----------\n",
      "Calculating aspect metrics and percent north for catchments & watersheds of interest in Bristol_Bay region\n",
      "----------\n",
      "Geodatabase: ['D:\\\\GIS_temp\\\\AKSSF\\\\Bristol_Bay\\\\Bristol_Bay.gdb']\n",
      "----------\n",
      "Elevation Raster: D:\\GIS_temp\\AKSSF\\Bristol_Bay\\elev.tif\n",
      "----------\n",
      "North Aspect Raster: D:\\GIS_temp\\AKSSF\\Bristol_Bay\\north.tif\n",
      "----------\n",
      "114 Watersheds to process\n",
      "----------\n",
      "Catchment intersect D:\\GIS_temp\\AKSSF\\Bristol_Bay\\Bristol_Bay.gdb\\cats_intersect selected\n",
      "----------\n",
      "Merged watershed dataset D:\\GIS_temp\\AKSSF\\Bristol_Bay\\Bristol_Bay.gdb\\wtds_merge already created\n",
      "----------\n",
      "Begin zonal statistics min/mean/max std dev for watersheds and catchments in Bristol_Bay region\n",
      "Zonal Stats for Bristol_Bay Elapsed time: (0:00:56)\n",
      "----------\n",
      "Begin tabulate area of north facing cells for watersheds and catchments in Bristol_Bay region\n",
      "Tabulate area for Bristol_Bay Elapsed time: (0:00:59)\n",
      "----------\n",
      "D:\\GIS_temp\\AKSSF\\Cook_Inlet\n",
      "D:\\GIS_temp\\AKSSF\\Copper_River\n",
      "D:\\GIS_temp\\AKSSF\\Kodiak\n",
      "D:\\GIS_temp\\AKSSF\\Prince_William_Sound\n",
      "Region Bristol_Bay not found in D:\\GIS_temp\\AKSSF\\Prince_William_Sound\n",
      "D:\\GIS_temp\\AKSSF\\Bristol_Bay\n",
      "D:\\GIS_temp\\AKSSF\\Cook_Inlet\n",
      "D:\\GIS_temp\\AKSSF\\Copper_River\n",
      "D:\\GIS_temp\\AKSSF\\Kodiak\n",
      "D:\\GIS_temp\\AKSSF\\Kodiak found for Kodiak\n",
      "TauDem data: north raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_north_aspect.tif\n",
      "         aspect raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_aspect.tif\n",
      "      elevation raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_extract.tif\n",
      "----------\n",
      "Adding cat_ID_txt field to catchment dataset D:\\GIS_temp\\AKSSF\\Kodiak\\Kodiak.gdb\\cats_intersect\n",
      "----------\n",
      "Adding cat_ID_txt field to watershed dataset D:\\GIS_temp\\AKSSF\\Kodiak\\Kodiak.gdb\\wtds_merge\n",
      "----------\n",
      "Calculating aspect metrics and percent north for catchments & watersheds of interest in Kodiak region\n",
      "----------\n",
      "Geodatabase: ['D:\\\\GIS_temp\\\\AKSSF\\\\Kodiak\\\\Kodiak.gdb']\n",
      "----------\n",
      "Elevation Raster: D:\\GIS_temp\\AKSSF\\Kodiak\\elev.tif\n",
      "----------\n",
      "North Aspect Raster: D:\\GIS_temp\\AKSSF\\Kodiak\\north.tif\n",
      "----------\n",
      "28 Watersheds to process\n",
      "----------\n",
      "Catchment intersect D:\\GIS_temp\\AKSSF\\Kodiak\\Kodiak.gdb\\cats_intersect selected\n",
      "----------\n",
      "Merged watershed dataset D:\\GIS_temp\\AKSSF\\Kodiak\\Kodiak.gdb\\wtds_merge already created\n",
      "----------\n",
      "Begin zonal statistics min/mean/max std dev for watersheds and catchments in Kodiak region\n",
      "Zonal Stats for Kodiak Elapsed time: (0:00:10)\n",
      "----------\n",
      "Begin tabulate area of north facing cells for watersheds and catchments in Kodiak region\n",
      "Tabulate area for Kodiak Elapsed time: (0:00:08)\n",
      "----------\n",
      "D:\\GIS_temp\\AKSSF\\Prince_William_Sound\n",
      "Region Kodiak not found in D:\\GIS_temp\\AKSSF\\Prince_William_Sound\n",
      "D:\\GIS_temp\\AKSSF\\Bristol_Bay\n",
      "D:\\GIS_temp\\AKSSF\\Cook_Inlet\n",
      "D:\\GIS_temp\\AKSSF\\Copper_River\n",
      "D:\\GIS_temp\\AKSSF\\Kodiak\n",
      "D:\\GIS_temp\\AKSSF\\Prince_William_Sound\n",
      "D:\\GIS_temp\\AKSSF\\Prince_William_Sound found for Prince_William_Sound\n",
      "TauDem data: north raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_north_aspect.tif\n",
      "         aspect raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_aspect.tif\n",
      "      elevation raster - D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_extract.tif\n",
      "----------\n",
      "Adding cat_ID_txt field to catchment dataset D:\\GIS_temp\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\\cats_intersect\n",
      "----------\n",
      "Adding cat_ID_txt field to watershed dataset D:\\GIS_temp\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\\wtds_merge\n",
      "----------\n",
      "Calculating aspect metrics and percent north for catchments & watersheds of interest in Prince_William_Sound region\n",
      "----------\n",
      "Geodatabase: ['D:\\\\GIS_temp\\\\AKSSF\\\\Prince_William_Sound\\\\Prince_William_Sound.gdb']\n",
      "----------\n",
      "Elevation Raster: D:\\GIS_temp\\AKSSF\\Prince_William_Sound\\elev.tif\n",
      "----------\n",
      "North Aspect Raster: D:\\GIS_temp\\AKSSF\\Prince_William_Sound\\north.tif\n",
      "----------\n",
      "19 Watersheds to process\n",
      "----------\n",
      "Catchment intersect D:\\GIS_temp\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\\cats_intersect selected\n",
      "----------\n",
      "Merged watershed dataset D:\\GIS_temp\\AKSSF\\Prince_William_Sound\\Prince_William_Sound.gdb\\wtds_merge already created\n",
      "----------\n",
      "Begin zonal statistics min/mean/max std dev for watersheds and catchments in Prince_William_Sound region\n",
      "Zonal Stats for Prince_William_Sound Elapsed time: (0:00:09)\n",
      "----------\n",
      "Begin tabulate area of north facing cells for watersheds and catchments in Prince_William_Sound region\n",
      "Tabulate area for Prince_William_Sound Elapsed time: (0:00:08)\n",
      "----------\n",
      "Region Prince_William_Sound not found in D:\\GIS_temp\\AKSSF\\Prince_William_Sound\n",
      "Process completed at 2021-10-18 11:45 (Elapsed time: 0:29:19)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "from arcpy.sa import *\n",
    "import re\n",
    "\n",
    "# Set data_dir equal to folder containing AKSSF regional subfolders containing GDBs and raster datasets\n",
    "arcpy.env.workspace = data_dir\n",
    "arcpy.env.overwriteOutput = True\n",
    "regions  = arcpy.ListWorkspaces(workspace_type=\"Folder\")\n",
    "\n",
    "# Lists for variables not needed at present time\n",
    "#cat_asp_ztables = []\n",
    "#wtd_asp_ztables = []\n",
    "#cat_pernorth_taba_tables=[]\n",
    "\n",
    "# Lists to store output tables\n",
    "wtd_pernorth_taba_tables=[]\n",
    "cat_elev_ztables = []\n",
    "wtd_elev_ztables = []\n",
    "\n",
    "# Start timing function\n",
    "processStart = time.time()\n",
    "processStartdt = datetime.datetime.now()\n",
    "\n",
    "# Seperate data by\n",
    "nhdplus_dat = ['Cook_Inlet','Copper_River']\n",
    "tauDem_dat = ['Bristol_Bay', 'Kodiak', 'Prince_William_Sound']\n",
    "\n",
    "# Loop through all processing areas\n",
    "rois = nhdplus_dat + tauDem_dat\n",
    "#xrois = ['Bristol_Bay']\n",
    "for roi in rois:\n",
    "# Loop through regional folders\n",
    "    for region in regions:\n",
    "        print (region)\n",
    "        if roi in str(region):\n",
    "            print(f'{region} found for {roi}')\n",
    "            if roi in nhdplus_dat:\n",
    "                # NHDPLus raster data for DM pc, variables will be overwritten below if they exist in source folder.\n",
    "                asp_rast = r\"D:\\Basedata\\AKSSF_Basedata\\AKSSF_NHDPlus_aspect.tif\"\n",
    "                elev_rast = r\"D:\\Basedata\\AKSSF_Basedata\\AKSSF_NHDPlus_elev_cm.tif\"\n",
    "                nor_rast = r\"D:\\Basedata\\AKSSF_Basedata\\AKSSF_NHDPlus_north_aspect.tif\"\n",
    "                cat_cur_fields = ['cat_ID_txt', 'NHDPlusID']\n",
    "                wtd_cur_fields = ['cat_ID_txt', 'cat_ID']\n",
    "\n",
    "                print(f'NHD data: north raster - {nor_rast}')\n",
    "                print(f'         aspect raster - {asp_rast}')\n",
    "                print(f'      elevation raster - {elev_rast}')\n",
    "                print('----------')\n",
    "\n",
    "            elif roi in tauDem_dat:\n",
    "                # TauDEM raster data for DM pc, variables will be overwritten below if they exist in source folder.\n",
    "                nor_rast = r\"D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_north_aspect.tif\"\n",
    "                asp_rast = r\"D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_aspect.tif\"\n",
    "                elev_rast = r\"D:\\Basedata\\AKSSF_Basedata\\AKSSF_Composite_10m_extract.tif\"\n",
    "                cat_cur_fields = ['cat_ID_txt', 'gridcode']\n",
    "                wtd_cur_fields = ['cat_ID_txt', 'cat_ID']\n",
    "                print(f'TauDem data: north raster - {nor_rast}')\n",
    "                print(f'         aspect raster - {asp_rast}')\n",
    "                print(f'      elevation raster - {elev_rast}')\n",
    "                print('----------')\n",
    "\n",
    "            wtds = []\n",
    "            cats = []\n",
    "            # Start iter timing function\n",
    "            iteration_start = time.time()\n",
    "            # Set workspace to region folder\n",
    "            arcpy.env.workspace = region\n",
    "            gdb = arcpy.ListWorkspaces(workspace_type='FileGDB')\n",
    "            walk = arcpy.da.Walk(region, datatype = ['FeatureClass','RasterDataset'])\n",
    "            for dirpath, dirnames, filenames in walk:\n",
    "                for filename in filenames:\n",
    "                    # Create list of watersheds\n",
    "                    if (\"wtd\" in filename) and (\"merge\" not in filename):\n",
    "                        wtds.append(os.path.join(dirpath, filename))\n",
    "\n",
    "                    # Set watershed merged watersheds dataset\n",
    "                    elif 'wtds_merge'in filename:\n",
    "                        wtd_merge = os.path.join(dirpath, filename)\n",
    "                        wtdfieldnames = []\n",
    "                        wtdlstFields = arcpy.ListFields(wtd_merge)\n",
    "                        for field in wtdlstFields:\n",
    "                            wtdfieldnames.append(field.name)\n",
    "                        if 'cat_ID_txt' in wtdfieldnames:\n",
    "                            print ('Id field already in dataset')\n",
    "                            print('----------')\n",
    "                        else:\n",
    "                            print (f'Adding cat_ID_txt field to watershed dataset {wtd_merge}')\n",
    "                            print('----------')\n",
    "                            # add cat_ID_txt field\n",
    "                            arcpy.AddField_management(wtd_merge,\"cat_ID_txt\",field_type='TEXT')\n",
    "                            # populate cat_ID_txt\n",
    "                            with arcpy.da.UpdateCursor(wtd_merge, wtd_cur_fields) as cur:\n",
    "                                for row in cur:\n",
    "                                    row[0] = str(row[1])\n",
    "                                    # Update rows\n",
    "                                    cur.updateRow(row)\n",
    "                                del(row)\n",
    "                            del(cur)\n",
    "\n",
    "                    # Select elevation raster\n",
    "                    elif 'elev.tif' == filename:\n",
    "                        elev_rast = os.path.join(dirpath, filename)\n",
    "\n",
    "                    # # Select aspect raster\n",
    "                    # elif 'aspect' in filename:\n",
    "                    #     asp_rast = os.path.join(dirpath, filename)\n",
    "\n",
    "                    # Select north raster\n",
    "                    elif 'north.tif' == filename:\n",
    "                        nor_rast = os.path.join(dirpath, filename)\n",
    "\n",
    "                    # Select catch_int fc (catchments of interest for region) and make a copy\n",
    "                    elif 'cats_intersect' in filename:\n",
    "                        cats = os.path.join(dirpath,filename)\n",
    "                        catlstfields = arcpy.ListFields(cats)\n",
    "                        catfieldnames = []\n",
    "                        for field in catlstfields:\n",
    "                            catfieldnames.append(field.name)\n",
    "                        if 'cat_ID_txt' in catfieldnames:\n",
    "                            print ('Id field already in dataset')\n",
    "                        else:\n",
    "                            print (f'Adding cat_ID_txt field to catchment dataset {cats}')\n",
    "                            print('----------')\n",
    "                            # add cat_ID_txt field\n",
    "                            arcpy.AddField_management(cats,\"cat_ID_txt\",field_type='TEXT')\n",
    "                            # populate cat_ID_txt\n",
    "                            with arcpy.da.UpdateCursor(cats, cat_cur_fields) as cur:\n",
    "                                for row in cur:\n",
    "                                    row[0] = str(row[1])\n",
    "                                    # Update rows\n",
    "                                    cur.updateRow(row)\n",
    "                                del(row)\n",
    "                            del(cur)\n",
    "\n",
    "            print (f'Calculating aspect metrics and percent north for catchments & watersheds of interest in {roi}'\n",
    "                   f' region')\n",
    "            print ('----------')\n",
    "            print(f'Geodatabase: {gdb}')\n",
    "            print ('----------')\n",
    "            print (f'Elevation Raster: {elev_rast}')\n",
    "            print ('----------')\n",
    "            print (f'North Aspect Raster: {nor_rast}')\n",
    "            print ('----------')\n",
    "            print (f'{len(wtds)} Watersheds to process')\n",
    "            print ('----------')\n",
    "            print (f'Catchment intersect {cats} selected')\n",
    "            print ('----------')\n",
    "\n",
    "            try:\n",
    "                # Set output names/paths for watershed and catchment tables\n",
    "                wtd_merge_name = roi + \"_Watersheds_Merge\"\n",
    "                wtd_merge_path = os.path.join(outgdb,wtd_merge_name)\n",
    "\n",
    "                # # Aspect variables\n",
    "                # wtd_merge_asp_table_name = roi + \"_Watersheds_Merge_AspectZstats\"\n",
    "                # wtd_merge_asp_table_path = os.path.join(outgdb, wtd_merge_asp_table_name)\n",
    "                # cat_asp_table_name = roi + \"_Catchments_AspectZstats\"\n",
    "                # cat_asp_table_path = os.path.join(outgdb, cat_asp_table_name)\n",
    "\n",
    "                # Percent North variables\n",
    "                wtd_merge_pernorth_table_name = roi + \"_Watersheds_Merge_PercentNorth\"\n",
    "                wtd_merge_pernorth_table_path = os.path.join(outgdb, wtd_merge_pernorth_table_name)\n",
    "                # cat_pernorth_table_name = roi + \"_Catchments_PercentNorth\"\n",
    "                # cat_pernorth_table_path = os.path.join(outgdb, cat_pernorth_table_name)\n",
    "\n",
    "                # Elevation variables\n",
    "                wtd_merge_elev_table_name = roi + \"_Watersheds_Merge_ElevZstats\"\n",
    "                wtd_merge_elev_table_path = os.path.join(outgdb, wtd_merge_elev_table_name)\n",
    "                cat_elev_table_name = roi + \"_Catchments_ElevZstats\"\n",
    "                cat_elev_table_path = os.path.join(outgdb, cat_elev_table_name)\n",
    "\n",
    "                if not arcpy.Exists(wtd_merge):\n",
    "                    mergestart = time.time()\n",
    "                    # Merge watersheds\n",
    "                    wtd_merge = arcpy.Merge_management( wtds, wtd_merge_path ,add_source='ADD_SOURCE_INFO')\n",
    "                    # Add wtd_id field\n",
    "                    arcpy.AddField_management(wtd_merge,'cat_ID_txt',field_type='TEXT')\n",
    "                    # Add region field\n",
    "                    arcpy.AddField_management(wtd_merge,'region',field_type='TEXT')\n",
    "                    # Populate watershed id and region information using update cursor - faster than field calc\n",
    "                    with arcpy.da.UpdateCursor(wtd_merge,['MERGE_SRC','cat_ID_txt','region']) as cur:\n",
    "                        for row in cur:\n",
    "                            row[1] = re.findall('\\d+', row[0])[0]\n",
    "                            row[2] = roi\n",
    "                            # Update\n",
    "                            cur.updateRow(row)\n",
    "                        del(row)\n",
    "                    del(cur)\n",
    "                    mergestop = time.time()\n",
    "                    mergetime = int (mergestop - mergestart)\n",
    "                    print(f'Watershed Merge for {roi} Elapsed time: ({datetime.timedelta(seconds=mergetime)})')\n",
    "                    print('----------')\n",
    "                else:\n",
    "                    print (f'Merged watershed dataset {wtd_merge} already created')\n",
    "                    print('----------')\n",
    "                    \n",
    "                # Begin Zonal Stats\n",
    "                zstat_start = time.time()\n",
    "                print(f'Begin zonal statistics min/mean/max std dev for watersheds and catchments in {roi} region')\n",
    "\n",
    "                # Elevation Zonal statistics  for watersheds\n",
    "                wtd_elev_metrics_table = ZonalStatisticsAsTable(in_zone_data = wtd_merge,\n",
    "                                                                zone_field = \"cat_ID_txt\",\n",
    "                                                                in_value_raster = elev_rast,\n",
    "                                                                out_table = wtd_merge_elev_table_path,\n",
    "                                                                statistics_type='ALL'\n",
    "                                                                )\n",
    "                # Add region identifier field for watershed tables                                                )\n",
    "                arcpy.AddField_management(wtd_elev_metrics_table,'region',field_type='TEXT')\n",
    "                # Update region field\n",
    "                with arcpy.da.UpdateCursor(wtd_elev_metrics_table,'region') as cur:\n",
    "                    for row in cur:\n",
    "                        row[0] = roi\n",
    "                        # Update\n",
    "                        cur.updateRow(row)\n",
    "                    del(row)\n",
    "                del(cur)\n",
    "                # Append watershed elev table to list\n",
    "                wtd_elev_ztables.append(wtd_elev_metrics_table)\n",
    "\n",
    "                # Elevation zonal statistics for catchments\n",
    "                cat_elev_metrics_table = ZonalStatisticsAsTable(in_zone_data = cats ,\n",
    "                                                                zone_field = \"cat_ID_txt\",\n",
    "                                                                in_value_raster = elev_rast,\n",
    "                                                                out_table = cat_elev_table_path,\n",
    "                                                                statistics_type='ALL'\n",
    "                                                                )\n",
    "                # Add region identifier field for catchment table\n",
    "                arcpy.AddField_management(cat_elev_metrics_table,'region',field_type='TEXT')\n",
    "\n",
    "                # Update region field\n",
    "                with arcpy.da.UpdateCursor(cat_elev_metrics_table,'region') as cur:\n",
    "                    for row in cur:\n",
    "                        row[0] = roi\n",
    "                        # Update\n",
    "                        cur.updateRow(row)\n",
    "                    del(row)\n",
    "                del(cur)\n",
    "                # Append catchment elev table to list\n",
    "                cat_elev_ztables.append(cat_elev_metrics_table)\n",
    "\n",
    "                # # Aspect Zonal statistics  for watersheds\n",
    "                # wtd_asp_metrics_table = ZonalStatisticsAsTable(in_zone_data = wtd_merge, zone_field =\"cat_ID_txt\",\n",
    "                #                                                in_value_raster = asp_rast, out_table = wtd_merge_asp_table_path,\n",
    "                #                                                statistics_type='ALL')\n",
    "                # arcpy.AddField_management(wtd_asp_metrics_table, 'region', field_type='TEXT')\n",
    "                # arcpy.CalculateField_management(wtd_asp_metrics_table, 'region', 'roi')\n",
    "                # wtd_asp_ztables.append(wtd_asp_metrics_table)\n",
    "\n",
    "                # # Aspect Zonal statistics for catchments\n",
    "                # cat_asp_metrics_table = ZonalStatisticsAsTable(in_zone_data = cats, zone_field =\"cat_ID_txt\",\n",
    "                #                                                in_value_raster = asp_rast, out_table = cat_asp_table_path,\n",
    "                #                                                statistics_type='ALL')\n",
    "                # cat_asp_ztables.append(cat_asp_metrics_table)\n",
    "\n",
    "                zstat_stop = time.time()\n",
    "                zstat_time = int (zstat_stop - zstat_start)\n",
    "                print(f'Zonal Stats for {roi} Elapsed time: ({datetime.timedelta(seconds=zstat_time)})')\n",
    "                print('----------')\n",
    "\n",
    "                # Tabulate Area with north grid and catchments/watersheds\n",
    "                tabarea_start = time.time()\n",
    "                print(f'Begin tabulate area of north facing cells for watersheds and catchments in {roi} region')\n",
    "                # Percent North Tabulate area for watersheds\n",
    "                wtd_per_north_tabarea = arcpy.sa.TabulateArea(in_zone_data= wtd_merge,\n",
    "                                                              zone_field='cat_ID_txt',\n",
    "                                                              in_class_data=nor_rast,\n",
    "                                                              class_field=\"Value\",\n",
    "                                                              out_table=wtd_merge_pernorth_table_path\n",
    "                                                              )\n",
    "                # Add region and percent north fields\n",
    "                arcpy.AddField_management(wtd_per_north_tabarea, 'region', field_type='TEXT')\n",
    "                arcpy.AddField_management(wtd_per_north_tabarea, 'wtd_north_per', field_type='Float')\n",
    "\n",
    "                with arcpy.da.UpdateCursor(wtd_per_north_tabarea,['cat_ID_txt','region', 'VALUE_0',\n",
    "                                                                        'VALUE_1', 'north_wtd']) as cur:\n",
    "                    for row in cur:\n",
    "                        row[1] = roi\n",
    "                        row[4] = row[3]/(row[3]+row[2])*100\n",
    "                        # Update\n",
    "                        cur.updateRow(row)\n",
    "                    del(row)\n",
    "                del(cur)\n",
    "                # Append watershed percent north table to list\n",
    "                wtd_pernorth_taba_tables.append(wtd_per_north_tabarea)\n",
    "\n",
    "                # # Percent North Tabulate Area for catchments\n",
    "                # cat_per_north_tabarea = arcpy.sa.TabulateArea(in_zone_data= cats, zone_field='cat_ID_txt',\n",
    "                #                                             in_class_data=nor_rast,\"Value\",\n",
    "                #                                             out_table=cat_pernorth_table_path)\n",
    "\n",
    "                # # Add and calculate region identifier field for catchment table\n",
    "                # arcpy.AddField_management(cat_per_north_tabarea, 'cat_ID_txt', field_type='Float')\n",
    "                # arcpy.AddField_management(cat_per_north_tabarea, 'region', field_type='TEXT')\n",
    "                # arcpy.AddField_management(cat_per_north_tabarea, 'north_cat', field_type='Float')\n",
    "                #\n",
    "                # with arcpy.da.UpdateCursor(cat_per_north_tabarea,['cat_ID_txt','region', 'VALUE_0',\n",
    "                #                                                         'VALUE_1', 'north_cat']) as cur:\n",
    "                #     for row in cur:\n",
    "                #         row[1] = roi\n",
    "                #         row[4] = row[3]/(row[3]+row[2])*100\n",
    "                #         # Update\n",
    "                #         cur.updateRow(row)\n",
    "                #     del(row)\n",
    "                # del(cur)\n",
    "                # cat_pernorth_taba_tables.append(cat_per_north_tabarea)\n",
    "                tabarea_stop = time.time()\n",
    "                tabarea_time = int (tabarea_stop - tabarea_start)\n",
    "                print(f'Tabulate area for {roi} Elapsed time: ({datetime.timedelta(seconds=tabarea_time)})')\n",
    "                print('----------')\n",
    "\n",
    "            except:\n",
    "                e = sys.exc_info()[1]\n",
    "                print(e.args[0])\n",
    "                arcpy.AddError(e.args[0])\n",
    "\n",
    "    else:\n",
    "        print(f'Region {str(roi)} not found in {region}')\n",
    "# End timing\n",
    "processEnd = time.time()\n",
    "processElapsed = int(processEnd - processStart)\n",
    "processSuccess_time = datetime.datetime.now()\n",
    "\n",
    "# Report success\n",
    "print(f'Process completed at {processSuccess_time.strftime(\"%Y-%m-%d %H:%M\")} '\n",
    "      f'(Elapsed time: {datetime.timedelta(seconds=processElapsed)})')\n",
    "print('----------')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Drop unnecessary fields and rename as needed from merged tables.\n",
    "- Create Key value dictionary and use update cursor to rename fields."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "# Table names/paths\n",
    "wtd_per_north_table_out = os.path.join(outgdb, 'AKSSF_wtd_north_per')\n",
    "cat_elev_table_out = os.path.join(outgdb,'AKSSF_cat_elev')\n",
    "wtd_elev_table_out = os.path.join(outgdb, 'AKSSF_wtd_elev')\n",
    "\n",
    "# Merge all regional tables together\n",
    "wtd_per_north = arcpy.Merge_management(wtd_pernorth_taba_tables, wtd_per_north_table_out)\n",
    "cat_elev = arcpy.Merge_management(cat_elev_ztables, cat_elev_table_out)\n",
    "wtd_elev = arcpy.Merge_management(wtd_elev_ztables, wtd_elev_table_out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "#Set up field dictionary\n",
    "dict = { 'ZONE_CODE': ('cat_elev_ZONE_CODE', 'wtd_elev_ZONE_CODE'),\n",
    " 'COUNT': ('cat_elev_COUNT', 'wtd_elev_COUNT'),\n",
    " 'AREA': ('cat_elev_AREA', 'wtd_elev_AREA'),\n",
    " 'MIN': ('cat_elev_MIN', 'wtd_elev_MIN'),\n",
    " 'MAX': ('cat_elev_MAX', 'wtd_elev_MAX'),\n",
    " 'RANGE': ('cat_elev_RANGE', 'wtd_elev_RANGE'),\n",
    " 'MEAN': ('cat_elev_MEAN', 'wtd_elev_MEAN'),\n",
    " 'STD': ('cat_elev_STD', 'wtd_elev_STD'),\n",
    " 'SUM': ('cat_elev_SUM', 'wtd_elev_SUM'),\n",
    " 'VARIETY': ('cat_elev_VARIETY', 'wtd_elev_VARIETY'),\n",
    " 'MAJORITY': ('cat_elev_MAJORITY', 'wtd_elev_MAJORITY'),\n",
    " 'MINORITY': ('cat_elev_MINORITY', 'wtd_elev_MINORITY'),\n",
    " 'MEDIAN': ('cat_elev_MEDIAN', 'wtd_elev_MEDIAN'),\n",
    " 'PCT90': ('cat_elev_PCT90', 'wtd_elev_PCT90')}\n",
    "\n",
    "catz = []\n",
    "catzup = []\n",
    "wtdz = []\n",
    "wtdzup = []\n",
    "\n",
    "# Field lists\n",
    "wtd_pernoth_fields = arcpy.ListFields(wtd_per_north)\n",
    "cat_elev_zfields = arcpy.ListFields(cat_elev)\n",
    "wtd_elev_zfields = arcpy.ListFields(wtd_elev)\n",
    "\n",
    "# for field in cat_elev_zfields:\n",
    "#     fnam = field.name\n",
    "#     print (fnam)\n",
    "#     catznew = 'cat_elev_' + str(fnam)\n",
    "#     catz.append(fnam)\n",
    "#     catzup.append(catznew)\n",
    "#\n",
    "# for field in wtd_elev_zfields:\n",
    "#     fnam = field.name\n",
    "#     print (fnam)\n",
    "#     wtdznew = 'wtd_elev_' + str(fnam)\n",
    "#     wtdz.append(fnam)\n",
    "#     wtdzup.append(wtdznew)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# Rename fields\n",
    "for field in arcpy.ListFields(wtd_elev):\n",
    "    keyval = field.name\n",
    "    if keyval in dict:\n",
    "        newname = dict[keyval][1]\n",
    "        newalias = dict[keyval][1]\n",
    "        print (keyval, newname)\n",
    "        arcpy.AlterField_management(wtd_elev, keyval, newname, newalias)\n",
    "\n",
    "for field in arcpy.ListFields(cat_elev):\n",
    "    keyval = field.name\n",
    "    if keyval in dict:\n",
    "        newname = dict[keyval][0]\n",
    "        newalias = dict[keyval][0]\n",
    "        print (keyval, newname)\n",
    "        arcpy.AlterField_management(cat_elev, keyval, newname, newalias)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert tables to pandas df and explore results\n",
    "* **Merge tables and export to csv**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.2f}'.format # only display 2 decimal places"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJECTID OBJECTID\n",
      "cat_ID_txt cat_ID_txt\n",
      "cat_elev_ZONE_CODE cat_elev_ZONE_CODE\n",
      "cat_elev_COUNT cat_elev_COUNT\n",
      "cat_elev_AREA cat_elev_AREA\n",
      "cat_elev_MIN cat_elev_MIN\n",
      "cat_elev_MAX cat_elev_MAX\n",
      "cat_elev_RANGE cat_elev_RANGE\n",
      "cat_elev_MEAN cat_elev_MEAN\n",
      "cat_elev_STD cat_elev_STD\n",
      "cat_elev_SUM cat_elev_SUM\n",
      "cat_elev_VARIETY cat_elev_VARIETY\n",
      "cat_elev_MAJORITY cat_elev_MAJORITY\n",
      "cat_elev_MINORITY cat_elev_MINORITY\n",
      "cat_elev_MEDIAN cat_elev_MEDIAN\n",
      "cat_elev_PCT90 cat_elev_PCT90\n",
      "region region\n"
     ]
    },
    {
     "data": {
      "text/plain": "                  cat_elev_COUNT  cat_elev_AREA  cat_elev_MIN  cat_elev_MAX  \\\ncat_ID_txt                                                                    \n75004200007057.0        38485.00      962125.00             0         90800   \n75004300006312.0        57576.00     1439400.00          5900          9800   \n75004300001906.0        12121.00      303025.00           300         14621   \n75004300000100.0        78743.00     1968575.00          3305          7800   \n75004300004983.0       113557.00     2838925.00          2100         47943   \n...                          ...            ...           ...           ...   \n43933                    3776.00      377600.00             0           512   \n43973                    2363.00      236300.00             1           362   \n44553                    3888.00      388800.00             0            35   \n44623                    4300.00      430000.00             0            13   \n46055                    1455.00      145500.00             2            70   \n\n                  cat_elev_RANGE  cat_elev_MEAN  cat_elev_STD  cat_elev_SUM  \\\ncat_ID_txt                                                                    \n75004200007057.0           90800       34649.43      25122.14 1333483286.00   \n75004300006312.0            3900        7654.30        935.80  440704003.00   \n75004300001906.0           14321        2818.64       2135.86   34164787.00   \n75004300000100.0            4495        5889.18        819.43  463731919.00   \n75004300004983.0           45843       26556.24      10043.37 3015646404.00   \n...                          ...            ...           ...           ...   \n43933                        512         222.92        164.12     841739.00   \n43973                        361          52.16         67.87     123252.00   \n44553                         35           4.44          3.49      17249.00   \n44623                         13           5.56          2.99      23918.00   \n46055                         68          17.64         13.27      25660.00   \n\n                  cat_elev_VARIETY  cat_elev_MAJORITY  cat_elev_MINORITY  \\\ncat_ID_txt                                                                 \n75004200007057.0             27216                400                 36   \n75004300006312.0              3605               6900               5909   \n75004300001906.0              4573               1000                301   \n75004300000100.0              3963               6500               3305   \n75004300004983.0             35402              33600               2103   \n...                            ...                ...                ...   \n43933                          512                  4                 32   \n43973                          258                  4                141   \n44553                           34                  5                 17   \n44623                           14                  6                 13   \n46055                           68                  3                 59   \n\n                  cat_elev_MEDIAN  cat_elev_PCT90                region  \ncat_ID_txt                                                               \n75004200007057.0            33377           70627            Cook_Inlet  \n75004300006312.0             7400            9002            Cook_Inlet  \n75004300001906.0             2126            5218            Cook_Inlet  \n75004300000100.0             5933            6800            Cook_Inlet  \n75004300004983.0            28233           38776            Cook_Inlet  \n...                           ...             ...                   ...  \n43933                         222             455  Prince_William_Sound  \n43973                          20             131  Prince_William_Sound  \n44553                           4               8  Prince_William_Sound  \n44623                           6               9  Prince_William_Sound  \n46055                          16              37  Prince_William_Sound  \n\n[428 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat_elev_COUNT</th>\n      <th>cat_elev_AREA</th>\n      <th>cat_elev_MIN</th>\n      <th>cat_elev_MAX</th>\n      <th>cat_elev_RANGE</th>\n      <th>cat_elev_MEAN</th>\n      <th>cat_elev_STD</th>\n      <th>cat_elev_SUM</th>\n      <th>cat_elev_VARIETY</th>\n      <th>cat_elev_MAJORITY</th>\n      <th>cat_elev_MINORITY</th>\n      <th>cat_elev_MEDIAN</th>\n      <th>cat_elev_PCT90</th>\n      <th>region</th>\n    </tr>\n    <tr>\n      <th>cat_ID_txt</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>75004200007057.0</th>\n      <td>38485.00</td>\n      <td>962125.00</td>\n      <td>0</td>\n      <td>90800</td>\n      <td>90800</td>\n      <td>34649.43</td>\n      <td>25122.14</td>\n      <td>1333483286.00</td>\n      <td>27216</td>\n      <td>400</td>\n      <td>36</td>\n      <td>33377</td>\n      <td>70627</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>75004300006312.0</th>\n      <td>57576.00</td>\n      <td>1439400.00</td>\n      <td>5900</td>\n      <td>9800</td>\n      <td>3900</td>\n      <td>7654.30</td>\n      <td>935.80</td>\n      <td>440704003.00</td>\n      <td>3605</td>\n      <td>6900</td>\n      <td>5909</td>\n      <td>7400</td>\n      <td>9002</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>75004300001906.0</th>\n      <td>12121.00</td>\n      <td>303025.00</td>\n      <td>300</td>\n      <td>14621</td>\n      <td>14321</td>\n      <td>2818.64</td>\n      <td>2135.86</td>\n      <td>34164787.00</td>\n      <td>4573</td>\n      <td>1000</td>\n      <td>301</td>\n      <td>2126</td>\n      <td>5218</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>75004300000100.0</th>\n      <td>78743.00</td>\n      <td>1968575.00</td>\n      <td>3305</td>\n      <td>7800</td>\n      <td>4495</td>\n      <td>5889.18</td>\n      <td>819.43</td>\n      <td>463731919.00</td>\n      <td>3963</td>\n      <td>6500</td>\n      <td>3305</td>\n      <td>5933</td>\n      <td>6800</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>75004300004983.0</th>\n      <td>113557.00</td>\n      <td>2838925.00</td>\n      <td>2100</td>\n      <td>47943</td>\n      <td>45843</td>\n      <td>26556.24</td>\n      <td>10043.37</td>\n      <td>3015646404.00</td>\n      <td>35402</td>\n      <td>33600</td>\n      <td>2103</td>\n      <td>28233</td>\n      <td>38776</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43933</th>\n      <td>3776.00</td>\n      <td>377600.00</td>\n      <td>0</td>\n      <td>512</td>\n      <td>512</td>\n      <td>222.92</td>\n      <td>164.12</td>\n      <td>841739.00</td>\n      <td>512</td>\n      <td>4</td>\n      <td>32</td>\n      <td>222</td>\n      <td>455</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n    <tr>\n      <th>43973</th>\n      <td>2363.00</td>\n      <td>236300.00</td>\n      <td>1</td>\n      <td>362</td>\n      <td>361</td>\n      <td>52.16</td>\n      <td>67.87</td>\n      <td>123252.00</td>\n      <td>258</td>\n      <td>4</td>\n      <td>141</td>\n      <td>20</td>\n      <td>131</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n    <tr>\n      <th>44553</th>\n      <td>3888.00</td>\n      <td>388800.00</td>\n      <td>0</td>\n      <td>35</td>\n      <td>35</td>\n      <td>4.44</td>\n      <td>3.49</td>\n      <td>17249.00</td>\n      <td>34</td>\n      <td>5</td>\n      <td>17</td>\n      <td>4</td>\n      <td>8</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n    <tr>\n      <th>44623</th>\n      <td>4300.00</td>\n      <td>430000.00</td>\n      <td>0</td>\n      <td>13</td>\n      <td>13</td>\n      <td>5.56</td>\n      <td>2.99</td>\n      <td>23918.00</td>\n      <td>14</td>\n      <td>6</td>\n      <td>13</td>\n      <td>6</td>\n      <td>9</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n    <tr>\n      <th>46055</th>\n      <td>1455.00</td>\n      <td>145500.00</td>\n      <td>2</td>\n      <td>70</td>\n      <td>68</td>\n      <td>17.64</td>\n      <td>13.27</td>\n      <td>25660.00</td>\n      <td>68</td>\n      <td>3</td>\n      <td>59</td>\n      <td>16</td>\n      <td>37</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n  </tbody>\n</table>\n<p>428 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make catchment elev df\n",
    "cat_df = pd.DataFrame()\n",
    "cat_field_list = []\n",
    "for field in arcpy.ListFields(cat_elev):\n",
    "    cat_field_list.append(field.name)\n",
    "    print (field.name, field.aliasName)\n",
    "cat_elev_arr = arcpy.da.TableToNumPyArray(cat_elev,cat_field_list)\n",
    "cat_df = pd.DataFrame(cat_elev_arr)\n",
    "cat_df = cat_df.drop([\"OBJECTID\",\"cat_elev_ZONE_CODE\"],axis=1)\n",
    "cat_df = cat_df.set_index('cat_ID_txt')\n",
    "cat_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "data": {
      "text/plain": "                  wtd_elev_COUNT  wtd_elev_AREA  wtd_elev_MIN  wtd_elev_MAX  \\\ncat_ID_txt                                                                    \n75004200007057.0       258728.00     6468200.00             0        144500   \n75004300006312.0      6172261.00   154306525.00          5900         56900   \n75004300001906.0      3674807.00    91870175.00           300         77174   \n75004300000100.0      1158453.00    28961325.00          3305         41700   \n75004300004983.0       610455.00    15261375.00          2100        147384   \n...                          ...            ...           ...           ...   \n43933.0                328912.00    32891200.00             0          3324   \n43973.0                172326.00    17232600.00             1          3324   \n44553.0                508260.00    50826000.00             0          3324   \n44623.0                354677.00    35467700.00             0          3324   \n46055.0                 32971.00     3297100.00             2          3324   \n\n                  wtd_elev_RANGE  wtd_elev_MEAN  wtd_elev_STD    wtd_elev_SUM  \\\ncat_ID_txt                                                                      \n75004200007057.0          144500       43255.27      37427.70  11191350026.00   \n75004300006312.0           51000       25127.05      11779.40 155090722985.00   \n75004300001906.0           76874       40142.44      11984.06 147515731019.00   \n75004300000100.0           38395       15654.17       8590.35  18134625884.00   \n75004300004983.0          145284       67339.95      33460.53  41108006739.00   \n...                          ...            ...           ...             ...   \n43933.0                     3324         659.88        420.19    217042673.00   \n43973.0                     3323         487.63        501.77     84030647.00   \n44553.0                     3324         617.58        428.77    313889063.00   \n44623.0                     3324         451.24        473.36    160046103.00   \n46055.0                     3322         542.06       1061.32     17872287.00   \n\n                  wtd_elev_VARIETY  wtd_elev_MAJORITY  wtd_elev_MINORITY  \\\ncat_ID_txt                                                                 \n75004200007057.0             99715                500                  4   \n75004300006312.0             50691              12600               5909   \n75004300001906.0             75573              37700                301   \n75004300000100.0             36389               9100               3305   \n75004300004983.0            126942              33600               2103   \n...                            ...                ...                ...   \n43933.0                       2275                200               1355   \n43973.0                       2021                254               1164   \n44553.0                       2515                 45               1493   \n44623.0                       2099                 19               1248   \n46055.0                        977                115                148   \n\n                  wtd_elev_MEDIAN  wtd_elev_PCT90                region  \ncat_ID_txt                                                               \n75004200007057.0            34500           95911            Cook_Inlet  \n75004300006312.0            22700           43157            Cook_Inlet  \n75004300001906.0            40200           54648            Cook_Inlet  \n75004300000100.0            12800           29401            Cook_Inlet  \n75004300004983.0            65060          117018            Cook_Inlet  \n...                           ...             ...                   ...  \n43933.0                       654            1030  Prince_William_Sound  \n43973.0                       394             794  Prince_William_Sound  \n44553.0                       592            1093  Prince_William_Sound  \n44623.0                       376             960  Prince_William_Sound  \n46055.0                        95            2903  Prince_William_Sound  \n\n[430 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>wtd_elev_COUNT</th>\n      <th>wtd_elev_AREA</th>\n      <th>wtd_elev_MIN</th>\n      <th>wtd_elev_MAX</th>\n      <th>wtd_elev_RANGE</th>\n      <th>wtd_elev_MEAN</th>\n      <th>wtd_elev_STD</th>\n      <th>wtd_elev_SUM</th>\n      <th>wtd_elev_VARIETY</th>\n      <th>wtd_elev_MAJORITY</th>\n      <th>wtd_elev_MINORITY</th>\n      <th>wtd_elev_MEDIAN</th>\n      <th>wtd_elev_PCT90</th>\n      <th>region</th>\n    </tr>\n    <tr>\n      <th>cat_ID_txt</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>75004200007057.0</th>\n      <td>258728.00</td>\n      <td>6468200.00</td>\n      <td>0</td>\n      <td>144500</td>\n      <td>144500</td>\n      <td>43255.27</td>\n      <td>37427.70</td>\n      <td>11191350026.00</td>\n      <td>99715</td>\n      <td>500</td>\n      <td>4</td>\n      <td>34500</td>\n      <td>95911</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>75004300006312.0</th>\n      <td>6172261.00</td>\n      <td>154306525.00</td>\n      <td>5900</td>\n      <td>56900</td>\n      <td>51000</td>\n      <td>25127.05</td>\n      <td>11779.40</td>\n      <td>155090722985.00</td>\n      <td>50691</td>\n      <td>12600</td>\n      <td>5909</td>\n      <td>22700</td>\n      <td>43157</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>75004300001906.0</th>\n      <td>3674807.00</td>\n      <td>91870175.00</td>\n      <td>300</td>\n      <td>77174</td>\n      <td>76874</td>\n      <td>40142.44</td>\n      <td>11984.06</td>\n      <td>147515731019.00</td>\n      <td>75573</td>\n      <td>37700</td>\n      <td>301</td>\n      <td>40200</td>\n      <td>54648</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>75004300000100.0</th>\n      <td>1158453.00</td>\n      <td>28961325.00</td>\n      <td>3305</td>\n      <td>41700</td>\n      <td>38395</td>\n      <td>15654.17</td>\n      <td>8590.35</td>\n      <td>18134625884.00</td>\n      <td>36389</td>\n      <td>9100</td>\n      <td>3305</td>\n      <td>12800</td>\n      <td>29401</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>75004300004983.0</th>\n      <td>610455.00</td>\n      <td>15261375.00</td>\n      <td>2100</td>\n      <td>147384</td>\n      <td>145284</td>\n      <td>67339.95</td>\n      <td>33460.53</td>\n      <td>41108006739.00</td>\n      <td>126942</td>\n      <td>33600</td>\n      <td>2103</td>\n      <td>65060</td>\n      <td>117018</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43933.0</th>\n      <td>328912.00</td>\n      <td>32891200.00</td>\n      <td>0</td>\n      <td>3324</td>\n      <td>3324</td>\n      <td>659.88</td>\n      <td>420.19</td>\n      <td>217042673.00</td>\n      <td>2275</td>\n      <td>200</td>\n      <td>1355</td>\n      <td>654</td>\n      <td>1030</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n    <tr>\n      <th>43973.0</th>\n      <td>172326.00</td>\n      <td>17232600.00</td>\n      <td>1</td>\n      <td>3324</td>\n      <td>3323</td>\n      <td>487.63</td>\n      <td>501.77</td>\n      <td>84030647.00</td>\n      <td>2021</td>\n      <td>254</td>\n      <td>1164</td>\n      <td>394</td>\n      <td>794</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n    <tr>\n      <th>44553.0</th>\n      <td>508260.00</td>\n      <td>50826000.00</td>\n      <td>0</td>\n      <td>3324</td>\n      <td>3324</td>\n      <td>617.58</td>\n      <td>428.77</td>\n      <td>313889063.00</td>\n      <td>2515</td>\n      <td>45</td>\n      <td>1493</td>\n      <td>592</td>\n      <td>1093</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n    <tr>\n      <th>44623.0</th>\n      <td>354677.00</td>\n      <td>35467700.00</td>\n      <td>0</td>\n      <td>3324</td>\n      <td>3324</td>\n      <td>451.24</td>\n      <td>473.36</td>\n      <td>160046103.00</td>\n      <td>2099</td>\n      <td>19</td>\n      <td>1248</td>\n      <td>376</td>\n      <td>960</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n    <tr>\n      <th>46055.0</th>\n      <td>32971.00</td>\n      <td>3297100.00</td>\n      <td>2</td>\n      <td>3324</td>\n      <td>3322</td>\n      <td>542.06</td>\n      <td>1061.32</td>\n      <td>17872287.00</td>\n      <td>977</td>\n      <td>115</td>\n      <td>148</td>\n      <td>95</td>\n      <td>2903</td>\n      <td>Prince_William_Sound</td>\n    </tr>\n  </tbody>\n</table>\n<p>430 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make watershed elev df\n",
    "wtd_df = pd.DataFrame()\n",
    "wtd_field_list = []\n",
    "for field in arcpy.ListFields(wtd_elev):\n",
    "    wtd_field_list.append(field.name)\n",
    "wtd_elev_arr = arcpy.da.TableToNumPyArray(wtd_elev,wtd_field_list)\n",
    "wtd_df = pd.DataFrame(wtd_elev_arr)\n",
    "wtd_df = wtd_df.drop([\"OBJECTID\",\"wtd_elev_ZONE_CODE\"],axis=1)\n",
    "wtd_df = wtd_df.set_index('cat_ID_txt')\n",
    "wtd_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "data": {
      "text/plain": "                     VALUE_0     VALUE_1                region  north_wtd\ncat_ID_txt                                                               \n75004200007057.0  5617525.00   850675.00            Cook_Inlet      13.15\n75004300006312.0 99366125.00 54940400.00            Cook_Inlet      35.60\n75004300001906.0 76968825.00 14901350.00            Cook_Inlet      16.22\n75004300000100.0 17976625.00 10984700.00            Cook_Inlet      37.93\n75004300004983.0 10688650.00  4572725.00            Cook_Inlet      29.96\n...                      ...         ...                   ...        ...\n43933.0          28684300.00  4206900.00  Prince_William_Sound      12.79\n43973.0          13954700.00  3277900.00  Prince_William_Sound      19.02\n44553.0          42757600.00  8068400.00  Prince_William_Sound      15.87\n44623.0          22243000.00 13224700.00  Prince_William_Sound      37.29\n46055.0           2785100.00   512000.00  Prince_William_Sound      15.53\n\n[430 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>VALUE_0</th>\n      <th>VALUE_1</th>\n      <th>region</th>\n      <th>north_wtd</th>\n    </tr>\n    <tr>\n      <th>cat_ID_txt</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>75004200007057.0</th>\n      <td>5617525.00</td>\n      <td>850675.00</td>\n      <td>Cook_Inlet</td>\n      <td>13.15</td>\n    </tr>\n    <tr>\n      <th>75004300006312.0</th>\n      <td>99366125.00</td>\n      <td>54940400.00</td>\n      <td>Cook_Inlet</td>\n      <td>35.60</td>\n    </tr>\n    <tr>\n      <th>75004300001906.0</th>\n      <td>76968825.00</td>\n      <td>14901350.00</td>\n      <td>Cook_Inlet</td>\n      <td>16.22</td>\n    </tr>\n    <tr>\n      <th>75004300000100.0</th>\n      <td>17976625.00</td>\n      <td>10984700.00</td>\n      <td>Cook_Inlet</td>\n      <td>37.93</td>\n    </tr>\n    <tr>\n      <th>75004300004983.0</th>\n      <td>10688650.00</td>\n      <td>4572725.00</td>\n      <td>Cook_Inlet</td>\n      <td>29.96</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43933.0</th>\n      <td>28684300.00</td>\n      <td>4206900.00</td>\n      <td>Prince_William_Sound</td>\n      <td>12.79</td>\n    </tr>\n    <tr>\n      <th>43973.0</th>\n      <td>13954700.00</td>\n      <td>3277900.00</td>\n      <td>Prince_William_Sound</td>\n      <td>19.02</td>\n    </tr>\n    <tr>\n      <th>44553.0</th>\n      <td>42757600.00</td>\n      <td>8068400.00</td>\n      <td>Prince_William_Sound</td>\n      <td>15.87</td>\n    </tr>\n    <tr>\n      <th>44623.0</th>\n      <td>22243000.00</td>\n      <td>13224700.00</td>\n      <td>Prince_William_Sound</td>\n      <td>37.29</td>\n    </tr>\n    <tr>\n      <th>46055.0</th>\n      <td>2785100.00</td>\n      <td>512000.00</td>\n      <td>Prince_William_Sound</td>\n      <td>15.53</td>\n    </tr>\n  </tbody>\n</table>\n<p>430 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make watershed north df\n",
    "wtd_n_df = pd.DataFrame()\n",
    "wtd_n_field_list = []\n",
    "for field in arcpy.ListFields(wtd_per_north):\n",
    "    wtd_n_field_list.append(field.name)\n",
    "wtd_n_arr = arcpy.da.TableToNumPyArray(wtd_per_north,wtd_n_field_list)\n",
    "wtd_n_df = pd.DataFrame(wtd_n_arr)\n",
    "wtd_n_df = wtd_n_df.drop(\"OBJECTID\",axis=1)\n",
    "wtd_n_df = wtd_n_df.set_index('cat_ID_txt')\n",
    "wtd_n_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "                  wtd_elev_COUNT  wtd_elev_AREA  wtd_elev_MIN  wtd_elev_MAX  \\\ncat_ID_txt                                                                    \n75004200007057.0       258728.00     6468200.00             0        144500   \n75000200010547.0      5613443.00   140336075.00         13141         45160   \n75000200005606.0       333424.00     8335600.00         14141         20215   \n75000200002554.0        94100.00     2352500.00         14175         17227   \n75000200017518.0      1790105.00    44752625.00         55716        197502   \n...                          ...            ...           ...           ...   \n75019800010313.0     22480838.00   562020950.00         72462        280991   \n75019800000406.0       294229.00     7355725.00         66017         72493   \n75003900039073.0       230415.00     5760375.00           489          9943   \n75003900033524.0      2162086.00    54052150.00          1613        146599   \n75003900027771.0        64405.00     1610125.00           560         10928   \n\n                  wtd_elev_RANGE  wtd_elev_MEAN  wtd_elev_STD  \\\ncat_ID_txt                                                      \n75004200007057.0          144500       43255.27      37427.70   \n75000200010547.0           32019       24260.98       6157.49   \n75000200005606.0            6074       16940.60       1153.71   \n75000200002554.0            3052       15846.43        575.76   \n75000200017518.0          141786      119840.65      26050.70   \n...                          ...            ...           ...   \n75019800010313.0          208529      122419.95      37416.27   \n75019800000406.0            6476       69062.47       1480.28   \n75003900039073.0            9454        3060.51       1557.69   \n75003900033524.0          144986       62382.77      31303.20   \n75003900027771.0           10368        4223.11       1479.12   \n\n                     wtd_elev_SUM  wtd_elev_VARIETY  wtd_elev_MAJORITY  ...  \\\ncat_ID_txt                                                              ...   \n75004200007057.0   11191350026.00             99715                500  ...   \n75000200010547.0  136187609252.00             31673              21432  ...   \n75000200005606.0    5648402724.00              5996              17421  ...   \n75000200002554.0    1491148775.00              2825              16230  ...   \n75000200017518.0  214527347400.00            122471             128903  ...   \n...                           ...               ...                ...  ...   \n75019800010313.0 2752102974453.00            193923              88700  ...   \n75019800000406.0   20320182865.00              6474              70062  ...   \n75003900039073.0     705188333.00              8339               2632  ...   \n75003900033524.0  134876923340.00            134789              13298  ...   \n75003900027771.0     271989608.00              7691               3060  ...   \n\n                  cat_elev_RANGE  cat_elev_MEAN  cat_elev_STD   cat_elev_SUM  \\\ncat_ID_txt                                                                     \n75004200007057.0           90800       34649.43      25122.14  1333483286.00   \n75000200010547.0             586       13395.05        125.80    35255769.00   \n75000200005606.0            2003       15215.23        522.56   435277309.00   \n75000200002554.0            2641       15593.10        521.04   980322504.00   \n75000200017518.0            8103       58948.07       2148.32   279531767.00   \n...                          ...            ...           ...            ...   \n75019800010313.0            1257       73133.74        268.65   864733310.00   \n75019800000406.0            6476       69062.47       1480.28 20320182865.00   \n75003900039073.0            1902        1140.87        479.45     1955444.00   \n75003900033524.0           11480        5407.86       3280.50    19273616.00   \n75003900027771.0            4806        3274.08       1101.73    26100941.00   \n\n                  cat_elev_VARIETY  cat_elev_MAJORITY  cat_elev_MINORITY  \\\ncat_ID_txt                                                                 \n75004200007057.0             27216                400                 36   \n75000200010547.0               510              13294              13141   \n75000200005606.0              1903              15864              14141   \n75000200002554.0              2566              15508              14178   \n75000200017518.0              3032              61427              55716   \n...                            ...                ...                ...   \n75019800010313.0              1165              73346              72462   \n75019800000406.0              6474              70062              66220   \n75003900039073.0               938                624                529   \n75003900033524.0              2805               2053               1613   \n75003900027771.0              3424               4316                560   \n\n                  cat_elev_MEDIAN  cat_elev_PCT90      region_y  \ncat_ID_txt                                                       \n75004200007057.0            33377           70627    Cook_Inlet  \n75000200010547.0            13388           13565    Cook_Inlet  \n75000200005606.0            15294           15853    Cook_Inlet  \n75000200002554.0            15626           16209    Cook_Inlet  \n75000200017518.0            58486           62625    Cook_Inlet  \n...                           ...             ...           ...  \n75019800010313.0            73171           73466  Copper_River  \n75019800000406.0            69057           71091  Copper_River  \n75003900039073.0             1092            1773  Copper_River  \n75003900033524.0             4049           10623  Copper_River  \n75003900027771.0             3413            4562  Copper_River  \n\n[269 rows x 28 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>wtd_elev_COUNT</th>\n      <th>wtd_elev_AREA</th>\n      <th>wtd_elev_MIN</th>\n      <th>wtd_elev_MAX</th>\n      <th>wtd_elev_RANGE</th>\n      <th>wtd_elev_MEAN</th>\n      <th>wtd_elev_STD</th>\n      <th>wtd_elev_SUM</th>\n      <th>wtd_elev_VARIETY</th>\n      <th>wtd_elev_MAJORITY</th>\n      <th>...</th>\n      <th>cat_elev_RANGE</th>\n      <th>cat_elev_MEAN</th>\n      <th>cat_elev_STD</th>\n      <th>cat_elev_SUM</th>\n      <th>cat_elev_VARIETY</th>\n      <th>cat_elev_MAJORITY</th>\n      <th>cat_elev_MINORITY</th>\n      <th>cat_elev_MEDIAN</th>\n      <th>cat_elev_PCT90</th>\n      <th>region_y</th>\n    </tr>\n    <tr>\n      <th>cat_ID_txt</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>75004200007057.0</th>\n      <td>258728.00</td>\n      <td>6468200.00</td>\n      <td>0</td>\n      <td>144500</td>\n      <td>144500</td>\n      <td>43255.27</td>\n      <td>37427.70</td>\n      <td>11191350026.00</td>\n      <td>99715</td>\n      <td>500</td>\n      <td>...</td>\n      <td>90800</td>\n      <td>34649.43</td>\n      <td>25122.14</td>\n      <td>1333483286.00</td>\n      <td>27216</td>\n      <td>400</td>\n      <td>36</td>\n      <td>33377</td>\n      <td>70627</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>75000200010547.0</th>\n      <td>5613443.00</td>\n      <td>140336075.00</td>\n      <td>13141</td>\n      <td>45160</td>\n      <td>32019</td>\n      <td>24260.98</td>\n      <td>6157.49</td>\n      <td>136187609252.00</td>\n      <td>31673</td>\n      <td>21432</td>\n      <td>...</td>\n      <td>586</td>\n      <td>13395.05</td>\n      <td>125.80</td>\n      <td>35255769.00</td>\n      <td>510</td>\n      <td>13294</td>\n      <td>13141</td>\n      <td>13388</td>\n      <td>13565</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>75000200005606.0</th>\n      <td>333424.00</td>\n      <td>8335600.00</td>\n      <td>14141</td>\n      <td>20215</td>\n      <td>6074</td>\n      <td>16940.60</td>\n      <td>1153.71</td>\n      <td>5648402724.00</td>\n      <td>5996</td>\n      <td>17421</td>\n      <td>...</td>\n      <td>2003</td>\n      <td>15215.23</td>\n      <td>522.56</td>\n      <td>435277309.00</td>\n      <td>1903</td>\n      <td>15864</td>\n      <td>14141</td>\n      <td>15294</td>\n      <td>15853</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>75000200002554.0</th>\n      <td>94100.00</td>\n      <td>2352500.00</td>\n      <td>14175</td>\n      <td>17227</td>\n      <td>3052</td>\n      <td>15846.43</td>\n      <td>575.76</td>\n      <td>1491148775.00</td>\n      <td>2825</td>\n      <td>16230</td>\n      <td>...</td>\n      <td>2641</td>\n      <td>15593.10</td>\n      <td>521.04</td>\n      <td>980322504.00</td>\n      <td>2566</td>\n      <td>15508</td>\n      <td>14178</td>\n      <td>15626</td>\n      <td>16209</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>75000200017518.0</th>\n      <td>1790105.00</td>\n      <td>44752625.00</td>\n      <td>55716</td>\n      <td>197502</td>\n      <td>141786</td>\n      <td>119840.65</td>\n      <td>26050.70</td>\n      <td>214527347400.00</td>\n      <td>122471</td>\n      <td>128903</td>\n      <td>...</td>\n      <td>8103</td>\n      <td>58948.07</td>\n      <td>2148.32</td>\n      <td>279531767.00</td>\n      <td>3032</td>\n      <td>61427</td>\n      <td>55716</td>\n      <td>58486</td>\n      <td>62625</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>75019800010313.0</th>\n      <td>22480838.00</td>\n      <td>562020950.00</td>\n      <td>72462</td>\n      <td>280991</td>\n      <td>208529</td>\n      <td>122419.95</td>\n      <td>37416.27</td>\n      <td>2752102974453.00</td>\n      <td>193923</td>\n      <td>88700</td>\n      <td>...</td>\n      <td>1257</td>\n      <td>73133.74</td>\n      <td>268.65</td>\n      <td>864733310.00</td>\n      <td>1165</td>\n      <td>73346</td>\n      <td>72462</td>\n      <td>73171</td>\n      <td>73466</td>\n      <td>Copper_River</td>\n    </tr>\n    <tr>\n      <th>75019800000406.0</th>\n      <td>294229.00</td>\n      <td>7355725.00</td>\n      <td>66017</td>\n      <td>72493</td>\n      <td>6476</td>\n      <td>69062.47</td>\n      <td>1480.28</td>\n      <td>20320182865.00</td>\n      <td>6474</td>\n      <td>70062</td>\n      <td>...</td>\n      <td>6476</td>\n      <td>69062.47</td>\n      <td>1480.28</td>\n      <td>20320182865.00</td>\n      <td>6474</td>\n      <td>70062</td>\n      <td>66220</td>\n      <td>69057</td>\n      <td>71091</td>\n      <td>Copper_River</td>\n    </tr>\n    <tr>\n      <th>75003900039073.0</th>\n      <td>230415.00</td>\n      <td>5760375.00</td>\n      <td>489</td>\n      <td>9943</td>\n      <td>9454</td>\n      <td>3060.51</td>\n      <td>1557.69</td>\n      <td>705188333.00</td>\n      <td>8339</td>\n      <td>2632</td>\n      <td>...</td>\n      <td>1902</td>\n      <td>1140.87</td>\n      <td>479.45</td>\n      <td>1955444.00</td>\n      <td>938</td>\n      <td>624</td>\n      <td>529</td>\n      <td>1092</td>\n      <td>1773</td>\n      <td>Copper_River</td>\n    </tr>\n    <tr>\n      <th>75003900033524.0</th>\n      <td>2162086.00</td>\n      <td>54052150.00</td>\n      <td>1613</td>\n      <td>146599</td>\n      <td>144986</td>\n      <td>62382.77</td>\n      <td>31303.20</td>\n      <td>134876923340.00</td>\n      <td>134789</td>\n      <td>13298</td>\n      <td>...</td>\n      <td>11480</td>\n      <td>5407.86</td>\n      <td>3280.50</td>\n      <td>19273616.00</td>\n      <td>2805</td>\n      <td>2053</td>\n      <td>1613</td>\n      <td>4049</td>\n      <td>10623</td>\n      <td>Copper_River</td>\n    </tr>\n    <tr>\n      <th>75003900027771.0</th>\n      <td>64405.00</td>\n      <td>1610125.00</td>\n      <td>560</td>\n      <td>10928</td>\n      <td>10368</td>\n      <td>4223.11</td>\n      <td>1479.12</td>\n      <td>271989608.00</td>\n      <td>7691</td>\n      <td>3060</td>\n      <td>...</td>\n      <td>4806</td>\n      <td>3274.08</td>\n      <td>1101.73</td>\n      <td>26100941.00</td>\n      <td>3424</td>\n      <td>4316</td>\n      <td>560</td>\n      <td>3413</td>\n      <td>4562</td>\n      <td>Copper_River</td>\n    </tr>\n  </tbody>\n</table>\n<p>269 rows × 28 columns</p>\n</div>"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmet_merge_df = pd.merge(wtd_df,cat_df,on='cat_ID_txt', how='outer')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "dfs = [wtd_df,cat_df]\n",
    "df_final = reduce(lambda left,right: pd.merge(left,right,on='cat_ID_txt'), dfs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "data": {
      "text/plain": "                  wtd_elev_COUNT  wtd_elev_AREA  wtd_elev_MIN  wtd_elev_MAX  \\\ncat_ID_txt                                                                    \n75004200007057.0       258728.00     6468200.00             0        144500   \n75004300006312.0      6172261.00   154306525.00          5900         56900   \n75004300001906.0      3674807.00    91870175.00           300         77174   \n75004300000100.0      1158453.00    28961325.00          3305         41700   \n75004300004983.0       610455.00    15261375.00          2100        147384   \n...                          ...            ...           ...           ...   \n75003900023674.0       155526.00     3888150.00          1357         67537   \n75003900062264.0       886085.00    22152125.00          2182         54687   \n75003900055316.0       293348.00     7333700.00          2943         57672   \n75003900039073.0       230415.00     5760375.00           489          9943   \n75003900027771.0        64405.00     1610125.00           560         10928   \n\n                  wtd_elev_RANGE  wtd_elev_MEAN  wtd_elev_STD    wtd_elev_SUM  \\\ncat_ID_txt                                                                      \n75004200007057.0          144500       43255.27      37427.70  11191350026.00   \n75004300006312.0           51000       25127.05      11779.40 155090722985.00   \n75004300001906.0           76874       40142.44      11984.06 147515731019.00   \n75004300000100.0           38395       15654.17       8590.35  18134625884.00   \n75004300004983.0          145284       67339.95      33460.53  41108006739.00   \n...                          ...            ...           ...             ...   \n75003900023674.0           66180       16985.47      16387.75   2641682563.00   \n75003900062264.0           52505       15531.18      13899.79  13761946382.00   \n75003900055316.0           54729       21011.88      14481.52   6163794155.00   \n75003900039073.0            9454        3060.51       1557.69    705188333.00   \n75003900027771.0           10368        4223.11       1479.12    271989608.00   \n\n                  wtd_elev_VARIETY  wtd_elev_MAJORITY  ...  cat_elev_RANGE  \\\ncat_ID_txt                                             ...                   \n75004200007057.0             99715                500  ...           90800   \n75004300006312.0             50691              12600  ...            3900   \n75004300001906.0             75573              37700  ...           14321   \n75004300000100.0             36389               9100  ...            4495   \n75004300004983.0            126942              33600  ...           45843   \n...                            ...                ...  ...             ...   \n75003900023674.0             43720               4726  ...             165   \n75003900062264.0             51028               3513  ...            1180   \n75003900055316.0             51198               3082  ...            3971   \n75003900039073.0              8339               2632  ...            1902   \n75003900027771.0              7691               3060  ...            4806   \n\n                  cat_elev_MEAN  cat_elev_STD  cat_elev_SUM  cat_elev_VARIETY  \\\ncat_ID_txt                                                                      \n75004200007057.0       34649.43      25122.14 1333483286.00             27216   \n75004300006312.0        7654.30        935.80  440704003.00              3605   \n75004300001906.0        2818.64       2135.86   34164787.00              4573   \n75004300000100.0        5889.18        819.43  463731919.00              3963   \n75004300004983.0       26556.24      10043.37 3015646404.00             35402   \n...                         ...           ...           ...               ...   \n75003900023674.0        1585.92         40.31     269606.00               105   \n75003900062264.0        3139.22        110.48   21054744.00               614   \n75003900055316.0        3256.86        626.21   30822898.00              1344   \n75003900039073.0        1140.87        479.45    1955444.00               938   \n75003900027771.0        3274.08       1101.73   26100941.00              3424   \n\n                  cat_elev_MAJORITY  cat_elev_MINORITY  cat_elev_MEDIAN  \\\ncat_ID_txt                                                                \n75004200007057.0                400                 36            33377   \n75004300006312.0               6900               5909             7400   \n75004300001906.0               1000                301             2126   \n75004300000100.0               6500               3305             5933   \n75004300004983.0              33600               2103            28233   \n...                             ...                ...              ...   \n75003900023674.0               1583               1508             1583   \n75003900062264.0               3175               2182             3161   \n75003900055316.0               3069               2943             3062   \n75003900039073.0                624                529             1092   \n75003900027771.0               4316                560             3413   \n\n                  cat_elev_PCT90      region_y  \ncat_ID_txt                                      \n75004200007057.0           70627    Cook_Inlet  \n75004300006312.0            9002    Cook_Inlet  \n75004300001906.0            5218    Cook_Inlet  \n75004300000100.0            6800    Cook_Inlet  \n75004300004983.0           38776    Cook_Inlet  \n...                          ...           ...  \n75003900023674.0            1642  Copper_River  \n75003900062264.0            3244  Copper_River  \n75003900055316.0            3621  Copper_River  \n75003900039073.0            1773  Copper_River  \n75003900027771.0            4562  Copper_River  \n\n[269 rows x 28 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>wtd_elev_COUNT</th>\n      <th>wtd_elev_AREA</th>\n      <th>wtd_elev_MIN</th>\n      <th>wtd_elev_MAX</th>\n      <th>wtd_elev_RANGE</th>\n      <th>wtd_elev_MEAN</th>\n      <th>wtd_elev_STD</th>\n      <th>wtd_elev_SUM</th>\n      <th>wtd_elev_VARIETY</th>\n      <th>wtd_elev_MAJORITY</th>\n      <th>...</th>\n      <th>cat_elev_RANGE</th>\n      <th>cat_elev_MEAN</th>\n      <th>cat_elev_STD</th>\n      <th>cat_elev_SUM</th>\n      <th>cat_elev_VARIETY</th>\n      <th>cat_elev_MAJORITY</th>\n      <th>cat_elev_MINORITY</th>\n      <th>cat_elev_MEDIAN</th>\n      <th>cat_elev_PCT90</th>\n      <th>region_y</th>\n    </tr>\n    <tr>\n      <th>cat_ID_txt</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>75004200007057.0</th>\n      <td>258728.00</td>\n      <td>6468200.00</td>\n      <td>0</td>\n      <td>144500</td>\n      <td>144500</td>\n      <td>43255.27</td>\n      <td>37427.70</td>\n      <td>11191350026.00</td>\n      <td>99715</td>\n      <td>500</td>\n      <td>...</td>\n      <td>90800</td>\n      <td>34649.43</td>\n      <td>25122.14</td>\n      <td>1333483286.00</td>\n      <td>27216</td>\n      <td>400</td>\n      <td>36</td>\n      <td>33377</td>\n      <td>70627</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>75004300006312.0</th>\n      <td>6172261.00</td>\n      <td>154306525.00</td>\n      <td>5900</td>\n      <td>56900</td>\n      <td>51000</td>\n      <td>25127.05</td>\n      <td>11779.40</td>\n      <td>155090722985.00</td>\n      <td>50691</td>\n      <td>12600</td>\n      <td>...</td>\n      <td>3900</td>\n      <td>7654.30</td>\n      <td>935.80</td>\n      <td>440704003.00</td>\n      <td>3605</td>\n      <td>6900</td>\n      <td>5909</td>\n      <td>7400</td>\n      <td>9002</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>75004300001906.0</th>\n      <td>3674807.00</td>\n      <td>91870175.00</td>\n      <td>300</td>\n      <td>77174</td>\n      <td>76874</td>\n      <td>40142.44</td>\n      <td>11984.06</td>\n      <td>147515731019.00</td>\n      <td>75573</td>\n      <td>37700</td>\n      <td>...</td>\n      <td>14321</td>\n      <td>2818.64</td>\n      <td>2135.86</td>\n      <td>34164787.00</td>\n      <td>4573</td>\n      <td>1000</td>\n      <td>301</td>\n      <td>2126</td>\n      <td>5218</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>75004300000100.0</th>\n      <td>1158453.00</td>\n      <td>28961325.00</td>\n      <td>3305</td>\n      <td>41700</td>\n      <td>38395</td>\n      <td>15654.17</td>\n      <td>8590.35</td>\n      <td>18134625884.00</td>\n      <td>36389</td>\n      <td>9100</td>\n      <td>...</td>\n      <td>4495</td>\n      <td>5889.18</td>\n      <td>819.43</td>\n      <td>463731919.00</td>\n      <td>3963</td>\n      <td>6500</td>\n      <td>3305</td>\n      <td>5933</td>\n      <td>6800</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>75004300004983.0</th>\n      <td>610455.00</td>\n      <td>15261375.00</td>\n      <td>2100</td>\n      <td>147384</td>\n      <td>145284</td>\n      <td>67339.95</td>\n      <td>33460.53</td>\n      <td>41108006739.00</td>\n      <td>126942</td>\n      <td>33600</td>\n      <td>...</td>\n      <td>45843</td>\n      <td>26556.24</td>\n      <td>10043.37</td>\n      <td>3015646404.00</td>\n      <td>35402</td>\n      <td>33600</td>\n      <td>2103</td>\n      <td>28233</td>\n      <td>38776</td>\n      <td>Cook_Inlet</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>75003900023674.0</th>\n      <td>155526.00</td>\n      <td>3888150.00</td>\n      <td>1357</td>\n      <td>67537</td>\n      <td>66180</td>\n      <td>16985.47</td>\n      <td>16387.75</td>\n      <td>2641682563.00</td>\n      <td>43720</td>\n      <td>4726</td>\n      <td>...</td>\n      <td>165</td>\n      <td>1585.92</td>\n      <td>40.31</td>\n      <td>269606.00</td>\n      <td>105</td>\n      <td>1583</td>\n      <td>1508</td>\n      <td>1583</td>\n      <td>1642</td>\n      <td>Copper_River</td>\n    </tr>\n    <tr>\n      <th>75003900062264.0</th>\n      <td>886085.00</td>\n      <td>22152125.00</td>\n      <td>2182</td>\n      <td>54687</td>\n      <td>52505</td>\n      <td>15531.18</td>\n      <td>13899.79</td>\n      <td>13761946382.00</td>\n      <td>51028</td>\n      <td>3513</td>\n      <td>...</td>\n      <td>1180</td>\n      <td>3139.22</td>\n      <td>110.48</td>\n      <td>21054744.00</td>\n      <td>614</td>\n      <td>3175</td>\n      <td>2182</td>\n      <td>3161</td>\n      <td>3244</td>\n      <td>Copper_River</td>\n    </tr>\n    <tr>\n      <th>75003900055316.0</th>\n      <td>293348.00</td>\n      <td>7333700.00</td>\n      <td>2943</td>\n      <td>57672</td>\n      <td>54729</td>\n      <td>21011.88</td>\n      <td>14481.52</td>\n      <td>6163794155.00</td>\n      <td>51198</td>\n      <td>3082</td>\n      <td>...</td>\n      <td>3971</td>\n      <td>3256.86</td>\n      <td>626.21</td>\n      <td>30822898.00</td>\n      <td>1344</td>\n      <td>3069</td>\n      <td>2943</td>\n      <td>3062</td>\n      <td>3621</td>\n      <td>Copper_River</td>\n    </tr>\n    <tr>\n      <th>75003900039073.0</th>\n      <td>230415.00</td>\n      <td>5760375.00</td>\n      <td>489</td>\n      <td>9943</td>\n      <td>9454</td>\n      <td>3060.51</td>\n      <td>1557.69</td>\n      <td>705188333.00</td>\n      <td>8339</td>\n      <td>2632</td>\n      <td>...</td>\n      <td>1902</td>\n      <td>1140.87</td>\n      <td>479.45</td>\n      <td>1955444.00</td>\n      <td>938</td>\n      <td>624</td>\n      <td>529</td>\n      <td>1092</td>\n      <td>1773</td>\n      <td>Copper_River</td>\n    </tr>\n    <tr>\n      <th>75003900027771.0</th>\n      <td>64405.00</td>\n      <td>1610125.00</td>\n      <td>560</td>\n      <td>10928</td>\n      <td>10368</td>\n      <td>4223.11</td>\n      <td>1479.12</td>\n      <td>271989608.00</td>\n      <td>7691</td>\n      <td>3060</td>\n      <td>...</td>\n      <td>4806</td>\n      <td>3274.08</td>\n      <td>1101.73</td>\n      <td>26100941.00</td>\n      <td>3424</td>\n      <td>4316</td>\n      <td>560</td>\n      <td>3413</td>\n      <td>4562</td>\n      <td>Copper_River</td>\n    </tr>\n  </tbody>\n</table>\n<p>269 rows × 28 columns</p>\n</div>"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8caab41e",
   "language": "python",
   "display_name": "PyCharm (AKSSF)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}